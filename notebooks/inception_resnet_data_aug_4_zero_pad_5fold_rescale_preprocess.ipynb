{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.0005\n",
    "    elif epoch < 30:\n",
    "        return 0.0001\n",
    "    elif epoch < 45:\n",
    "        return 0.00005\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 3\n",
    "    \n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def create_incept_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    \n",
    "    # bn\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = conv2d_bn(x, 64, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "     # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    \n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    x = Conv2D(96, 3, strides=2, padding='same',activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69615, saving model to best_m.h5\n",
      " - 12s - loss: 0.6647 - acc: 0.6718 - val_loss: 0.6961 - val_acc: 0.5389\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5169 - acc: 0.7476 - val_loss: 0.8253 - val_acc: 0.5389\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4728 - acc: 0.7841 - val_loss: 0.7864 - val_acc: 0.5389\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4538 - acc: 0.7929 - val_loss: 0.9291 - val_acc: 0.5389\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.3715 - acc: 0.8334 - val_loss: 0.9528 - val_acc: 0.5452\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.69615 to 0.64626, saving model to best_m.h5\n",
      " - 6s - loss: 0.3742 - acc: 0.8052 - val_loss: 0.6463 - val_acc: 0.7352\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.64626 to 0.50936, saving model to best_m.h5\n",
      " - 6s - loss: 0.3565 - acc: 0.8427 - val_loss: 0.5094 - val_acc: 0.7695\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.50936 to 0.32322, saving model to best_m.h5\n",
      " - 6s - loss: 0.3608 - acc: 0.8172 - val_loss: 0.3232 - val_acc: 0.8660\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.3345 - acc: 0.8523 - val_loss: 0.3817 - val_acc: 0.8536\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3685 - acc: 0.8380 - val_loss: 0.3405 - val_acc: 0.8037\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 8s - loss: 0.3353 - acc: 0.8248 - val_loss: 1.1660 - val_acc: 0.6916\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 8s - loss: 0.3611 - acc: 0.8265 - val_loss: 0.5313 - val_acc: 0.8069\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.3488 - acc: 0.8324 - val_loss: 0.5886 - val_acc: 0.7726\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3516 - acc: 0.8539 - val_loss: 0.4536 - val_acc: 0.7477\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3294 - acc: 0.8591 - val_loss: 0.3438 - val_acc: 0.8224\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.32322 to 0.29007, saving model to best_m.h5\n",
      " - 6s - loss: 0.3010 - acc: 0.8586 - val_loss: 0.2901 - val_acc: 0.8598\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.29007 to 0.27706, saving model to best_m.h5\n",
      " - 6s - loss: 0.2694 - acc: 0.8828 - val_loss: 0.2771 - val_acc: 0.8629\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3011 - acc: 0.8708 - val_loss: 0.2833 - val_acc: 0.8598\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.27706 to 0.27106, saving model to best_m.h5\n",
      " - 9s - loss: 0.2775 - acc: 0.8719 - val_loss: 0.2711 - val_acc: 0.8567\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2794 - acc: 0.8750 - val_loss: 0.2996 - val_acc: 0.8474\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2785 - acc: 0.8745 - val_loss: 0.2748 - val_acc: 0.8754\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2701 - acc: 0.8841 - val_loss: 0.2846 - val_acc: 0.8660\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2893 - acc: 0.8677 - val_loss: 0.3032 - val_acc: 0.8598\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.27106 to 0.26882, saving model to best_m.h5\n",
      " - 6s - loss: 0.2437 - acc: 0.8914 - val_loss: 0.2688 - val_acc: 0.8723\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2518 - acc: 0.8875 - val_loss: 0.2797 - val_acc: 0.8660\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 9s - loss: 0.2900 - acc: 0.8696 - val_loss: 0.2923 - val_acc: 0.8411\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 8s - loss: 0.2497 - acc: 0.8867 - val_loss: 0.2814 - val_acc: 0.8660\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.26882 to 0.26406, saving model to best_m.h5\n",
      " - 6s - loss: 0.2850 - acc: 0.8841 - val_loss: 0.2641 - val_acc: 0.8660\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2500 - acc: 0.8875 - val_loss: 0.2717 - val_acc: 0.8536\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.2841 - acc: 0.8761 - val_loss: 0.3134 - val_acc: 0.8536\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 9s - loss: 0.2266 - acc: 0.8961 - val_loss: 0.2661 - val_acc: 0.8629\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.26406 to 0.25299, saving model to best_m.h5\n",
      " - 6s - loss: 0.2650 - acc: 0.8896 - val_loss: 0.2530 - val_acc: 0.8692\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 9s - loss: 0.2363 - acc: 0.8953 - val_loss: 0.2560 - val_acc: 0.8629\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 8s - loss: 0.2311 - acc: 0.9011 - val_loss: 0.2629 - val_acc: 0.8660\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.25299 to 0.25067, saving model to best_m.h5\n",
      " - 7s - loss: 0.2626 - acc: 0.8875 - val_loss: 0.2507 - val_acc: 0.8723\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 8s - loss: 0.2312 - acc: 0.9044 - val_loss: 0.2538 - val_acc: 0.8567\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 8s - loss: 0.2416 - acc: 0.9016 - val_loss: 0.2662 - val_acc: 0.8660\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.25067 to 0.25056, saving model to best_m.h5\n",
      " - 6s - loss: 0.2290 - acc: 0.9102 - val_loss: 0.2506 - val_acc: 0.8629\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2659 - acc: 0.8878 - val_loss: 0.2727 - val_acc: 0.8723\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 10s - loss: 0.2420 - acc: 0.8941 - val_loss: 0.2933 - val_acc: 0.8692\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2105 - acc: 0.9125 - val_loss: 0.2572 - val_acc: 0.8692\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.25056 to 0.24521, saving model to best_m.h5\n",
      " - 6s - loss: 0.2171 - acc: 0.9086 - val_loss: 0.2452 - val_acc: 0.8816\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2316 - acc: 0.9000 - val_loss: 0.2528 - val_acc: 0.8816\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2100 - acc: 0.9078 - val_loss: 0.2582 - val_acc: 0.8879\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 8s - loss: 0.2358 - acc: 0.8964 - val_loss: 0.2467 - val_acc: 0.8754\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 8s - loss: 0.2248 - acc: 0.9070 - val_loss: 0.2503 - val_acc: 0.8754\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2081 - acc: 0.9070 - val_loss: 0.2494 - val_acc: 0.8723\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.24521 to 0.24213, saving model to best_m.h5\n",
      " - 9s - loss: 0.2302 - acc: 0.9042 - val_loss: 0.2421 - val_acc: 0.8754\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2096 - acc: 0.9109 - val_loss: 0.2453 - val_acc: 0.8723\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2141 - acc: 0.9078 - val_loss: 0.2449 - val_acc: 0.8754\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.1996 - acc: 0.9226 - val_loss: 0.2430 - val_acc: 0.8692\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2364 - acc: 0.9084 - val_loss: 0.2473 - val_acc: 0.8785\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2003 - acc: 0.9287 - val_loss: 0.2460 - val_acc: 0.8816\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.2194 - acc: 0.9156 - val_loss: 0.2526 - val_acc: 0.8847\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 8s - loss: 0.2208 - acc: 0.9070 - val_loss: 0.2424 - val_acc: 0.8785\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.24213 to 0.23986, saving model to best_m.h5\n",
      " - 9s - loss: 0.2339 - acc: 0.9034 - val_loss: 0.2399 - val_acc: 0.8847\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.1855 - acc: 0.9234 - val_loss: 0.2429 - val_acc: 0.8785\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 8s - loss: 0.2092 - acc: 0.9117 - val_loss: 0.2448 - val_acc: 0.8785\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2293 - acc: 0.9164 - val_loss: 0.2458 - val_acc: 0.8785\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2000 - acc: 0.9159 - val_loss: 0.2520 - val_acc: 0.8785\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2075 - acc: 0.9060 - val_loss: 0.2461 - val_acc: 0.8847\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2026 - acc: 0.9211 - val_loss: 0.2451 - val_acc: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2035 - acc: 0.9162 - val_loss: 0.2495 - val_acc: 0.8754\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2087 - acc: 0.9062 - val_loss: 0.2436 - val_acc: 0.8816\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2056 - acc: 0.9234 - val_loss: 0.2457 - val_acc: 0.8847\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2223 - acc: 0.9035 - val_loss: 0.2427 - val_acc: 0.8847\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.1973 - acc: 0.9162 - val_loss: 0.2440 - val_acc: 0.8879\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2020 - acc: 0.9201 - val_loss: 0.2404 - val_acc: 0.8785\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2148 - acc: 0.9058 - val_loss: 0.2465 - val_acc: 0.8847\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.23986 to 0.23941, saving model to best_m.h5\n",
      " - 6s - loss: 0.2205 - acc: 0.9125 - val_loss: 0.2394 - val_acc: 0.8816\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.2143 - acc: 0.9115 - val_loss: 0.2415 - val_acc: 0.8941\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2187 - acc: 0.9066 - val_loss: 0.2436 - val_acc: 0.8847\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.1984 - acc: 0.9180 - val_loss: 0.2424 - val_acc: 0.8785\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.1945 - acc: 0.9156 - val_loss: 0.2427 - val_acc: 0.8847\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2015 - acc: 0.9099 - val_loss: 0.2456 - val_acc: 0.8816\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2248 - acc: 0.9201 - val_loss: 0.2414 - val_acc: 0.8816\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.2206 - acc: 0.9094 - val_loss: 0.2421 - val_acc: 0.8847\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2005 - acc: 0.9164 - val_loss: 0.2404 - val_acc: 0.8847\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.1990 - acc: 0.9195 - val_loss: 0.2396 - val_acc: 0.8941\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss improved from 0.23941 to 0.23772, saving model to best_m.h5\n",
      " - 6s - loss: 0.1979 - acc: 0.9172 - val_loss: 0.2377 - val_acc: 0.8847\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.1910 - acc: 0.9203 - val_loss: 0.2405 - val_acc: 0.8847\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.1953 - acc: 0.9209 - val_loss: 0.2437 - val_acc: 0.8847\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2188 - acc: 0.9107 - val_loss: 0.2405 - val_acc: 0.8847\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.1912 - acc: 0.9273 - val_loss: 0.2405 - val_acc: 0.8847\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.1927 - acc: 0.9219 - val_loss: 0.2386 - val_acc: 0.8910\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.23772 to 0.23645, saving model to best_m.h5\n",
      " - 7s - loss: 0.2113 - acc: 0.9089 - val_loss: 0.2364 - val_acc: 0.8816\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss improved from 0.23645 to 0.23598, saving model to best_m.h5\n",
      " - 6s - loss: 0.2152 - acc: 0.9117 - val_loss: 0.2360 - val_acc: 0.8879\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss improved from 0.23598 to 0.23596, saving model to best_m.h5\n",
      " - 6s - loss: 0.1862 - acc: 0.9287 - val_loss: 0.2360 - val_acc: 0.8910\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.23596 to 0.23351, saving model to best_m.h5\n",
      " - 6s - loss: 0.2291 - acc: 0.9123 - val_loss: 0.2335 - val_acc: 0.8910\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.2041 - acc: 0.9136 - val_loss: 0.2341 - val_acc: 0.8879\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.1841 - acc: 0.9234 - val_loss: 0.2392 - val_acc: 0.8910\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.2041 - acc: 0.9094 - val_loss: 0.2378 - val_acc: 0.8879\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.2026 - acc: 0.9164 - val_loss: 0.2383 - val_acc: 0.8785\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss improved from 0.23351 to 0.23343, saving model to best_m.h5\n",
      " - 6s - loss: 0.1867 - acc: 0.9240 - val_loss: 0.2334 - val_acc: 0.8910\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 0.2118 - acc: 0.9131 - val_loss: 0.2353 - val_acc: 0.8847\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss improved from 0.23343 to 0.23026, saving model to best_m.h5\n",
      " - 6s - loss: 0.1945 - acc: 0.9201 - val_loss: 0.2303 - val_acc: 0.8847\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 6s - loss: 0.1823 - acc: 0.9250 - val_loss: 0.2371 - val_acc: 0.8879\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 6s - loss: 0.2018 - acc: 0.9226 - val_loss: 0.2339 - val_acc: 0.8879\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 6s - loss: 0.2019 - acc: 0.9185 - val_loss: 0.2346 - val_acc: 0.8910\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 6s - loss: 0.1907 - acc: 0.9219 - val_loss: 0.2336 - val_acc: 0.8847\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 6s - loss: 0.1854 - acc: 0.9273 - val_loss: 0.2334 - val_acc: 0.8847\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 6s - loss: 0.1953 - acc: 0.9180 - val_loss: 0.2316 - val_acc: 0.8879\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 6s - loss: 0.1821 - acc: 0.9141 - val_loss: 0.2393 - val_acc: 0.8816\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 6s - loss: 0.1738 - acc: 0.9226 - val_loss: 0.2407 - val_acc: 0.8879\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 6s - loss: 0.1873 - acc: 0.9195 - val_loss: 0.2427 - val_acc: 0.8972\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 6s - loss: 0.1978 - acc: 0.9076 - val_loss: 0.2361 - val_acc: 0.8910\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 6s - loss: 0.1870 - acc: 0.9148 - val_loss: 0.2321 - val_acc: 0.8972\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 6s - loss: 0.1934 - acc: 0.9242 - val_loss: 0.2357 - val_acc: 0.8847\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss improved from 0.23026 to 0.23006, saving model to best_m.h5\n",
      " - 6s - loss: 0.1931 - acc: 0.9250 - val_loss: 0.2301 - val_acc: 0.8879\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 6s - loss: 0.1950 - acc: 0.9187 - val_loss: 0.2351 - val_acc: 0.8941\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 7s - loss: 0.1769 - acc: 0.9177 - val_loss: 0.2317 - val_acc: 0.8879\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 6s - loss: 0.1874 - acc: 0.9211 - val_loss: 0.2350 - val_acc: 0.8910\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss improved from 0.23006 to 0.22756, saving model to best_m.h5\n",
      " - 6s - loss: 0.1992 - acc: 0.9074 - val_loss: 0.2276 - val_acc: 0.8910\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 7s - loss: 0.1852 - acc: 0.9289 - val_loss: 0.2297 - val_acc: 0.8910\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 6s - loss: 0.1951 - acc: 0.9148 - val_loss: 0.2317 - val_acc: 0.8910\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss improved from 0.22756 to 0.22672, saving model to best_m.h5\n",
      " - 6s - loss: 0.1852 - acc: 0.9169 - val_loss: 0.2267 - val_acc: 0.9003\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 6s - loss: 0.1663 - acc: 0.9328 - val_loss: 0.2321 - val_acc: 0.8972\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 6s - loss: 0.1982 - acc: 0.9146 - val_loss: 0.2287 - val_acc: 0.8879\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 6s - loss: 0.1970 - acc: 0.9125 - val_loss: 0.2289 - val_acc: 0.8941\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss improved from 0.22672 to 0.22319, saving model to best_m.h5\n",
      " - 6s - loss: 0.1829 - acc: 0.9289 - val_loss: 0.2232 - val_acc: 0.8910\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69257, saving model to best_m.h5\n",
      " - 14s - loss: 0.7491 - acc: 0.6302 - val_loss: 0.6926 - val_acc: 0.5639\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69257 to 0.68655, saving model to best_m.h5\n",
      " - 6s - loss: 0.5025 - acc: 0.7435 - val_loss: 0.6866 - val_acc: 0.5639\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4071 - acc: 0.8047 - val_loss: 1.2179 - val_acc: 0.5639\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4396 - acc: 0.7890 - val_loss: 0.6910 - val_acc: 0.4829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68655 to 0.67931, saving model to best_m.h5\n",
      " - 6s - loss: 0.3866 - acc: 0.8234 - val_loss: 0.6793 - val_acc: 0.5639\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.3735 - acc: 0.8259 - val_loss: 0.9769 - val_acc: 0.6511\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.67931 to 0.43408, saving model to best_m.h5\n",
      " - 6s - loss: 0.3747 - acc: 0.8183 - val_loss: 0.4341 - val_acc: 0.7788\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4055 - acc: 0.8201 - val_loss: 0.4649 - val_acc: 0.7165\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.43408 to 0.36334, saving model to best_m.h5\n",
      " - 6s - loss: 0.3640 - acc: 0.8390 - val_loss: 0.3633 - val_acc: 0.7944\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.3650 - acc: 0.8175 - val_loss: 1.1376 - val_acc: 0.7072\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3531 - acc: 0.8422 - val_loss: 0.7281 - val_acc: 0.7227\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.36334 to 0.34716, saving model to best_m.h5\n",
      " - 7s - loss: 0.3934 - acc: 0.8255 - val_loss: 0.3472 - val_acc: 0.8224\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.3343 - acc: 0.8500 - val_loss: 0.3908 - val_acc: 0.8474\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 8s - loss: 0.3425 - acc: 0.8555 - val_loss: 0.4481 - val_acc: 0.7695\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.34716 to 0.30684, saving model to best_m.h5\n",
      " - 7s - loss: 0.3617 - acc: 0.8433 - val_loss: 0.3068 - val_acc: 0.8629\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.30684 to 0.21006, saving model to best_m.h5\n",
      " - 8s - loss: 0.3088 - acc: 0.8568 - val_loss: 0.2101 - val_acc: 0.8972\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.3021 - acc: 0.8570 - val_loss: 0.2512 - val_acc: 0.8816\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.2840 - acc: 0.8664 - val_loss: 0.2206 - val_acc: 0.9159\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 9s - loss: 0.2903 - acc: 0.8662 - val_loss: 0.2116 - val_acc: 0.8910\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.21006 to 0.18990, saving model to best_m.h5\n",
      " - 6s - loss: 0.2512 - acc: 0.8758 - val_loss: 0.1899 - val_acc: 0.9190\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2645 - acc: 0.8844 - val_loss: 0.2201 - val_acc: 0.8879\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2739 - acc: 0.8765 - val_loss: 0.2304 - val_acc: 0.8847\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.2520 - acc: 0.8890 - val_loss: 0.2106 - val_acc: 0.9097\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2503 - acc: 0.8773 - val_loss: 0.2011 - val_acc: 0.9190\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 8s - loss: 0.2644 - acc: 0.8797 - val_loss: 0.2189 - val_acc: 0.9065\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2718 - acc: 0.8833 - val_loss: 0.1959 - val_acc: 0.9097\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 10s - loss: 0.2989 - acc: 0.8675 - val_loss: 0.3084 - val_acc: 0.8598\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2502 - acc: 0.8914 - val_loss: 0.2058 - val_acc: 0.9097\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2927 - acc: 0.8720 - val_loss: 0.2930 - val_acc: 0.8910\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2715 - acc: 0.8789 - val_loss: 0.2574 - val_acc: 0.8723\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2571 - acc: 0.8945 - val_loss: 0.2014 - val_acc: 0.9003\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.2674 - acc: 0.8826 - val_loss: 0.1941 - val_acc: 0.9128\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2347 - acc: 0.9023 - val_loss: 0.1971 - val_acc: 0.9065\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2511 - acc: 0.8914 - val_loss: 0.2061 - val_acc: 0.9065\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2409 - acc: 0.8961 - val_loss: 0.1962 - val_acc: 0.9097\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2525 - acc: 0.8891 - val_loss: 0.1919 - val_acc: 0.9003\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss improved from 0.18990 to 0.18870, saving model to best_m.h5\n",
      " - 6s - loss: 0.2446 - acc: 0.8927 - val_loss: 0.1887 - val_acc: 0.9097\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.18870 to 0.18774, saving model to best_m.h5\n",
      " - 7s - loss: 0.2553 - acc: 0.8896 - val_loss: 0.1877 - val_acc: 0.9003\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2447 - acc: 0.8873 - val_loss: 0.1910 - val_acc: 0.9065\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2609 - acc: 0.8779 - val_loss: 0.2105 - val_acc: 0.9097\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.18774 to 0.17984, saving model to best_m.h5\n",
      " - 7s - loss: 0.2484 - acc: 0.8945 - val_loss: 0.1798 - val_acc: 0.9128\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2556 - acc: 0.8937 - val_loss: 0.1971 - val_acc: 0.8910\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2252 - acc: 0.9023 - val_loss: 0.1919 - val_acc: 0.9097\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 8s - loss: 0.2331 - acc: 0.8982 - val_loss: 0.1853 - val_acc: 0.9159\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 8s - loss: 0.2335 - acc: 0.8969 - val_loss: 0.2204 - val_acc: 0.8972\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2316 - acc: 0.8953 - val_loss: 0.1894 - val_acc: 0.9097\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2187 - acc: 0.9027 - val_loss: 0.1883 - val_acc: 0.9221\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2555 - acc: 0.8855 - val_loss: 0.1897 - val_acc: 0.9159\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2300 - acc: 0.8953 - val_loss: 0.1861 - val_acc: 0.9128\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2304 - acc: 0.8914 - val_loss: 0.1942 - val_acc: 0.9128\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2494 - acc: 0.8985 - val_loss: 0.1823 - val_acc: 0.9252\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2367 - acc: 0.8920 - val_loss: 0.1886 - val_acc: 0.9190\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2228 - acc: 0.9078 - val_loss: 0.1876 - val_acc: 0.9128\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.17984 to 0.17911, saving model to best_m.h5\n",
      " - 6s - loss: 0.2074 - acc: 0.9140 - val_loss: 0.1791 - val_acc: 0.9190\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2202 - acc: 0.8953 - val_loss: 0.1864 - val_acc: 0.9190\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2266 - acc: 0.8930 - val_loss: 0.1819 - val_acc: 0.9315\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2082 - acc: 0.9109 - val_loss: 0.1873 - val_acc: 0.9065\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2422 - acc: 0.8966 - val_loss: 0.1821 - val_acc: 0.9190\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2342 - acc: 0.8914 - val_loss: 0.1834 - val_acc: 0.9159\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2240 - acc: 0.9013 - val_loss: 0.1890 - val_acc: 0.9190\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2180 - acc: 0.8977 - val_loss: 0.1839 - val_acc: 0.9159\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2313 - acc: 0.8988 - val_loss: 0.1895 - val_acc: 0.9159\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2160 - acc: 0.9060 - val_loss: 0.1960 - val_acc: 0.9128\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2619 - acc: 0.8852 - val_loss: 0.1872 - val_acc: 0.9128\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2401 - acc: 0.8841 - val_loss: 0.1846 - val_acc: 0.9159\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2137 - acc: 0.9094 - val_loss: 0.1794 - val_acc: 0.9128\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.2229 - acc: 0.8984 - val_loss: 0.1834 - val_acc: 0.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2220 - acc: 0.9060 - val_loss: 0.1856 - val_acc: 0.9159\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2188 - acc: 0.9037 - val_loss: 0.1882 - val_acc: 0.9190\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.17911 to 0.17754, saving model to best_m.h5\n",
      " - 6s - loss: 0.2298 - acc: 0.8949 - val_loss: 0.1775 - val_acc: 0.9252\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.2403 - acc: 0.8954 - val_loss: 0.1814 - val_acc: 0.9190\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.17754 to 0.17583, saving model to best_m.h5\n",
      " - 6s - loss: 0.2088 - acc: 0.9099 - val_loss: 0.1758 - val_acc: 0.9190\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss improved from 0.17583 to 0.17396, saving model to best_m.h5\n",
      " - 6s - loss: 0.2310 - acc: 0.8966 - val_loss: 0.1740 - val_acc: 0.9252\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.2046 - acc: 0.9070 - val_loss: 0.1774 - val_acc: 0.9221\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2568 - acc: 0.8946 - val_loss: 0.1825 - val_acc: 0.9159\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2161 - acc: 0.9091 - val_loss: 0.1847 - val_acc: 0.9128\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.2532 - acc: 0.8845 - val_loss: 0.1828 - val_acc: 0.9221\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2167 - acc: 0.9039 - val_loss: 0.1772 - val_acc: 0.9221\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.2283 - acc: 0.9013 - val_loss: 0.1765 - val_acc: 0.9252\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.2254 - acc: 0.9070 - val_loss: 0.1926 - val_acc: 0.9252\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.2267 - acc: 0.8966 - val_loss: 0.1828 - val_acc: 0.9097\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.2054 - acc: 0.9039 - val_loss: 0.1796 - val_acc: 0.9159\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2246 - acc: 0.9037 - val_loss: 0.1822 - val_acc: 0.9128\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.1844 - acc: 0.9187 - val_loss: 0.1811 - val_acc: 0.9190\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.2069 - acc: 0.9141 - val_loss: 0.1780 - val_acc: 0.9159\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.2115 - acc: 0.9047 - val_loss: 0.1761 - val_acc: 0.9190\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 0.2167 - acc: 0.9066 - val_loss: 0.1748 - val_acc: 0.9190\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 6s - loss: 0.2146 - acc: 0.9003 - val_loss: 0.1771 - val_acc: 0.9252\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 6s - loss: 0.2133 - acc: 0.9062 - val_loss: 0.1804 - val_acc: 0.9221\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.2242 - acc: 0.9078 - val_loss: 0.1780 - val_acc: 0.9283\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.2101 - acc: 0.8990 - val_loss: 0.1858 - val_acc: 0.9221\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.2107 - acc: 0.9164 - val_loss: 0.1799 - val_acc: 0.9190\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.2128 - acc: 0.9078 - val_loss: 0.1780 - val_acc: 0.9190\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69260, saving model to best_m.h5\n",
      " - 20s - loss: 0.6681 - acc: 0.6589 - val_loss: 0.6926 - val_acc: 0.5327\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5281 - acc: 0.7368 - val_loss: 0.7660 - val_acc: 0.5327\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4195 - acc: 0.8070 - val_loss: 1.3785 - val_acc: 0.5327\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4577 - acc: 0.7870 - val_loss: 0.7044 - val_acc: 0.5950\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.4440 - acc: 0.8050 - val_loss: 0.7998 - val_acc: 0.5483\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.4014 - acc: 0.8154 - val_loss: 0.7082 - val_acc: 0.7009\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.69260 to 0.50580, saving model to best_m.h5\n",
      " - 6s - loss: 0.3520 - acc: 0.8336 - val_loss: 0.5058 - val_acc: 0.7913\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.50580 to 0.41304, saving model to best_m.h5\n",
      " - 6s - loss: 0.3506 - acc: 0.8341 - val_loss: 0.4130 - val_acc: 0.8100\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.41304 to 0.32268, saving model to best_m.h5\n",
      " - 6s - loss: 0.3439 - acc: 0.8391 - val_loss: 0.3227 - val_acc: 0.8380\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3844 - acc: 0.8276 - val_loss: 0.6398 - val_acc: 0.7539\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3625 - acc: 0.8230 - val_loss: 4.3198 - val_acc: 0.5327\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3428 - acc: 0.8406 - val_loss: 0.3617 - val_acc: 0.8411\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.32268 to 0.29617, saving model to best_m.h5\n",
      " - 6s - loss: 0.3214 - acc: 0.8497 - val_loss: 0.2962 - val_acc: 0.8474\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.3073 - acc: 0.8570 - val_loss: 0.7821 - val_acc: 0.7508\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.29617 to 0.26300, saving model to best_m.h5\n",
      " - 6s - loss: 0.2998 - acc: 0.8773 - val_loss: 0.2630 - val_acc: 0.8723\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 6s - loss: 0.2693 - acc: 0.8742 - val_loss: 0.2861 - val_acc: 0.8754\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.2987 - acc: 0.8800 - val_loss: 0.2657 - val_acc: 0.8754\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.26300 to 0.25321, saving model to best_m.h5\n",
      " - 6s - loss: 0.2652 - acc: 0.8742 - val_loss: 0.2532 - val_acc: 0.8816\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.2685 - acc: 0.8812 - val_loss: 0.2638 - val_acc: 0.8598\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2665 - acc: 0.8806 - val_loss: 0.2585 - val_acc: 0.8598\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2944 - acc: 0.8656 - val_loss: 0.2619 - val_acc: 0.8785\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2561 - acc: 0.8685 - val_loss: 0.2760 - val_acc: 0.8660\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2496 - acc: 0.8922 - val_loss: 0.2757 - val_acc: 0.8785\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2497 - acc: 0.9023 - val_loss: 0.2747 - val_acc: 0.8847\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2467 - acc: 0.8843 - val_loss: 0.2707 - val_acc: 0.8785\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2395 - acc: 0.8787 - val_loss: 0.2745 - val_acc: 0.8723\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2689 - acc: 0.8685 - val_loss: 0.3208 - val_acc: 0.8660\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2539 - acc: 0.8873 - val_loss: 0.3113 - val_acc: 0.8692\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2646 - acc: 0.8953 - val_loss: 0.2627 - val_acc: 0.8692\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2196 - acc: 0.9039 - val_loss: 0.2756 - val_acc: 0.8879\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2588 - acc: 0.8740 - val_loss: 0.2777 - val_acc: 0.8660\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2275 - acc: 0.8945 - val_loss: 0.2714 - val_acc: 0.8785\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss improved from 0.25321 to 0.24792, saving model to best_m.h5\n",
      " - 6s - loss: 0.2450 - acc: 0.8906 - val_loss: 0.2479 - val_acc: 0.8785\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2607 - acc: 0.8820 - val_loss: 0.2563 - val_acc: 0.8910\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2504 - acc: 0.8933 - val_loss: 0.2543 - val_acc: 0.8879\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2368 - acc: 0.8953 - val_loss: 0.2533 - val_acc: 0.9003\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2380 - acc: 0.9060 - val_loss: 0.2807 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2349 - acc: 0.8937 - val_loss: 0.2749 - val_acc: 0.8754\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2349 - acc: 0.8966 - val_loss: 0.3220 - val_acc: 0.8598\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2296 - acc: 0.8953 - val_loss: 0.2709 - val_acc: 0.8847\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2257 - acc: 0.8930 - val_loss: 0.3098 - val_acc: 0.8785\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2068 - acc: 0.8990 - val_loss: 0.2986 - val_acc: 0.8723\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2367 - acc: 0.8984 - val_loss: 0.2605 - val_acc: 0.8910\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2174 - acc: 0.9008 - val_loss: 0.2761 - val_acc: 0.8598\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2253 - acc: 0.9091 - val_loss: 0.2607 - val_acc: 0.8723\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2242 - acc: 0.9039 - val_loss: 0.2595 - val_acc: 0.8972\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2246 - acc: 0.9115 - val_loss: 0.2668 - val_acc: 0.8723\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2324 - acc: 0.9029 - val_loss: 0.2562 - val_acc: 0.8847\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2003 - acc: 0.9055 - val_loss: 0.2636 - val_acc: 0.8847\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2180 - acc: 0.9013 - val_loss: 0.2631 - val_acc: 0.8816\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2269 - acc: 0.8943 - val_loss: 0.2600 - val_acc: 0.8847\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.1981 - acc: 0.9172 - val_loss: 0.2666 - val_acc: 0.8941\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2281 - acc: 0.8974 - val_loss: 0.2643 - val_acc: 0.8692\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.70630, saving model to best_m.h5\n",
      " - 30s - loss: 0.7120 - acc: 0.6456 - val_loss: 0.7063 - val_acc: 0.4860\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5072 - acc: 0.7404 - val_loss: 0.7500 - val_acc: 0.4860\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4667 - acc: 0.7726 - val_loss: 0.9292 - val_acc: 0.4860\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.70630 to 0.68213, saving model to best_m.h5\n",
      " - 7s - loss: 0.4649 - acc: 0.7914 - val_loss: 0.6821 - val_acc: 0.4860\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68213 to 0.57878, saving model to best_m.h5\n",
      " - 6s - loss: 0.4061 - acc: 0.8172 - val_loss: 0.5788 - val_acc: 0.5732\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.57878 to 0.36168, saving model to best_m.h5\n",
      " - 7s - loss: 0.3893 - acc: 0.8052 - val_loss: 0.3617 - val_acc: 0.8474\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.3852 - acc: 0.8234 - val_loss: 0.6486 - val_acc: 0.7103\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.36168 to 0.30243, saving model to best_m.h5\n",
      " - 6s - loss: 0.3748 - acc: 0.8412 - val_loss: 0.3024 - val_acc: 0.8598\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.3128 - acc: 0.8516 - val_loss: 0.4336 - val_acc: 0.8100\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3959 - acc: 0.8259 - val_loss: 0.7436 - val_acc: 0.7508\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3194 - acc: 0.8451 - val_loss: 0.3269 - val_acc: 0.8411\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3579 - acc: 0.8320 - val_loss: 0.4144 - val_acc: 0.8224\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.3247 - acc: 0.8609 - val_loss: 0.4270 - val_acc: 0.8037\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.30243 to 0.27578, saving model to best_m.h5\n",
      " - 6s - loss: 0.3134 - acc: 0.8555 - val_loss: 0.2758 - val_acc: 0.8660\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3490 - acc: 0.8490 - val_loss: 0.3107 - val_acc: 0.8598\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.27578 to 0.27284, saving model to best_m.h5\n",
      " - 6s - loss: 0.2891 - acc: 0.8680 - val_loss: 0.2728 - val_acc: 0.8692\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.2735 - acc: 0.8789 - val_loss: 0.2847 - val_acc: 0.8847\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.2663 - acc: 0.8802 - val_loss: 0.3054 - val_acc: 0.8536\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.27284 to 0.27011, saving model to best_m.h5\n",
      " - 6s - loss: 0.2565 - acc: 0.8935 - val_loss: 0.2701 - val_acc: 0.8816\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2720 - acc: 0.8724 - val_loss: 0.2975 - val_acc: 0.8536\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.2737 - acc: 0.8763 - val_loss: 0.2919 - val_acc: 0.8629\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.27011 to 0.26283, saving model to best_m.h5\n",
      " - 6s - loss: 0.2234 - acc: 0.9008 - val_loss: 0.2628 - val_acc: 0.8972\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2783 - acc: 0.8828 - val_loss: 0.3075 - val_acc: 0.8536\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.26283 to 0.26015, saving model to best_m.h5\n",
      " - 6s - loss: 0.2354 - acc: 0.9000 - val_loss: 0.2602 - val_acc: 0.8847\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2518 - acc: 0.9060 - val_loss: 0.3407 - val_acc: 0.8567\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.26015 to 0.25238, saving model to best_m.h5\n",
      " - 6s - loss: 0.2919 - acc: 0.8763 - val_loss: 0.2524 - val_acc: 0.8847\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2499 - acc: 0.8961 - val_loss: 0.3237 - val_acc: 0.8380\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2566 - acc: 0.8806 - val_loss: 0.3173 - val_acc: 0.8598\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2628 - acc: 0.8812 - val_loss: 0.2591 - val_acc: 0.8785\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2433 - acc: 0.8961 - val_loss: 0.2858 - val_acc: 0.8660\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2344 - acc: 0.9023 - val_loss: 0.2670 - val_acc: 0.8723\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2434 - acc: 0.8937 - val_loss: 0.2546 - val_acc: 0.8879\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2332 - acc: 0.9008 - val_loss: 0.2563 - val_acc: 0.8816\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.25238 to 0.24129, saving model to best_m.h5\n",
      " - 6s - loss: 0.2343 - acc: 0.8898 - val_loss: 0.2413 - val_acc: 0.9128\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2732 - acc: 0.8782 - val_loss: 0.2485 - val_acc: 0.8692\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.24129 to 0.23793, saving model to best_m.h5\n",
      " - 6s - loss: 0.2548 - acc: 0.8873 - val_loss: 0.2379 - val_acc: 0.8879\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2216 - acc: 0.9070 - val_loss: 0.2546 - val_acc: 0.8879\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2321 - acc: 0.8976 - val_loss: 0.2506 - val_acc: 0.8816\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2560 - acc: 0.8902 - val_loss: 0.2709 - val_acc: 0.8660\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2420 - acc: 0.8949 - val_loss: 0.2537 - val_acc: 0.8723\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2296 - acc: 0.9008 - val_loss: 0.2535 - val_acc: 0.8910\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2149 - acc: 0.9016 - val_loss: 0.2488 - val_acc: 0.9034\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2336 - acc: 0.9066 - val_loss: 0.2740 - val_acc: 0.8660\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2147 - acc: 0.9062 - val_loss: 0.2403 - val_acc: 0.9128\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2419 - acc: 0.8855 - val_loss: 0.2474 - val_acc: 0.9065\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2153 - acc: 0.9094 - val_loss: 0.2472 - val_acc: 0.9034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2128 - acc: 0.9109 - val_loss: 0.2460 - val_acc: 0.9034\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.1994 - acc: 0.9099 - val_loss: 0.2423 - val_acc: 0.9097\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2267 - acc: 0.9008 - val_loss: 0.2418 - val_acc: 0.9159\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2151 - acc: 0.9115 - val_loss: 0.2492 - val_acc: 0.8972\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.1925 - acc: 0.9125 - val_loss: 0.2422 - val_acc: 0.9159\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2272 - acc: 0.8966 - val_loss: 0.2430 - val_acc: 0.9128\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2242 - acc: 0.9097 - val_loss: 0.2388 - val_acc: 0.9128\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.23793 to 0.23729, saving model to best_m.h5\n",
      " - 6s - loss: 0.2144 - acc: 0.9066 - val_loss: 0.2373 - val_acc: 0.9128\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2235 - acc: 0.8976 - val_loss: 0.2396 - val_acc: 0.9065\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2029 - acc: 0.9086 - val_loss: 0.2389 - val_acc: 0.9097\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.1979 - acc: 0.9109 - val_loss: 0.2392 - val_acc: 0.9034\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2186 - acc: 0.9021 - val_loss: 0.2429 - val_acc: 0.9097\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2300 - acc: 0.9060 - val_loss: 0.2398 - val_acc: 0.9065\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.1853 - acc: 0.9195 - val_loss: 0.2422 - val_acc: 0.9065\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2485 - acc: 0.8982 - val_loss: 0.2391 - val_acc: 0.9097\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss improved from 0.23729 to 0.23650, saving model to best_m.h5\n",
      " - 6s - loss: 0.2141 - acc: 0.9099 - val_loss: 0.2365 - val_acc: 0.9221\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2171 - acc: 0.9027 - val_loss: 0.2404 - val_acc: 0.9159\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.1999 - acc: 0.9070 - val_loss: 0.2389 - val_acc: 0.9003\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2062 - acc: 0.9101 - val_loss: 0.2381 - val_acc: 0.9190\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.1928 - acc: 0.9117 - val_loss: 0.2382 - val_acc: 0.9128\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.1924 - acc: 0.9219 - val_loss: 0.2454 - val_acc: 0.9003\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2092 - acc: 0.9123 - val_loss: 0.2438 - val_acc: 0.9003\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.1926 - acc: 0.9180 - val_loss: 0.2410 - val_acc: 0.9128\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.1967 - acc: 0.9141 - val_loss: 0.2414 - val_acc: 0.9159\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.1983 - acc: 0.9125 - val_loss: 0.2381 - val_acc: 0.9034\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.23650 to 0.23644, saving model to best_m.h5\n",
      " - 6s - loss: 0.2055 - acc: 0.9068 - val_loss: 0.2364 - val_acc: 0.9034\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.1977 - acc: 0.9078 - val_loss: 0.2376 - val_acc: 0.9159\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.1897 - acc: 0.9180 - val_loss: 0.2401 - val_acc: 0.9003\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.1853 - acc: 0.9203 - val_loss: 0.2420 - val_acc: 0.9034\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2060 - acc: 0.9125 - val_loss: 0.2492 - val_acc: 0.8941\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.2265 - acc: 0.9120 - val_loss: 0.2424 - val_acc: 0.9034\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.1878 - acc: 0.9211 - val_loss: 0.2433 - val_acc: 0.9034\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.1763 - acc: 0.9242 - val_loss: 0.2432 - val_acc: 0.8941\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.1904 - acc: 0.9164 - val_loss: 0.2446 - val_acc: 0.9034\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.1975 - acc: 0.9160 - val_loss: 0.2481 - val_acc: 0.9065\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.1870 - acc: 0.9211 - val_loss: 0.2452 - val_acc: 0.9065\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.1851 - acc: 0.9242 - val_loss: 0.2509 - val_acc: 0.8941\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.1832 - acc: 0.9250 - val_loss: 0.2450 - val_acc: 0.9065\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.1925 - acc: 0.9076 - val_loss: 0.2461 - val_acc: 0.9128\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.1953 - acc: 0.9172 - val_loss: 0.2469 - val_acc: 0.9097\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 0.1868 - acc: 0.9156 - val_loss: 0.2420 - val_acc: 0.8972\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 6s - loss: 0.1906 - acc: 0.9226 - val_loss: 0.2490 - val_acc: 0.9003\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 6s - loss: 0.1720 - acc: 0.9211 - val_loss: 0.2421 - val_acc: 0.8972\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.1852 - acc: 0.9164 - val_loss: 0.2416 - val_acc: 0.9065\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.1945 - acc: 0.9117 - val_loss: 0.2437 - val_acc: 0.9034\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.1912 - acc: 0.9172 - val_loss: 0.2543 - val_acc: 0.8972\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69075, saving model to best_m.h5\n",
      " - 30s - loss: 0.7387 - acc: 0.6336 - val_loss: 0.6908 - val_acc: 0.5312\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.4999 - acc: 0.7477 - val_loss: 1.2492 - val_acc: 0.5312\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4355 - acc: 0.7914 - val_loss: 1.1059 - val_acc: 0.5312\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4875 - acc: 0.7641 - val_loss: 1.0647 - val_acc: 0.5312\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.4191 - acc: 0.7875 - val_loss: 1.6884 - val_acc: 0.5312\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.3949 - acc: 0.8219 - val_loss: 0.8588 - val_acc: 0.5938\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.3701 - acc: 0.8305 - val_loss: 1.2568 - val_acc: 0.5594\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.69075 to 0.31252, saving model to best_m.h5\n",
      " - 6s - loss: 0.3715 - acc: 0.8195 - val_loss: 0.3125 - val_acc: 0.8562\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.3522 - acc: 0.8445 - val_loss: 0.3558 - val_acc: 0.8375\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3210 - acc: 0.8555 - val_loss: 0.4907 - val_acc: 0.7250\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3251 - acc: 0.8422 - val_loss: 1.0309 - val_acc: 0.7063\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3454 - acc: 0.8531 - val_loss: 2.3850 - val_acc: 0.5500\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.2967 - acc: 0.8531 - val_loss: 0.5099 - val_acc: 0.7094\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3791 - acc: 0.8266 - val_loss: 0.7668 - val_acc: 0.6781\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3731 - acc: 0.8313 - val_loss: 0.4598 - val_acc: 0.7781\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.31252 to 0.29376, saving model to best_m.h5\n",
      " - 6s - loss: 0.3531 - acc: 0.8438 - val_loss: 0.2938 - val_acc: 0.8594\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.2952 - acc: 0.8516 - val_loss: 0.4585 - val_acc: 0.8031\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.2853 - acc: 0.8688 - val_loss: 0.3657 - val_acc: 0.8469\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.2660 - acc: 0.8758 - val_loss: 0.3228 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2933 - acc: 0.8672 - val_loss: 0.3260 - val_acc: 0.8531\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.29376 to 0.27080, saving model to best_m.h5\n",
      " - 6s - loss: 0.2515 - acc: 0.8828 - val_loss: 0.2708 - val_acc: 0.8844\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.27080 to 0.26641, saving model to best_m.h5\n",
      " - 6s - loss: 0.2615 - acc: 0.8867 - val_loss: 0.2664 - val_acc: 0.8906\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2666 - acc: 0.8649 - val_loss: 0.2903 - val_acc: 0.8812\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2399 - acc: 0.8844 - val_loss: 0.2769 - val_acc: 0.8844\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2714 - acc: 0.8727 - val_loss: 0.2812 - val_acc: 0.8594\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2450 - acc: 0.8859 - val_loss: 0.2730 - val_acc: 0.8938\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2636 - acc: 0.8906 - val_loss: 0.2962 - val_acc: 0.8750\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2550 - acc: 0.8875 - val_loss: 0.2913 - val_acc: 0.8781\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2459 - acc: 0.8867 - val_loss: 0.2665 - val_acc: 0.8906\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2565 - acc: 0.8844 - val_loss: 0.2900 - val_acc: 0.8875\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2281 - acc: 0.9094 - val_loss: 0.2735 - val_acc: 0.8875\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2500 - acc: 0.8930 - val_loss: 0.2803 - val_acc: 0.9031\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2355 - acc: 0.8828 - val_loss: 0.2934 - val_acc: 0.8844\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.26641 to 0.26374, saving model to best_m.h5\n",
      " - 6s - loss: 0.2536 - acc: 0.8922 - val_loss: 0.2637 - val_acc: 0.8875\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2507 - acc: 0.8860 - val_loss: 0.2699 - val_acc: 0.8906\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2130 - acc: 0.8976 - val_loss: 0.2787 - val_acc: 0.8938\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2399 - acc: 0.8914 - val_loss: 0.2978 - val_acc: 0.8781\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2512 - acc: 0.8890 - val_loss: 0.2678 - val_acc: 0.8812\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2544 - acc: 0.8906 - val_loss: 0.2664 - val_acc: 0.8969\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2213 - acc: 0.9094 - val_loss: 0.2643 - val_acc: 0.9125\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2140 - acc: 0.9008 - val_loss: 0.2968 - val_acc: 0.8781\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2053 - acc: 0.9031 - val_loss: 0.3073 - val_acc: 0.8812\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2099 - acc: 0.9109 - val_loss: 0.2751 - val_acc: 0.8906\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2279 - acc: 0.8883 - val_loss: 0.2943 - val_acc: 0.8844\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2183 - acc: 0.9023 - val_loss: 0.2866 - val_acc: 0.8938\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2097 - acc: 0.9031 - val_loss: 0.2684 - val_acc: 0.9062\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2052 - acc: 0.9024 - val_loss: 0.2643 - val_acc: 0.8938\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2081 - acc: 0.9078 - val_loss: 0.2749 - val_acc: 0.9031\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2111 - acc: 0.8992 - val_loss: 0.2725 - val_acc: 0.9031\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2048 - acc: 0.9102 - val_loss: 0.2692 - val_acc: 0.9000\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2027 - acc: 0.9016 - val_loss: 0.2704 - val_acc: 0.9031\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.1996 - acc: 0.9078 - val_loss: 0.2803 - val_acc: 0.9031\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2037 - acc: 0.9140 - val_loss: 0.2737 - val_acc: 0.8969\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.1981 - acc: 0.9102 - val_loss: 0.2935 - val_acc: 0.8844\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=99):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_incept_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.229028814853\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.220901\n",
      "1  4023181e    0.336924\n",
      "2  b20200e4    0.062305\n",
      "3  e7f018bb    0.999241\n",
      "4  4371c8c3    0.116947\n"
     ]
    }
   ],
   "source": [
    "with open('../features/incept_aug4_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/incept_aug4_sub.csv', index=False)\n",
    "# deep2 0.2110\n",
    "# deep3 0.2119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, strides=2, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.73744, saving model to best_m.h5\n",
      " - 31s - loss: 1.0459 - acc: 0.5964 - val_loss: 0.7374 - val_acc: 0.5265\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.73744 to 0.73618, saving model to best_m.h5\n",
      " - 7s - loss: 0.6184 - acc: 0.6204 - val_loss: 0.7362 - val_acc: 0.5265\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.73618 to 0.71047, saving model to best_m.h5\n",
      " - 7s - loss: 0.6139 - acc: 0.6646 - val_loss: 0.7105 - val_acc: 0.5265\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.71047 to 0.66811, saving model to best_m.h5\n",
      " - 7s - loss: 0.5858 - acc: 0.6836 - val_loss: 0.6681 - val_acc: 0.5265\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 7s - loss: 0.5540 - acc: 0.7026 - val_loss: 0.6939 - val_acc: 0.5265\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 7s - loss: 0.5324 - acc: 0.7341 - val_loss: 1.6208 - val_acc: 0.5265\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.66811 to 0.58510, saving model to best_m.h5\n",
      " - 7s - loss: 0.5445 - acc: 0.7273 - val_loss: 0.5851 - val_acc: 0.6791\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.5250 - acc: 0.7498 - val_loss: 0.8253 - val_acc: 0.7196\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.58510 to 0.40107, saving model to best_m.h5\n",
      " - 7s - loss: 0.5189 - acc: 0.7406 - val_loss: 0.4011 - val_acc: 0.8380\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4764 - acc: 0.7550 - val_loss: 0.5824 - val_acc: 0.6324\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4821 - acc: 0.7555 - val_loss: 0.5709 - val_acc: 0.6667\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4773 - acc: 0.7753 - val_loss: 0.5011 - val_acc: 0.8006\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4972 - acc: 0.7679 - val_loss: 0.4099 - val_acc: 0.8567\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.40107 to 0.31885, saving model to best_m.h5\n",
      " - 7s - loss: 0.4756 - acc: 0.7703 - val_loss: 0.3189 - val_acc: 0.8505\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4383 - acc: 0.7857 - val_loss: 0.3494 - val_acc: 0.8723\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.4077 - acc: 0.8140 - val_loss: 0.5192 - val_acc: 0.6916\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.31885 to 0.27039, saving model to best_m.h5\n",
      " - 7s - loss: 0.3755 - acc: 0.8258 - val_loss: 0.2704 - val_acc: 0.8816\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3711 - acc: 0.8271 - val_loss: 0.2737 - val_acc: 0.8754\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3737 - acc: 0.8406 - val_loss: 0.3112 - val_acc: 0.8474\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 8s - loss: 0.3577 - acc: 0.8343 - val_loss: 0.3919 - val_acc: 0.8255\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 8s - loss: 0.3477 - acc: 0.8305 - val_loss: 0.3267 - val_acc: 0.8660\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3539 - acc: 0.8318 - val_loss: 0.3426 - val_acc: 0.8380\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.27039 to 0.26070, saving model to best_m.h5\n",
      " - 9s - loss: 0.3392 - acc: 0.8305 - val_loss: 0.2607 - val_acc: 0.8723\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 10s - loss: 0.3265 - acc: 0.8458 - val_loss: 0.2952 - val_acc: 0.8598\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3343 - acc: 0.8375 - val_loss: 0.3212 - val_acc: 0.8598\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.26070 to 0.23407, saving model to best_m.h5\n",
      " - 7s - loss: 0.3355 - acc: 0.8441 - val_loss: 0.2341 - val_acc: 0.9065\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3199 - acc: 0.8570 - val_loss: 0.2537 - val_acc: 0.8910\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.3693 - acc: 0.8277 - val_loss: 0.2915 - val_acc: 0.8754\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3331 - acc: 0.8341 - val_loss: 0.2426 - val_acc: 0.8910\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.2948 - acc: 0.8607 - val_loss: 0.5077 - val_acc: 0.7414\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.23407 to 0.22568, saving model to best_m.h5\n",
      " - 8s - loss: 0.3168 - acc: 0.8437 - val_loss: 0.2257 - val_acc: 0.9065\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.3257 - acc: 0.8576 - val_loss: 0.3105 - val_acc: 0.8723\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2750 - acc: 0.8711 - val_loss: 0.2273 - val_acc: 0.8910\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.3370 - acc: 0.8383 - val_loss: 0.2516 - val_acc: 0.8879\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.3133 - acc: 0.8574 - val_loss: 0.2263 - val_acc: 0.8972\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.3105 - acc: 0.8646 - val_loss: 0.2297 - val_acc: 0.8910\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.3038 - acc: 0.8544 - val_loss: 0.4603 - val_acc: 0.7913\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.2891 - acc: 0.8594 - val_loss: 0.2404 - val_acc: 0.8941\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2895 - acc: 0.8630 - val_loss: 0.3016 - val_acc: 0.8754\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.3059 - acc: 0.8555 - val_loss: 0.5541 - val_acc: 0.7539\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2929 - acc: 0.8500 - val_loss: 0.2390 - val_acc: 0.8879\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.3099 - acc: 0.8617 - val_loss: 0.2420 - val_acc: 0.8972\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2916 - acc: 0.8679 - val_loss: 0.2520 - val_acc: 0.9034\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2740 - acc: 0.8703 - val_loss: 0.3475 - val_acc: 0.8567\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2910 - acc: 0.8662 - val_loss: 0.2642 - val_acc: 0.8754\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.22568 to 0.21583, saving model to best_m.h5\n",
      " - 7s - loss: 0.2873 - acc: 0.8693 - val_loss: 0.2158 - val_acc: 0.9097\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2745 - acc: 0.8625 - val_loss: 0.2328 - val_acc: 0.8910\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2770 - acc: 0.8656 - val_loss: 0.2184 - val_acc: 0.9034\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2897 - acc: 0.8628 - val_loss: 0.2252 - val_acc: 0.9003\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2633 - acc: 0.8706 - val_loss: 0.2210 - val_acc: 0.8972\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2637 - acc: 0.8609 - val_loss: 0.2202 - val_acc: 0.9003\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2739 - acc: 0.8709 - val_loss: 0.2160 - val_acc: 0.8941\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2622 - acc: 0.8685 - val_loss: 0.2175 - val_acc: 0.8941\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.21583 to 0.21406, saving model to best_m.h5\n",
      " - 7s - loss: 0.2608 - acc: 0.8797 - val_loss: 0.2141 - val_acc: 0.8972\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss improved from 0.21406 to 0.20926, saving model to best_m.h5\n",
      " - 7s - loss: 0.2385 - acc: 0.8781 - val_loss: 0.2093 - val_acc: 0.8972\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2851 - acc: 0.8709 - val_loss: 0.2384 - val_acc: 0.8941\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2844 - acc: 0.8597 - val_loss: 0.2257 - val_acc: 0.9003\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2679 - acc: 0.8672 - val_loss: 0.2201 - val_acc: 0.8941\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2763 - acc: 0.8742 - val_loss: 0.2461 - val_acc: 0.8910\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2685 - acc: 0.8677 - val_loss: 0.2185 - val_acc: 0.9003\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2739 - acc: 0.8734 - val_loss: 0.2125 - val_acc: 0.8972\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2505 - acc: 0.8703 - val_loss: 0.2192 - val_acc: 0.8941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2598 - acc: 0.8726 - val_loss: 0.2156 - val_acc: 0.8847\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2743 - acc: 0.8758 - val_loss: 0.2211 - val_acc: 0.8847\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2490 - acc: 0.8734 - val_loss: 0.2112 - val_acc: 0.9003\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2535 - acc: 0.8873 - val_loss: 0.2211 - val_acc: 0.8941\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2611 - acc: 0.8812 - val_loss: 0.2171 - val_acc: 0.9003\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2589 - acc: 0.8719 - val_loss: 0.2137 - val_acc: 0.8941\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2616 - acc: 0.8726 - val_loss: 0.2159 - val_acc: 0.8847\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2602 - acc: 0.8740 - val_loss: 0.2177 - val_acc: 0.8879\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2746 - acc: 0.8695 - val_loss: 0.2257 - val_acc: 0.8910\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2587 - acc: 0.8765 - val_loss: 0.2204 - val_acc: 0.8879\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2606 - acc: 0.8789 - val_loss: 0.2148 - val_acc: 0.8941\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2712 - acc: 0.8730 - val_loss: 0.2189 - val_acc: 0.8879\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2629 - acc: 0.8734 - val_loss: 0.2153 - val_acc: 0.9003\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69065, saving model to best_m.h5\n",
      " - 35s - loss: 1.1705 - acc: 0.5849 - val_loss: 0.6907 - val_acc: 0.5327\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.6234 - acc: 0.6435 - val_loss: 0.6931 - val_acc: 0.5327\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69065 to 0.66423, saving model to best_m.h5\n",
      " - 7s - loss: 0.5755 - acc: 0.6607 - val_loss: 0.6642 - val_acc: 0.5327\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 7s - loss: 0.5714 - acc: 0.7117 - val_loss: 0.6924 - val_acc: 0.4953\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.66423 to 0.64361, saving model to best_m.h5\n",
      " - 7s - loss: 0.5170 - acc: 0.7320 - val_loss: 0.6436 - val_acc: 0.5327\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.64361 to 0.60841, saving model to best_m.h5\n",
      " - 7s - loss: 0.5449 - acc: 0.7380 - val_loss: 0.6084 - val_acc: 0.5452\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 7s - loss: 0.5173 - acc: 0.7437 - val_loss: 0.6269 - val_acc: 0.5452\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.60841 to 0.49417, saving model to best_m.h5\n",
      " - 7s - loss: 0.5071 - acc: 0.7623 - val_loss: 0.4942 - val_acc: 0.7414\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.5030 - acc: 0.7519 - val_loss: 0.7138 - val_acc: 0.7196\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4631 - acc: 0.7656 - val_loss: 0.5679 - val_acc: 0.5794\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.49417 to 0.36527, saving model to best_m.h5\n",
      " - 8s - loss: 0.5012 - acc: 0.7784 - val_loss: 0.3653 - val_acc: 0.8255\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4801 - acc: 0.7769 - val_loss: 0.4200 - val_acc: 0.7944\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4161 - acc: 0.8062 - val_loss: 0.3846 - val_acc: 0.7757\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.4693 - acc: 0.7613 - val_loss: 0.4865 - val_acc: 0.7227\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4293 - acc: 0.7945 - val_loss: 0.4677 - val_acc: 0.7259\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.4200 - acc: 0.8031 - val_loss: 0.4034 - val_acc: 0.7944\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.36527 to 0.31803, saving model to best_m.h5\n",
      " - 7s - loss: 0.3893 - acc: 0.8177 - val_loss: 0.3180 - val_acc: 0.8474\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3869 - acc: 0.8187 - val_loss: 0.3307 - val_acc: 0.8380\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3532 - acc: 0.8390 - val_loss: 0.3550 - val_acc: 0.8287\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3412 - acc: 0.8472 - val_loss: 0.3283 - val_acc: 0.8380\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3500 - acc: 0.8375 - val_loss: 0.3358 - val_acc: 0.8318\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3476 - acc: 0.8461 - val_loss: 0.3800 - val_acc: 0.7913\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.31803 to 0.31647, saving model to best_m.h5\n",
      " - 7s - loss: 0.3179 - acc: 0.8609 - val_loss: 0.3165 - val_acc: 0.8442\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3497 - acc: 0.8312 - val_loss: 0.3792 - val_acc: 0.8006\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3186 - acc: 0.8641 - val_loss: 0.3627 - val_acc: 0.8255\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3333 - acc: 0.8482 - val_loss: 0.3443 - val_acc: 0.8442\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3207 - acc: 0.8531 - val_loss: 0.3496 - val_acc: 0.8380\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.3099 - acc: 0.8630 - val_loss: 0.4143 - val_acc: 0.7944\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3195 - acc: 0.8640 - val_loss: 0.3191 - val_acc: 0.8474\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.3394 - acc: 0.8412 - val_loss: 0.3174 - val_acc: 0.8411\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 7s - loss: 0.2902 - acc: 0.8633 - val_loss: 0.3341 - val_acc: 0.8224\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.2860 - acc: 0.8742 - val_loss: 0.3209 - val_acc: 0.8474\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss improved from 0.31647 to 0.28429, saving model to best_m.h5\n",
      " - 7s - loss: 0.2725 - acc: 0.8758 - val_loss: 0.2843 - val_acc: 0.8629\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.3053 - acc: 0.8594 - val_loss: 0.2995 - val_acc: 0.8505\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.2786 - acc: 0.8792 - val_loss: 0.3776 - val_acc: 0.8287\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.3099 - acc: 0.8602 - val_loss: 0.3118 - val_acc: 0.8536\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.2793 - acc: 0.8726 - val_loss: 0.3199 - val_acc: 0.8287\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.3208 - acc: 0.8579 - val_loss: 0.2976 - val_acc: 0.8660\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2695 - acc: 0.8633 - val_loss: 0.3030 - val_acc: 0.8505\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.3096 - acc: 0.8561 - val_loss: 0.3394 - val_acc: 0.8411\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2757 - acc: 0.8695 - val_loss: 0.3035 - val_acc: 0.8505\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2970 - acc: 0.8774 - val_loss: 0.3273 - val_acc: 0.8442\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2798 - acc: 0.8750 - val_loss: 0.3233 - val_acc: 0.8474\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2729 - acc: 0.8851 - val_loss: 0.3760 - val_acc: 0.8380\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2643 - acc: 0.8758 - val_loss: 0.2936 - val_acc: 0.8598\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.28429 to 0.28023, saving model to best_m.h5\n",
      " - 7s - loss: 0.2667 - acc: 0.8794 - val_loss: 0.2802 - val_acc: 0.8692\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2699 - acc: 0.8773 - val_loss: 0.2839 - val_acc: 0.8598\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2394 - acc: 0.8961 - val_loss: 0.2844 - val_acc: 0.8629\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2588 - acc: 0.8745 - val_loss: 0.2885 - val_acc: 0.8598\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2601 - acc: 0.8859 - val_loss: 0.2904 - val_acc: 0.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.28023 to 0.27979, saving model to best_m.h5\n",
      " - 7s - loss: 0.2612 - acc: 0.8812 - val_loss: 0.2798 - val_acc: 0.8629\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2629 - acc: 0.8836 - val_loss: 0.3019 - val_acc: 0.8567\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2524 - acc: 0.8812 - val_loss: 0.2902 - val_acc: 0.8567\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2691 - acc: 0.8750 - val_loss: 0.3135 - val_acc: 0.8567\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2315 - acc: 0.8953 - val_loss: 0.2946 - val_acc: 0.8629\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2600 - acc: 0.8766 - val_loss: 0.3020 - val_acc: 0.8567\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2533 - acc: 0.8867 - val_loss: 0.3001 - val_acc: 0.8536\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2416 - acc: 0.8922 - val_loss: 0.2991 - val_acc: 0.8629\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2498 - acc: 0.8919 - val_loss: 0.2982 - val_acc: 0.8598\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2474 - acc: 0.8820 - val_loss: 0.3110 - val_acc: 0.8567\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2531 - acc: 0.8777 - val_loss: 0.3086 - val_acc: 0.8536\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2569 - acc: 0.8732 - val_loss: 0.2914 - val_acc: 0.8567\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2555 - acc: 0.8875 - val_loss: 0.2883 - val_acc: 0.8660\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2744 - acc: 0.8857 - val_loss: 0.2875 - val_acc: 0.8567\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2633 - acc: 0.8732 - val_loss: 0.2882 - val_acc: 0.8567\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2525 - acc: 0.8844 - val_loss: 0.2908 - val_acc: 0.8660\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2596 - acc: 0.8865 - val_loss: 0.3013 - val_acc: 0.8567\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2575 - acc: 0.8875 - val_loss: 0.2966 - val_acc: 0.8598\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2447 - acc: 0.8802 - val_loss: 0.2980 - val_acc: 0.8629\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2529 - acc: 0.8818 - val_loss: 0.3171 - val_acc: 0.8598\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2668 - acc: 0.8789 - val_loss: 0.3030 - val_acc: 0.8598\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69378, saving model to best_m.h5\n",
      " - 40s - loss: 1.1077 - acc: 0.5396 - val_loss: 0.6938 - val_acc: 0.4798\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69378 to 0.69107, saving model to best_m.h5\n",
      " - 7s - loss: 0.6333 - acc: 0.6294 - val_loss: 0.6911 - val_acc: 0.5047\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69107 to 0.68799, saving model to best_m.h5\n",
      " - 7s - loss: 0.6261 - acc: 0.6352 - val_loss: 0.6880 - val_acc: 0.5826\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 7s - loss: 0.6196 - acc: 0.6544 - val_loss: 0.6895 - val_acc: 0.6262\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68799 to 0.64158, saving model to best_m.h5\n",
      " - 7s - loss: 0.5594 - acc: 0.6826 - val_loss: 0.6416 - val_acc: 0.6791\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.64158 to 0.56390, saving model to best_m.h5\n",
      " - 7s - loss: 0.5431 - acc: 0.7031 - val_loss: 0.5639 - val_acc: 0.7103\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 7s - loss: 0.5465 - acc: 0.7196 - val_loss: 0.5926 - val_acc: 0.6698\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.5374 - acc: 0.7281 - val_loss: 1.7507 - val_acc: 0.6542\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.56390 to 0.47300, saving model to best_m.h5\n",
      " - 7s - loss: 0.5326 - acc: 0.7646 - val_loss: 0.4730 - val_acc: 0.7664\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4721 - acc: 0.7672 - val_loss: 0.5603 - val_acc: 0.7009\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4324 - acc: 0.7929 - val_loss: 3.5284 - val_acc: 0.5857\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4413 - acc: 0.8086 - val_loss: 0.6097 - val_acc: 0.5826\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4327 - acc: 0.8097 - val_loss: 0.6983 - val_acc: 0.6573\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.4085 - acc: 0.8195 - val_loss: 0.5758 - val_acc: 0.6168\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.47300 to 0.37098, saving model to best_m.h5\n",
      " - 7s - loss: 0.4064 - acc: 0.8141 - val_loss: 0.3710 - val_acc: 0.8006\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.37098 to 0.36439, saving model to best_m.h5\n",
      " - 7s - loss: 0.3646 - acc: 0.8304 - val_loss: 0.3644 - val_acc: 0.8162\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.36439 to 0.34229, saving model to best_m.h5\n",
      " - 7s - loss: 0.3559 - acc: 0.8412 - val_loss: 0.3423 - val_acc: 0.8287\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3457 - acc: 0.8601 - val_loss: 0.3632 - val_acc: 0.8037\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.34229 to 0.32540, saving model to best_m.h5\n",
      " - 7s - loss: 0.3509 - acc: 0.8414 - val_loss: 0.3254 - val_acc: 0.8224\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3191 - acc: 0.8531 - val_loss: 0.3388 - val_acc: 0.8193\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3302 - acc: 0.8584 - val_loss: 0.3847 - val_acc: 0.7913\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3422 - acc: 0.8464 - val_loss: 0.4460 - val_acc: 0.7695\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3146 - acc: 0.8539 - val_loss: 0.3603 - val_acc: 0.7944\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3574 - acc: 0.8427 - val_loss: 0.3576 - val_acc: 0.8287\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3307 - acc: 0.8591 - val_loss: 0.3845 - val_acc: 0.8193\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3691 - acc: 0.8378 - val_loss: 0.5055 - val_acc: 0.7445\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3417 - acc: 0.8568 - val_loss: 0.3258 - val_acc: 0.8318\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 8s - loss: 0.3323 - acc: 0.8601 - val_loss: 0.3702 - val_acc: 0.8069\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.2912 - acc: 0.8781 - val_loss: 0.3448 - val_acc: 0.8069\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.3186 - acc: 0.8578 - val_loss: 0.5389 - val_acc: 0.7009\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.32540 to 0.30716, saving model to best_m.h5\n",
      " - 7s - loss: 0.3168 - acc: 0.8617 - val_loss: 0.3072 - val_acc: 0.8411\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.2915 - acc: 0.8831 - val_loss: 0.3104 - val_acc: 0.8411\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2882 - acc: 0.8781 - val_loss: 0.3758 - val_acc: 0.8474\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.3142 - acc: 0.8633 - val_loss: 0.3086 - val_acc: 0.8255\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.2998 - acc: 0.8648 - val_loss: 0.3109 - val_acc: 0.8536\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.30716 to 0.29808, saving model to best_m.h5\n",
      " - 7s - loss: 0.2781 - acc: 0.8755 - val_loss: 0.2981 - val_acc: 0.8660\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss improved from 0.29808 to 0.29323, saving model to best_m.h5\n",
      " - 7s - loss: 0.2767 - acc: 0.8852 - val_loss: 0.2932 - val_acc: 0.8349\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.3004 - acc: 0.8670 - val_loss: 0.3296 - val_acc: 0.8349\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2906 - acc: 0.8693 - val_loss: 0.4486 - val_acc: 0.7664\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2621 - acc: 0.8883 - val_loss: 0.3008 - val_acc: 0.8474\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.29323 to 0.28982, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 7s - loss: 0.2806 - acc: 0.8789 - val_loss: 0.2898 - val_acc: 0.8474\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2904 - acc: 0.8699 - val_loss: 0.3033 - val_acc: 0.8380\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2944 - acc: 0.8742 - val_loss: 0.2985 - val_acc: 0.8474\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2887 - acc: 0.8664 - val_loss: 0.2919 - val_acc: 0.8380\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2699 - acc: 0.8719 - val_loss: 0.3179 - val_acc: 0.8037\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.28982 to 0.28419, saving model to best_m.h5\n",
      " - 7s - loss: 0.2670 - acc: 0.8896 - val_loss: 0.2842 - val_acc: 0.8411\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.28419 to 0.28395, saving model to best_m.h5\n",
      " - 7s - loss: 0.2955 - acc: 0.8857 - val_loss: 0.2839 - val_acc: 0.8474\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2518 - acc: 0.8867 - val_loss: 0.2881 - val_acc: 0.8411\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2722 - acc: 0.8810 - val_loss: 0.2841 - val_acc: 0.8474\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2622 - acc: 0.8849 - val_loss: 0.2872 - val_acc: 0.8567\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.28395 to 0.28388, saving model to best_m.h5\n",
      " - 7s - loss: 0.2696 - acc: 0.8734 - val_loss: 0.2839 - val_acc: 0.8474\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2429 - acc: 0.8841 - val_loss: 0.2849 - val_acc: 0.8380\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.28388 to 0.27880, saving model to best_m.h5\n",
      " - 7s - loss: 0.2378 - acc: 0.9037 - val_loss: 0.2788 - val_acc: 0.8442\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2589 - acc: 0.8820 - val_loss: 0.2791 - val_acc: 0.8629\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2547 - acc: 0.8943 - val_loss: 0.2861 - val_acc: 0.8411\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.27880 to 0.27676, saving model to best_m.h5\n",
      " - 7s - loss: 0.2659 - acc: 0.8859 - val_loss: 0.2768 - val_acc: 0.8442\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2593 - acc: 0.8844 - val_loss: 0.2829 - val_acc: 0.8442\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2327 - acc: 0.8990 - val_loss: 0.2776 - val_acc: 0.8474\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2704 - acc: 0.8859 - val_loss: 0.2797 - val_acc: 0.8505\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2499 - acc: 0.8888 - val_loss: 0.2791 - val_acc: 0.8474\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2451 - acc: 0.8890 - val_loss: 0.2799 - val_acc: 0.8442\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2580 - acc: 0.8883 - val_loss: 0.2793 - val_acc: 0.8474\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2484 - acc: 0.8784 - val_loss: 0.2797 - val_acc: 0.8411\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.27676 to 0.27592, saving model to best_m.h5\n",
      " - 7s - loss: 0.2620 - acc: 0.8859 - val_loss: 0.2759 - val_acc: 0.8536\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2513 - acc: 0.8912 - val_loss: 0.2785 - val_acc: 0.8411\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2352 - acc: 0.8937 - val_loss: 0.2820 - val_acc: 0.8474\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2422 - acc: 0.8841 - val_loss: 0.2789 - val_acc: 0.8380\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2492 - acc: 0.9008 - val_loss: 0.2890 - val_acc: 0.8318\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2361 - acc: 0.9008 - val_loss: 0.2787 - val_acc: 0.8536\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.27592 to 0.27515, saving model to best_m.h5\n",
      " - 7s - loss: 0.2526 - acc: 0.8867 - val_loss: 0.2752 - val_acc: 0.8474\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.27515 to 0.27380, saving model to best_m.h5\n",
      " - 7s - loss: 0.2515 - acc: 0.8912 - val_loss: 0.2738 - val_acc: 0.8567\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2568 - acc: 0.8927 - val_loss: 0.2767 - val_acc: 0.8505\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2403 - acc: 0.8922 - val_loss: 0.2791 - val_acc: 0.8349\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2481 - acc: 0.8828 - val_loss: 0.2801 - val_acc: 0.8474\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2547 - acc: 0.9016 - val_loss: 0.2771 - val_acc: 0.8567\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 7s - loss: 0.2485 - acc: 0.8935 - val_loss: 0.2763 - val_acc: 0.8660\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 7s - loss: 0.2407 - acc: 0.8992 - val_loss: 0.2805 - val_acc: 0.8349\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 7s - loss: 0.2457 - acc: 0.8855 - val_loss: 0.2770 - val_acc: 0.8567\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.27380 to 0.27205, saving model to best_m.h5\n",
      " - 7s - loss: 0.2418 - acc: 0.8945 - val_loss: 0.2720 - val_acc: 0.8754\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 7s - loss: 0.2360 - acc: 0.8886 - val_loss: 0.2844 - val_acc: 0.8380\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 7s - loss: 0.2720 - acc: 0.8860 - val_loss: 0.2727 - val_acc: 0.8505\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 7s - loss: 0.2319 - acc: 0.8859 - val_loss: 0.2736 - val_acc: 0.8598\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 7s - loss: 0.2371 - acc: 0.8945 - val_loss: 0.2723 - val_acc: 0.8598\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 7s - loss: 0.2466 - acc: 0.8841 - val_loss: 0.2885 - val_acc: 0.8442\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss improved from 0.27205 to 0.27161, saving model to best_m.h5\n",
      " - 7s - loss: 0.2290 - acc: 0.9000 - val_loss: 0.2716 - val_acc: 0.8660\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.27161 to 0.26845, saving model to best_m.h5\n",
      " - 7s - loss: 0.2431 - acc: 0.8945 - val_loss: 0.2684 - val_acc: 0.8692\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss improved from 0.26845 to 0.26729, saving model to best_m.h5\n",
      " - 7s - loss: 0.2061 - acc: 0.9148 - val_loss: 0.2673 - val_acc: 0.8629\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 7s - loss: 0.2267 - acc: 0.8966 - val_loss: 0.2691 - val_acc: 0.8660\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 7s - loss: 0.2290 - acc: 0.8945 - val_loss: 0.2713 - val_acc: 0.8474\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 0.2636 - acc: 0.8910 - val_loss: 0.2720 - val_acc: 0.8723\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 7s - loss: 0.2153 - acc: 0.9039 - val_loss: 0.2702 - val_acc: 0.8692\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 7s - loss: 0.2534 - acc: 0.8966 - val_loss: 0.2763 - val_acc: 0.8567\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 7s - loss: 0.2190 - acc: 0.9078 - val_loss: 0.2719 - val_acc: 0.8723\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 7s - loss: 0.2154 - acc: 0.9039 - val_loss: 0.2764 - val_acc: 0.8474\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 7s - loss: 0.2280 - acc: 0.8966 - val_loss: 0.2742 - val_acc: 0.8474\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss improved from 0.26729 to 0.26406, saving model to best_m.h5\n",
      " - 7s - loss: 0.2340 - acc: 0.8945 - val_loss: 0.2641 - val_acc: 0.8723\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 7s - loss: 0.2273 - acc: 0.8966 - val_loss: 0.2701 - val_acc: 0.8660\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 7s - loss: 0.2196 - acc: 0.9094 - val_loss: 0.2727 - val_acc: 0.8536\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 7s - loss: 0.2478 - acc: 0.8980 - val_loss: 0.2711 - val_acc: 0.8660\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 7s - loss: 0.2472 - acc: 0.9027 - val_loss: 0.2742 - val_acc: 0.8723\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 7s - loss: 0.2524 - acc: 0.8880 - val_loss: 0.2704 - val_acc: 0.8785\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 7s - loss: 0.2294 - acc: 0.8920 - val_loss: 0.2672 - val_acc: 0.8629\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 7s - loss: 0.2125 - acc: 0.9154 - val_loss: 0.2694 - val_acc: 0.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 7s - loss: 0.2419 - acc: 0.8977 - val_loss: 0.2643 - val_acc: 0.8692\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 8s - loss: 0.2128 - acc: 0.9094 - val_loss: 0.2648 - val_acc: 0.8598\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 7s - loss: 0.2227 - acc: 0.9062 - val_loss: 0.2656 - val_acc: 0.8598\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 7s - loss: 0.2304 - acc: 0.9133 - val_loss: 0.2647 - val_acc: 0.8754\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 7s - loss: 0.2335 - acc: 0.8964 - val_loss: 0.3035 - val_acc: 0.8567\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 7s - loss: 0.2534 - acc: 0.8951 - val_loss: 0.2675 - val_acc: 0.8692\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 7s - loss: 0.2234 - acc: 0.9055 - val_loss: 0.2802 - val_acc: 0.8567\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 7s - loss: 0.2230 - acc: 0.8945 - val_loss: 0.2683 - val_acc: 0.8723\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 7s - loss: 0.2196 - acc: 0.9023 - val_loss: 0.2675 - val_acc: 0.8723\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 7s - loss: 0.2235 - acc: 0.9045 - val_loss: 0.2646 - val_acc: 0.8754\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 7s - loss: 0.2153 - acc: 0.9068 - val_loss: 0.2683 - val_acc: 0.8598\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 7s - loss: 0.2120 - acc: 0.9031 - val_loss: 0.2689 - val_acc: 0.8505\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 7s - loss: 0.2023 - acc: 0.9070 - val_loss: 0.2661 - val_acc: 0.8629\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69384, saving model to best_m.h5\n",
      " - 44s - loss: 1.0629 - acc: 0.5813 - val_loss: 0.6938 - val_acc: 0.4268\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.6105 - acc: 0.6659 - val_loss: 0.7090 - val_acc: 0.4268\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69384 to 0.68336, saving model to best_m.h5\n",
      " - 7s - loss: 0.5513 - acc: 0.7083 - val_loss: 0.6834 - val_acc: 0.5732\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 7s - loss: 0.5024 - acc: 0.7570 - val_loss: 0.6902 - val_acc: 0.5763\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68336 to 0.65807, saving model to best_m.h5\n",
      " - 7s - loss: 0.5344 - acc: 0.7474 - val_loss: 0.6581 - val_acc: 0.5732\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.65807 to 0.46689, saving model to best_m.h5\n",
      " - 7s - loss: 0.4952 - acc: 0.7609 - val_loss: 0.4669 - val_acc: 0.7695\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.46689 to 0.37884, saving model to best_m.h5\n",
      " - 7s - loss: 0.4621 - acc: 0.7583 - val_loss: 0.3788 - val_acc: 0.8131\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 8s - loss: 0.4914 - acc: 0.7576 - val_loss: 0.5152 - val_acc: 0.7165\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.4892 - acc: 0.7556 - val_loss: 0.5514 - val_acc: 0.7009\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4589 - acc: 0.8047 - val_loss: 0.4679 - val_acc: 0.7570\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4335 - acc: 0.7802 - val_loss: 0.6476 - val_acc: 0.5826\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4205 - acc: 0.7883 - val_loss: 0.4527 - val_acc: 0.7913\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4131 - acc: 0.8286 - val_loss: 0.6266 - val_acc: 0.6417\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.4230 - acc: 0.7898 - val_loss: 0.4640 - val_acc: 0.7819\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.3983 - acc: 0.8123 - val_loss: 0.6960 - val_acc: 0.6355\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.3434 - acc: 0.8380 - val_loss: 0.3880 - val_acc: 0.8131\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.37884 to 0.33035, saving model to best_m.h5\n",
      " - 7s - loss: 0.3305 - acc: 0.8435 - val_loss: 0.3304 - val_acc: 0.8505\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.33035 to 0.29737, saving model to best_m.h5\n",
      " - 7s - loss: 0.3101 - acc: 0.8469 - val_loss: 0.2974 - val_acc: 0.8692\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3240 - acc: 0.8547 - val_loss: 0.3100 - val_acc: 0.8567\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3248 - acc: 0.8459 - val_loss: 0.3413 - val_acc: 0.8598\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3446 - acc: 0.8591 - val_loss: 0.3218 - val_acc: 0.8536\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3149 - acc: 0.8562 - val_loss: 0.3202 - val_acc: 0.8474\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.2802 - acc: 0.8656 - val_loss: 0.3119 - val_acc: 0.8411\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 8s - loss: 0.3224 - acc: 0.8427 - val_loss: 0.3317 - val_acc: 0.8442\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3039 - acc: 0.8568 - val_loss: 0.3309 - val_acc: 0.8318\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.29737 to 0.29347, saving model to best_m.h5\n",
      " - 7s - loss: 0.2774 - acc: 0.8695 - val_loss: 0.2935 - val_acc: 0.8598\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3117 - acc: 0.8521 - val_loss: 0.3005 - val_acc: 0.8505\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.3145 - acc: 0.8527 - val_loss: 0.3721 - val_acc: 0.8069\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3094 - acc: 0.8607 - val_loss: 0.4409 - val_acc: 0.7975\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.29347 to 0.28918, saving model to best_m.h5\n",
      " - 7s - loss: 0.2951 - acc: 0.8607 - val_loss: 0.2892 - val_acc: 0.8754\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 7s - loss: 0.3057 - acc: 0.8685 - val_loss: 0.3464 - val_acc: 0.8349\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.28918 to 0.28111, saving model to best_m.h5\n",
      " - 7s - loss: 0.2835 - acc: 0.8719 - val_loss: 0.2811 - val_acc: 0.8692\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2906 - acc: 0.8675 - val_loss: 0.3154 - val_acc: 0.8474\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2893 - acc: 0.8656 - val_loss: 0.3141 - val_acc: 0.8660\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.28111 to 0.27293, saving model to best_m.h5\n",
      " - 7s - loss: 0.2714 - acc: 0.8703 - val_loss: 0.2729 - val_acc: 0.8910\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.27293 to 0.26568, saving model to best_m.h5\n",
      " - 7s - loss: 0.2479 - acc: 0.8896 - val_loss: 0.2657 - val_acc: 0.8941\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.2852 - acc: 0.8640 - val_loss: 0.3243 - val_acc: 0.8505\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.2830 - acc: 0.8610 - val_loss: 0.3909 - val_acc: 0.7882\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.3061 - acc: 0.8578 - val_loss: 0.2896 - val_acc: 0.8692\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2707 - acc: 0.8652 - val_loss: 0.2897 - val_acc: 0.8598\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2639 - acc: 0.8773 - val_loss: 0.2751 - val_acc: 0.8536\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2592 - acc: 0.8857 - val_loss: 0.2748 - val_acc: 0.8785\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2638 - acc: 0.8820 - val_loss: 0.2898 - val_acc: 0.8785\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2691 - acc: 0.8789 - val_loss: 0.2809 - val_acc: 0.8598\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2359 - acc: 0.8945 - val_loss: 0.3190 - val_acc: 0.8536\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2486 - acc: 0.8844 - val_loss: 0.2747 - val_acc: 0.8816\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2611 - acc: 0.8841 - val_loss: 0.2671 - val_acc: 0.8816\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.26568 to 0.26180, saving model to best_m.h5\n",
      " - 7s - loss: 0.2637 - acc: 0.8773 - val_loss: 0.2618 - val_acc: 0.9003\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.26180 to 0.25129, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 7s - loss: 0.2529 - acc: 0.8945 - val_loss: 0.2513 - val_acc: 0.8879\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2453 - acc: 0.8797 - val_loss: 0.2572 - val_acc: 0.8941\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2363 - acc: 0.8865 - val_loss: 0.2589 - val_acc: 0.9003\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2546 - acc: 0.8724 - val_loss: 0.2534 - val_acc: 0.8910\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.25129 to 0.24557, saving model to best_m.h5\n",
      " - 7s - loss: 0.2444 - acc: 0.8914 - val_loss: 0.2456 - val_acc: 0.8847\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.24557 to 0.24397, saving model to best_m.h5\n",
      " - 7s - loss: 0.2489 - acc: 0.8834 - val_loss: 0.2440 - val_acc: 0.8972\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2273 - acc: 0.8992 - val_loss: 0.2485 - val_acc: 0.8910\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2583 - acc: 0.8761 - val_loss: 0.2599 - val_acc: 0.8816\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2432 - acc: 0.8914 - val_loss: 0.2494 - val_acc: 0.8941\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2359 - acc: 0.8851 - val_loss: 0.2443 - val_acc: 0.8910\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2433 - acc: 0.8961 - val_loss: 0.2590 - val_acc: 0.8660\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2414 - acc: 0.8914 - val_loss: 0.2513 - val_acc: 0.8910\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2668 - acc: 0.8974 - val_loss: 0.2551 - val_acc: 0.8941\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2410 - acc: 0.8992 - val_loss: 0.2485 - val_acc: 0.8879\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2520 - acc: 0.8867 - val_loss: 0.2484 - val_acc: 0.8879\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2442 - acc: 0.8914 - val_loss: 0.2489 - val_acc: 0.8879\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2164 - acc: 0.8992 - val_loss: 0.2489 - val_acc: 0.8847\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2596 - acc: 0.8880 - val_loss: 0.2570 - val_acc: 0.8972\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2387 - acc: 0.8914 - val_loss: 0.2440 - val_acc: 0.8879\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2399 - acc: 0.8898 - val_loss: 0.2493 - val_acc: 0.8785\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2511 - acc: 0.8812 - val_loss: 0.2549 - val_acc: 0.8723\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2351 - acc: 0.8844 - val_loss: 0.2498 - val_acc: 0.9003\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2447 - acc: 0.8894 - val_loss: 0.2516 - val_acc: 0.9003\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2504 - acc: 0.8875 - val_loss: 0.2502 - val_acc: 0.9034\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2402 - acc: 0.8992 - val_loss: 0.2522 - val_acc: 0.8941\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 8s - loss: 0.2356 - acc: 0.8888 - val_loss: 0.2482 - val_acc: 0.8879\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69335, saving model to best_m.h5\n",
      " - 50s - loss: 1.0486 - acc: 0.6266 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.6119 - acc: 0.6321 - val_loss: 0.6957 - val_acc: 0.5000\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69335 to 0.69318, saving model to best_m.h5\n",
      " - 7s - loss: 0.6177 - acc: 0.6492 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69318 to 0.69317, saving model to best_m.h5\n",
      " - 7s - loss: 0.5990 - acc: 0.6321 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.69317 to 0.67458, saving model to best_m.h5\n",
      " - 7s - loss: 0.5608 - acc: 0.7164 - val_loss: 0.6746 - val_acc: 0.5188\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.67458 to 0.61680, saving model to best_m.h5\n",
      " - 7s - loss: 0.5246 - acc: 0.7563 - val_loss: 0.6168 - val_acc: 0.5469\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 7s - loss: 0.5613 - acc: 0.7297 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.5319 - acc: 0.6930 - val_loss: 0.6345 - val_acc: 0.5375\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.61680 to 0.54126, saving model to best_m.h5\n",
      " - 7s - loss: 0.5258 - acc: 0.7547 - val_loss: 0.5413 - val_acc: 0.7031\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4806 - acc: 0.7555 - val_loss: 0.5442 - val_acc: 0.7594\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4519 - acc: 0.7750 - val_loss: 0.7743 - val_acc: 0.5000\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.54126 to 0.37312, saving model to best_m.h5\n",
      " - 7s - loss: 0.4488 - acc: 0.7836 - val_loss: 0.3731 - val_acc: 0.8187\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4236 - acc: 0.7984 - val_loss: 1.1652 - val_acc: 0.5062\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.37312 to 0.34692, saving model to best_m.h5\n",
      " - 7s - loss: 0.4525 - acc: 0.7945 - val_loss: 0.3469 - val_acc: 0.8250\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4039 - acc: 0.8078 - val_loss: 1.7911 - val_acc: 0.5375\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.34692 to 0.32839, saving model to best_m.h5\n",
      " - 7s - loss: 0.4057 - acc: 0.8086 - val_loss: 0.3284 - val_acc: 0.8500\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 7s - loss: 0.3661 - acc: 0.8258 - val_loss: 0.5270 - val_acc: 0.7094\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.32839 to 0.28477, saving model to best_m.h5\n",
      " - 7s - loss: 0.3450 - acc: 0.8289 - val_loss: 0.2848 - val_acc: 0.8656\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3380 - acc: 0.8547 - val_loss: 0.2998 - val_acc: 0.8688\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3289 - acc: 0.8383 - val_loss: 0.3522 - val_acc: 0.8313\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3413 - acc: 0.8594 - val_loss: 0.2849 - val_acc: 0.8594\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3584 - acc: 0.8266 - val_loss: 0.6900 - val_acc: 0.6156\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.2988 - acc: 0.8461 - val_loss: 0.4362 - val_acc: 0.7750\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.28477 to 0.26426, saving model to best_m.h5\n",
      " - 7s - loss: 0.3420 - acc: 0.8454 - val_loss: 0.2643 - val_acc: 0.8750\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3058 - acc: 0.8625 - val_loss: 0.3964 - val_acc: 0.8281\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3217 - acc: 0.8399 - val_loss: 0.2912 - val_acc: 0.8812\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3050 - acc: 0.8508 - val_loss: 0.2863 - val_acc: 0.8625\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.26426 to 0.26360, saving model to best_m.h5\n",
      " - 7s - loss: 0.2870 - acc: 0.8625 - val_loss: 0.2636 - val_acc: 0.8812\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3167 - acc: 0.8648 - val_loss: 0.3241 - val_acc: 0.8531\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.3235 - acc: 0.8469 - val_loss: 0.4081 - val_acc: 0.8094\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.26360 to 0.25886, saving model to best_m.h5\n",
      " - 7s - loss: 0.3323 - acc: 0.8493 - val_loss: 0.2589 - val_acc: 0.8656\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.2977 - acc: 0.8571 - val_loss: 0.2614 - val_acc: 0.8719\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2898 - acc: 0.8555 - val_loss: 0.3214 - val_acc: 0.8344\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2866 - acc: 0.8641 - val_loss: 0.2808 - val_acc: 0.8875\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.25886 to 0.25652, saving model to best_m.h5\n",
      " - 7s - loss: 0.2880 - acc: 0.8680 - val_loss: 0.2565 - val_acc: 0.8844\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.2888 - acc: 0.8734 - val_loss: 0.2868 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.2829 - acc: 0.8695 - val_loss: 0.2610 - val_acc: 0.8625\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.25652 to 0.24370, saving model to best_m.h5\n",
      " - 7s - loss: 0.2880 - acc: 0.8664 - val_loss: 0.2437 - val_acc: 0.8812\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2963 - acc: 0.8688 - val_loss: 0.3788 - val_acc: 0.8094\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2802 - acc: 0.8633 - val_loss: 0.3128 - val_acc: 0.8625\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2920 - acc: 0.8711 - val_loss: 0.3007 - val_acc: 0.8750\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2844 - acc: 0.8640 - val_loss: 0.2828 - val_acc: 0.8750\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2608 - acc: 0.8812 - val_loss: 0.2700 - val_acc: 0.8656\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss improved from 0.24370 to 0.23567, saving model to best_m.h5\n",
      " - 7s - loss: 0.2765 - acc: 0.8726 - val_loss: 0.2357 - val_acc: 0.9062\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2708 - acc: 0.8719 - val_loss: 0.3614 - val_acc: 0.8500\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2581 - acc: 0.8774 - val_loss: 0.2540 - val_acc: 0.8844\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.23567 to 0.23483, saving model to best_m.h5\n",
      " - 7s - loss: 0.2570 - acc: 0.8805 - val_loss: 0.2348 - val_acc: 0.8938\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.23483 to 0.23145, saving model to best_m.h5\n",
      " - 7s - loss: 0.2590 - acc: 0.8852 - val_loss: 0.2315 - val_acc: 0.8906\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2752 - acc: 0.8734 - val_loss: 0.2420 - val_acc: 0.8969\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2967 - acc: 0.8688 - val_loss: 0.2375 - val_acc: 0.9031\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.23145 to 0.23139, saving model to best_m.h5\n",
      " - 7s - loss: 0.2653 - acc: 0.8859 - val_loss: 0.2314 - val_acc: 0.9031\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.23139 to 0.23039, saving model to best_m.h5\n",
      " - 7s - loss: 0.2478 - acc: 0.8906 - val_loss: 0.2304 - val_acc: 0.9000\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2556 - acc: 0.8781 - val_loss: 0.2422 - val_acc: 0.8906\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2546 - acc: 0.8922 - val_loss: 0.2385 - val_acc: 0.9062\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2731 - acc: 0.8844 - val_loss: 0.2477 - val_acc: 0.8969\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2451 - acc: 0.8899 - val_loss: 0.2368 - val_acc: 0.8969\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2717 - acc: 0.8743 - val_loss: 0.2596 - val_acc: 0.8844\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2643 - acc: 0.8781 - val_loss: 0.2355 - val_acc: 0.9031\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.23039 to 0.22999, saving model to best_m.h5\n",
      " - 7s - loss: 0.2651 - acc: 0.8734 - val_loss: 0.2300 - val_acc: 0.9031\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2657 - acc: 0.8789 - val_loss: 0.2581 - val_acc: 0.8844\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2485 - acc: 0.8727 - val_loss: 0.2380 - val_acc: 0.8969\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2697 - acc: 0.8750 - val_loss: 0.2587 - val_acc: 0.8781\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.22999 to 0.22512, saving model to best_m.h5\n",
      " - 7s - loss: 0.2461 - acc: 0.8781 - val_loss: 0.2251 - val_acc: 0.9031\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2633 - acc: 0.8852 - val_loss: 0.2251 - val_acc: 0.8906\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2700 - acc: 0.8742 - val_loss: 0.2255 - val_acc: 0.8875\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2572 - acc: 0.8790 - val_loss: 0.2287 - val_acc: 0.9125\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2553 - acc: 0.8742 - val_loss: 0.2293 - val_acc: 0.9062\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss improved from 0.22512 to 0.22200, saving model to best_m.h5\n",
      " - 7s - loss: 0.2482 - acc: 0.8820 - val_loss: 0.2220 - val_acc: 0.9125\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2452 - acc: 0.8867 - val_loss: 0.2228 - val_acc: 0.9094\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2544 - acc: 0.8695 - val_loss: 0.2332 - val_acc: 0.9000\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2619 - acc: 0.8890 - val_loss: 0.2325 - val_acc: 0.9094\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2433 - acc: 0.8969 - val_loss: 0.2240 - val_acc: 0.8969\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2654 - acc: 0.8812 - val_loss: 0.2248 - val_acc: 0.9125\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2445 - acc: 0.8890 - val_loss: 0.2267 - val_acc: 0.9062\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2670 - acc: 0.8750 - val_loss: 0.2291 - val_acc: 0.9125\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 7s - loss: 0.2477 - acc: 0.8821 - val_loss: 0.2284 - val_acc: 0.9062\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss improved from 0.22200 to 0.22092, saving model to best_m.h5\n",
      " - 7s - loss: 0.2589 - acc: 0.8828 - val_loss: 0.2209 - val_acc: 0.9156\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 7s - loss: 0.2648 - acc: 0.8727 - val_loss: 0.2274 - val_acc: 0.9000\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 7s - loss: 0.2548 - acc: 0.8851 - val_loss: 0.2228 - val_acc: 0.8969\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss improved from 0.22092 to 0.21979, saving model to best_m.h5\n",
      " - 7s - loss: 0.2310 - acc: 0.8922 - val_loss: 0.2198 - val_acc: 0.9125\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 7s - loss: 0.2293 - acc: 0.8922 - val_loss: 0.2245 - val_acc: 0.9094\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 7s - loss: 0.2415 - acc: 0.8805 - val_loss: 0.2449 - val_acc: 0.8875\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss improved from 0.21979 to 0.21957, saving model to best_m.h5\n",
      " - 7s - loss: 0.2433 - acc: 0.8899 - val_loss: 0.2196 - val_acc: 0.9062\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 7s - loss: 0.2406 - acc: 0.8797 - val_loss: 0.2200 - val_acc: 0.9187\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 7s - loss: 0.2695 - acc: 0.8899 - val_loss: 0.2438 - val_acc: 0.9000\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.21957 to 0.21898, saving model to best_m.h5\n",
      " - 7s - loss: 0.2431 - acc: 0.8922 - val_loss: 0.2190 - val_acc: 0.9000\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 7s - loss: 0.2541 - acc: 0.8742 - val_loss: 0.2225 - val_acc: 0.9125\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 7s - loss: 0.2581 - acc: 0.8790 - val_loss: 0.2238 - val_acc: 0.9094\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 7s - loss: 0.2628 - acc: 0.8852 - val_loss: 0.2328 - val_acc: 0.9062\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 0.2496 - acc: 0.8867 - val_loss: 0.2220 - val_acc: 0.9094\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 7s - loss: 0.2490 - acc: 0.8875 - val_loss: 0.2250 - val_acc: 0.9125\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 7s - loss: 0.2484 - acc: 0.8828 - val_loss: 0.2430 - val_acc: 0.9000\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 7s - loss: 0.2604 - acc: 0.8774 - val_loss: 0.2319 - val_acc: 0.9156\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss improved from 0.21898 to 0.21489, saving model to best_m.h5\n",
      " - 7s - loss: 0.2302 - acc: 0.8992 - val_loss: 0.2149 - val_acc: 0.8969\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 7s - loss: 0.2392 - acc: 0.8937 - val_loss: 0.2154 - val_acc: 0.9062\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 7s - loss: 0.2508 - acc: 0.8852 - val_loss: 0.2181 - val_acc: 0.9062\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 7s - loss: 0.2344 - acc: 0.8946 - val_loss: 0.2253 - val_acc: 0.9094\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 7s - loss: 0.2454 - acc: 0.8937 - val_loss: 0.2180 - val_acc: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 7s - loss: 0.2406 - acc: 0.8906 - val_loss: 0.2395 - val_acc: 0.8938\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 7s - loss: 0.2412 - acc: 0.8898 - val_loss: 0.2224 - val_acc: 0.9094\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 7s - loss: 0.2323 - acc: 0.8977 - val_loss: 0.2301 - val_acc: 0.8969\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 7s - loss: 0.2398 - acc: 0.8914 - val_loss: 0.2237 - val_acc: 0.9094\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 7s - loss: 0.2472 - acc: 0.8844 - val_loss: 0.2589 - val_acc: 0.8875\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 7s - loss: 0.2268 - acc: 0.8930 - val_loss: 0.2312 - val_acc: 0.8875\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 7s - loss: 0.2421 - acc: 0.8898 - val_loss: 0.2234 - val_acc: 0.9094\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss improved from 0.21489 to 0.21333, saving model to best_m.h5\n",
      " - 7s - loss: 0.2329 - acc: 0.8992 - val_loss: 0.2133 - val_acc: 0.9031\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 7s - loss: 0.2446 - acc: 0.8890 - val_loss: 0.2290 - val_acc: 0.9031\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 7s - loss: 0.2270 - acc: 0.8953 - val_loss: 0.2221 - val_acc: 0.9125\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 7s - loss: 0.2209 - acc: 0.9023 - val_loss: 0.2278 - val_acc: 0.8906\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 7s - loss: 0.2474 - acc: 0.9000 - val_loss: 0.2268 - val_acc: 0.9000\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 7s - loss: 0.2090 - acc: 0.9062 - val_loss: 0.2229 - val_acc: 0.9031\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 7s - loss: 0.2158 - acc: 0.9008 - val_loss: 0.2191 - val_acc: 0.9031\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 7s - loss: 0.2602 - acc: 0.8820 - val_loss: 0.2199 - val_acc: 0.8938\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 7s - loss: 0.2407 - acc: 0.8898 - val_loss: 0.2183 - val_acc: 0.8969\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 7s - loss: 0.2379 - acc: 0.8883 - val_loss: 0.2217 - val_acc: 0.8906\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 7s - loss: 0.2187 - acc: 0.8930 - val_loss: 0.2327 - val_acc: 0.8969\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 7s - loss: 0.2486 - acc: 0.8844 - val_loss: 0.2153 - val_acc: 0.9000\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 7s - loss: 0.2575 - acc: 0.8915 - val_loss: 0.2353 - val_acc: 0.8875\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 7s - loss: 0.2401 - acc: 0.8914 - val_loss: 0.2139 - val_acc: 0.9062\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 7s - loss: 0.2461 - acc: 0.8867 - val_loss: 0.2200 - val_acc: 0.9094\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=999):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_resnet_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.242099828676\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.479608\n",
      "1  4023181e    0.410470\n",
      "2  b20200e4    0.112072\n",
      "3  e7f018bb    0.989842\n",
      "4  4371c8c3    0.206648\n"
     ]
    }
   ],
   "source": [
    "with open('../features/resnet_aug4_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/resnet_aug4_sub.csv', index=False)\n",
    "# deep2 0.227\n",
    "# deep3 0.223"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

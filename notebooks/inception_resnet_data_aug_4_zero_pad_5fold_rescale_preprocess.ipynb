{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.0005\n",
    "    elif epoch < 30:\n",
    "        return 0.0001\n",
    "    elif epoch < 45:\n",
    "        return 0.00005\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 3\n",
    "    \n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def create_incept_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    \n",
    "    # bn\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = conv2d_bn(x, 64, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "     # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    \n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    x = Conv2D(96, 3, strides=2, padding='same',activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69151, saving model to best_m.h5\n",
      " - 10s - loss: 0.7064 - acc: 0.6154 - val_loss: 0.6915 - val_acc: 0.5389\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.4888 - acc: 0.7718 - val_loss: 0.7333 - val_acc: 0.5389\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4336 - acc: 0.7941 - val_loss: 0.7453 - val_acc: 0.5389\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69151 to 0.68049, saving model to best_m.h5\n",
      " - 6s - loss: 0.4203 - acc: 0.8044 - val_loss: 0.6805 - val_acc: 0.5421\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68049 to 0.58927, saving model to best_m.h5\n",
      " - 6s - loss: 0.4304 - acc: 0.7958 - val_loss: 0.5893 - val_acc: 0.5857\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.58927 to 0.48550, saving model to best_m.h5\n",
      " - 6s - loss: 0.3917 - acc: 0.8292 - val_loss: 0.4855 - val_acc: 0.7726\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.48550 to 0.35620, saving model to best_m.h5\n",
      " - 6s - loss: 0.4110 - acc: 0.8044 - val_loss: 0.3562 - val_acc: 0.8411\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.35620 to 0.35322, saving model to best_m.h5\n",
      " - 6s - loss: 0.3440 - acc: 0.8445 - val_loss: 0.3532 - val_acc: 0.8380\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.35322 to 0.34052, saving model to best_m.h5\n",
      " - 6s - loss: 0.3179 - acc: 0.8453 - val_loss: 0.3405 - val_acc: 0.8069\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4108 - acc: 0.8191 - val_loss: 0.3951 - val_acc: 0.8037\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4398 - acc: 0.7925 - val_loss: 0.3850 - val_acc: 0.7913\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3790 - acc: 0.8177 - val_loss: 0.3930 - val_acc: 0.8069\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.34052 to 0.32653, saving model to best_m.h5\n",
      " - 6s - loss: 0.3212 - acc: 0.8398 - val_loss: 0.3265 - val_acc: 0.8536\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3526 - acc: 0.8427 - val_loss: 0.3657 - val_acc: 0.8100\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3756 - acc: 0.8261 - val_loss: 0.4348 - val_acc: 0.8255\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 6s - loss: 0.2952 - acc: 0.8672 - val_loss: 0.3531 - val_acc: 0.8287\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.32653 to 0.27909, saving model to best_m.h5\n",
      " - 7s - loss: 0.3072 - acc: 0.8779 - val_loss: 0.2791 - val_acc: 0.8598\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.2696 - acc: 0.8805 - val_loss: 0.2842 - val_acc: 0.8567\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3081 - acc: 0.8800 - val_loss: 0.3068 - val_acc: 0.8660\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.27909 to 0.26958, saving model to best_m.h5\n",
      " - 6s - loss: 0.2826 - acc: 0.8797 - val_loss: 0.2696 - val_acc: 0.8692\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.2976 - acc: 0.8652 - val_loss: 0.2717 - val_acc: 0.8660\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 8s - loss: 0.2735 - acc: 0.8738 - val_loss: 0.2728 - val_acc: 0.8692\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.2781 - acc: 0.8781 - val_loss: 0.2728 - val_acc: 0.8754\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 8s - loss: 0.2641 - acc: 0.8826 - val_loss: 0.2798 - val_acc: 0.8598\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 9s - loss: 0.2837 - acc: 0.8734 - val_loss: 0.2817 - val_acc: 0.8629\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2516 - acc: 0.8930 - val_loss: 0.2751 - val_acc: 0.8692\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2595 - acc: 0.8937 - val_loss: 0.2786 - val_acc: 0.8723\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.26958 to 0.26015, saving model to best_m.h5\n",
      " - 6s - loss: 0.2444 - acc: 0.8890 - val_loss: 0.2601 - val_acc: 0.8692\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.2579 - acc: 0.8933 - val_loss: 0.3100 - val_acc: 0.8598\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2382 - acc: 0.8865 - val_loss: 0.2856 - val_acc: 0.8629\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 8s - loss: 0.2656 - acc: 0.8945 - val_loss: 0.2771 - val_acc: 0.8879\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2354 - acc: 0.9023 - val_loss: 0.2999 - val_acc: 0.8660\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 9s - loss: 0.2816 - acc: 0.8790 - val_loss: 0.2801 - val_acc: 0.8847\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2273 - acc: 0.9000 - val_loss: 0.2787 - val_acc: 0.8692\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.2232 - acc: 0.9031 - val_loss: 0.2826 - val_acc: 0.8723\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2233 - acc: 0.9005 - val_loss: 0.2841 - val_acc: 0.8598\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2365 - acc: 0.9016 - val_loss: 0.2839 - val_acc: 0.8660\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2348 - acc: 0.8912 - val_loss: 0.2621 - val_acc: 0.8692\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2246 - acc: 0.9086 - val_loss: 0.2703 - val_acc: 0.8785\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2397 - acc: 0.8980 - val_loss: 0.2644 - val_acc: 0.8816\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2400 - acc: 0.9008 - val_loss: 0.2971 - val_acc: 0.8754\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2174 - acc: 0.9016 - val_loss: 0.2846 - val_acc: 0.8692\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2264 - acc: 0.8984 - val_loss: 0.2710 - val_acc: 0.8816\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2432 - acc: 0.8945 - val_loss: 0.2665 - val_acc: 0.8754\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.1997 - acc: 0.9086 - val_loss: 0.2768 - val_acc: 0.8598\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2259 - acc: 0.9094 - val_loss: 0.2722 - val_acc: 0.8754\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2050 - acc: 0.9062 - val_loss: 0.2795 - val_acc: 0.8879\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2012 - acc: 0.9219 - val_loss: 0.2698 - val_acc: 0.8879\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.68335, saving model to best_m.h5\n",
      " - 14s - loss: 0.7009 - acc: 0.6851 - val_loss: 0.6834 - val_acc: 0.5639\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.4681 - acc: 0.7734 - val_loss: 0.7215 - val_acc: 0.5639\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4153 - acc: 0.8062 - val_loss: 0.6929 - val_acc: 0.5639\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.3859 - acc: 0.8047 - val_loss: 0.6850 - val_acc: 0.5794\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68335 to 0.66970, saving model to best_m.h5\n",
      " - 6s - loss: 0.3851 - acc: 0.8164 - val_loss: 0.6697 - val_acc: 0.7664\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.66970 to 0.62634, saving model to best_m.h5\n",
      " - 6s - loss: 0.3853 - acc: 0.8164 - val_loss: 0.6263 - val_acc: 0.7383\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.62634 to 0.38474, saving model to best_m.h5\n",
      " - 6s - loss: 0.4482 - acc: 0.7894 - val_loss: 0.3847 - val_acc: 0.8349\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.3923 - acc: 0.7980 - val_loss: 0.8053 - val_acc: 0.7290\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.38474 to 0.26983, saving model to best_m.h5\n",
      " - 6s - loss: 0.3832 - acc: 0.8140 - val_loss: 0.2698 - val_acc: 0.8536\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4044 - acc: 0.8265 - val_loss: 0.4227 - val_acc: 0.8069\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3937 - acc: 0.8214 - val_loss: 0.5537 - val_acc: 0.7975\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3848 - acc: 0.8191 - val_loss: 0.3892 - val_acc: 0.7695\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.3764 - acc: 0.8427 - val_loss: 0.2756 - val_acc: 0.8754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3558 - acc: 0.8359 - val_loss: 0.4589 - val_acc: 0.7913\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3385 - acc: 0.8344 - val_loss: 0.2753 - val_acc: 0.8692\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.26983 to 0.24955, saving model to best_m.h5\n",
      " - 6s - loss: 0.3132 - acc: 0.8537 - val_loss: 0.2495 - val_acc: 0.9003\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.24955 to 0.23175, saving model to best_m.h5\n",
      " - 6s - loss: 0.2794 - acc: 0.8726 - val_loss: 0.2317 - val_acc: 0.9159\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.23175 to 0.22925, saving model to best_m.h5\n",
      " - 6s - loss: 0.2985 - acc: 0.8552 - val_loss: 0.2293 - val_acc: 0.8847\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.22925 to 0.22861, saving model to best_m.h5\n",
      " - 6s - loss: 0.3079 - acc: 0.8566 - val_loss: 0.2286 - val_acc: 0.9128\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.22861 to 0.21992, saving model to best_m.h5\n",
      " - 6s - loss: 0.2835 - acc: 0.8755 - val_loss: 0.2199 - val_acc: 0.8692\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.3056 - acc: 0.8545 - val_loss: 0.2409 - val_acc: 0.9034\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2854 - acc: 0.8818 - val_loss: 0.2232 - val_acc: 0.9003\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.21992 to 0.21606, saving model to best_m.h5\n",
      " - 6s - loss: 0.2849 - acc: 0.8633 - val_loss: 0.2161 - val_acc: 0.9128\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2940 - acc: 0.8709 - val_loss: 0.2521 - val_acc: 0.9065\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3057 - acc: 0.8620 - val_loss: 0.2237 - val_acc: 0.9065\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.3089 - acc: 0.8638 - val_loss: 0.2748 - val_acc: 0.8692\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3140 - acc: 0.8513 - val_loss: 0.2405 - val_acc: 0.9034\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2775 - acc: 0.8789 - val_loss: 0.2180 - val_acc: 0.9128\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.21606 to 0.20241, saving model to best_m.h5\n",
      " - 6s - loss: 0.2645 - acc: 0.8688 - val_loss: 0.2024 - val_acc: 0.9221\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2280 - acc: 0.9039 - val_loss: 0.2483 - val_acc: 0.8910\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.20241 to 0.20077, saving model to best_m.h5\n",
      " - 6s - loss: 0.2668 - acc: 0.8836 - val_loss: 0.2008 - val_acc: 0.9221\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.20077 to 0.19413, saving model to best_m.h5\n",
      " - 6s - loss: 0.2727 - acc: 0.8718 - val_loss: 0.1941 - val_acc: 0.9283\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2533 - acc: 0.8898 - val_loss: 0.1986 - val_acc: 0.9128\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2623 - acc: 0.8792 - val_loss: 0.2007 - val_acc: 0.9221\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2736 - acc: 0.8812 - val_loss: 0.2184 - val_acc: 0.9128\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2498 - acc: 0.8836 - val_loss: 0.2028 - val_acc: 0.9128\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2746 - acc: 0.8654 - val_loss: 0.2019 - val_acc: 0.9097\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2558 - acc: 0.8914 - val_loss: 0.1964 - val_acc: 0.9346\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2530 - acc: 0.8836 - val_loss: 0.2070 - val_acc: 0.9190\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2531 - acc: 0.8865 - val_loss: 0.2450 - val_acc: 0.9097\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2814 - acc: 0.8672 - val_loss: 0.2209 - val_acc: 0.9065\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2301 - acc: 0.8883 - val_loss: 0.1971 - val_acc: 0.9097\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2437 - acc: 0.8984 - val_loss: 0.2004 - val_acc: 0.9128\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss improved from 0.19413 to 0.19246, saving model to best_m.h5\n",
      " - 6s - loss: 0.2276 - acc: 0.8937 - val_loss: 0.1925 - val_acc: 0.9159\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2555 - acc: 0.8914 - val_loss: 0.2099 - val_acc: 0.9190\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.19246 to 0.18699, saving model to best_m.h5\n",
      " - 6s - loss: 0.2495 - acc: 0.8820 - val_loss: 0.1870 - val_acc: 0.9346\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.18699 to 0.18532, saving model to best_m.h5\n",
      " - 6s - loss: 0.2259 - acc: 0.9029 - val_loss: 0.1853 - val_acc: 0.9283\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2203 - acc: 0.9047 - val_loss: 0.1867 - val_acc: 0.9283\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2564 - acc: 0.8839 - val_loss: 0.1890 - val_acc: 0.9252\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss improved from 0.18532 to 0.18347, saving model to best_m.h5\n",
      " - 6s - loss: 0.2212 - acc: 0.9109 - val_loss: 0.1835 - val_acc: 0.9346\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.18347 to 0.18318, saving model to best_m.h5\n",
      " - 6s - loss: 0.2254 - acc: 0.8953 - val_loss: 0.1832 - val_acc: 0.9252\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2431 - acc: 0.8959 - val_loss: 0.1863 - val_acc: 0.9190\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2234 - acc: 0.9031 - val_loss: 0.1836 - val_acc: 0.9159\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.18318 to 0.18153, saving model to best_m.h5\n",
      " - 6s - loss: 0.2204 - acc: 0.9008 - val_loss: 0.1815 - val_acc: 0.9252\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2447 - acc: 0.8865 - val_loss: 0.1822 - val_acc: 0.9252\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2191 - acc: 0.8953 - val_loss: 0.1822 - val_acc: 0.9283\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2469 - acc: 0.8875 - val_loss: 0.1873 - val_acc: 0.9221\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2114 - acc: 0.9078 - val_loss: 0.1857 - val_acc: 0.9252\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2367 - acc: 0.8867 - val_loss: 0.1867 - val_acc: 0.9252\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2323 - acc: 0.8976 - val_loss: 0.1853 - val_acc: 0.9252\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2233 - acc: 0.9029 - val_loss: 0.1834 - val_acc: 0.9315\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2351 - acc: 0.8930 - val_loss: 0.1844 - val_acc: 0.9128\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2190 - acc: 0.8992 - val_loss: 0.1863 - val_acc: 0.9252\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2180 - acc: 0.8969 - val_loss: 0.1837 - val_acc: 0.9221\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2318 - acc: 0.8974 - val_loss: 0.1826 - val_acc: 0.9221\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2229 - acc: 0.8945 - val_loss: 0.1834 - val_acc: 0.9221\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.2285 - acc: 0.9047 - val_loss: 0.1857 - val_acc: 0.9097\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2397 - acc: 0.8912 - val_loss: 0.1883 - val_acc: 0.9097\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2194 - acc: 0.9000 - val_loss: 0.1878 - val_acc: 0.9159\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.2242 - acc: 0.9047 - val_loss: 0.1838 - val_acc: 0.9252\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.2270 - acc: 0.9037 - val_loss: 0.1901 - val_acc: 0.9159\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2095 - acc: 0.9045 - val_loss: 0.1849 - val_acc: 0.9159\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.2089 - acc: 0.8984 - val_loss: 0.1874 - val_acc: 0.9128\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.2234 - acc: 0.9078 - val_loss: 0.1880 - val_acc: 0.9065\n",
      "============================\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001: val_loss improved from inf to 0.71297, saving model to best_m.h5\n",
      " - 19s - loss: 0.6743 - acc: 0.6734 - val_loss: 0.7130 - val_acc: 0.5327\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.4636 - acc: 0.7784 - val_loss: 0.7492 - val_acc: 0.5327\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4200 - acc: 0.8086 - val_loss: 1.0043 - val_acc: 0.5327\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4099 - acc: 0.8029 - val_loss: 1.3124 - val_acc: 0.5327\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.3652 - acc: 0.8271 - val_loss: 1.2926 - val_acc: 0.5327\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.71297 to 0.68425, saving model to best_m.h5\n",
      " - 6s - loss: 0.3634 - acc: 0.8365 - val_loss: 0.6842 - val_acc: 0.5421\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.68425 to 0.39181, saving model to best_m.h5\n",
      " - 6s - loss: 0.3472 - acc: 0.8320 - val_loss: 0.3918 - val_acc: 0.8006\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4239 - acc: 0.7863 - val_loss: 0.5111 - val_acc: 0.8100\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.39181 to 0.33657, saving model to best_m.h5\n",
      " - 6s - loss: 0.3489 - acc: 0.8359 - val_loss: 0.3366 - val_acc: 0.8567\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3866 - acc: 0.8372 - val_loss: 0.4406 - val_acc: 0.7944\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3608 - acc: 0.8367 - val_loss: 0.9320 - val_acc: 0.6355\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.33657 to 0.31466, saving model to best_m.h5\n",
      " - 6s - loss: 0.3266 - acc: 0.8570 - val_loss: 0.3147 - val_acc: 0.8598\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.31466 to 0.28967, saving model to best_m.h5\n",
      " - 6s - loss: 0.3223 - acc: 0.8383 - val_loss: 0.2897 - val_acc: 0.8847\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3408 - acc: 0.8310 - val_loss: 0.2908 - val_acc: 0.8692\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3153 - acc: 0.8422 - val_loss: 0.3162 - val_acc: 0.8505\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.28967 to 0.26765, saving model to best_m.h5\n",
      " - 6s - loss: 0.2861 - acc: 0.8726 - val_loss: 0.2676 - val_acc: 0.8910\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.2821 - acc: 0.8670 - val_loss: 0.2721 - val_acc: 0.8816\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.26765 to 0.24888, saving model to best_m.h5\n",
      " - 6s - loss: 0.2709 - acc: 0.8805 - val_loss: 0.2489 - val_acc: 0.8972\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.2833 - acc: 0.8792 - val_loss: 0.2693 - val_acc: 0.8660\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.24888 to 0.24246, saving model to best_m.h5\n",
      " - 6s - loss: 0.2592 - acc: 0.8904 - val_loss: 0.2425 - val_acc: 0.9003\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2450 - acc: 0.8930 - val_loss: 0.2448 - val_acc: 0.8941\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2832 - acc: 0.8805 - val_loss: 0.2491 - val_acc: 0.8754\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2417 - acc: 0.8906 - val_loss: 0.2637 - val_acc: 0.8785\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2589 - acc: 0.8873 - val_loss: 0.2965 - val_acc: 0.8598\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2298 - acc: 0.9023 - val_loss: 0.2628 - val_acc: 0.8816\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2147 - acc: 0.9109 - val_loss: 0.2526 - val_acc: 0.8754\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2435 - acc: 0.8922 - val_loss: 0.2749 - val_acc: 0.8785\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2080 - acc: 0.9078 - val_loss: 0.2644 - val_acc: 0.8816\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2680 - acc: 0.8888 - val_loss: 0.2607 - val_acc: 0.8847\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2500 - acc: 0.8966 - val_loss: 0.2480 - val_acc: 0.8972\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2057 - acc: 0.9172 - val_loss: 0.2535 - val_acc: 0.8972\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.24246 to 0.24012, saving model to best_m.h5\n",
      " - 6s - loss: 0.2432 - acc: 0.8904 - val_loss: 0.2401 - val_acc: 0.9003\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2031 - acc: 0.9107 - val_loss: 0.2434 - val_acc: 0.8847\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2188 - acc: 0.9047 - val_loss: 0.2459 - val_acc: 0.8972\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2357 - acc: 0.9027 - val_loss: 0.2993 - val_acc: 0.8474\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.24012 to 0.23517, saving model to best_m.h5\n",
      " - 6s - loss: 0.2271 - acc: 0.9013 - val_loss: 0.2352 - val_acc: 0.8941\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss improved from 0.23517 to 0.23097, saving model to best_m.h5\n",
      " - 6s - loss: 0.2238 - acc: 0.8992 - val_loss: 0.2310 - val_acc: 0.8847\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2203 - acc: 0.9068 - val_loss: 0.2368 - val_acc: 0.8879\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2152 - acc: 0.9076 - val_loss: 0.3031 - val_acc: 0.8723\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2321 - acc: 0.8898 - val_loss: 0.2384 - val_acc: 0.8910\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.23097 to 0.22713, saving model to best_m.h5\n",
      " - 6s - loss: 0.2434 - acc: 0.8898 - val_loss: 0.2271 - val_acc: 0.8847\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2249 - acc: 0.9011 - val_loss: 0.2342 - val_acc: 0.8754\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.22713 to 0.22265, saving model to best_m.h5\n",
      " - 6s - loss: 0.2191 - acc: 0.9035 - val_loss: 0.2227 - val_acc: 0.8879\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2078 - acc: 0.9031 - val_loss: 0.2330 - val_acc: 0.8879\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2085 - acc: 0.9084 - val_loss: 0.2301 - val_acc: 0.8879\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.1969 - acc: 0.9180 - val_loss: 0.2321 - val_acc: 0.8941\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.1996 - acc: 0.9076 - val_loss: 0.2351 - val_acc: 0.8879\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2237 - acc: 0.9066 - val_loss: 0.2246 - val_acc: 0.8941\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.1781 - acc: 0.9226 - val_loss: 0.2290 - val_acc: 0.9003\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2118 - acc: 0.9115 - val_loss: 0.2313 - val_acc: 0.8972\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2029 - acc: 0.9156 - val_loss: 0.2303 - val_acc: 0.8972\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.1940 - acc: 0.9169 - val_loss: 0.2365 - val_acc: 0.8972\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.1880 - acc: 0.9164 - val_loss: 0.2306 - val_acc: 0.8941\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.1915 - acc: 0.9162 - val_loss: 0.2328 - val_acc: 0.8879\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.1991 - acc: 0.9099 - val_loss: 0.2313 - val_acc: 0.8941\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.1991 - acc: 0.9094 - val_loss: 0.2304 - val_acc: 0.8816\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.1843 - acc: 0.9219 - val_loss: 0.2403 - val_acc: 0.8941\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.1952 - acc: 0.9167 - val_loss: 0.2373 - val_acc: 0.8847\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.1835 - acc: 0.9201 - val_loss: 0.2365 - val_acc: 0.8879\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2036 - acc: 0.9074 - val_loss: 0.2405 - val_acc: 0.8910\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.1943 - acc: 0.9133 - val_loss: 0.2335 - val_acc: 0.8879\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2049 - acc: 0.9084 - val_loss: 0.2365 - val_acc: 0.8910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.1915 - acc: 0.9219 - val_loss: 0.2401 - val_acc: 0.8910\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69875, saving model to best_m.h5\n",
      " - 26s - loss: 0.7067 - acc: 0.6427 - val_loss: 0.6988 - val_acc: 0.4860\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5204 - acc: 0.7456 - val_loss: 0.8960 - val_acc: 0.4860\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4703 - acc: 0.7597 - val_loss: 1.3599 - val_acc: 0.4860\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4242 - acc: 0.7968 - val_loss: 2.0140 - val_acc: 0.4860\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.4329 - acc: 0.8084 - val_loss: 1.0839 - val_acc: 0.4860\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.69875 to 0.60864, saving model to best_m.h5\n",
      " - 6s - loss: 0.4172 - acc: 0.8044 - val_loss: 0.6086 - val_acc: 0.5576\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.60864 to 0.30963, saving model to best_m.h5\n",
      " - 6s - loss: 0.3441 - acc: 0.8429 - val_loss: 0.3096 - val_acc: 0.8723\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.30963 to 0.29873, saving model to best_m.h5\n",
      " - 6s - loss: 0.3450 - acc: 0.8453 - val_loss: 0.2987 - val_acc: 0.8536\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.3529 - acc: 0.8437 - val_loss: 0.4359 - val_acc: 0.8629\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3964 - acc: 0.8255 - val_loss: 0.4855 - val_acc: 0.7850\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3893 - acc: 0.8294 - val_loss: 0.3307 - val_acc: 0.8318\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.29873 to 0.28973, saving model to best_m.h5\n",
      " - 6s - loss: 0.3234 - acc: 0.8539 - val_loss: 0.2897 - val_acc: 0.8567\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.28973 to 0.28737, saving model to best_m.h5\n",
      " - 6s - loss: 0.3686 - acc: 0.8188 - val_loss: 0.2874 - val_acc: 0.8629\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3109 - acc: 0.8555 - val_loss: 0.2949 - val_acc: 0.8723\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.28737 to 0.28291, saving model to best_m.h5\n",
      " - 6s - loss: 0.3139 - acc: 0.8570 - val_loss: 0.2829 - val_acc: 0.8723\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.28291 to 0.25193, saving model to best_m.h5\n",
      " - 6s - loss: 0.3062 - acc: 0.8529 - val_loss: 0.2519 - val_acc: 0.8754\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.25193 to 0.24987, saving model to best_m.h5\n",
      " - 6s - loss: 0.2770 - acc: 0.8805 - val_loss: 0.2499 - val_acc: 0.8785\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.24987 to 0.24661, saving model to best_m.h5\n",
      " - 6s - loss: 0.2683 - acc: 0.8773 - val_loss: 0.2466 - val_acc: 0.8879\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.2687 - acc: 0.8648 - val_loss: 0.2505 - val_acc: 0.8941\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2538 - acc: 0.8883 - val_loss: 0.2583 - val_acc: 0.8847\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.24661 to 0.24350, saving model to best_m.h5\n",
      " - 6s - loss: 0.2890 - acc: 0.8670 - val_loss: 0.2435 - val_acc: 0.8972\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.24350 to 0.24254, saving model to best_m.h5\n",
      " - 6s - loss: 0.2545 - acc: 0.8922 - val_loss: 0.2425 - val_acc: 0.8972\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2930 - acc: 0.8693 - val_loss: 0.2462 - val_acc: 0.8879\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2540 - acc: 0.8875 - val_loss: 0.2461 - val_acc: 0.8847\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2733 - acc: 0.8841 - val_loss: 0.2493 - val_acc: 0.9128\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2627 - acc: 0.8719 - val_loss: 0.2589 - val_acc: 0.8847\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2782 - acc: 0.8750 - val_loss: 0.3258 - val_acc: 0.8816\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.2840 - acc: 0.8701 - val_loss: 0.2478 - val_acc: 0.8785\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2832 - acc: 0.8849 - val_loss: 0.2486 - val_acc: 0.8785\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.24254 to 0.24108, saving model to best_m.h5\n",
      " - 6s - loss: 0.2704 - acc: 0.8722 - val_loss: 0.2411 - val_acc: 0.8941\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2462 - acc: 0.8922 - val_loss: 0.2441 - val_acc: 0.8972\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2275 - acc: 0.8984 - val_loss: 0.2466 - val_acc: 0.8941\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2833 - acc: 0.8860 - val_loss: 0.2609 - val_acc: 0.8910\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2319 - acc: 0.8912 - val_loss: 0.2510 - val_acc: 0.8941\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2444 - acc: 0.8930 - val_loss: 0.2444 - val_acc: 0.8941\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.24108 to 0.22984, saving model to best_m.h5\n",
      " - 6s - loss: 0.2341 - acc: 0.9000 - val_loss: 0.2298 - val_acc: 0.8972\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2348 - acc: 0.8922 - val_loss: 0.2373 - val_acc: 0.8910\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2080 - acc: 0.9125 - val_loss: 0.2323 - val_acc: 0.9097\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.22984 to 0.22975, saving model to best_m.h5\n",
      " - 6s - loss: 0.2269 - acc: 0.9035 - val_loss: 0.2297 - val_acc: 0.9190\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2378 - acc: 0.8937 - val_loss: 0.2527 - val_acc: 0.8972\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2184 - acc: 0.9031 - val_loss: 0.2367 - val_acc: 0.8941\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2264 - acc: 0.8968 - val_loss: 0.2344 - val_acc: 0.9034\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2172 - acc: 0.9117 - val_loss: 0.2396 - val_acc: 0.9034\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2274 - acc: 0.8953 - val_loss: 0.2537 - val_acc: 0.9003\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2230 - acc: 0.8998 - val_loss: 0.2517 - val_acc: 0.8972\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2165 - acc: 0.9062 - val_loss: 0.2380 - val_acc: 0.9097\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2184 - acc: 0.8912 - val_loss: 0.2362 - val_acc: 0.9065\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2186 - acc: 0.9183 - val_loss: 0.2305 - val_acc: 0.9128\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2418 - acc: 0.8976 - val_loss: 0.2363 - val_acc: 0.9128\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2132 - acc: 0.9078 - val_loss: 0.2345 - val_acc: 0.9128\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.1944 - acc: 0.9141 - val_loss: 0.2372 - val_acc: 0.9097\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2213 - acc: 0.9016 - val_loss: 0.2372 - val_acc: 0.9128\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2349 - acc: 0.8922 - val_loss: 0.2410 - val_acc: 0.9128\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.1884 - acc: 0.9187 - val_loss: 0.2364 - val_acc: 0.9097\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2198 - acc: 0.9031 - val_loss: 0.2349 - val_acc: 0.9097\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2135 - acc: 0.9000 - val_loss: 0.2347 - val_acc: 0.9065\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2046 - acc: 0.9140 - val_loss: 0.2380 - val_acc: 0.9065\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.1974 - acc: 0.9039 - val_loss: 0.2332 - val_acc: 0.9097\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2226 - acc: 0.9023 - val_loss: 0.2342 - val_acc: 0.9034\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69040, saving model to best_m.h5\n",
      " - 30s - loss: 0.6913 - acc: 0.6422 - val_loss: 0.6904 - val_acc: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.4915 - acc: 0.7563 - val_loss: 0.9883 - val_acc: 0.5312\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4516 - acc: 0.7765 - val_loss: 1.2898 - val_acc: 0.5312\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4376 - acc: 0.8055 - val_loss: 0.8213 - val_acc: 0.5312\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.69040 to 0.58113, saving model to best_m.h5\n",
      " - 6s - loss: 0.4255 - acc: 0.7977 - val_loss: 0.5811 - val_acc: 0.5656\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.58113 to 0.43974, saving model to best_m.h5\n",
      " - 6s - loss: 0.3829 - acc: 0.8289 - val_loss: 0.4397 - val_acc: 0.7969\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.43974 to 0.34853, saving model to best_m.h5\n",
      " - 6s - loss: 0.3812 - acc: 0.8226 - val_loss: 0.3485 - val_acc: 0.8500\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.3296 - acc: 0.8375 - val_loss: 0.7979 - val_acc: 0.6562\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.3507 - acc: 0.8406 - val_loss: 0.3701 - val_acc: 0.8031\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.3878 - acc: 0.8102 - val_loss: 0.4548 - val_acc: 0.8094\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3311 - acc: 0.8406 - val_loss: 0.3607 - val_acc: 0.8219\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3758 - acc: 0.8189 - val_loss: 0.4253 - val_acc: 0.8094\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.3539 - acc: 0.8500 - val_loss: 0.3732 - val_acc: 0.8250\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.34853 to 0.30644, saving model to best_m.h5\n",
      " - 6s - loss: 0.3229 - acc: 0.8515 - val_loss: 0.3064 - val_acc: 0.8531\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.30644 to 0.27910, saving model to best_m.h5\n",
      " - 7s - loss: 0.3688 - acc: 0.8383 - val_loss: 0.2791 - val_acc: 0.8719\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.27910 to 0.26925, saving model to best_m.h5\n",
      " - 6s - loss: 0.2972 - acc: 0.8672 - val_loss: 0.2692 - val_acc: 0.8812\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.26925 to 0.26922, saving model to best_m.h5\n",
      " - 6s - loss: 0.2982 - acc: 0.8539 - val_loss: 0.2692 - val_acc: 0.8812\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.2566 - acc: 0.8867 - val_loss: 0.2889 - val_acc: 0.8719\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.26922 to 0.25749, saving model to best_m.h5\n",
      " - 6s - loss: 0.2993 - acc: 0.8657 - val_loss: 0.2575 - val_acc: 0.8906\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.2769 - acc: 0.8680 - val_loss: 0.2622 - val_acc: 0.8781\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.3248 - acc: 0.8587 - val_loss: 0.3158 - val_acc: 0.8656\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2681 - acc: 0.8703 - val_loss: 0.2585 - val_acc: 0.8781\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2602 - acc: 0.8844 - val_loss: 0.2632 - val_acc: 0.8875\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2574 - acc: 0.8875 - val_loss: 0.2826 - val_acc: 0.8812\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.25749 to 0.24931, saving model to best_m.h5\n",
      " - 6s - loss: 0.2504 - acc: 0.8859 - val_loss: 0.2493 - val_acc: 0.8938\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2737 - acc: 0.8735 - val_loss: 0.2644 - val_acc: 0.8969\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2605 - acc: 0.8875 - val_loss: 0.2580 - val_acc: 0.8844\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.24931 to 0.24840, saving model to best_m.h5\n",
      " - 6s - loss: 0.2479 - acc: 0.8805 - val_loss: 0.2484 - val_acc: 0.8812\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2512 - acc: 0.8836 - val_loss: 0.2689 - val_acc: 0.8812\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2832 - acc: 0.8680 - val_loss: 0.2599 - val_acc: 0.8844\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.24840 to 0.24186, saving model to best_m.h5\n",
      " - 6s - loss: 0.2363 - acc: 0.8898 - val_loss: 0.2419 - val_acc: 0.8875\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.24186 to 0.23954, saving model to best_m.h5\n",
      " - 6s - loss: 0.2472 - acc: 0.8914 - val_loss: 0.2395 - val_acc: 0.9031\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2519 - acc: 0.8860 - val_loss: 0.2497 - val_acc: 0.8938\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2507 - acc: 0.8914 - val_loss: 0.2565 - val_acc: 0.8938\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2196 - acc: 0.9039 - val_loss: 0.2434 - val_acc: 0.9125\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2432 - acc: 0.8969 - val_loss: 0.2547 - val_acc: 0.8938\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2351 - acc: 0.9024 - val_loss: 0.2776 - val_acc: 0.8750\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2051 - acc: 0.9070 - val_loss: 0.2736 - val_acc: 0.8875\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2222 - acc: 0.8961 - val_loss: 0.2397 - val_acc: 0.8969\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2347 - acc: 0.9016 - val_loss: 0.2519 - val_acc: 0.8906\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2316 - acc: 0.8945 - val_loss: 0.2421 - val_acc: 0.8844\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2263 - acc: 0.9016 - val_loss: 0.2450 - val_acc: 0.9062\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2186 - acc: 0.9000 - val_loss: 0.2410 - val_acc: 0.8938\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss improved from 0.23954 to 0.23434, saving model to best_m.h5\n",
      " - 6s - loss: 0.2185 - acc: 0.9063 - val_loss: 0.2343 - val_acc: 0.9156\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.1971 - acc: 0.9086 - val_loss: 0.2474 - val_acc: 0.9062\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.23434 to 0.22948, saving model to best_m.h5\n",
      " - 6s - loss: 0.2060 - acc: 0.9078 - val_loss: 0.2295 - val_acc: 0.9156\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2195 - acc: 0.8977 - val_loss: 0.2318 - val_acc: 0.9219\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.22948 to 0.22940, saving model to best_m.h5\n",
      " - 6s - loss: 0.2217 - acc: 0.8969 - val_loss: 0.2294 - val_acc: 0.9187\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.22940 to 0.22935, saving model to best_m.h5\n",
      " - 6s - loss: 0.2185 - acc: 0.9047 - val_loss: 0.2293 - val_acc: 0.9156\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2120 - acc: 0.9070 - val_loss: 0.2326 - val_acc: 0.9219\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.22935 to 0.22933, saving model to best_m.h5\n",
      " - 6s - loss: 0.2448 - acc: 0.9016 - val_loss: 0.2293 - val_acc: 0.9156\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2099 - acc: 0.9101 - val_loss: 0.2320 - val_acc: 0.9219\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.22933 to 0.22828, saving model to best_m.h5\n",
      " - 6s - loss: 0.2109 - acc: 0.9062 - val_loss: 0.2283 - val_acc: 0.9156\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.2069 - acc: 0.9062 - val_loss: 0.2333 - val_acc: 0.9062\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2038 - acc: 0.9063 - val_loss: 0.2311 - val_acc: 0.9156\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.1774 - acc: 0.9273 - val_loss: 0.2327 - val_acc: 0.9156\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.1912 - acc: 0.9195 - val_loss: 0.2306 - val_acc: 0.9125\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.1928 - acc: 0.9156 - val_loss: 0.2294 - val_acc: 0.9125\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2177 - acc: 0.8992 - val_loss: 0.2286 - val_acc: 0.9187\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss improved from 0.22828 to 0.22612, saving model to best_m.h5\n",
      " - 6s - loss: 0.2161 - acc: 0.8977 - val_loss: 0.2261 - val_acc: 0.9187\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2103 - acc: 0.9117 - val_loss: 0.2297 - val_acc: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.1818 - acc: 0.9266 - val_loss: 0.2280 - val_acc: 0.9125\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.1910 - acc: 0.9203 - val_loss: 0.2272 - val_acc: 0.9156\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.22612 to 0.22608, saving model to best_m.h5\n",
      " - 6s - loss: 0.2045 - acc: 0.9195 - val_loss: 0.2261 - val_acc: 0.9156\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2103 - acc: 0.9016 - val_loss: 0.2263 - val_acc: 0.9094\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2022 - acc: 0.9196 - val_loss: 0.2262 - val_acc: 0.9187\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.1849 - acc: 0.9226 - val_loss: 0.2297 - val_acc: 0.9219\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.1898 - acc: 0.9172 - val_loss: 0.2292 - val_acc: 0.9187\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.1808 - acc: 0.9164 - val_loss: 0.2303 - val_acc: 0.9187\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.1814 - acc: 0.9195 - val_loss: 0.2301 - val_acc: 0.9156\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.1966 - acc: 0.9164 - val_loss: 0.2263 - val_acc: 0.9219\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.1856 - acc: 0.9180 - val_loss: 0.2320 - val_acc: 0.9156\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.1942 - acc: 0.9149 - val_loss: 0.2293 - val_acc: 0.9250\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.1911 - acc: 0.9164 - val_loss: 0.2323 - val_acc: 0.9156\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2033 - acc: 0.9031 - val_loss: 0.2338 - val_acc: 0.9187\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.1813 - acc: 0.9234 - val_loss: 0.2285 - val_acc: 0.9250\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 7s - loss: 0.1813 - acc: 0.9219 - val_loss: 0.2297 - val_acc: 0.9187\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.1761 - acc: 0.9266 - val_loss: 0.2291 - val_acc: 0.9156\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.2102 - acc: 0.9062 - val_loss: 0.2296 - val_acc: 0.9187\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.1864 - acc: 0.9180 - val_loss: 0.2298 - val_acc: 0.9187\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.1929 - acc: 0.9203 - val_loss: 0.2278 - val_acc: 0.9250\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.1925 - acc: 0.9094 - val_loss: 0.2298 - val_acc: 0.9219\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2062 - acc: 0.9086 - val_loss: 0.2374 - val_acc: 0.9094\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.1968 - acc: 0.9031 - val_loss: 0.2312 - val_acc: 0.9219\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=99):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_incept_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224029977288\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.381580\n",
      "1  4023181e    0.371532\n",
      "2  b20200e4    0.250473\n",
      "3  e7f018bb    0.998929\n",
      "4  4371c8c3    0.201019\n"
     ]
    }
   ],
   "source": [
    "with open('../features/incept_aug4_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/incept_aug4_sub.csv', index=False)\n",
    "# deep2 0.2110\n",
    "# deep3 0.2119\n",
    "\n",
    "# pre 2290\n",
    "# new 2240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, strides=2, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69470, saving model to best_m.h5\n",
      " - 60s - loss: 0.9460 - acc: 0.5997 - val_loss: 0.6947 - val_acc: 0.4735\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69470 to 0.69363, saving model to best_m.h5\n",
      " - 7s - loss: 0.6006 - acc: 0.6505 - val_loss: 0.6936 - val_acc: 0.5265\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69363 to 0.68148, saving model to best_m.h5\n",
      " - 7s - loss: 0.5950 - acc: 0.6755 - val_loss: 0.6815 - val_acc: 0.5265\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68148 to 0.66741, saving model to best_m.h5\n",
      " - 7s - loss: 0.5895 - acc: 0.6708 - val_loss: 0.6674 - val_acc: 0.5265\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.66741 to 0.60875, saving model to best_m.h5\n",
      " - 7s - loss: 0.5317 - acc: 0.7044 - val_loss: 0.6087 - val_acc: 0.5265\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 7s - loss: 0.5495 - acc: 0.7181 - val_loss: 0.6829 - val_acc: 0.5514\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.60875 to 0.53724, saving model to best_m.h5\n",
      " - 8s - loss: 0.5261 - acc: 0.7347 - val_loss: 0.5372 - val_acc: 0.6916\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.4849 - acc: 0.7547 - val_loss: 0.6168 - val_acc: 0.5670\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.5031 - acc: 0.7507 - val_loss: 0.6618 - val_acc: 0.5265\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4595 - acc: 0.7769 - val_loss: 0.7397 - val_acc: 0.5265\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4543 - acc: 0.7836 - val_loss: 1.5953 - val_acc: 0.5265\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4650 - acc: 0.8008 - val_loss: 0.7305 - val_acc: 0.5327\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.53724 to 0.41451, saving model to best_m.h5\n",
      " - 7s - loss: 0.4420 - acc: 0.7933 - val_loss: 0.4145 - val_acc: 0.7757\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.3999 - acc: 0.8008 - val_loss: 0.7816 - val_acc: 0.6760\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4835 - acc: 0.7825 - val_loss: 0.6225 - val_acc: 0.5670\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.41451 to 0.36259, saving model to best_m.h5\n",
      " - 7s - loss: 0.3996 - acc: 0.8023 - val_loss: 0.3626 - val_acc: 0.8442\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 7s - loss: 0.3887 - acc: 0.8081 - val_loss: 0.4566 - val_acc: 0.7539\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.36259 to 0.32010, saving model to best_m.h5\n",
      " - 7s - loss: 0.3691 - acc: 0.8281 - val_loss: 0.3201 - val_acc: 0.8816\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3432 - acc: 0.8326 - val_loss: 0.3223 - val_acc: 0.8692\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.32010 to 0.28014, saving model to best_m.h5\n",
      " - 7s - loss: 0.3337 - acc: 0.8438 - val_loss: 0.2801 - val_acc: 0.8972\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3807 - acc: 0.8125 - val_loss: 0.4759 - val_acc: 0.6791\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.28014 to 0.26441, saving model to best_m.h5\n",
      " - 7s - loss: 0.3475 - acc: 0.8198 - val_loss: 0.2644 - val_acc: 0.8910\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3299 - acc: 0.8383 - val_loss: 0.2990 - val_acc: 0.8785\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3286 - acc: 0.8459 - val_loss: 0.2901 - val_acc: 0.8785\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.26441 to 0.25150, saving model to best_m.h5\n",
      " - 7s - loss: 0.3306 - acc: 0.8375 - val_loss: 0.2515 - val_acc: 0.9034\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3176 - acc: 0.8271 - val_loss: 0.2911 - val_acc: 0.8692\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3259 - acc: 0.8500 - val_loss: 0.2899 - val_acc: 0.8754\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.3211 - acc: 0.8427 - val_loss: 0.3148 - val_acc: 0.8754\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3371 - acc: 0.8258 - val_loss: 0.2737 - val_acc: 0.9159\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.2957 - acc: 0.8508 - val_loss: 0.4007 - val_acc: 0.8069\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.25150 to 0.23812, saving model to best_m.h5\n",
      " - 7s - loss: 0.3138 - acc: 0.8341 - val_loss: 0.2381 - val_acc: 0.9190\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.3001 - acc: 0.8615 - val_loss: 0.2549 - val_acc: 0.9034\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.3177 - acc: 0.8284 - val_loss: 0.2552 - val_acc: 0.8941\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2887 - acc: 0.8609 - val_loss: 0.2456 - val_acc: 0.9065\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.23812 to 0.23337, saving model to best_m.h5\n",
      " - 7s - loss: 0.2973 - acc: 0.8547 - val_loss: 0.2334 - val_acc: 0.9003\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.3104 - acc: 0.8508 - val_loss: 0.2582 - val_acc: 0.9065\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.3047 - acc: 0.8445 - val_loss: 0.2689 - val_acc: 0.9128\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.2947 - acc: 0.8644 - val_loss: 0.2417 - val_acc: 0.9128\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2997 - acc: 0.8508 - val_loss: 0.2556 - val_acc: 0.9003\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2927 - acc: 0.8570 - val_loss: 0.2439 - val_acc: 0.9034\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.3003 - acc: 0.8464 - val_loss: 0.2730 - val_acc: 0.8816\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.3156 - acc: 0.8552 - val_loss: 0.2882 - val_acc: 0.8879\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 8s - loss: 0.2902 - acc: 0.8641 - val_loss: 0.2786 - val_acc: 0.9003\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2844 - acc: 0.8591 - val_loss: 0.3497 - val_acc: 0.8474\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 8s - loss: 0.2908 - acc: 0.8672 - val_loss: 0.2526 - val_acc: 0.9097\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2644 - acc: 0.8687 - val_loss: 0.2437 - val_acc: 0.9159\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 8s - loss: 0.2925 - acc: 0.8654 - val_loss: 0.2481 - val_acc: 0.9159\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2843 - acc: 0.8734 - val_loss: 0.2476 - val_acc: 0.8972\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2897 - acc: 0.8537 - val_loss: 0.2496 - val_acc: 0.9128\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2765 - acc: 0.8719 - val_loss: 0.2662 - val_acc: 0.9065\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2787 - acc: 0.8636 - val_loss: 0.2516 - val_acc: 0.9034\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2846 - acc: 0.8664 - val_loss: 0.2519 - val_acc: 0.9065\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2716 - acc: 0.8716 - val_loss: 0.2466 - val_acc: 0.8941\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2915 - acc: 0.8521 - val_loss: 0.2420 - val_acc: 0.9034\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2761 - acc: 0.8687 - val_loss: 0.2401 - val_acc: 0.9065\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2789 - acc: 0.8748 - val_loss: 0.2489 - val_acc: 0.8941\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2849 - acc: 0.8636 - val_loss: 0.2460 - val_acc: 0.9003\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2959 - acc: 0.8583 - val_loss: 0.2443 - val_acc: 0.8972\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2625 - acc: 0.8641 - val_loss: 0.2460 - val_acc: 0.8816\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2852 - acc: 0.8638 - val_loss: 0.2725 - val_acc: 0.8972\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2489 - acc: 0.8836 - val_loss: 0.2688 - val_acc: 0.8941\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2855 - acc: 0.8601 - val_loss: 0.2452 - val_acc: 0.8972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2698 - acc: 0.8586 - val_loss: 0.2471 - val_acc: 0.9034\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2729 - acc: 0.8781 - val_loss: 0.2444 - val_acc: 0.9034\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.3244 - acc: 0.8585 - val_loss: 0.2586 - val_acc: 0.8910\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.68965, saving model to best_m.h5\n",
      " - 62s - loss: 1.0577 - acc: 0.6154 - val_loss: 0.6897 - val_acc: 0.5327\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.5996 - acc: 0.6757 - val_loss: 0.6952 - val_acc: 0.5327\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 7s - loss: 0.5619 - acc: 0.7034 - val_loss: 0.6943 - val_acc: 0.5327\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68965 to 0.65973, saving model to best_m.h5\n",
      " - 7s - loss: 0.5470 - acc: 0.7333 - val_loss: 0.6597 - val_acc: 0.5327\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.65973 to 0.59508, saving model to best_m.h5\n",
      " - 8s - loss: 0.5278 - acc: 0.7412 - val_loss: 0.5951 - val_acc: 0.5389\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.59508 to 0.59032, saving model to best_m.h5\n",
      " - 8s - loss: 0.5100 - acc: 0.7648 - val_loss: 0.5903 - val_acc: 0.5950\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.59032 to 0.44824, saving model to best_m.h5\n",
      " - 7s - loss: 0.4767 - acc: 0.7771 - val_loss: 0.4482 - val_acc: 0.7850\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.5112 - acc: 0.7601 - val_loss: 0.5379 - val_acc: 0.6667\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.5221 - acc: 0.7513 - val_loss: 1.0717 - val_acc: 0.6417\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.44824 to 0.43151, saving model to best_m.h5\n",
      " - 7s - loss: 0.4782 - acc: 0.7847 - val_loss: 0.4315 - val_acc: 0.8069\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4574 - acc: 0.7935 - val_loss: 0.5841 - val_acc: 0.5607\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.43151 to 0.40802, saving model to best_m.h5\n",
      " - 7s - loss: 0.4757 - acc: 0.7943 - val_loss: 0.4080 - val_acc: 0.7913\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4398 - acc: 0.8021 - val_loss: 0.4871 - val_acc: 0.7570\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.4282 - acc: 0.7919 - val_loss: 0.4265 - val_acc: 0.7383\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4311 - acc: 0.7945 - val_loss: 0.9333 - val_acc: 0.6199\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.40802 to 0.40336, saving model to best_m.h5\n",
      " - 7s - loss: 0.3650 - acc: 0.8146 - val_loss: 0.4034 - val_acc: 0.7695\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.40336 to 0.33841, saving model to best_m.h5\n",
      " - 7s - loss: 0.4035 - acc: 0.8048 - val_loss: 0.3384 - val_acc: 0.8411\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.33841 to 0.33654, saving model to best_m.h5\n",
      " - 7s - loss: 0.3544 - acc: 0.8438 - val_loss: 0.3365 - val_acc: 0.8474\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3243 - acc: 0.8568 - val_loss: 0.4318 - val_acc: 0.7632\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3561 - acc: 0.8240 - val_loss: 0.5116 - val_acc: 0.7570\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.33654 to 0.29963, saving model to best_m.h5\n",
      " - 7s - loss: 0.3219 - acc: 0.8539 - val_loss: 0.2996 - val_acc: 0.8411\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3317 - acc: 0.8484 - val_loss: 0.3656 - val_acc: 0.8380\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3391 - acc: 0.8398 - val_loss: 0.4361 - val_acc: 0.7850\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3032 - acc: 0.8599 - val_loss: 0.3260 - val_acc: 0.8474\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3140 - acc: 0.8492 - val_loss: 0.5690 - val_acc: 0.6978\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3174 - acc: 0.8586 - val_loss: 0.3699 - val_acc: 0.8224\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3062 - acc: 0.8625 - val_loss: 0.3256 - val_acc: 0.8505\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.3013 - acc: 0.8576 - val_loss: 0.3441 - val_acc: 0.8505\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.29963 to 0.29048, saving model to best_m.h5\n",
      " - 7s - loss: 0.2988 - acc: 0.8599 - val_loss: 0.2905 - val_acc: 0.8567\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.3171 - acc: 0.8453 - val_loss: 0.3164 - val_acc: 0.8349\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 7s - loss: 0.3058 - acc: 0.8568 - val_loss: 0.3641 - val_acc: 0.8349\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.3087 - acc: 0.8537 - val_loss: 0.3217 - val_acc: 0.8380\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2927 - acc: 0.8617 - val_loss: 0.3301 - val_acc: 0.8567\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2804 - acc: 0.8732 - val_loss: 0.3146 - val_acc: 0.8660\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.3119 - acc: 0.8508 - val_loss: 0.3278 - val_acc: 0.8442\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.2954 - acc: 0.8630 - val_loss: 0.3146 - val_acc: 0.8411\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.2788 - acc: 0.8734 - val_loss: 0.5532 - val_acc: 0.7414\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.2831 - acc: 0.8719 - val_loss: 0.3228 - val_acc: 0.8474\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2938 - acc: 0.8688 - val_loss: 0.3165 - val_acc: 0.8536\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2924 - acc: 0.8595 - val_loss: 0.3418 - val_acc: 0.8349\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2886 - acc: 0.8537 - val_loss: 0.3510 - val_acc: 0.8536\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2307 - acc: 0.9039 - val_loss: 0.3165 - val_acc: 0.8474\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2633 - acc: 0.8727 - val_loss: 0.3331 - val_acc: 0.8442\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.3053 - acc: 0.8576 - val_loss: 0.3621 - val_acc: 0.8318\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2466 - acc: 0.8812 - val_loss: 0.3048 - val_acc: 0.8536\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2632 - acc: 0.8709 - val_loss: 0.2994 - val_acc: 0.8754\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2775 - acc: 0.8669 - val_loss: 0.3294 - val_acc: 0.8505\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2578 - acc: 0.8755 - val_loss: 0.3422 - val_acc: 0.8411\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2646 - acc: 0.8680 - val_loss: 0.3038 - val_acc: 0.8567\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2592 - acc: 0.8726 - val_loss: 0.3009 - val_acc: 0.8598\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2513 - acc: 0.8740 - val_loss: 0.3185 - val_acc: 0.8474\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2559 - acc: 0.8820 - val_loss: 0.3305 - val_acc: 0.8442\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2901 - acc: 0.8644 - val_loss: 0.3167 - val_acc: 0.8474\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2460 - acc: 0.8906 - val_loss: 0.3057 - val_acc: 0.8598\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.3038 - acc: 0.8599 - val_loss: 0.3183 - val_acc: 0.8536\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2481 - acc: 0.8844 - val_loss: 0.3118 - val_acc: 0.8598\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2659 - acc: 0.8797 - val_loss: 0.3107 - val_acc: 0.8598\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2617 - acc: 0.8640 - val_loss: 0.3392 - val_acc: 0.8411\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2796 - acc: 0.8646 - val_loss: 0.3745 - val_acc: 0.8442\n",
      "============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69182, saving model to best_m.h5\n",
      " - 64s - loss: 1.1470 - acc: 0.5790 - val_loss: 0.6918 - val_acc: 0.5202\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.6351 - acc: 0.6507 - val_loss: 0.6919 - val_acc: 0.5202\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69182 to 0.69082, saving model to best_m.h5\n",
      " - 8s - loss: 0.6028 - acc: 0.6786 - val_loss: 0.6908 - val_acc: 0.5202\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69082 to 0.66788, saving model to best_m.h5\n",
      " - 8s - loss: 0.5685 - acc: 0.7058 - val_loss: 0.6679 - val_acc: 0.5202\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.66788 to 0.62576, saving model to best_m.h5\n",
      " - 8s - loss: 0.5605 - acc: 0.7226 - val_loss: 0.6258 - val_acc: 0.5202\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.62576 to 0.51077, saving model to best_m.h5\n",
      " - 8s - loss: 0.5101 - acc: 0.7320 - val_loss: 0.5108 - val_acc: 0.6698\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.51077 to 0.50882, saving model to best_m.h5\n",
      " - 8s - loss: 0.5320 - acc: 0.7427 - val_loss: 0.5088 - val_acc: 0.7570\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 0.5019 - acc: 0.7427 - val_loss: 0.5403 - val_acc: 0.6106\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 8s - loss: 0.4819 - acc: 0.7630 - val_loss: 0.5383 - val_acc: 0.6542\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.4661 - acc: 0.7703 - val_loss: 0.6401 - val_acc: 0.5576\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.4373 - acc: 0.7953 - val_loss: 0.6003 - val_acc: 0.5202\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.5088 - acc: 0.7091 - val_loss: 0.5771 - val_acc: 0.6791\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4544 - acc: 0.7687 - val_loss: 0.5965 - val_acc: 0.6075\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.50882 to 0.44886, saving model to best_m.h5\n",
      " - 8s - loss: 0.4438 - acc: 0.7919 - val_loss: 0.4489 - val_acc: 0.7290\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4106 - acc: 0.8086 - val_loss: 0.9588 - val_acc: 0.5421\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.3549 - acc: 0.8445 - val_loss: 0.4586 - val_acc: 0.7726\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.44886 to 0.37852, saving model to best_m.h5\n",
      " - 8s - loss: 0.3838 - acc: 0.8310 - val_loss: 0.3785 - val_acc: 0.7788\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.37852 to 0.34023, saving model to best_m.h5\n",
      " - 8s - loss: 0.3168 - acc: 0.8443 - val_loss: 0.3402 - val_acc: 0.8287\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3711 - acc: 0.8277 - val_loss: 0.3687 - val_acc: 0.8100\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.34023 to 0.33327, saving model to best_m.h5\n",
      " - 8s - loss: 0.3224 - acc: 0.8508 - val_loss: 0.3333 - val_acc: 0.8442\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3566 - acc: 0.8451 - val_loss: 0.3903 - val_acc: 0.8069\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3203 - acc: 0.8453 - val_loss: 0.3794 - val_acc: 0.8131\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3265 - acc: 0.8492 - val_loss: 0.3412 - val_acc: 0.8287\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3224 - acc: 0.8574 - val_loss: 0.5840 - val_acc: 0.7196\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3300 - acc: 0.8472 - val_loss: 0.3741 - val_acc: 0.8037\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3490 - acc: 0.8419 - val_loss: 0.3338 - val_acc: 0.8349\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3158 - acc: 0.8435 - val_loss: 0.3377 - val_acc: 0.8287\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 7s - loss: 0.2965 - acc: 0.8521 - val_loss: 0.5592 - val_acc: 0.6916\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3003 - acc: 0.8630 - val_loss: 0.4281 - val_acc: 0.7508\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.2978 - acc: 0.8648 - val_loss: 0.3850 - val_acc: 0.7975\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.33327 to 0.32003, saving model to best_m.h5\n",
      " - 8s - loss: 0.3195 - acc: 0.8576 - val_loss: 0.3200 - val_acc: 0.8349\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.32003 to 0.31830, saving model to best_m.h5\n",
      " - 8s - loss: 0.2963 - acc: 0.8632 - val_loss: 0.3183 - val_acc: 0.8380\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.3072 - acc: 0.8641 - val_loss: 0.3274 - val_acc: 0.8380\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.31830 to 0.30859, saving model to best_m.h5\n",
      " - 8s - loss: 0.2849 - acc: 0.8740 - val_loss: 0.3086 - val_acc: 0.8536\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.30859 to 0.30568, saving model to best_m.h5\n",
      " - 8s - loss: 0.3046 - acc: 0.8498 - val_loss: 0.3057 - val_acc: 0.8442\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.2754 - acc: 0.8709 - val_loss: 0.3889 - val_acc: 0.7788\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss improved from 0.30568 to 0.30561, saving model to best_m.h5\n",
      " - 8s - loss: 0.2841 - acc: 0.8633 - val_loss: 0.3056 - val_acc: 0.8380\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.2838 - acc: 0.8685 - val_loss: 0.3099 - val_acc: 0.8411\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.3091 - acc: 0.8446 - val_loss: 0.3657 - val_acc: 0.8100\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.3056 - acc: 0.8670 - val_loss: 0.3243 - val_acc: 0.8411\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.2668 - acc: 0.8709 - val_loss: 0.3175 - val_acc: 0.8442\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2755 - acc: 0.8701 - val_loss: 0.3228 - val_acc: 0.8380\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.30561 to 0.29456, saving model to best_m.h5\n",
      " - 8s - loss: 0.2804 - acc: 0.8750 - val_loss: 0.2946 - val_acc: 0.8349\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2795 - acc: 0.8818 - val_loss: 0.4653 - val_acc: 0.7321\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.29456 to 0.28751, saving model to best_m.h5\n",
      " - 8s - loss: 0.2667 - acc: 0.8820 - val_loss: 0.2875 - val_acc: 0.8505\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2598 - acc: 0.8828 - val_loss: 0.2888 - val_acc: 0.8442\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2669 - acc: 0.8719 - val_loss: 0.2960 - val_acc: 0.8318\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2738 - acc: 0.8765 - val_loss: 0.2916 - val_acc: 0.8411\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2608 - acc: 0.8789 - val_loss: 0.2914 - val_acc: 0.8474\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2472 - acc: 0.8875 - val_loss: 0.2901 - val_acc: 0.8474\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2731 - acc: 0.8800 - val_loss: 0.2931 - val_acc: 0.8474\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2529 - acc: 0.8836 - val_loss: 0.2970 - val_acc: 0.8411\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2670 - acc: 0.8657 - val_loss: 0.2891 - val_acc: 0.8380\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2574 - acc: 0.8851 - val_loss: 0.2909 - val_acc: 0.8411\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2385 - acc: 0.8898 - val_loss: 0.2909 - val_acc: 0.8318\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2475 - acc: 0.8716 - val_loss: 0.2907 - val_acc: 0.8411\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2348 - acc: 0.8820 - val_loss: 0.2943 - val_acc: 0.8287\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2730 - acc: 0.8727 - val_loss: 0.2959 - val_acc: 0.8380\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2622 - acc: 0.8828 - val_loss: 0.2919 - val_acc: 0.8474\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2505 - acc: 0.8818 - val_loss: 0.2905 - val_acc: 0.8442\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2490 - acc: 0.8750 - val_loss: 0.2988 - val_acc: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2601 - acc: 0.8859 - val_loss: 0.2911 - val_acc: 0.8442\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2491 - acc: 0.8930 - val_loss: 0.2910 - val_acc: 0.8442\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2356 - acc: 0.8865 - val_loss: 0.2916 - val_acc: 0.8411\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2327 - acc: 0.8896 - val_loss: 0.2983 - val_acc: 0.8442\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2457 - acc: 0.8873 - val_loss: 0.2906 - val_acc: 0.8474\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2401 - acc: 0.8937 - val_loss: 0.2923 - val_acc: 0.8380\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2369 - acc: 0.8828 - val_loss: 0.2978 - val_acc: 0.8380\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2104 - acc: 0.9131 - val_loss: 0.3049 - val_acc: 0.8411\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2612 - acc: 0.8773 - val_loss: 0.2986 - val_acc: 0.8318\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2245 - acc: 0.9031 - val_loss: 0.2918 - val_acc: 0.8442\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2501 - acc: 0.8951 - val_loss: 0.2922 - val_acc: 0.8318\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2304 - acc: 0.9021 - val_loss: 0.2897 - val_acc: 0.8411\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2608 - acc: 0.8787 - val_loss: 0.3027 - val_acc: 0.8380\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2564 - acc: 0.8716 - val_loss: 0.2911 - val_acc: 0.8411\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69331, saving model to best_m.h5\n",
      " - 69s - loss: 1.0534 - acc: 0.5708 - val_loss: 0.6933 - val_acc: 0.4299\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69331 to 0.69063, saving model to best_m.h5\n",
      " - 8s - loss: 0.6043 - acc: 0.6597 - val_loss: 0.6906 - val_acc: 0.5732\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 7s - loss: 0.5945 - acc: 0.6968 - val_loss: 0.6960 - val_acc: 0.4268\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 7s - loss: 0.6054 - acc: 0.6470 - val_loss: 0.6911 - val_acc: 0.5109\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.69063 to 0.68238, saving model to best_m.h5\n",
      " - 7s - loss: 0.5999 - acc: 0.6726 - val_loss: 0.6824 - val_acc: 0.5296\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.68238 to 0.58781, saving model to best_m.h5\n",
      " - 7s - loss: 0.5697 - acc: 0.6851 - val_loss: 0.5878 - val_acc: 0.6573\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 7s - loss: 0.5322 - acc: 0.7159 - val_loss: 0.6057 - val_acc: 0.5794\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.58781 to 0.58464, saving model to best_m.h5\n",
      " - 8s - loss: 0.5115 - acc: 0.7271 - val_loss: 0.5846 - val_acc: 0.6231\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.5404 - acc: 0.7188 - val_loss: 1.0951 - val_acc: 0.7103\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.58464 to 0.45817, saving model to best_m.h5\n",
      " - 8s - loss: 0.5121 - acc: 0.7500 - val_loss: 0.4582 - val_acc: 0.8349\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 0.5379 - acc: 0.6984 - val_loss: 0.5970 - val_acc: 0.6511\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.5180 - acc: 0.7359 - val_loss: 0.6004 - val_acc: 0.5888\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4770 - acc: 0.7601 - val_loss: 0.9994 - val_acc: 0.6012\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 7s - loss: 0.4450 - acc: 0.7951 - val_loss: 0.5692 - val_acc: 0.6854\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4603 - acc: 0.7693 - val_loss: 0.9860 - val_acc: 0.6667\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.4587 - acc: 0.7667 - val_loss: 0.4883 - val_acc: 0.8037\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.45817 to 0.37178, saving model to best_m.h5\n",
      " - 8s - loss: 0.4041 - acc: 0.8164 - val_loss: 0.3718 - val_acc: 0.8567\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3844 - acc: 0.8200 - val_loss: 0.4049 - val_acc: 0.8442\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.4065 - acc: 0.8220 - val_loss: 0.3802 - val_acc: 0.8536\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 7s - loss: 0.3603 - acc: 0.8297 - val_loss: 0.4130 - val_acc: 0.8287\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.37178 to 0.33680, saving model to best_m.h5\n",
      " - 8s - loss: 0.3715 - acc: 0.8255 - val_loss: 0.3368 - val_acc: 0.8411\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3648 - acc: 0.8292 - val_loss: 0.6130 - val_acc: 0.5888\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3594 - acc: 0.8269 - val_loss: 0.3647 - val_acc: 0.8567\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3444 - acc: 0.8383 - val_loss: 0.3505 - val_acc: 0.8692\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3640 - acc: 0.8422 - val_loss: 0.4039 - val_acc: 0.8287\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.33680 to 0.31404, saving model to best_m.h5\n",
      " - 8s - loss: 0.3319 - acc: 0.8352 - val_loss: 0.3140 - val_acc: 0.8567\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3340 - acc: 0.8375 - val_loss: 0.5118 - val_acc: 0.7290\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.31404 to 0.30665, saving model to best_m.h5\n",
      " - 8s - loss: 0.3151 - acc: 0.8537 - val_loss: 0.3066 - val_acc: 0.8785\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3513 - acc: 0.8300 - val_loss: 0.3264 - val_acc: 0.8567\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 0.3219 - acc: 0.8445 - val_loss: 0.3074 - val_acc: 0.8723\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 7s - loss: 0.2945 - acc: 0.8547 - val_loss: 0.3069 - val_acc: 0.8567\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.30665 to 0.28242, saving model to best_m.h5\n",
      " - 8s - loss: 0.2670 - acc: 0.8648 - val_loss: 0.2824 - val_acc: 0.8692\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.3473 - acc: 0.8443 - val_loss: 0.3190 - val_acc: 0.8754\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.3045 - acc: 0.8648 - val_loss: 0.3068 - val_acc: 0.8660\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.2922 - acc: 0.8576 - val_loss: 0.6756 - val_acc: 0.6698\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.28242 to 0.26567, saving model to best_m.h5\n",
      " - 8s - loss: 0.2895 - acc: 0.8734 - val_loss: 0.2657 - val_acc: 0.8629\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.3159 - acc: 0.8539 - val_loss: 0.3607 - val_acc: 0.8692\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.3047 - acc: 0.8656 - val_loss: 0.3358 - val_acc: 0.8629\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.2909 - acc: 0.8602 - val_loss: 0.3114 - val_acc: 0.8785\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2957 - acc: 0.8531 - val_loss: 0.2960 - val_acc: 0.8567\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.3099 - acc: 0.8599 - val_loss: 0.3493 - val_acc: 0.8287\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.3246 - acc: 0.8584 - val_loss: 0.3005 - val_acc: 0.8785\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2813 - acc: 0.8623 - val_loss: 0.2848 - val_acc: 0.8785\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.3013 - acc: 0.8648 - val_loss: 0.2936 - val_acc: 0.8660\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2972 - acc: 0.8595 - val_loss: 0.3261 - val_acc: 0.8536\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2971 - acc: 0.8633 - val_loss: 0.2960 - val_acc: 0.8567\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2556 - acc: 0.8769 - val_loss: 0.2920 - val_acc: 0.8629\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2629 - acc: 0.8828 - val_loss: 0.2980 - val_acc: 0.8629\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2584 - acc: 0.8742 - val_loss: 0.2815 - val_acc: 0.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2557 - acc: 0.8781 - val_loss: 0.2689 - val_acc: 0.8785\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.26567 to 0.26457, saving model to best_m.h5\n",
      " - 7s - loss: 0.3043 - acc: 0.8441 - val_loss: 0.2646 - val_acc: 0.8785\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 7s - loss: 0.2724 - acc: 0.8740 - val_loss: 0.2727 - val_acc: 0.8816\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.26457 to 0.26283, saving model to best_m.h5\n",
      " - 8s - loss: 0.2750 - acc: 0.8672 - val_loss: 0.2628 - val_acc: 0.8723\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2716 - acc: 0.8773 - val_loss: 0.2674 - val_acc: 0.8754\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2799 - acc: 0.8638 - val_loss: 0.2807 - val_acc: 0.8785\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2835 - acc: 0.8828 - val_loss: 0.2785 - val_acc: 0.8754\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2602 - acc: 0.8672 - val_loss: 0.2717 - val_acc: 0.8754\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2672 - acc: 0.8805 - val_loss: 0.2722 - val_acc: 0.8785\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.2657 - acc: 0.8703 - val_loss: 0.2719 - val_acc: 0.8785\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 7s - loss: 0.2636 - acc: 0.8818 - val_loss: 0.2822 - val_acc: 0.8785\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 8s - loss: 0.2632 - acc: 0.8738 - val_loss: 0.2842 - val_acc: 0.8723\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2586 - acc: 0.8789 - val_loss: 0.2712 - val_acc: 0.8723\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2694 - acc: 0.8609 - val_loss: 0.2855 - val_acc: 0.8785\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2509 - acc: 0.8734 - val_loss: 0.2708 - val_acc: 0.8723\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2665 - acc: 0.8773 - val_loss: 0.2908 - val_acc: 0.8754\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2637 - acc: 0.8758 - val_loss: 0.2710 - val_acc: 0.8723\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 7s - loss: 0.2654 - acc: 0.8787 - val_loss: 0.2968 - val_acc: 0.8754\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2763 - acc: 0.8687 - val_loss: 0.2705 - val_acc: 0.8785\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss improved from 0.26283 to 0.26063, saving model to best_m.h5\n",
      " - 8s - loss: 0.2707 - acc: 0.8781 - val_loss: 0.2606 - val_acc: 0.8785\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2495 - acc: 0.8857 - val_loss: 0.2675 - val_acc: 0.8785\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.26063 to 0.25877, saving model to best_m.h5\n",
      " - 8s - loss: 0.2407 - acc: 0.8695 - val_loss: 0.2588 - val_acc: 0.8723\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2461 - acc: 0.8922 - val_loss: 0.2597 - val_acc: 0.8754\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2756 - acc: 0.8576 - val_loss: 0.2708 - val_acc: 0.8785\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2489 - acc: 0.8890 - val_loss: 0.2907 - val_acc: 0.8847\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2461 - acc: 0.8836 - val_loss: 0.2666 - val_acc: 0.8660\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 7s - loss: 0.2597 - acc: 0.8826 - val_loss: 0.2749 - val_acc: 0.8754\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 7s - loss: 0.2392 - acc: 0.8771 - val_loss: 0.2764 - val_acc: 0.8785\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 7s - loss: 0.2440 - acc: 0.8867 - val_loss: 0.2631 - val_acc: 0.8785\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 7s - loss: 0.2947 - acc: 0.8693 - val_loss: 0.2658 - val_acc: 0.8754\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 7s - loss: 0.2487 - acc: 0.8734 - val_loss: 0.2597 - val_acc: 0.8629\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 7s - loss: 0.2644 - acc: 0.8709 - val_loss: 0.2619 - val_acc: 0.8692\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 7s - loss: 0.2505 - acc: 0.8787 - val_loss: 0.2704 - val_acc: 0.8723\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss improved from 0.25877 to 0.25853, saving model to best_m.h5\n",
      " - 8s - loss: 0.2571 - acc: 0.8755 - val_loss: 0.2585 - val_acc: 0.8754\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss improved from 0.25853 to 0.25612, saving model to best_m.h5\n",
      " - 8s - loss: 0.2507 - acc: 0.8701 - val_loss: 0.2561 - val_acc: 0.8723\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 7s - loss: 0.2475 - acc: 0.8927 - val_loss: 0.2654 - val_acc: 0.8754\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 7s - loss: 0.2533 - acc: 0.8781 - val_loss: 0.2604 - val_acc: 0.8692\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 7s - loss: 0.2579 - acc: 0.8841 - val_loss: 0.2825 - val_acc: 0.8754\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 7s - loss: 0.2440 - acc: 0.8797 - val_loss: 0.2570 - val_acc: 0.8660\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.25612 to 0.25442, saving model to best_m.h5\n",
      " - 8s - loss: 0.2311 - acc: 0.8976 - val_loss: 0.2544 - val_acc: 0.8660\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 0.2503 - acc: 0.8859 - val_loss: 0.2656 - val_acc: 0.8660\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 7s - loss: 0.2439 - acc: 0.8841 - val_loss: 0.2648 - val_acc: 0.8660\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 7s - loss: 0.2486 - acc: 0.8820 - val_loss: 0.2868 - val_acc: 0.8723\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 7s - loss: 0.2544 - acc: 0.8820 - val_loss: 0.2571 - val_acc: 0.8692\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 7s - loss: 0.2370 - acc: 0.8937 - val_loss: 0.2570 - val_acc: 0.8692\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 7s - loss: 0.2248 - acc: 0.8937 - val_loss: 0.2576 - val_acc: 0.8660\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 7s - loss: 0.2637 - acc: 0.8851 - val_loss: 0.2654 - val_acc: 0.8692\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 7s - loss: 0.2505 - acc: 0.8781 - val_loss: 0.2619 - val_acc: 0.8567\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 7s - loss: 0.2429 - acc: 0.8896 - val_loss: 0.2748 - val_acc: 0.8598\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 7s - loss: 0.2479 - acc: 0.8763 - val_loss: 0.2718 - val_acc: 0.8598\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 7s - loss: 0.2546 - acc: 0.8828 - val_loss: 0.2654 - val_acc: 0.8754\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 7s - loss: 0.2425 - acc: 0.8852 - val_loss: 0.2695 - val_acc: 0.8692\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 7s - loss: 0.2316 - acc: 0.8828 - val_loss: 0.2759 - val_acc: 0.8660\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 7s - loss: 0.2550 - acc: 0.8836 - val_loss: 0.2749 - val_acc: 0.8692\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 7s - loss: 0.2430 - acc: 0.8852 - val_loss: 0.2655 - val_acc: 0.8567\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 7s - loss: 0.2405 - acc: 0.8904 - val_loss: 0.2741 - val_acc: 0.8660\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 7s - loss: 0.2438 - acc: 0.8828 - val_loss: 0.2801 - val_acc: 0.8692\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 7s - loss: 0.2369 - acc: 0.8953 - val_loss: 0.2711 - val_acc: 0.8629\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 7s - loss: 0.2604 - acc: 0.8703 - val_loss: 0.2690 - val_acc: 0.8629\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 7s - loss: 0.2394 - acc: 0.8765 - val_loss: 0.2618 - val_acc: 0.8692\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 7s - loss: 0.2202 - acc: 0.8844 - val_loss: 0.2631 - val_acc: 0.8629\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 7s - loss: 0.2672 - acc: 0.8810 - val_loss: 0.2627 - val_acc: 0.8660\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 7s - loss: 0.2227 - acc: 0.8935 - val_loss: 0.2704 - val_acc: 0.8505\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 7s - loss: 0.2614 - acc: 0.8812 - val_loss: 0.2630 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 7s - loss: 0.2547 - acc: 0.8750 - val_loss: 0.2782 - val_acc: 0.8785\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 7s - loss: 0.2346 - acc: 0.8894 - val_loss: 0.3027 - val_acc: 0.8629\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 7s - loss: 0.2314 - acc: 0.8898 - val_loss: 0.2663 - val_acc: 0.8505\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 7s - loss: 0.2197 - acc: 0.8961 - val_loss: 0.2695 - val_acc: 0.8692\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 7s - loss: 0.2316 - acc: 0.8937 - val_loss: 0.2579 - val_acc: 0.8567\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 7s - loss: 0.2390 - acc: 0.8961 - val_loss: 0.2590 - val_acc: 0.8629\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69218, saving model to best_m.h5\n",
      " - 73s - loss: 0.9433 - acc: 0.6047 - val_loss: 0.6922 - val_acc: 0.4844\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 7s - loss: 0.6204 - acc: 0.6492 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 7s - loss: 0.6106 - acc: 0.6469 - val_loss: 0.6931 - val_acc: 0.4969\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69218 to 0.69158, saving model to best_m.h5\n",
      " - 8s - loss: 0.6141 - acc: 0.6625 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 7s - loss: 0.5535 - acc: 0.6937 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.69158 to 0.59260, saving model to best_m.h5\n",
      " - 8s - loss: 0.5488 - acc: 0.6899 - val_loss: 0.5926 - val_acc: 0.6531\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 7s - loss: 0.5571 - acc: 0.7071 - val_loss: 0.9606 - val_acc: 0.5250\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.59260 to 0.48999, saving model to best_m.h5\n",
      " - 8s - loss: 0.5864 - acc: 0.6789 - val_loss: 0.4900 - val_acc: 0.7875\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 7s - loss: 0.5441 - acc: 0.7531 - val_loss: 0.5460 - val_acc: 0.7250\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.5163 - acc: 0.7422 - val_loss: 0.5101 - val_acc: 0.7531\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.48999 to 0.40452, saving model to best_m.h5\n",
      " - 8s - loss: 0.5261 - acc: 0.7399 - val_loss: 0.4045 - val_acc: 0.8094\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 0.4958 - acc: 0.7461 - val_loss: 0.9620 - val_acc: 0.6094\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.5000 - acc: 0.7399 - val_loss: 0.4466 - val_acc: 0.7625\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.40452 to 0.40244, saving model to best_m.h5\n",
      " - 8s - loss: 0.4731 - acc: 0.7734 - val_loss: 0.4024 - val_acc: 0.8406\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 7s - loss: 0.4371 - acc: 0.7781 - val_loss: 0.4803 - val_acc: 0.8063\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 7s - loss: 0.3918 - acc: 0.8172 - val_loss: 0.4771 - val_acc: 0.7500\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.40244 to 0.32969, saving model to best_m.h5\n",
      " - 8s - loss: 0.3854 - acc: 0.8164 - val_loss: 0.3297 - val_acc: 0.8688\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 7s - loss: 0.3676 - acc: 0.8289 - val_loss: 0.4017 - val_acc: 0.8500\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 7s - loss: 0.3913 - acc: 0.8125 - val_loss: 0.4417 - val_acc: 0.7937\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.32969 to 0.31798, saving model to best_m.h5\n",
      " - 8s - loss: 0.3750 - acc: 0.8195 - val_loss: 0.3180 - val_acc: 0.8656\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.31798 to 0.29136, saving model to best_m.h5\n",
      " - 8s - loss: 0.3675 - acc: 0.8273 - val_loss: 0.2914 - val_acc: 0.8938\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 7s - loss: 0.3499 - acc: 0.8562 - val_loss: 0.3926 - val_acc: 0.8156\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 7s - loss: 0.3799 - acc: 0.8203 - val_loss: 0.3889 - val_acc: 0.8406\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 7s - loss: 0.3639 - acc: 0.8312 - val_loss: 0.3239 - val_acc: 0.8625\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.3377 - acc: 0.8390 - val_loss: 0.2928 - val_acc: 0.8812\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 7s - loss: 0.3531 - acc: 0.8407 - val_loss: 0.4627 - val_acc: 0.7688\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 7s - loss: 0.3376 - acc: 0.8438 - val_loss: 0.3134 - val_acc: 0.8812\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.29136 to 0.28222, saving model to best_m.h5\n",
      " - 8s - loss: 0.3549 - acc: 0.8368 - val_loss: 0.2822 - val_acc: 0.8844\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 7s - loss: 0.3349 - acc: 0.8359 - val_loss: 0.3930 - val_acc: 0.8250\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.28222 to 0.27283, saving model to best_m.h5\n",
      " - 8s - loss: 0.3355 - acc: 0.8406 - val_loss: 0.2728 - val_acc: 0.8781\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 7s - loss: 0.3042 - acc: 0.8508 - val_loss: 0.2787 - val_acc: 0.8938\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 7s - loss: 0.3326 - acc: 0.8469 - val_loss: 0.3456 - val_acc: 0.8531\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.3325 - acc: 0.8383 - val_loss: 0.3706 - val_acc: 0.8438\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.3052 - acc: 0.8547 - val_loss: 0.3025 - val_acc: 0.8688\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 0.3111 - acc: 0.8610 - val_loss: 0.2766 - val_acc: 0.8875\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.27283 to 0.25838, saving model to best_m.h5\n",
      " - 8s - loss: 0.2997 - acc: 0.8531 - val_loss: 0.2584 - val_acc: 0.9031\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.3280 - acc: 0.8578 - val_loss: 0.3055 - val_acc: 0.8812\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 7s - loss: 0.3054 - acc: 0.8625 - val_loss: 0.2813 - val_acc: 0.8625\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 0.3350 - acc: 0.8578 - val_loss: 0.2791 - val_acc: 0.8844\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 0.2982 - acc: 0.8664 - val_loss: 0.3552 - val_acc: 0.8531\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.3000 - acc: 0.8633 - val_loss: 0.2668 - val_acc: 0.8750\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.25838 to 0.24979, saving model to best_m.h5\n",
      " - 8s - loss: 0.3191 - acc: 0.8500 - val_loss: 0.2498 - val_acc: 0.8938\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.3011 - acc: 0.8657 - val_loss: 0.3170 - val_acc: 0.8812\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.3078 - acc: 0.8664 - val_loss: 0.3263 - val_acc: 0.8375\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.3270 - acc: 0.8602 - val_loss: 0.3228 - val_acc: 0.8594\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.2937 - acc: 0.8617 - val_loss: 0.2699 - val_acc: 0.9094\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 0.2868 - acc: 0.8609 - val_loss: 0.2623 - val_acc: 0.8969\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2704 - acc: 0.8797 - val_loss: 0.2672 - val_acc: 0.8781\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 7s - loss: 0.2829 - acc: 0.8726 - val_loss: 0.2704 - val_acc: 0.8781\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 7s - loss: 0.2830 - acc: 0.8695 - val_loss: 0.2505 - val_acc: 0.9031\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 0.2481 - acc: 0.8953 - val_loss: 0.2533 - val_acc: 0.8969\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.24979 to 0.24962, saving model to best_m.h5\n",
      " - 8s - loss: 0.2850 - acc: 0.8696 - val_loss: 0.2496 - val_acc: 0.8969\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 7s - loss: 0.2826 - acc: 0.8711 - val_loss: 0.2714 - val_acc: 0.8875\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.3033 - acc: 0.8704 - val_loss: 0.2558 - val_acc: 0.8938\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2893 - acc: 0.8563 - val_loss: 0.2501 - val_acc: 0.8938\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.24962 to 0.24870, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 8s - loss: 0.2777 - acc: 0.8711 - val_loss: 0.2487 - val_acc: 0.8812\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 0.2893 - acc: 0.8609 - val_loss: 0.2616 - val_acc: 0.8938\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.3134 - acc: 0.8547 - val_loss: 0.2514 - val_acc: 0.8969\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.24870 to 0.24867, saving model to best_m.h5\n",
      " - 8s - loss: 0.2661 - acc: 0.8820 - val_loss: 0.2487 - val_acc: 0.8781\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss improved from 0.24867 to 0.24559, saving model to best_m.h5\n",
      " - 8s - loss: 0.2698 - acc: 0.8851 - val_loss: 0.2456 - val_acc: 0.9031\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.2848 - acc: 0.8719 - val_loss: 0.2503 - val_acc: 0.8875\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.2696 - acc: 0.8734 - val_loss: 0.2639 - val_acc: 0.8875\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 0.2649 - acc: 0.8852 - val_loss: 0.2615 - val_acc: 0.8812\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2579 - acc: 0.8859 - val_loss: 0.2458 - val_acc: 0.8875\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.2904 - acc: 0.8750 - val_loss: 0.2759 - val_acc: 0.8781\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.2696 - acc: 0.8743 - val_loss: 0.2520 - val_acc: 0.8844\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss improved from 0.24559 to 0.24223, saving model to best_m.h5\n",
      " - 8s - loss: 0.2833 - acc: 0.8586 - val_loss: 0.2422 - val_acc: 0.8781\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 0.2603 - acc: 0.8680 - val_loss: 0.2508 - val_acc: 0.8750\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 7s - loss: 0.2651 - acc: 0.8851 - val_loss: 0.2498 - val_acc: 0.8812\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 0.2869 - acc: 0.8719 - val_loss: 0.2579 - val_acc: 0.8812\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2934 - acc: 0.8719 - val_loss: 0.2527 - val_acc: 0.8875\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 0.2801 - acc: 0.8672 - val_loss: 0.2633 - val_acc: 0.8750\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 7s - loss: 0.2918 - acc: 0.8688 - val_loss: 0.2560 - val_acc: 0.8812\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.24223 to 0.24152, saving model to best_m.h5\n",
      " - 8s - loss: 0.2539 - acc: 0.8898 - val_loss: 0.2415 - val_acc: 0.8844\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 7s - loss: 0.2674 - acc: 0.8890 - val_loss: 0.2422 - val_acc: 0.8938\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss improved from 0.24152 to 0.23938, saving model to best_m.h5\n",
      " - 8s - loss: 0.2748 - acc: 0.8742 - val_loss: 0.2394 - val_acc: 0.8812\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 7s - loss: 0.2530 - acc: 0.8805 - val_loss: 0.2442 - val_acc: 0.8906\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 7s - loss: 0.2740 - acc: 0.8789 - val_loss: 0.2702 - val_acc: 0.8812\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 7s - loss: 0.2702 - acc: 0.8805 - val_loss: 0.2411 - val_acc: 0.9000\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 7s - loss: 0.2867 - acc: 0.8672 - val_loss: 0.2490 - val_acc: 0.8875\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 7s - loss: 0.2674 - acc: 0.8820 - val_loss: 0.2436 - val_acc: 0.8938\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 7s - loss: 0.2990 - acc: 0.8602 - val_loss: 0.2409 - val_acc: 0.8844\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 7s - loss: 0.2827 - acc: 0.8711 - val_loss: 0.2456 - val_acc: 0.9000\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 7s - loss: 0.2703 - acc: 0.8657 - val_loss: 0.2449 - val_acc: 0.8906\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 7s - loss: 0.2589 - acc: 0.8726 - val_loss: 0.2449 - val_acc: 0.8906\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 7s - loss: 0.2592 - acc: 0.8875 - val_loss: 0.2662 - val_acc: 0.8812\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 7s - loss: 0.2389 - acc: 0.8906 - val_loss: 0.2503 - val_acc: 0.8719\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 7s - loss: 0.2978 - acc: 0.8727 - val_loss: 0.2467 - val_acc: 0.8906\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 7s - loss: 0.2617 - acc: 0.8812 - val_loss: 0.2426 - val_acc: 0.8812\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 0.2538 - acc: 0.8820 - val_loss: 0.2448 - val_acc: 0.8750\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 7s - loss: 0.2674 - acc: 0.8781 - val_loss: 0.2448 - val_acc: 0.8844\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 7s - loss: 0.2559 - acc: 0.8875 - val_loss: 0.2416 - val_acc: 0.8875\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 7s - loss: 0.2628 - acc: 0.8735 - val_loss: 0.2542 - val_acc: 0.8750\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 7s - loss: 0.2472 - acc: 0.8961 - val_loss: 0.2401 - val_acc: 0.8844\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 7s - loss: 0.2725 - acc: 0.8734 - val_loss: 0.2413 - val_acc: 0.8688\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 7s - loss: 0.2612 - acc: 0.8828 - val_loss: 0.2398 - val_acc: 0.8750\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 7s - loss: 0.2927 - acc: 0.8735 - val_loss: 0.2585 - val_acc: 0.8625\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 7s - loss: 0.2676 - acc: 0.8758 - val_loss: 0.2504 - val_acc: 0.8844\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 7s - loss: 0.2429 - acc: 0.8852 - val_loss: 0.2468 - val_acc: 0.8812\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss improved from 0.23938 to 0.23789, saving model to best_m.h5\n",
      " - 8s - loss: 0.2615 - acc: 0.8844 - val_loss: 0.2379 - val_acc: 0.8906\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 7s - loss: 0.2486 - acc: 0.8922 - val_loss: 0.2467 - val_acc: 0.8719\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 7s - loss: 0.2551 - acc: 0.8875 - val_loss: 0.2773 - val_acc: 0.8625\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 7s - loss: 0.2672 - acc: 0.8844 - val_loss: 0.2417 - val_acc: 0.8781\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 7s - loss: 0.2543 - acc: 0.8860 - val_loss: 0.2685 - val_acc: 0.8750\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 7s - loss: 0.2507 - acc: 0.8906 - val_loss: 0.2502 - val_acc: 0.8812\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 7s - loss: 0.2424 - acc: 0.8906 - val_loss: 0.2477 - val_acc: 0.8812\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 7s - loss: 0.2912 - acc: 0.8711 - val_loss: 0.2443 - val_acc: 0.8812\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 7s - loss: 0.2606 - acc: 0.8766 - val_loss: 0.2935 - val_acc: 0.8625\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 7s - loss: 0.2400 - acc: 0.8898 - val_loss: 0.2436 - val_acc: 0.8656\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 7s - loss: 0.2520 - acc: 0.8844 - val_loss: 0.2459 - val_acc: 0.8812\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 7s - loss: 0.2665 - acc: 0.8774 - val_loss: 0.2433 - val_acc: 0.8969\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 7s - loss: 0.2593 - acc: 0.8953 - val_loss: 0.2404 - val_acc: 0.8750\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 7s - loss: 0.2629 - acc: 0.8828 - val_loss: 0.2422 - val_acc: 0.8906\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss improved from 0.23789 to 0.23712, saving model to best_m.h5\n",
      " - 8s - loss: 0.2618 - acc: 0.8734 - val_loss: 0.2371 - val_acc: 0.8844\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 7s - loss: 0.2627 - acc: 0.8836 - val_loss: 0.2388 - val_acc: 0.8875\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 7s - loss: 0.2552 - acc: 0.8758 - val_loss: 0.2479 - val_acc: 0.8812\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 7s - loss: 0.2461 - acc: 0.8867 - val_loss: 0.2438 - val_acc: 0.8844\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 7s - loss: 0.2317 - acc: 0.8930 - val_loss: 0.2493 - val_acc: 0.8906\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 7s - loss: 0.2430 - acc: 0.8875 - val_loss: 0.2529 - val_acc: 0.8938\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 7s - loss: 0.2548 - acc: 0.8906 - val_loss: 0.2441 - val_acc: 0.8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=999):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_resnet_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 30, verbose = 0, mode= 'min')\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26059597144\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.463484\n",
      "1  4023181e    0.412983\n",
      "2  b20200e4    0.129309\n",
      "3  e7f018bb    0.987797\n",
      "4  4371c8c3    0.301235\n"
     ]
    }
   ],
   "source": [
    "with open('../features/resnet_aug4_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/resnet_aug4_sub.csv', index=False)\n",
    "# deep2 0.227\n",
    "# deep3 0.223\n",
    "\n",
    "# pre 2420\n",
    "# new patience to 30, 2605"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

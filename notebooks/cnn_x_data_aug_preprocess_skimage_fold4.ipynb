{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "        \n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "        \n",
    "        img = np.dstack([r,g,b])\n",
    "        img = equalize_adapthist(img)\n",
    "        #img = std_img(img)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same',input_shape=(75,75,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(16, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.62190, saving model to best_m.h5\n",
      " - 3s - loss: 0.6900 - acc: 0.5500 - val_loss: 0.6219 - val_acc: 0.6958\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6848 - acc: 0.6063 - val_loss: 0.6540 - val_acc: 0.6534\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.62190 to 0.61919, saving model to best_m.h5\n",
      " - 2s - loss: 0.6555 - acc: 0.6022 - val_loss: 0.6192 - val_acc: 0.6160\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 1s - loss: 0.6190 - acc: 0.6403 - val_loss: 0.6300 - val_acc: 0.5087\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.61919 to 0.58234, saving model to best_m.h5\n",
      " - 2s - loss: 0.6061 - acc: 0.6533 - val_loss: 0.5823 - val_acc: 0.6908\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.6169 - acc: 0.6503 - val_loss: 0.6222 - val_acc: 0.6883\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.6055 - acc: 0.6741 - val_loss: 0.5856 - val_acc: 0.6858\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.5911 - acc: 0.6733 - val_loss: 0.6296 - val_acc: 0.6708\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.6624 - acc: 0.5822 - val_loss: 0.6298 - val_acc: 0.5910\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6098 - acc: 0.6458 - val_loss: 0.5903 - val_acc: 0.6883\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.58234 to 0.57836, saving model to best_m.h5\n",
      " - 1s - loss: 0.6057 - acc: 0.6769 - val_loss: 0.5784 - val_acc: 0.7007\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.5879 - acc: 0.6847 - val_loss: 0.5844 - val_acc: 0.6783\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.5903 - acc: 0.6691 - val_loss: 0.6116 - val_acc: 0.6534\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.57836 to 0.55812, saving model to best_m.h5\n",
      " - 2s - loss: 0.5963 - acc: 0.6806 - val_loss: 0.5581 - val_acc: 0.7057\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.5815 - acc: 0.6814 - val_loss: 0.5780 - val_acc: 0.6783\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.5817 - acc: 0.6772 - val_loss: 0.5681 - val_acc: 0.7132\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.55812 to 0.53703, saving model to best_m.h5\n",
      " - 2s - loss: 0.5884 - acc: 0.6633 - val_loss: 0.5370 - val_acc: 0.7332\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.5768 - acc: 0.6906 - val_loss: 0.5418 - val_acc: 0.7456\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.6069 - acc: 0.6275 - val_loss: 0.5958 - val_acc: 0.6135\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.53703 to 0.52093, saving model to best_m.h5\n",
      " - 2s - loss: 0.5611 - acc: 0.6917 - val_loss: 0.5209 - val_acc: 0.7132\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.5607 - acc: 0.6932 - val_loss: 0.5210 - val_acc: 0.7506\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.52093 to 0.51109, saving model to best_m.h5\n",
      " - 2s - loss: 0.5348 - acc: 0.7072 - val_loss: 0.5111 - val_acc: 0.7606\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.5366 - acc: 0.7114 - val_loss: 0.5697 - val_acc: 0.7057\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.51109 to 0.49644, saving model to best_m.h5\n",
      " - 2s - loss: 0.5359 - acc: 0.7141 - val_loss: 0.4964 - val_acc: 0.7506\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.5457 - acc: 0.7081 - val_loss: 0.5113 - val_acc: 0.7556\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.5442 - acc: 0.6942 - val_loss: 0.5993 - val_acc: 0.7007\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.49644 to 0.48966, saving model to best_m.h5\n",
      " - 2s - loss: 0.5274 - acc: 0.7111 - val_loss: 0.4897 - val_acc: 0.7706\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.48966 to 0.48418, saving model to best_m.h5\n",
      " - 1s - loss: 0.5088 - acc: 0.7226 - val_loss: 0.4842 - val_acc: 0.7756\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.48418 to 0.43692, saving model to best_m.h5\n",
      " - 2s - loss: 0.5148 - acc: 0.7233 - val_loss: 0.4369 - val_acc: 0.7855\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.5001 - acc: 0.7226 - val_loss: 0.4870 - val_acc: 0.7706\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.43692 to 0.43183, saving model to best_m.h5\n",
      " - 2s - loss: 0.4728 - acc: 0.7492 - val_loss: 0.4318 - val_acc: 0.7930\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.4780 - acc: 0.7341 - val_loss: 0.4447 - val_acc: 0.7805\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4714 - acc: 0.7475 - val_loss: 0.4357 - val_acc: 0.7855\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.4576 - acc: 0.7531 - val_loss: 0.4653 - val_acc: 0.7905\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.43183 to 0.42581, saving model to best_m.h5\n",
      " - 1s - loss: 0.4694 - acc: 0.7406 - val_loss: 0.4258 - val_acc: 0.7980\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.42581 to 0.40541, saving model to best_m.h5\n",
      " - 2s - loss: 0.4862 - acc: 0.7395 - val_loss: 0.4054 - val_acc: 0.7955\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.4685 - acc: 0.7625 - val_loss: 0.4727 - val_acc: 0.7830\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.40541 to 0.39307, saving model to best_m.h5\n",
      " - 2s - loss: 0.4524 - acc: 0.7683 - val_loss: 0.3931 - val_acc: 0.8155\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.4244 - acc: 0.7800 - val_loss: 0.3944 - val_acc: 0.7930\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4327 - acc: 0.7680 - val_loss: 0.4525 - val_acc: 0.7830\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.39307 to 0.38411, saving model to best_m.h5\n",
      " - 2s - loss: 0.4430 - acc: 0.7600 - val_loss: 0.3841 - val_acc: 0.8204\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.38411 to 0.37851, saving model to best_m.h5\n",
      " - 1s - loss: 0.4403 - acc: 0.7733 - val_loss: 0.3785 - val_acc: 0.7855\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.37851 to 0.34482, saving model to best_m.h5\n",
      " - 1s - loss: 0.4295 - acc: 0.7872 - val_loss: 0.3448 - val_acc: 0.8229\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4345 - acc: 0.7730 - val_loss: 0.3720 - val_acc: 0.8254\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.4338 - acc: 0.7842 - val_loss: 0.3641 - val_acc: 0.8254\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.34482 to 0.34303, saving model to best_m.h5\n",
      " - 2s - loss: 0.4152 - acc: 0.7800 - val_loss: 0.3430 - val_acc: 0.8329\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.4304 - acc: 0.7903 - val_loss: 0.4159 - val_acc: 0.7980\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.34303 to 0.34005, saving model to best_m.h5\n",
      " - 2s - loss: 0.4192 - acc: 0.7808 - val_loss: 0.3400 - val_acc: 0.8454\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.4187 - acc: 0.7875 - val_loss: 0.3650 - val_acc: 0.8229\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss improved from 0.34005 to 0.33503, saving model to best_m.h5\n",
      " - 2s - loss: 0.3808 - acc: 0.8114 - val_loss: 0.3350 - val_acc: 0.8404\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.33503 to 0.31955, saving model to best_m.h5\n",
      " - 2s - loss: 0.4359 - acc: 0.7824 - val_loss: 0.3195 - val_acc: 0.8429\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 1s - loss: 0.3921 - acc: 0.8058 - val_loss: 0.3409 - val_acc: 0.8180\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.4229 - acc: 0.7745 - val_loss: 0.3295 - val_acc: 0.8229\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.3948 - acc: 0.7900 - val_loss: 0.3366 - val_acc: 0.8429\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.4154 - acc: 0.7922 - val_loss: 0.3777 - val_acc: 0.8180\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.31955 to 0.30312, saving model to best_m.h5\n",
      " - 2s - loss: 0.4031 - acc: 0.7983 - val_loss: 0.3031 - val_acc: 0.8504\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.4078 - acc: 0.8014 - val_loss: 0.3162 - val_acc: 0.8379\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss improved from 0.30312 to 0.30230, saving model to best_m.h5\n",
      " - 2s - loss: 0.3888 - acc: 0.7983 - val_loss: 0.3023 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.4156 - acc: 0.7858 - val_loss: 0.3592 - val_acc: 0.8130\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 1s - loss: 0.3902 - acc: 0.8001 - val_loss: 0.3101 - val_acc: 0.8603\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 1s - loss: 0.3756 - acc: 0.8114 - val_loss: 0.3682 - val_acc: 0.8155\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3925 - acc: 0.7833 - val_loss: 0.3294 - val_acc: 0.8304\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 1s - loss: 0.3933 - acc: 0.8076 - val_loss: 0.4678 - val_acc: 0.7830\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.30230 to 0.28761, saving model to best_m.h5\n",
      " - 2s - loss: 0.3882 - acc: 0.8133 - val_loss: 0.2876 - val_acc: 0.8678\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.4154 - acc: 0.7875 - val_loss: 0.3122 - val_acc: 0.8504\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.3941 - acc: 0.8150 - val_loss: 0.2942 - val_acc: 0.8703\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3916 - acc: 0.8022 - val_loss: 0.2959 - val_acc: 0.8653\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3969 - acc: 0.8039 - val_loss: 0.2933 - val_acc: 0.8703\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3776 - acc: 0.8089 - val_loss: 0.3448 - val_acc: 0.8329\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3896 - acc: 0.7989 - val_loss: 0.3144 - val_acc: 0.8429\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 1s - loss: 0.3539 - acc: 0.8233 - val_loss: 0.3085 - val_acc: 0.8579\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 1s - loss: 0.3545 - acc: 0.8283 - val_loss: 0.3076 - val_acc: 0.8579\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3598 - acc: 0.8372 - val_loss: 0.3076 - val_acc: 0.8479\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.3658 - acc: 0.8206 - val_loss: 0.3035 - val_acc: 0.8579\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3338 - acc: 0.8364 - val_loss: 0.2919 - val_acc: 0.8579\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss improved from 0.28761 to 0.28441, saving model to best_m.h5\n",
      " - 2s - loss: 0.3540 - acc: 0.8358 - val_loss: 0.2844 - val_acc: 0.8653\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3633 - acc: 0.8208 - val_loss: 0.2969 - val_acc: 0.8628\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.3626 - acc: 0.8033 - val_loss: 0.3118 - val_acc: 0.8529\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 1s - loss: 0.3320 - acc: 0.8281 - val_loss: 0.3027 - val_acc: 0.8579\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss improved from 0.28441 to 0.27997, saving model to best_m.h5\n",
      " - 2s - loss: 0.3701 - acc: 0.8233 - val_loss: 0.2800 - val_acc: 0.8728\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3375 - acc: 0.8375 - val_loss: 0.2929 - val_acc: 0.8628\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3539 - acc: 0.8281 - val_loss: 0.2943 - val_acc: 0.8628\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 1s - loss: 0.3510 - acc: 0.8358 - val_loss: 0.2984 - val_acc: 0.8579\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 1s - loss: 0.3431 - acc: 0.8212 - val_loss: 0.2850 - val_acc: 0.8728\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3614 - acc: 0.8266 - val_loss: 0.2969 - val_acc: 0.8579\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3451 - acc: 0.8239 - val_loss: 0.2817 - val_acc: 0.8703\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.3585 - acc: 0.8316 - val_loss: 0.2807 - val_acc: 0.8728\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.3457 - acc: 0.8162 - val_loss: 0.2965 - val_acc: 0.8603\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 1s - loss: 0.3311 - acc: 0.8308 - val_loss: 0.3208 - val_acc: 0.8329\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3425 - acc: 0.8283 - val_loss: 0.2941 - val_acc: 0.8603\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.3820 - acc: 0.8106 - val_loss: 0.2821 - val_acc: 0.8753\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.3388 - acc: 0.8317 - val_loss: 0.3055 - val_acc: 0.8579\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3382 - acc: 0.8275 - val_loss: 0.3134 - val_acc: 0.8479\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.3455 - acc: 0.8241 - val_loss: 0.2928 - val_acc: 0.8529\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.3553 - acc: 0.8247 - val_loss: 0.3249 - val_acc: 0.8379\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3411 - acc: 0.8287 - val_loss: 0.2865 - val_acc: 0.8678\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.3580 - acc: 0.8314 - val_loss: 0.3108 - val_acc: 0.8554\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.3368 - acc: 0.8303 - val_loss: 0.3328 - val_acc: 0.8379\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3604 - acc: 0.8264 - val_loss: 0.3125 - val_acc: 0.8529\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.3528 - acc: 0.8258 - val_loss: 0.2933 - val_acc: 0.8554\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3586 - acc: 0.8125 - val_loss: 0.3126 - val_acc: 0.8579\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.3509 - acc: 0.8151 - val_loss: 0.2852 - val_acc: 0.8653\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3350 - acc: 0.8317 - val_loss: 0.2834 - val_acc: 0.8678\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.3436 - acc: 0.8276 - val_loss: 0.3148 - val_acc: 0.8404\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.3441 - acc: 0.8258 - val_loss: 0.3395 - val_acc: 0.8354\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.3485 - acc: 0.8214 - val_loss: 0.2951 - val_acc: 0.8603\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.3221 - acc: 0.8383 - val_loss: 0.3058 - val_acc: 0.8628\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.3484 - acc: 0.8225 - val_loss: 0.3110 - val_acc: 0.8554\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3740 - acc: 0.8100 - val_loss: 0.2902 - val_acc: 0.8628\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss improved from 0.27997 to 0.27738, saving model to best_m.h5\n",
      " - 2s - loss: 0.3298 - acc: 0.8422 - val_loss: 0.2774 - val_acc: 0.8628\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.3497 - acc: 0.8241 - val_loss: 0.2972 - val_acc: 0.8603\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 1s - loss: 0.3302 - acc: 0.8233 - val_loss: 0.2854 - val_acc: 0.8603\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.3388 - acc: 0.8331 - val_loss: 0.2911 - val_acc: 0.8678\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.3539 - acc: 0.8147 - val_loss: 0.2841 - val_acc: 0.8653\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 1s - loss: 0.3296 - acc: 0.8356 - val_loss: 0.2882 - val_acc: 0.8603\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.3340 - acc: 0.8287 - val_loss: 0.2800 - val_acc: 0.8728\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.3524 - acc: 0.8408 - val_loss: 0.2819 - val_acc: 0.8678\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3544 - acc: 0.8231 - val_loss: 0.2982 - val_acc: 0.8554\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3315 - acc: 0.8367 - val_loss: 0.2912 - val_acc: 0.8628\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.3333 - acc: 0.8341 - val_loss: 0.2931 - val_acc: 0.8653\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.68790, saving model to best_m.h5\n",
      " - 3s - loss: 0.7073 - acc: 0.5061 - val_loss: 0.6879 - val_acc: 0.5611\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.68790 to 0.67575, saving model to best_m.h5\n",
      " - 1s - loss: 0.6825 - acc: 0.5991 - val_loss: 0.6758 - val_acc: 0.6135\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 1s - loss: 0.6798 - acc: 0.5809 - val_loss: 0.6832 - val_acc: 0.5337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 1s - loss: 0.6847 - acc: 0.5664 - val_loss: 0.6894 - val_acc: 0.5461\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.6705 - acc: 0.5897 - val_loss: 0.6871 - val_acc: 0.5411\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.67575 to 0.63351, saving model to best_m.h5\n",
      " - 2s - loss: 0.6646 - acc: 0.6020 - val_loss: 0.6335 - val_acc: 0.6484\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.63351 to 0.62856, saving model to best_m.h5\n",
      " - 2s - loss: 0.6206 - acc: 0.6550 - val_loss: 0.6286 - val_acc: 0.6534\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.62856 to 0.60325, saving model to best_m.h5\n",
      " - 2s - loss: 0.6286 - acc: 0.6180 - val_loss: 0.6032 - val_acc: 0.6758\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.60325 to 0.58909, saving model to best_m.h5\n",
      " - 2s - loss: 0.5900 - acc: 0.6789 - val_loss: 0.5891 - val_acc: 0.6783\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6200 - acc: 0.6308 - val_loss: 0.6250 - val_acc: 0.6359\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.6063 - acc: 0.6695 - val_loss: 0.6330 - val_acc: 0.6060\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.6076 - acc: 0.6495 - val_loss: 0.6016 - val_acc: 0.6509\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.6040 - acc: 0.6589 - val_loss: 0.6304 - val_acc: 0.6434\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.5923 - acc: 0.6700 - val_loss: 0.6057 - val_acc: 0.6434\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.58909 to 0.57908, saving model to best_m.h5\n",
      " - 2s - loss: 0.5965 - acc: 0.6647 - val_loss: 0.5791 - val_acc: 0.6858\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.57908 to 0.56654, saving model to best_m.h5\n",
      " - 2s - loss: 0.6026 - acc: 0.6656 - val_loss: 0.5665 - val_acc: 0.6958\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.5892 - acc: 0.6534 - val_loss: 0.5782 - val_acc: 0.6758\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.56654 to 0.56552, saving model to best_m.h5\n",
      " - 2s - loss: 0.5998 - acc: 0.6797 - val_loss: 0.5655 - val_acc: 0.6983\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.56552 to 0.55992, saving model to best_m.h5\n",
      " - 2s - loss: 0.5863 - acc: 0.6739 - val_loss: 0.5599 - val_acc: 0.7032\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.55992 to 0.54666, saving model to best_m.h5\n",
      " - 1s - loss: 0.5613 - acc: 0.6941 - val_loss: 0.5467 - val_acc: 0.7107\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.5660 - acc: 0.7097 - val_loss: 0.5671 - val_acc: 0.6808\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.5765 - acc: 0.6867 - val_loss: 0.5666 - val_acc: 0.6908\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.54666 to 0.53244, saving model to best_m.h5\n",
      " - 2s - loss: 0.5605 - acc: 0.6909 - val_loss: 0.5324 - val_acc: 0.7157\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.5810 - acc: 0.6778 - val_loss: 0.5375 - val_acc: 0.7157\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.5518 - acc: 0.7166 - val_loss: 0.5386 - val_acc: 0.7107\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.5625 - acc: 0.6847 - val_loss: 0.5634 - val_acc: 0.6808\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.53244 to 0.51566, saving model to best_m.h5\n",
      " - 2s - loss: 0.5606 - acc: 0.7025 - val_loss: 0.5157 - val_acc: 0.7157\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.5472 - acc: 0.7116 - val_loss: 0.5198 - val_acc: 0.7182\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.51566 to 0.48577, saving model to best_m.h5\n",
      " - 2s - loss: 0.5358 - acc: 0.7142 - val_loss: 0.4858 - val_acc: 0.7332\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.5499 - acc: 0.7039 - val_loss: 0.5047 - val_acc: 0.7357\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.5305 - acc: 0.7356 - val_loss: 0.4976 - val_acc: 0.7406\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.5390 - acc: 0.7158 - val_loss: 0.4859 - val_acc: 0.7207\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss improved from 0.48577 to 0.47005, saving model to best_m.h5\n",
      " - 2s - loss: 0.5192 - acc: 0.7337 - val_loss: 0.4700 - val_acc: 0.7332\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.5298 - acc: 0.7297 - val_loss: 0.5101 - val_acc: 0.7431\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.5137 - acc: 0.7322 - val_loss: 0.4803 - val_acc: 0.7581\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.47005 to 0.46908, saving model to best_m.h5\n",
      " - 2s - loss: 0.5134 - acc: 0.7272 - val_loss: 0.4691 - val_acc: 0.7556\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.5058 - acc: 0.7266 - val_loss: 0.4775 - val_acc: 0.7706\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.46908 to 0.45729, saving model to best_m.h5\n",
      " - 1s - loss: 0.5237 - acc: 0.7089 - val_loss: 0.4573 - val_acc: 0.7781\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.45729 to 0.44795, saving model to best_m.h5\n",
      " - 2s - loss: 0.4948 - acc: 0.7617 - val_loss: 0.4480 - val_acc: 0.7706\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4737 - acc: 0.7522 - val_loss: 0.4493 - val_acc: 0.7631\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.4953 - acc: 0.7491 - val_loss: 0.4541 - val_acc: 0.7531\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.44795 to 0.43405, saving model to best_m.h5\n",
      " - 2s - loss: 0.5016 - acc: 0.7483 - val_loss: 0.4341 - val_acc: 0.7781\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.4753 - acc: 0.7541 - val_loss: 0.4634 - val_acc: 0.7357\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4961 - acc: 0.7506 - val_loss: 0.4495 - val_acc: 0.7805\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.43405 to 0.41719, saving model to best_m.h5\n",
      " - 2s - loss: 0.4928 - acc: 0.7500 - val_loss: 0.4172 - val_acc: 0.7955\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.41719 to 0.41149, saving model to best_m.h5\n",
      " - 2s - loss: 0.4733 - acc: 0.7589 - val_loss: 0.4115 - val_acc: 0.7955\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.4605 - acc: 0.7814 - val_loss: 0.4473 - val_acc: 0.7606\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.4573 - acc: 0.7675 - val_loss: 0.4214 - val_acc: 0.7756\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.4555 - acc: 0.7630 - val_loss: 0.4994 - val_acc: 0.7406\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss improved from 0.41149 to 0.40483, saving model to best_m.h5\n",
      " - 2s - loss: 0.4108 - acc: 0.7983 - val_loss: 0.4048 - val_acc: 0.7855\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 1s - loss: 0.4570 - acc: 0.7772 - val_loss: 0.4343 - val_acc: 0.7606\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.40483 to 0.38910, saving model to best_m.h5\n",
      " - 2s - loss: 0.4220 - acc: 0.7716 - val_loss: 0.3891 - val_acc: 0.7855\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.38910 to 0.37681, saving model to best_m.h5\n",
      " - 2s - loss: 0.4444 - acc: 0.7730 - val_loss: 0.3768 - val_acc: 0.8080\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.4182 - acc: 0.7992 - val_loss: 0.3891 - val_acc: 0.7905\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.4250 - acc: 0.7941 - val_loss: 0.3775 - val_acc: 0.8030\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.4337 - acc: 0.7881 - val_loss: 0.4033 - val_acc: 0.8130\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.4457 - acc: 0.7749 - val_loss: 0.3905 - val_acc: 0.8055\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss improved from 0.37681 to 0.35250, saving model to best_m.h5\n",
      " - 2s - loss: 0.4114 - acc: 0.8058 - val_loss: 0.3525 - val_acc: 0.8105\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.4137 - acc: 0.7991 - val_loss: 0.3576 - val_acc: 0.8229\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss improved from 0.35250 to 0.34953, saving model to best_m.h5\n",
      " - 2s - loss: 0.4094 - acc: 0.7891 - val_loss: 0.3495 - val_acc: 0.8180\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 1s - loss: 0.3924 - acc: 0.8158 - val_loss: 0.3876 - val_acc: 0.8030\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.4125 - acc: 0.7903 - val_loss: 0.3836 - val_acc: 0.8080\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 1s - loss: 0.4033 - acc: 0.8025 - val_loss: 0.3512 - val_acc: 0.8204\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.34953 to 0.34330, saving model to best_m.h5\n",
      " - 2s - loss: 0.3964 - acc: 0.7972 - val_loss: 0.3433 - val_acc: 0.8354\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss improved from 0.34330 to 0.32846, saving model to best_m.h5\n",
      " - 1s - loss: 0.3939 - acc: 0.8041 - val_loss: 0.3285 - val_acc: 0.8379\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.4030 - acc: 0.7991 - val_loss: 0.3455 - val_acc: 0.8204\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss improved from 0.32846 to 0.31983, saving model to best_m.h5\n",
      " - 2s - loss: 0.3693 - acc: 0.8158 - val_loss: 0.3198 - val_acc: 0.8254\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3962 - acc: 0.8164 - val_loss: 0.3663 - val_acc: 0.8130\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3982 - acc: 0.8097 - val_loss: 0.3390 - val_acc: 0.8379\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3796 - acc: 0.8208 - val_loss: 0.3354 - val_acc: 0.8254\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.31983 to 0.31774, saving model to best_m.h5\n",
      " - 2s - loss: 0.3706 - acc: 0.8200 - val_loss: 0.3177 - val_acc: 0.8404\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 1s - loss: 0.3648 - acc: 0.8075 - val_loss: 0.3186 - val_acc: 0.8304\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3558 - acc: 0.8241 - val_loss: 0.3260 - val_acc: 0.8254\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.3502 - acc: 0.8283 - val_loss: 0.3180 - val_acc: 0.8279\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss improved from 0.31774 to 0.31343, saving model to best_m.h5\n",
      " - 2s - loss: 0.3460 - acc: 0.8339 - val_loss: 0.3134 - val_acc: 0.8329\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3710 - acc: 0.8206 - val_loss: 0.3193 - val_acc: 0.8429\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3581 - acc: 0.8308 - val_loss: 0.3186 - val_acc: 0.8254\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.3673 - acc: 0.8322 - val_loss: 0.3177 - val_acc: 0.8304\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 1s - loss: 0.3433 - acc: 0.8339 - val_loss: 0.3144 - val_acc: 0.8279\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.3403 - acc: 0.8441 - val_loss: 0.3176 - val_acc: 0.8379\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3834 - acc: 0.8191 - val_loss: 0.3138 - val_acc: 0.8329\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3503 - acc: 0.8300 - val_loss: 0.3179 - val_acc: 0.8379\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss improved from 0.31343 to 0.31137, saving model to best_m.h5\n",
      " - 2s - loss: 0.3526 - acc: 0.8267 - val_loss: 0.3114 - val_acc: 0.8254\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 1s - loss: 0.3608 - acc: 0.8283 - val_loss: 0.3114 - val_acc: 0.8354\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3574 - acc: 0.8241 - val_loss: 0.3184 - val_acc: 0.8329\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.31137 to 0.30843, saving model to best_m.h5\n",
      " - 2s - loss: 0.3424 - acc: 0.8433 - val_loss: 0.3084 - val_acc: 0.8279\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss improved from 0.30843 to 0.30683, saving model to best_m.h5\n",
      " - 2s - loss: 0.3573 - acc: 0.8225 - val_loss: 0.3068 - val_acc: 0.8354\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.3450 - acc: 0.8306 - val_loss: 0.3180 - val_acc: 0.8304\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 1s - loss: 0.3762 - acc: 0.8175 - val_loss: 0.3089 - val_acc: 0.8429\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss improved from 0.30683 to 0.30635, saving model to best_m.h5\n",
      " - 1s - loss: 0.3363 - acc: 0.8475 - val_loss: 0.3064 - val_acc: 0.8404\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss improved from 0.30635 to 0.30583, saving model to best_m.h5\n",
      " - 2s - loss: 0.3711 - acc: 0.8200 - val_loss: 0.3058 - val_acc: 0.8379\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.3526 - acc: 0.8383 - val_loss: 0.3075 - val_acc: 0.8379\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3682 - acc: 0.8314 - val_loss: 0.3104 - val_acc: 0.8354\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.3672 - acc: 0.8130 - val_loss: 0.3096 - val_acc: 0.8454\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.3339 - acc: 0.8485 - val_loss: 0.3109 - val_acc: 0.8254\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3506 - acc: 0.8425 - val_loss: 0.3075 - val_acc: 0.8404\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss improved from 0.30583 to 0.30566, saving model to best_m.h5\n",
      " - 2s - loss: 0.3635 - acc: 0.8356 - val_loss: 0.3057 - val_acc: 0.8404\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.3537 - acc: 0.8272 - val_loss: 0.3213 - val_acc: 0.8304\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3565 - acc: 0.8172 - val_loss: 0.3100 - val_acc: 0.8254\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss improved from 0.30566 to 0.30422, saving model to best_m.h5\n",
      " - 2s - loss: 0.3079 - acc: 0.8491 - val_loss: 0.3042 - val_acc: 0.8379\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3580 - acc: 0.8258 - val_loss: 0.3091 - val_acc: 0.8329\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss improved from 0.30422 to 0.30161, saving model to best_m.h5\n",
      " - 1s - loss: 0.3533 - acc: 0.8341 - val_loss: 0.3016 - val_acc: 0.8379\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3382 - acc: 0.8308 - val_loss: 0.3152 - val_acc: 0.8379\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.3404 - acc: 0.8289 - val_loss: 0.3028 - val_acc: 0.8354\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss improved from 0.30161 to 0.30144, saving model to best_m.h5\n",
      " - 1s - loss: 0.3375 - acc: 0.8358 - val_loss: 0.3014 - val_acc: 0.8429\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss improved from 0.30144 to 0.30084, saving model to best_m.h5\n",
      " - 2s - loss: 0.3455 - acc: 0.8441 - val_loss: 0.3008 - val_acc: 0.8454\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.3474 - acc: 0.8316 - val_loss: 0.3027 - val_acc: 0.8354\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.3499 - acc: 0.8300 - val_loss: 0.3111 - val_acc: 0.8329\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3393 - acc: 0.8275 - val_loss: 0.3035 - val_acc: 0.8329\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.3326 - acc: 0.8420 - val_loss: 0.3043 - val_acc: 0.8279\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.3487 - acc: 0.8400 - val_loss: 0.3058 - val_acc: 0.8304\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 1s - loss: 0.3144 - acc: 0.8608 - val_loss: 0.3112 - val_acc: 0.8304\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss improved from 0.30084 to 0.29829, saving model to best_m.h5\n",
      " - 2s - loss: 0.3492 - acc: 0.8185 - val_loss: 0.2983 - val_acc: 0.8479\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.3337 - acc: 0.8433 - val_loss: 0.3075 - val_acc: 0.8504\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss improved from 0.29829 to 0.29738, saving model to best_m.h5\n",
      " - 1s - loss: 0.3446 - acc: 0.8366 - val_loss: 0.2974 - val_acc: 0.8404\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss improved from 0.29738 to 0.29631, saving model to best_m.h5\n",
      " - 1s - loss: 0.3323 - acc: 0.8333 - val_loss: 0.2963 - val_acc: 0.8379\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.3521 - acc: 0.8408 - val_loss: 0.2972 - val_acc: 0.8404\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3418 - acc: 0.8253 - val_loss: 0.3011 - val_acc: 0.8379\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3447 - acc: 0.8291 - val_loss: 0.3020 - val_acc: 0.8354\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.3457 - acc: 0.8247 - val_loss: 0.3000 - val_acc: 0.8429\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.64538, saving model to best_m.h5\n",
      " - 3s - loss: 0.6915 - acc: 0.5289 - val_loss: 0.6454 - val_acc: 0.6484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.64538 to 0.63246, saving model to best_m.h5\n",
      " - 2s - loss: 0.6820 - acc: 0.5453 - val_loss: 0.6325 - val_acc: 0.5786\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 1s - loss: 0.6466 - acc: 0.6133 - val_loss: 0.6357 - val_acc: 0.6633\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.63246 to 0.60206, saving model to best_m.h5\n",
      " - 1s - loss: 0.6533 - acc: 0.6347 - val_loss: 0.6021 - val_acc: 0.6384\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.60206 to 0.58349, saving model to best_m.h5\n",
      " - 1s - loss: 0.6113 - acc: 0.6650 - val_loss: 0.5835 - val_acc: 0.6783\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.6075 - acc: 0.6706 - val_loss: 0.5856 - val_acc: 0.6683\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.58349 to 0.55711, saving model to best_m.h5\n",
      " - 2s - loss: 0.6034 - acc: 0.6925 - val_loss: 0.5571 - val_acc: 0.6958\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.55711 to 0.53357, saving model to best_m.h5\n",
      " - 2s - loss: 0.5807 - acc: 0.6933 - val_loss: 0.5336 - val_acc: 0.7282\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.5693 - acc: 0.6939 - val_loss: 0.5359 - val_acc: 0.7207\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.53357 to 0.52882, saving model to best_m.h5\n",
      " - 1s - loss: 0.5737 - acc: 0.6814 - val_loss: 0.5288 - val_acc: 0.7257\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.5973 - acc: 0.6914 - val_loss: 0.5428 - val_acc: 0.7257\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.52882 to 0.49182, saving model to best_m.h5\n",
      " - 1s - loss: 0.5483 - acc: 0.7081 - val_loss: 0.4918 - val_acc: 0.7307\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.5293 - acc: 0.7358 - val_loss: 0.5662 - val_acc: 0.6808\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.5597 - acc: 0.7067 - val_loss: 0.5704 - val_acc: 0.6633\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.5596 - acc: 0.7191 - val_loss: 0.5888 - val_acc: 0.6334\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.49182 to 0.45766, saving model to best_m.h5\n",
      " - 2s - loss: 0.5302 - acc: 0.7208 - val_loss: 0.4577 - val_acc: 0.7531\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.5310 - acc: 0.7058 - val_loss: 0.5619 - val_acc: 0.6658\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.45766 to 0.44532, saving model to best_m.h5\n",
      " - 1s - loss: 0.5140 - acc: 0.7428 - val_loss: 0.4453 - val_acc: 0.7731\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.5172 - acc: 0.7314 - val_loss: 0.5288 - val_acc: 0.7431\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.44532 to 0.43528, saving model to best_m.h5\n",
      " - 2s - loss: 0.5121 - acc: 0.7414 - val_loss: 0.4353 - val_acc: 0.7855\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.4876 - acc: 0.7531 - val_loss: 0.4426 - val_acc: 0.7531\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.43528 to 0.42075, saving model to best_m.h5\n",
      " - 2s - loss: 0.4499 - acc: 0.7806 - val_loss: 0.4208 - val_acc: 0.7681\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.4707 - acc: 0.7556 - val_loss: 0.4681 - val_acc: 0.7307\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.4744 - acc: 0.7758 - val_loss: 0.4234 - val_acc: 0.7756\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.42075 to 0.41430, saving model to best_m.h5\n",
      " - 2s - loss: 0.4591 - acc: 0.7667 - val_loss: 0.4143 - val_acc: 0.7681\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.41430 to 0.40235, saving model to best_m.h5\n",
      " - 1s - loss: 0.4508 - acc: 0.7833 - val_loss: 0.4024 - val_acc: 0.7855\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.40235 to 0.39360, saving model to best_m.h5\n",
      " - 2s - loss: 0.4490 - acc: 0.7842 - val_loss: 0.3936 - val_acc: 0.7955\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.39360 to 0.39352, saving model to best_m.h5\n",
      " - 2s - loss: 0.4334 - acc: 0.7728 - val_loss: 0.3935 - val_acc: 0.7880\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.39352 to 0.38448, saving model to best_m.h5\n",
      " - 2s - loss: 0.4556 - acc: 0.7647 - val_loss: 0.3845 - val_acc: 0.7980\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.38448 to 0.37226, saving model to best_m.h5\n",
      " - 2s - loss: 0.4363 - acc: 0.7758 - val_loss: 0.3723 - val_acc: 0.8229\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.4296 - acc: 0.7808 - val_loss: 0.3779 - val_acc: 0.7905\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.4247 - acc: 0.7983 - val_loss: 0.4027 - val_acc: 0.7905\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4523 - acc: 0.7714 - val_loss: 0.3797 - val_acc: 0.8105\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.4074 - acc: 0.7964 - val_loss: 0.3736 - val_acc: 0.8180\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.37226 to 0.36249, saving model to best_m.h5\n",
      " - 2s - loss: 0.4379 - acc: 0.7733 - val_loss: 0.3625 - val_acc: 0.8155\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.4218 - acc: 0.7891 - val_loss: 0.3741 - val_acc: 0.7955\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss improved from 0.36249 to 0.36217, saving model to best_m.h5\n",
      " - 1s - loss: 0.4159 - acc: 0.7983 - val_loss: 0.3622 - val_acc: 0.8055\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.36217 to 0.35620, saving model to best_m.h5\n",
      " - 2s - loss: 0.4211 - acc: 0.7906 - val_loss: 0.3562 - val_acc: 0.8254\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.4226 - acc: 0.7864 - val_loss: 0.3663 - val_acc: 0.8030\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4050 - acc: 0.8022 - val_loss: 0.3767 - val_acc: 0.7955\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.3873 - acc: 0.8125 - val_loss: 0.4257 - val_acc: 0.7731\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.35620 to 0.35001, saving model to best_m.h5\n",
      " - 1s - loss: 0.4006 - acc: 0.8075 - val_loss: 0.3500 - val_acc: 0.8279\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.3635 - acc: 0.8149 - val_loss: 0.3899 - val_acc: 0.8105\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss improved from 0.35001 to 0.33804, saving model to best_m.h5\n",
      " - 2s - loss: 0.4186 - acc: 0.7875 - val_loss: 0.3380 - val_acc: 0.8454\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.3923 - acc: 0.8033 - val_loss: 0.3543 - val_acc: 0.8180\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.3908 - acc: 0.8225 - val_loss: 0.4052 - val_acc: 0.7830\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.3983 - acc: 0.8031 - val_loss: 0.3454 - val_acc: 0.8479\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.3994 - acc: 0.8072 - val_loss: 0.3447 - val_acc: 0.8454\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.3989 - acc: 0.7958 - val_loss: 0.3490 - val_acc: 0.8454\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.4130 - acc: 0.7933 - val_loss: 0.3520 - val_acc: 0.8404\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.33804 to 0.32512, saving model to best_m.h5\n",
      " - 2s - loss: 0.3847 - acc: 0.8187 - val_loss: 0.3251 - val_acc: 0.8653\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.32512 to 0.31766, saving model to best_m.h5\n",
      " - 2s - loss: 0.3610 - acc: 0.8416 - val_loss: 0.3177 - val_acc: 0.8554\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.3929 - acc: 0.8125 - val_loss: 0.3380 - val_acc: 0.8504\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.3560 - acc: 0.8308 - val_loss: 0.3295 - val_acc: 0.8379\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3828 - acc: 0.8120 - val_loss: 0.3395 - val_acc: 0.8204\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.4000 - acc: 0.8142 - val_loss: 0.3198 - val_acc: 0.8579\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.3977 - acc: 0.7989 - val_loss: 0.3223 - val_acc: 0.8529\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 1s - loss: 0.3488 - acc: 0.8483 - val_loss: 0.3221 - val_acc: 0.8429\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3837 - acc: 0.8200 - val_loss: 0.3241 - val_acc: 0.8404\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00060: val_loss did not improve\n",
      " - 1s - loss: 0.3840 - acc: 0.8256 - val_loss: 0.3366 - val_acc: 0.8379\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.31766 to 0.30926, saving model to best_m.h5\n",
      " - 2s - loss: 0.3444 - acc: 0.8342 - val_loss: 0.3093 - val_acc: 0.8653\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3500 - acc: 0.8416 - val_loss: 0.3105 - val_acc: 0.8653\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.30926 to 0.30799, saving model to best_m.h5\n",
      " - 1s - loss: 0.3622 - acc: 0.8316 - val_loss: 0.3080 - val_acc: 0.8753\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.30799 to 0.29972, saving model to best_m.h5\n",
      " - 2s - loss: 0.3533 - acc: 0.8187 - val_loss: 0.2997 - val_acc: 0.8678\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3689 - acc: 0.8197 - val_loss: 0.3202 - val_acc: 0.8354\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.3531 - acc: 0.8281 - val_loss: 0.3111 - val_acc: 0.8628\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3654 - acc: 0.8316 - val_loss: 0.3381 - val_acc: 0.8229\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3678 - acc: 0.8166 - val_loss: 0.3276 - val_acc: 0.8628\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3738 - acc: 0.8191 - val_loss: 0.3060 - val_acc: 0.8653\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3455 - acc: 0.8395 - val_loss: 0.3187 - val_acc: 0.8628\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.29972 to 0.29905, saving model to best_m.h5\n",
      " - 2s - loss: 0.3341 - acc: 0.8508 - val_loss: 0.2990 - val_acc: 0.8703\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.29905 to 0.29431, saving model to best_m.h5\n",
      " - 2s - loss: 0.3071 - acc: 0.8491 - val_loss: 0.2943 - val_acc: 0.8678\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3218 - acc: 0.8500 - val_loss: 0.2948 - val_acc: 0.8803\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.29431 to 0.29328, saving model to best_m.h5\n",
      " - 1s - loss: 0.3279 - acc: 0.8397 - val_loss: 0.2933 - val_acc: 0.8703\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3271 - acc: 0.8491 - val_loss: 0.2937 - val_acc: 0.8678\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3155 - acc: 0.8497 - val_loss: 0.3001 - val_acc: 0.8753\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3356 - acc: 0.8533 - val_loss: 0.2963 - val_acc: 0.8529\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.3182 - acc: 0.8497 - val_loss: 0.2944 - val_acc: 0.8628\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.29328 to 0.28847, saving model to best_m.h5\n",
      " - 2s - loss: 0.3246 - acc: 0.8475 - val_loss: 0.2885 - val_acc: 0.8703\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.3169 - acc: 0.8500 - val_loss: 0.2896 - val_acc: 0.8753\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3150 - acc: 0.8541 - val_loss: 0.2932 - val_acc: 0.8803\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3076 - acc: 0.8575 - val_loss: 0.2955 - val_acc: 0.8554\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 1s - loss: 0.3075 - acc: 0.8650 - val_loss: 0.2902 - val_acc: 0.8803\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss improved from 0.28847 to 0.28756, saving model to best_m.h5\n",
      " - 2s - loss: 0.3227 - acc: 0.8508 - val_loss: 0.2876 - val_acc: 0.8703\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3109 - acc: 0.8437 - val_loss: 0.2978 - val_acc: 0.8504\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3090 - acc: 0.8591 - val_loss: 0.2984 - val_acc: 0.8479\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss improved from 0.28756 to 0.28715, saving model to best_m.h5\n",
      " - 2s - loss: 0.3188 - acc: 0.8600 - val_loss: 0.2871 - val_acc: 0.8803\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.3366 - acc: 0.8379 - val_loss: 0.2898 - val_acc: 0.8728\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 1s - loss: 0.3081 - acc: 0.8541 - val_loss: 0.2897 - val_acc: 0.8828\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3244 - acc: 0.8431 - val_loss: 0.2938 - val_acc: 0.8803\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss improved from 0.28715 to 0.28571, saving model to best_m.h5\n",
      " - 2s - loss: 0.3003 - acc: 0.8683 - val_loss: 0.2857 - val_acc: 0.8678\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss improved from 0.28571 to 0.28391, saving model to best_m.h5\n",
      " - 2s - loss: 0.3400 - acc: 0.8431 - val_loss: 0.2839 - val_acc: 0.8828\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3064 - acc: 0.8606 - val_loss: 0.2887 - val_acc: 0.8678\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.2898 - acc: 0.8664 - val_loss: 0.2869 - val_acc: 0.8653\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss improved from 0.28391 to 0.28381, saving model to best_m.h5\n",
      " - 2s - loss: 0.3331 - acc: 0.8342 - val_loss: 0.2838 - val_acc: 0.8728\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss improved from 0.28381 to 0.28146, saving model to best_m.h5\n",
      " - 1s - loss: 0.3162 - acc: 0.8514 - val_loss: 0.2815 - val_acc: 0.8878\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 1s - loss: 0.3018 - acc: 0.8700 - val_loss: 0.2863 - val_acc: 0.8753\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.3183 - acc: 0.8458 - val_loss: 0.2885 - val_acc: 0.8628\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3233 - acc: 0.8531 - val_loss: 0.2886 - val_acc: 0.8603\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss improved from 0.28146 to 0.28141, saving model to best_m.h5\n",
      " - 1s - loss: 0.3040 - acc: 0.8566 - val_loss: 0.2814 - val_acc: 0.8703\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3113 - acc: 0.8606 - val_loss: 0.2823 - val_acc: 0.8803\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.3015 - acc: 0.8564 - val_loss: 0.2825 - val_acc: 0.8728\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3037 - acc: 0.8683 - val_loss: 0.2816 - val_acc: 0.8753\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss improved from 0.28141 to 0.27989, saving model to best_m.h5\n",
      " - 2s - loss: 0.3004 - acc: 0.8656 - val_loss: 0.2799 - val_acc: 0.8828\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.3227 - acc: 0.8516 - val_loss: 0.2889 - val_acc: 0.8753\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.3183 - acc: 0.8556 - val_loss: 0.2830 - val_acc: 0.8853\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.3104 - acc: 0.8725 - val_loss: 0.2869 - val_acc: 0.8903\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.2917 - acc: 0.8766 - val_loss: 0.2820 - val_acc: 0.8778\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3056 - acc: 0.8608 - val_loss: 0.2821 - val_acc: 0.8678\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.2944 - acc: 0.8564 - val_loss: 0.2946 - val_acc: 0.8903\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss improved from 0.27989 to 0.27939, saving model to best_m.h5\n",
      " - 2s - loss: 0.3103 - acc: 0.8691 - val_loss: 0.2794 - val_acc: 0.8803\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.3151 - acc: 0.8550 - val_loss: 0.2820 - val_acc: 0.8703\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.2951 - acc: 0.8689 - val_loss: 0.2860 - val_acc: 0.8653\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.3175 - acc: 0.8472 - val_loss: 0.2823 - val_acc: 0.8803\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.3041 - acc: 0.8654 - val_loss: 0.2857 - val_acc: 0.8903\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.2995 - acc: 0.8595 - val_loss: 0.2882 - val_acc: 0.8878\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.3231 - acc: 0.8533 - val_loss: 0.2858 - val_acc: 0.8803\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.3016 - acc: 0.8633 - val_loss: 0.2839 - val_acc: 0.8978\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.2869 - acc: 0.8666 - val_loss: 0.2811 - val_acc: 0.8878\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.3052 - acc: 0.8600 - val_loss: 0.2853 - val_acc: 0.8853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.66328, saving model to best_m.h5\n",
      " - 3s - loss: 0.6877 - acc: 0.5330 - val_loss: 0.6633 - val_acc: 0.5062\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 1s - loss: 0.6860 - acc: 0.5203 - val_loss: 0.6928 - val_acc: 0.5062\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 1s - loss: 0.6896 - acc: 0.5708 - val_loss: 0.6938 - val_acc: 0.5062\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 1s - loss: 0.6862 - acc: 0.5536 - val_loss: 0.6827 - val_acc: 0.5062\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.66328 to 0.65142, saving model to best_m.h5\n",
      " - 1s - loss: 0.6373 - acc: 0.5414 - val_loss: 0.6514 - val_acc: 0.5062\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.6650 - acc: 0.5317 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.65142 to 0.61581, saving model to best_m.h5\n",
      " - 2s - loss: 0.6667 - acc: 0.5873 - val_loss: 0.6158 - val_acc: 0.6858\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.61581 to 0.59655, saving model to best_m.h5\n",
      " - 2s - loss: 0.6201 - acc: 0.6303 - val_loss: 0.5965 - val_acc: 0.6683\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.6685 - acc: 0.5861 - val_loss: 0.6281 - val_acc: 0.5935\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6058 - acc: 0.6378 - val_loss: 0.5987 - val_acc: 0.6633\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.6236 - acc: 0.6397 - val_loss: 0.6205 - val_acc: 0.6633\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.59655 to 0.58209, saving model to best_m.h5\n",
      " - 2s - loss: 0.5979 - acc: 0.6756 - val_loss: 0.5821 - val_acc: 0.6833\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.5877 - acc: 0.6781 - val_loss: 0.5842 - val_acc: 0.6758\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.5986 - acc: 0.6600 - val_loss: 0.5926 - val_acc: 0.6783\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.5985 - acc: 0.6761 - val_loss: 0.5898 - val_acc: 0.6883\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.58209 to 0.57776, saving model to best_m.h5\n",
      " - 2s - loss: 0.6015 - acc: 0.6697 - val_loss: 0.5778 - val_acc: 0.6983\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.57776 to 0.57232, saving model to best_m.h5\n",
      " - 2s - loss: 0.5819 - acc: 0.6781 - val_loss: 0.5723 - val_acc: 0.6933\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.5801 - acc: 0.6966 - val_loss: 0.5894 - val_acc: 0.6783\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.5985 - acc: 0.6492 - val_loss: 0.5793 - val_acc: 0.6933\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.5923 - acc: 0.6653 - val_loss: 0.5759 - val_acc: 0.7082\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.57232 to 0.56201, saving model to best_m.h5\n",
      " - 1s - loss: 0.5674 - acc: 0.7083 - val_loss: 0.5620 - val_acc: 0.7032\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.5987 - acc: 0.6858 - val_loss: 0.5755 - val_acc: 0.6958\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.56201 to 0.51735, saving model to best_m.h5\n",
      " - 2s - loss: 0.5607 - acc: 0.6966 - val_loss: 0.5173 - val_acc: 0.7382\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.51735 to 0.50899, saving model to best_m.h5\n",
      " - 2s - loss: 0.5398 - acc: 0.7167 - val_loss: 0.5090 - val_acc: 0.7382\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.5522 - acc: 0.6941 - val_loss: 0.5144 - val_acc: 0.7282\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.5636 - acc: 0.6947 - val_loss: 0.5377 - val_acc: 0.7232\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.50899 to 0.50292, saving model to best_m.h5\n",
      " - 2s - loss: 0.5293 - acc: 0.7208 - val_loss: 0.5029 - val_acc: 0.7382\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.5527 - acc: 0.7082 - val_loss: 0.5045 - val_acc: 0.7382\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.5147 - acc: 0.7391 - val_loss: 0.5035 - val_acc: 0.7332\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.50292 to 0.49123, saving model to best_m.h5\n",
      " - 1s - loss: 0.5360 - acc: 0.7047 - val_loss: 0.4912 - val_acc: 0.7456\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.49123 to 0.47628, saving model to best_m.h5\n",
      " - 2s - loss: 0.5135 - acc: 0.7483 - val_loss: 0.4763 - val_acc: 0.7456\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.5268 - acc: 0.7067 - val_loss: 0.4885 - val_acc: 0.7406\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4990 - acc: 0.7376 - val_loss: 0.4784 - val_acc: 0.7332\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.47628 to 0.46423, saving model to best_m.h5\n",
      " - 2s - loss: 0.5102 - acc: 0.7181 - val_loss: 0.4642 - val_acc: 0.7531\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.4973 - acc: 0.7425 - val_loss: 0.4734 - val_acc: 0.7406\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.4985 - acc: 0.7389 - val_loss: 0.4748 - val_acc: 0.7681\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.4825 - acc: 0.7466 - val_loss: 0.4781 - val_acc: 0.7631\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 0.4945 - acc: 0.7409 - val_loss: 0.4652 - val_acc: 0.7556\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.46423 to 0.42667, saving model to best_m.h5\n",
      " - 2s - loss: 0.4785 - acc: 0.7328 - val_loss: 0.4267 - val_acc: 0.7706\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4916 - acc: 0.7433 - val_loss: 0.4338 - val_acc: 0.7656\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.42667 to 0.41579, saving model to best_m.h5\n",
      " - 2s - loss: 0.4654 - acc: 0.7633 - val_loss: 0.4158 - val_acc: 0.7706\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.4696 - acc: 0.7575 - val_loss: 0.4250 - val_acc: 0.7805\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.4179 - acc: 0.7791 - val_loss: 0.4246 - val_acc: 0.7581\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss improved from 0.41579 to 0.41044, saving model to best_m.h5\n",
      " - 2s - loss: 0.4678 - acc: 0.7531 - val_loss: 0.4104 - val_acc: 0.7656\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.41044 to 0.40798, saving model to best_m.h5\n",
      " - 2s - loss: 0.4265 - acc: 0.7842 - val_loss: 0.4080 - val_acc: 0.7756\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.40798 to 0.39692, saving model to best_m.h5\n",
      " - 2s - loss: 0.4371 - acc: 0.7833 - val_loss: 0.3969 - val_acc: 0.7905\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.4474 - acc: 0.7747 - val_loss: 0.4185 - val_acc: 0.7855\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.39692 to 0.37927, saving model to best_m.h5\n",
      " - 2s - loss: 0.4369 - acc: 0.7941 - val_loss: 0.3793 - val_acc: 0.8005\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.4075 - acc: 0.7875 - val_loss: 0.3888 - val_acc: 0.8080\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.4355 - acc: 0.7875 - val_loss: 0.3981 - val_acc: 0.7905\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 1s - loss: 0.4257 - acc: 0.7881 - val_loss: 0.3941 - val_acc: 0.8005\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 1s - loss: 0.4086 - acc: 0.7933 - val_loss: 0.4190 - val_acc: 0.7855\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.4120 - acc: 0.8000 - val_loss: 0.3997 - val_acc: 0.7905\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.37927 to 0.37529, saving model to best_m.h5\n",
      " - 1s - loss: 0.4327 - acc: 0.7864 - val_loss: 0.3753 - val_acc: 0.8005\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3840 - acc: 0.8075 - val_loss: 0.3995 - val_acc: 0.7955\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.3788 - acc: 0.8208 - val_loss: 0.3780 - val_acc: 0.8055\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.4104 - acc: 0.8039 - val_loss: 0.3760 - val_acc: 0.8130\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 1s - loss: 0.4238 - acc: 0.7975 - val_loss: 0.3784 - val_acc: 0.8030\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3899 - acc: 0.8028 - val_loss: 0.4323 - val_acc: 0.7606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "Epoch 00060: val_loss improved from 0.37529 to 0.37264, saving model to best_m.h5\n",
      " - 2s - loss: 0.4023 - acc: 0.8055 - val_loss: 0.3726 - val_acc: 0.7955\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 1s - loss: 0.3833 - acc: 0.7967 - val_loss: 0.3896 - val_acc: 0.7905\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss improved from 0.37264 to 0.35521, saving model to best_m.h5\n",
      " - 2s - loss: 0.3972 - acc: 0.7875 - val_loss: 0.3552 - val_acc: 0.8279\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 1s - loss: 0.3817 - acc: 0.7958 - val_loss: 0.3719 - val_acc: 0.8080\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 1s - loss: 0.3999 - acc: 0.8014 - val_loss: 0.3750 - val_acc: 0.7955\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3772 - acc: 0.8045 - val_loss: 0.3658 - val_acc: 0.8080\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.4038 - acc: 0.8116 - val_loss: 0.3573 - val_acc: 0.8180\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss improved from 0.35521 to 0.35189, saving model to best_m.h5\n",
      " - 2s - loss: 0.3856 - acc: 0.8141 - val_loss: 0.3519 - val_acc: 0.8354\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3763 - acc: 0.8116 - val_loss: 0.3555 - val_acc: 0.8279\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3807 - acc: 0.8189 - val_loss: 0.3687 - val_acc: 0.8180\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3887 - acc: 0.8139 - val_loss: 0.3742 - val_acc: 0.7930\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 1s - loss: 0.3788 - acc: 0.8195 - val_loss: 0.3532 - val_acc: 0.8180\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.35189 to 0.34869, saving model to best_m.h5\n",
      " - 2s - loss: 0.3432 - acc: 0.8397 - val_loss: 0.3487 - val_acc: 0.8279\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3660 - acc: 0.8272 - val_loss: 0.3506 - val_acc: 0.8279\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.3447 - acc: 0.8289 - val_loss: 0.3567 - val_acc: 0.8229\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3443 - acc: 0.8331 - val_loss: 0.3593 - val_acc: 0.8130\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss improved from 0.34869 to 0.34625, saving model to best_m.h5\n",
      " - 2s - loss: 0.3576 - acc: 0.8164 - val_loss: 0.3462 - val_acc: 0.8329\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3583 - acc: 0.8350 - val_loss: 0.3538 - val_acc: 0.8105\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss improved from 0.34625 to 0.34573, saving model to best_m.h5\n",
      " - 2s - loss: 0.3452 - acc: 0.8283 - val_loss: 0.3457 - val_acc: 0.8279\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 1s - loss: 0.3439 - acc: 0.8333 - val_loss: 0.3508 - val_acc: 0.8105\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.3697 - acc: 0.8175 - val_loss: 0.3504 - val_acc: 0.8254\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3444 - acc: 0.8408 - val_loss: 0.3465 - val_acc: 0.8254\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3404 - acc: 0.8433 - val_loss: 0.3494 - val_acc: 0.8180\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 1s - loss: 0.3554 - acc: 0.8292 - val_loss: 0.3540 - val_acc: 0.8204\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss improved from 0.34573 to 0.34040, saving model to best_m.h5\n",
      " - 2s - loss: 0.3451 - acc: 0.8278 - val_loss: 0.3404 - val_acc: 0.8354\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3317 - acc: 0.8325 - val_loss: 0.3496 - val_acc: 0.8180\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3349 - acc: 0.8308 - val_loss: 0.3469 - val_acc: 0.8279\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.3507 - acc: 0.8256 - val_loss: 0.3534 - val_acc: 0.8180\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.3569 - acc: 0.8216 - val_loss: 0.3455 - val_acc: 0.8155\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.34040 to 0.33965, saving model to best_m.h5\n",
      " - 2s - loss: 0.3371 - acc: 0.8387 - val_loss: 0.3397 - val_acc: 0.8354\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3262 - acc: 0.8408 - val_loss: 0.3456 - val_acc: 0.8329\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.3512 - acc: 0.8297 - val_loss: 0.3403 - val_acc: 0.8354\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.3386 - acc: 0.8433 - val_loss: 0.3424 - val_acc: 0.8279\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3313 - acc: 0.8316 - val_loss: 0.3469 - val_acc: 0.8354\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.3265 - acc: 0.8256 - val_loss: 0.3445 - val_acc: 0.8204\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.3279 - acc: 0.8400 - val_loss: 0.3458 - val_acc: 0.8204\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3433 - acc: 0.8272 - val_loss: 0.3449 - val_acc: 0.8279\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss improved from 0.33965 to 0.33930, saving model to best_m.h5\n",
      " - 2s - loss: 0.3534 - acc: 0.8231 - val_loss: 0.3393 - val_acc: 0.8379\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.3376 - acc: 0.8317 - val_loss: 0.3400 - val_acc: 0.8279\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3014 - acc: 0.8550 - val_loss: 0.3557 - val_acc: 0.8130\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.3383 - acc: 0.8416 - val_loss: 0.3557 - val_acc: 0.8254\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3395 - acc: 0.8308 - val_loss: 0.3418 - val_acc: 0.8304\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.3226 - acc: 0.8425 - val_loss: 0.3470 - val_acc: 0.8379\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3332 - acc: 0.8317 - val_loss: 0.3532 - val_acc: 0.8204\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss improved from 0.33930 to 0.33847, saving model to best_m.h5\n",
      " - 2s - loss: 0.3440 - acc: 0.8341 - val_loss: 0.3385 - val_acc: 0.8329\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.3132 - acc: 0.8558 - val_loss: 0.3402 - val_acc: 0.8329\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.3411 - acc: 0.8356 - val_loss: 0.3512 - val_acc: 0.8204\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss improved from 0.33847 to 0.33578, saving model to best_m.h5\n",
      " - 2s - loss: 0.3307 - acc: 0.8333 - val_loss: 0.3358 - val_acc: 0.8429\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.3477 - acc: 0.8366 - val_loss: 0.3461 - val_acc: 0.8204\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss improved from 0.33578 to 0.33249, saving model to best_m.h5\n",
      " - 1s - loss: 0.3381 - acc: 0.8383 - val_loss: 0.3325 - val_acc: 0.8404\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.3124 - acc: 0.8591 - val_loss: 0.3477 - val_acc: 0.8254\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.3348 - acc: 0.8450 - val_loss: 0.3383 - val_acc: 0.8304\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.3449 - acc: 0.8222 - val_loss: 0.3341 - val_acc: 0.8329\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.3348 - acc: 0.8333 - val_loss: 0.3392 - val_acc: 0.8279\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.3439 - acc: 0.8308 - val_loss: 0.3374 - val_acc: 0.8329\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 1s - loss: 0.3346 - acc: 0.8500 - val_loss: 0.3409 - val_acc: 0.8279\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.3258 - acc: 0.8291 - val_loss: 0.3371 - val_acc: 0.8354\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.3538 - acc: 0.8158 - val_loss: 0.3431 - val_acc: 0.8304\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3329 - acc: 0.8406 - val_loss: 0.3402 - val_acc: 0.8304\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3199 - acc: 0.8450 - val_loss: 0.3409 - val_acc: 0.8329\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.3236 - acc: 0.8375 - val_loss: 0.3468 - val_acc: 0.8180\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch<20:\n",
    "        return 0.001\n",
    "    elif epoch<70:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n",
    "    \n",
    "\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296393091624\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.466271\n",
      "1  4023181e    0.553343\n",
      "2  b20200e4    0.525201\n",
      "3  e7f018bb    0.986323\n",
      "4  4371c8c3    0.658490\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_1_aug_skimage_preprocess_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "\n",
    "#pre 3219\n",
    "# new 2965\n",
    "\n",
    "# skimage 2725\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_1_aug_skimage_preprocess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),input_shape=(75, 75, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69115, saving model to best_m.h5\n",
      " - 4s - loss: 0.6938 - acc: 0.5020 - val_loss: 0.6912 - val_acc: 0.5461\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69115 to 0.69027, saving model to best_m.h5\n",
      " - 1s - loss: 0.6925 - acc: 0.5322 - val_loss: 0.6903 - val_acc: 0.5461\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69027 to 0.68929, saving model to best_m.h5\n",
      " - 1s - loss: 0.6910 - acc: 0.5414 - val_loss: 0.6893 - val_acc: 0.5461\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68929 to 0.68893, saving model to best_m.h5\n",
      " - 1s - loss: 0.6929 - acc: 0.5270 - val_loss: 0.6889 - val_acc: 0.5461\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.6912 - acc: 0.5311 - val_loss: 0.6893 - val_acc: 0.5461\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.6924 - acc: 0.5255 - val_loss: 0.6899 - val_acc: 0.5461\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.68893 to 0.64628, saving model to best_m.h5\n",
      " - 1s - loss: 0.6807 - acc: 0.5311 - val_loss: 0.6463 - val_acc: 0.5486\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.6913 - acc: 0.5367 - val_loss: 0.6894 - val_acc: 0.5461\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.6917 - acc: 0.5273 - val_loss: 0.6893 - val_acc: 0.5461\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6920 - acc: 0.5205 - val_loss: 0.6880 - val_acc: 0.5461\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.6910 - acc: 0.5347 - val_loss: 0.6883 - val_acc: 0.5461\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.6885 - acc: 0.5353 - val_loss: 0.6820 - val_acc: 0.5461\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.64628 to 0.61992, saving model to best_m.h5\n",
      " - 1s - loss: 0.6601 - acc: 0.6130 - val_loss: 0.6199 - val_acc: 0.6334\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.6404 - acc: 0.6172 - val_loss: 0.6734 - val_acc: 0.5935\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.6237 - acc: 0.6475 - val_loss: 0.6206 - val_acc: 0.6334\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.61992 to 0.60051, saving model to best_m.h5\n",
      " - 1s - loss: 0.5999 - acc: 0.6600 - val_loss: 0.6005 - val_acc: 0.6459\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.60051 to 0.59201, saving model to best_m.h5\n",
      " - 1s - loss: 0.5769 - acc: 0.6975 - val_loss: 0.5920 - val_acc: 0.6633\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.59201 to 0.58397, saving model to best_m.h5\n",
      " - 1s - loss: 0.5762 - acc: 0.6892 - val_loss: 0.5840 - val_acc: 0.6808\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.5738 - acc: 0.6995 - val_loss: 0.5849 - val_acc: 0.6633\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.58397 to 0.56691, saving model to best_m.h5\n",
      " - 1s - loss: 0.5531 - acc: 0.7125 - val_loss: 0.5669 - val_acc: 0.6758\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.56691 to 0.56212, saving model to best_m.h5\n",
      " - 1s - loss: 0.5386 - acc: 0.7142 - val_loss: 0.5621 - val_acc: 0.6858\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.56212 to 0.55821, saving model to best_m.h5\n",
      " - 1s - loss: 0.5341 - acc: 0.7283 - val_loss: 0.5582 - val_acc: 0.6883\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.5463 - acc: 0.7156 - val_loss: 0.5645 - val_acc: 0.7007\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.55821 to 0.53874, saving model to best_m.h5\n",
      " - 1s - loss: 0.5401 - acc: 0.7183 - val_loss: 0.5387 - val_acc: 0.7082\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.5281 - acc: 0.7372 - val_loss: 0.5598 - val_acc: 0.6908\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.53874 to 0.52829, saving model to best_m.h5\n",
      " - 1s - loss: 0.5235 - acc: 0.7433 - val_loss: 0.5283 - val_acc: 0.7332\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.52829 to 0.51163, saving model to best_m.h5\n",
      " - 1s - loss: 0.5083 - acc: 0.7516 - val_loss: 0.5116 - val_acc: 0.7357\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.4981 - acc: 0.7683 - val_loss: 0.5315 - val_acc: 0.7431\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.51163 to 0.49059, saving model to best_m.h5\n",
      " - 1s - loss: 0.5002 - acc: 0.7586 - val_loss: 0.4906 - val_acc: 0.7606\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.4975 - acc: 0.7758 - val_loss: 0.4961 - val_acc: 0.7481\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.4969 - acc: 0.7614 - val_loss: 0.4962 - val_acc: 0.7481\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.4893 - acc: 0.7750 - val_loss: 0.4949 - val_acc: 0.7606\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4516 - acc: 0.7858 - val_loss: 0.4987 - val_acc: 0.7631\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.49059 to 0.46651, saving model to best_m.h5\n",
      " - 1s - loss: 0.4574 - acc: 0.7966 - val_loss: 0.4665 - val_acc: 0.7980\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.46651 to 0.45146, saving model to best_m.h5\n",
      " - 1s - loss: 0.4599 - acc: 0.7867 - val_loss: 0.4515 - val_acc: 0.8030\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.45146 to 0.44378, saving model to best_m.h5\n",
      " - 1s - loss: 0.4455 - acc: 0.7958 - val_loss: 0.4438 - val_acc: 0.7930\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.4557 - acc: 0.7864 - val_loss: 0.4573 - val_acc: 0.8030\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.44378 to 0.43819, saving model to best_m.h5\n",
      " - 1s - loss: 0.4394 - acc: 0.7900 - val_loss: 0.4382 - val_acc: 0.7930\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.4623 - acc: 0.7925 - val_loss: 0.4866 - val_acc: 0.7706\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4739 - acc: 0.7801 - val_loss: 0.4382 - val_acc: 0.7930\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.43819 to 0.43548, saving model to best_m.h5\n",
      " - 1s - loss: 0.4396 - acc: 0.7900 - val_loss: 0.4355 - val_acc: 0.8055\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.43548 to 0.41251, saving model to best_m.h5\n",
      " - 1s - loss: 0.4368 - acc: 0.7941 - val_loss: 0.4125 - val_acc: 0.8155\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.4317 - acc: 0.8006 - val_loss: 0.4204 - val_acc: 0.7955\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4159 - acc: 0.8064 - val_loss: 0.4353 - val_acc: 0.7930\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.4570 - acc: 0.7808 - val_loss: 0.4445 - val_acc: 0.7731\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.4239 - acc: 0.7991 - val_loss: 0.4196 - val_acc: 0.7980\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.4243 - acc: 0.8089 - val_loss: 0.4283 - val_acc: 0.7930\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss improved from 0.41251 to 0.41035, saving model to best_m.h5\n",
      " - 1s - loss: 0.4182 - acc: 0.8022 - val_loss: 0.4103 - val_acc: 0.8105\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.41035 to 0.40940, saving model to best_m.h5\n",
      " - 1s - loss: 0.4204 - acc: 0.8056 - val_loss: 0.4094 - val_acc: 0.8105\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss improved from 0.40940 to 0.39950, saving model to best_m.h5\n",
      " - 1s - loss: 0.4182 - acc: 0.7945 - val_loss: 0.3995 - val_acc: 0.8180\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.39950 to 0.39148, saving model to best_m.h5\n",
      " - 1s - loss: 0.4044 - acc: 0.8100 - val_loss: 0.3915 - val_acc: 0.8105\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.39148 to 0.39018, saving model to best_m.h5\n",
      " - 1s - loss: 0.4004 - acc: 0.8050 - val_loss: 0.3902 - val_acc: 0.8130\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.3868 - acc: 0.8175 - val_loss: 0.4027 - val_acc: 0.8254\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss improved from 0.39018 to 0.38978, saving model to best_m.h5\n",
      " - 1s - loss: 0.4189 - acc: 0.8058 - val_loss: 0.3898 - val_acc: 0.8229\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3921 - acc: 0.8166 - val_loss: 0.4005 - val_acc: 0.8055\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.38978 to 0.38415, saving model to best_m.h5\n",
      " - 1s - loss: 0.3972 - acc: 0.8130 - val_loss: 0.3842 - val_acc: 0.8254\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.3795 - acc: 0.8225 - val_loss: 0.4053 - val_acc: 0.8180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 1s - loss: 0.4026 - acc: 0.8214 - val_loss: 0.4104 - val_acc: 0.8155\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3930 - acc: 0.8142 - val_loss: 0.4124 - val_acc: 0.8105\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 1s - loss: 0.4072 - acc: 0.8122 - val_loss: 0.4127 - val_acc: 0.8080\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.38415 to 0.37466, saving model to best_m.h5\n",
      " - 1s - loss: 0.4051 - acc: 0.8016 - val_loss: 0.3747 - val_acc: 0.8304\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3971 - acc: 0.8026 - val_loss: 0.3821 - val_acc: 0.8105\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 1s - loss: 0.4118 - acc: 0.7964 - val_loss: 0.4154 - val_acc: 0.8055\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 1s - loss: 0.3960 - acc: 0.8125 - val_loss: 0.3754 - val_acc: 0.8229\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3708 - acc: 0.8190 - val_loss: 0.3918 - val_acc: 0.8130\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss improved from 0.37466 to 0.37057, saving model to best_m.h5\n",
      " - 1s - loss: 0.3728 - acc: 0.8217 - val_loss: 0.3706 - val_acc: 0.8329\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3812 - acc: 0.8150 - val_loss: 0.3947 - val_acc: 0.8130\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3835 - acc: 0.8258 - val_loss: 0.3845 - val_acc: 0.8180\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.4251 - acc: 0.7934 - val_loss: 0.3856 - val_acc: 0.8180\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.37057 to 0.36745, saving model to best_m.h5\n",
      " - 1s - loss: 0.3754 - acc: 0.8262 - val_loss: 0.3674 - val_acc: 0.8204\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.36745 to 0.36563, saving model to best_m.h5\n",
      " - 1s - loss: 0.3560 - acc: 0.8250 - val_loss: 0.3656 - val_acc: 0.8155\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.36563 to 0.36375, saving model to best_m.h5\n",
      " - 1s - loss: 0.3613 - acc: 0.8316 - val_loss: 0.3637 - val_acc: 0.8279\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss improved from 0.36375 to 0.35912, saving model to best_m.h5\n",
      " - 1s - loss: 0.3472 - acc: 0.8372 - val_loss: 0.3591 - val_acc: 0.8304\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.3349 - acc: 0.8397 - val_loss: 0.3647 - val_acc: 0.8254\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3499 - acc: 0.8308 - val_loss: 0.3598 - val_acc: 0.8329\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3579 - acc: 0.8308 - val_loss: 0.3592 - val_acc: 0.8329\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3449 - acc: 0.8308 - val_loss: 0.3628 - val_acc: 0.8329\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.3557 - acc: 0.8283 - val_loss: 0.3639 - val_acc: 0.8279\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.35912 to 0.35833, saving model to best_m.h5\n",
      " - 1s - loss: 0.3717 - acc: 0.8225 - val_loss: 0.3583 - val_acc: 0.8229\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.3426 - acc: 0.8458 - val_loss: 0.3603 - val_acc: 0.8204\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3410 - acc: 0.8341 - val_loss: 0.3596 - val_acc: 0.8204\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3516 - acc: 0.8350 - val_loss: 0.3588 - val_acc: 0.8279\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss improved from 0.35833 to 0.35547, saving model to best_m.h5\n",
      " - 1s - loss: 0.3478 - acc: 0.8406 - val_loss: 0.3555 - val_acc: 0.8279\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 1s - loss: 0.3563 - acc: 0.8289 - val_loss: 0.3578 - val_acc: 0.8229\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3563 - acc: 0.8341 - val_loss: 0.3563 - val_acc: 0.8254\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3581 - acc: 0.8291 - val_loss: 0.3582 - val_acc: 0.8379\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.3158 - acc: 0.8616 - val_loss: 0.3595 - val_acc: 0.8155\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss improved from 0.35547 to 0.35407, saving model to best_m.h5\n",
      " - 1s - loss: 0.3385 - acc: 0.8391 - val_loss: 0.3541 - val_acc: 0.8279\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.35407 to 0.35025, saving model to best_m.h5\n",
      " - 1s - loss: 0.3424 - acc: 0.8306 - val_loss: 0.3503 - val_acc: 0.8254\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3453 - acc: 0.8314 - val_loss: 0.3508 - val_acc: 0.8304\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.3488 - acc: 0.8350 - val_loss: 0.3677 - val_acc: 0.8279\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.3480 - acc: 0.8475 - val_loss: 0.3562 - val_acc: 0.8304\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss improved from 0.35025 to 0.34879, saving model to best_m.h5\n",
      " - 1s - loss: 0.3564 - acc: 0.8383 - val_loss: 0.3488 - val_acc: 0.8254\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss improved from 0.34879 to 0.34716, saving model to best_m.h5\n",
      " - 1s - loss: 0.3368 - acc: 0.8345 - val_loss: 0.3472 - val_acc: 0.8354\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.3441 - acc: 0.8347 - val_loss: 0.3566 - val_acc: 0.8304\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3462 - acc: 0.8425 - val_loss: 0.3519 - val_acc: 0.8229\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 1s - loss: 0.3372 - acc: 0.8425 - val_loss: 0.3588 - val_acc: 0.8204\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.3481 - acc: 0.8308 - val_loss: 0.3556 - val_acc: 0.8254\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3414 - acc: 0.8391 - val_loss: 0.3613 - val_acc: 0.8379\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.3221 - acc: 0.8500 - val_loss: 0.3552 - val_acc: 0.8304\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3409 - acc: 0.8347 - val_loss: 0.3698 - val_acc: 0.8254\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.3435 - acc: 0.8425 - val_loss: 0.3615 - val_acc: 0.8304\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3244 - acc: 0.8458 - val_loss: 0.3566 - val_acc: 0.8304\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.3463 - acc: 0.8375 - val_loss: 0.3527 - val_acc: 0.8404\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.3273 - acc: 0.8406 - val_loss: 0.3554 - val_acc: 0.8354\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.3423 - acc: 0.8417 - val_loss: 0.3600 - val_acc: 0.8329\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.3429 - acc: 0.8598 - val_loss: 0.3542 - val_acc: 0.8304\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.3535 - acc: 0.8258 - val_loss: 0.3487 - val_acc: 0.8379\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3148 - acc: 0.8492 - val_loss: 0.3556 - val_acc: 0.8304\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.3400 - acc: 0.8483 - val_loss: 0.3474 - val_acc: 0.8354\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.3345 - acc: 0.8483 - val_loss: 0.3528 - val_acc: 0.8354\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss improved from 0.34716 to 0.34695, saving model to best_m.h5\n",
      " - 1s - loss: 0.3191 - acc: 0.8525 - val_loss: 0.3470 - val_acc: 0.8379\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.3140 - acc: 0.8516 - val_loss: 0.3508 - val_acc: 0.8379\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss improved from 0.34695 to 0.34434, saving model to best_m.h5\n",
      " - 1s - loss: 0.3545 - acc: 0.8425 - val_loss: 0.3443 - val_acc: 0.8429\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 1s - loss: 0.3237 - acc: 0.8508 - val_loss: 0.3466 - val_acc: 0.8404\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.3415 - acc: 0.8414 - val_loss: 0.3506 - val_acc: 0.8329\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.3349 - acc: 0.8425 - val_loss: 0.3594 - val_acc: 0.8229\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3523 - acc: 0.8383 - val_loss: 0.3472 - val_acc: 0.8429\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3283 - acc: 0.8425 - val_loss: 0.3541 - val_acc: 0.8379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.3533 - acc: 0.8406 - val_loss: 0.3453 - val_acc: 0.8404\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69390, saving model to best_m.h5\n",
      " - 4s - loss: 0.6923 - acc: 0.5295 - val_loss: 0.6939 - val_acc: 0.4963\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 1s - loss: 0.6898 - acc: 0.5439 - val_loss: 0.6986 - val_acc: 0.4963\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 1s - loss: 0.6900 - acc: 0.5389 - val_loss: 0.7016 - val_acc: 0.4963\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69390 to 0.68610, saving model to best_m.h5\n",
      " - 1s - loss: 0.6890 - acc: 0.5303 - val_loss: 0.6861 - val_acc: 0.4963\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.6729 - acc: 0.5499 - val_loss: 0.6951 - val_acc: 0.4963\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.6904 - acc: 0.5349 - val_loss: 0.6876 - val_acc: 0.4963\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.68610 to 0.67280, saving model to best_m.h5\n",
      " - 1s - loss: 0.6799 - acc: 0.5591 - val_loss: 0.6728 - val_acc: 0.7157\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.6858 - acc: 0.5400 - val_loss: 0.6976 - val_acc: 0.4963\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.67280 to 0.62937, saving model to best_m.h5\n",
      " - 1s - loss: 0.6371 - acc: 0.6086 - val_loss: 0.6294 - val_acc: 0.6608\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.62937 to 0.59180, saving model to best_m.h5\n",
      " - 1s - loss: 0.6146 - acc: 0.6667 - val_loss: 0.5918 - val_acc: 0.6958\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.5965 - acc: 0.6664 - val_loss: 0.6012 - val_acc: 0.6883\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.6080 - acc: 0.6569 - val_loss: 0.5993 - val_acc: 0.6908\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.5979 - acc: 0.6606 - val_loss: 0.6016 - val_acc: 0.6808\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.6066 - acc: 0.6475 - val_loss: 0.6048 - val_acc: 0.6833\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.5933 - acc: 0.6553 - val_loss: 0.6012 - val_acc: 0.6908\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.6110 - acc: 0.6547 - val_loss: 0.6516 - val_acc: 0.6209\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.59180 to 0.58820, saving model to best_m.h5\n",
      " - 1s - loss: 0.5903 - acc: 0.6641 - val_loss: 0.5882 - val_acc: 0.6883\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.5812 - acc: 0.6756 - val_loss: 0.5920 - val_acc: 0.7082\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.58820 to 0.57613, saving model to best_m.h5\n",
      " - 1s - loss: 0.5878 - acc: 0.6583 - val_loss: 0.5761 - val_acc: 0.7007\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.57613 to 0.57073, saving model to best_m.h5\n",
      " - 1s - loss: 0.5539 - acc: 0.6999 - val_loss: 0.5707 - val_acc: 0.7132\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.57073 to 0.55115, saving model to best_m.h5\n",
      " - 1s - loss: 0.5612 - acc: 0.7008 - val_loss: 0.5512 - val_acc: 0.7307\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.5484 - acc: 0.7116 - val_loss: 0.5577 - val_acc: 0.7132\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.5302 - acc: 0.7136 - val_loss: 0.5700 - val_acc: 0.6783\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.55115 to 0.52584, saving model to best_m.h5\n",
      " - 1s - loss: 0.5280 - acc: 0.7139 - val_loss: 0.5258 - val_acc: 0.7606\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.5295 - acc: 0.7217 - val_loss: 0.5269 - val_acc: 0.7556\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.52584 to 0.47002, saving model to best_m.h5\n",
      " - 1s - loss: 0.5200 - acc: 0.7391 - val_loss: 0.4700 - val_acc: 0.7955\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.4997 - acc: 0.7412 - val_loss: 0.4739 - val_acc: 0.7980\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.47002 to 0.46623, saving model to best_m.h5\n",
      " - 1s - loss: 0.4963 - acc: 0.7492 - val_loss: 0.4662 - val_acc: 0.7980\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.46623 to 0.43718, saving model to best_m.h5\n",
      " - 1s - loss: 0.4471 - acc: 0.7839 - val_loss: 0.4372 - val_acc: 0.8005\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.4767 - acc: 0.7459 - val_loss: 0.4516 - val_acc: 0.7905\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.4577 - acc: 0.7631 - val_loss: 0.4417 - val_acc: 0.8055\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.43718 to 0.40111, saving model to best_m.h5\n",
      " - 1s - loss: 0.4631 - acc: 0.7653 - val_loss: 0.4011 - val_acc: 0.8080\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4204 - acc: 0.7891 - val_loss: 0.4106 - val_acc: 0.8130\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.4394 - acc: 0.7817 - val_loss: 0.4019 - val_acc: 0.7980\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.40111 to 0.38916, saving model to best_m.h5\n",
      " - 1s - loss: 0.4278 - acc: 0.7872 - val_loss: 0.3892 - val_acc: 0.8130\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.3989 - acc: 0.8066 - val_loss: 0.4333 - val_acc: 0.7731\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.4086 - acc: 0.7866 - val_loss: 0.3996 - val_acc: 0.8130\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 0.4103 - acc: 0.7950 - val_loss: 0.4395 - val_acc: 0.7905\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.4015 - acc: 0.8066 - val_loss: 0.4317 - val_acc: 0.8005\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss improved from 0.38916 to 0.37425, saving model to best_m.h5\n",
      " - 1s - loss: 0.4093 - acc: 0.7983 - val_loss: 0.3743 - val_acc: 0.8080\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.3861 - acc: 0.8025 - val_loss: 0.5197 - val_acc: 0.7631\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.4041 - acc: 0.7956 - val_loss: 0.4129 - val_acc: 0.8055\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.3516 - acc: 0.8339 - val_loss: 0.4746 - val_acc: 0.7980\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4019 - acc: 0.8072 - val_loss: 0.3913 - val_acc: 0.8254\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.3643 - acc: 0.8114 - val_loss: 0.4065 - val_acc: 0.8055\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.37425 to 0.36251, saving model to best_m.h5\n",
      " - 1s - loss: 0.3666 - acc: 0.8272 - val_loss: 0.3625 - val_acc: 0.8180\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.3586 - acc: 0.8283 - val_loss: 0.3745 - val_acc: 0.8180\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.3838 - acc: 0.8139 - val_loss: 0.3770 - val_acc: 0.8155\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.3448 - acc: 0.8283 - val_loss: 0.3761 - val_acc: 0.8229\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.3713 - acc: 0.8200 - val_loss: 0.4270 - val_acc: 0.7905\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 1s - loss: 0.3887 - acc: 0.8159 - val_loss: 0.3694 - val_acc: 0.8304\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 1s - loss: 0.3370 - acc: 0.8475 - val_loss: 0.3975 - val_acc: 0.8254\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.3622 - acc: 0.8366 - val_loss: 0.4016 - val_acc: 0.7955\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.3675 - acc: 0.8216 - val_loss: 0.3675 - val_acc: 0.8130\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3630 - acc: 0.8375 - val_loss: 0.3654 - val_acc: 0.8130\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.3565 - acc: 0.8350 - val_loss: 0.4157 - val_acc: 0.8254\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss improved from 0.36251 to 0.35474, saving model to best_m.h5\n",
      " - 1s - loss: 0.3546 - acc: 0.8408 - val_loss: 0.3547 - val_acc: 0.8379\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss improved from 0.35474 to 0.33791, saving model to best_m.h5\n",
      " - 1s - loss: 0.3707 - acc: 0.8150 - val_loss: 0.3379 - val_acc: 0.8379\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3301 - acc: 0.8475 - val_loss: 0.3709 - val_acc: 0.8329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 1s - loss: 0.3262 - acc: 0.8397 - val_loss: 0.3615 - val_acc: 0.8329\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 1s - loss: 0.3458 - acc: 0.8314 - val_loss: 0.3683 - val_acc: 0.8304\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3525 - acc: 0.8245 - val_loss: 0.3594 - val_acc: 0.8229\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 1s - loss: 0.3254 - acc: 0.8520 - val_loss: 0.3689 - val_acc: 0.8354\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 1s - loss: 0.3416 - acc: 0.8308 - val_loss: 0.3674 - val_acc: 0.8279\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3301 - acc: 0.8441 - val_loss: 0.3426 - val_acc: 0.8229\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.3564 - acc: 0.8306 - val_loss: 0.3573 - val_acc: 0.8304\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3189 - acc: 0.8516 - val_loss: 0.3717 - val_acc: 0.8454\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3369 - acc: 0.8358 - val_loss: 0.3862 - val_acc: 0.8204\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3313 - acc: 0.8533 - val_loss: 0.3743 - val_acc: 0.8204\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3216 - acc: 0.8456 - val_loss: 0.3405 - val_acc: 0.8379\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 1s - loss: 0.2985 - acc: 0.8608 - val_loss: 0.3414 - val_acc: 0.8504\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 1s - loss: 0.3248 - acc: 0.8425 - val_loss: 0.3437 - val_acc: 0.8304\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3020 - acc: 0.8566 - val_loss: 0.3535 - val_acc: 0.8254\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.3052 - acc: 0.8650 - val_loss: 0.3419 - val_acc: 0.8479\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.2988 - acc: 0.8558 - val_loss: 0.3396 - val_acc: 0.8429\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3122 - acc: 0.8572 - val_loss: 0.3397 - val_acc: 0.8329\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.2982 - acc: 0.8633 - val_loss: 0.3382 - val_acc: 0.8279\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss improved from 0.33791 to 0.33782, saving model to best_m.h5\n",
      " - 1s - loss: 0.2957 - acc: 0.8758 - val_loss: 0.3378 - val_acc: 0.8329\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 1s - loss: 0.3036 - acc: 0.8441 - val_loss: 0.3399 - val_acc: 0.8180\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.3169 - acc: 0.8664 - val_loss: 0.3482 - val_acc: 0.8229\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss improved from 0.33782 to 0.33644, saving model to best_m.h5\n",
      " - 1s - loss: 0.2999 - acc: 0.8489 - val_loss: 0.3364 - val_acc: 0.8279\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss improved from 0.33644 to 0.33063, saving model to best_m.h5\n",
      " - 1s - loss: 0.3086 - acc: 0.8533 - val_loss: 0.3306 - val_acc: 0.8254\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss improved from 0.33063 to 0.33045, saving model to best_m.h5\n",
      " - 1s - loss: 0.3100 - acc: 0.8633 - val_loss: 0.3304 - val_acc: 0.8304\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 1s - loss: 0.3055 - acc: 0.8456 - val_loss: 0.3314 - val_acc: 0.8429\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.2955 - acc: 0.8616 - val_loss: 0.3368 - val_acc: 0.8304\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3094 - acc: 0.8608 - val_loss: 0.3330 - val_acc: 0.8304\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.2921 - acc: 0.8683 - val_loss: 0.3305 - val_acc: 0.8254\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.2839 - acc: 0.8625 - val_loss: 0.3336 - val_acc: 0.8379\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 1s - loss: 0.2891 - acc: 0.8648 - val_loss: 0.3426 - val_acc: 0.8354\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3161 - acc: 0.8598 - val_loss: 0.3345 - val_acc: 0.8304\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.2829 - acc: 0.8583 - val_loss: 0.3381 - val_acc: 0.8379\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.2933 - acc: 0.8625 - val_loss: 0.3346 - val_acc: 0.8429\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.2908 - acc: 0.8758 - val_loss: 0.3363 - val_acc: 0.8454\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.3015 - acc: 0.8556 - val_loss: 0.3313 - val_acc: 0.8354\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.2667 - acc: 0.8892 - val_loss: 0.3360 - val_acc: 0.8429\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.2948 - acc: 0.8550 - val_loss: 0.3354 - val_acc: 0.8429\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 1s - loss: 0.3093 - acc: 0.8547 - val_loss: 0.3307 - val_acc: 0.8429\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.2952 - acc: 0.8692 - val_loss: 0.3500 - val_acc: 0.8354\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss improved from 0.33045 to 0.32714, saving model to best_m.h5\n",
      " - 1s - loss: 0.2700 - acc: 0.8722 - val_loss: 0.3271 - val_acc: 0.8329\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.2956 - acc: 0.8591 - val_loss: 0.3391 - val_acc: 0.8504\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3140 - acc: 0.8433 - val_loss: 0.3322 - val_acc: 0.8354\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.2687 - acc: 0.8775 - val_loss: 0.3359 - val_acc: 0.8354\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 1s - loss: 0.3021 - acc: 0.8581 - val_loss: 0.3427 - val_acc: 0.8379\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.2909 - acc: 0.8650 - val_loss: 0.3514 - val_acc: 0.8329\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.2839 - acc: 0.8591 - val_loss: 0.3320 - val_acc: 0.8354\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.2963 - acc: 0.8625 - val_loss: 0.3315 - val_acc: 0.8329\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss improved from 0.32714 to 0.32160, saving model to best_m.h5\n",
      " - 1s - loss: 0.2939 - acc: 0.8653 - val_loss: 0.3216 - val_acc: 0.8329\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.2894 - acc: 0.8850 - val_loss: 0.3270 - val_acc: 0.8354\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.2735 - acc: 0.8741 - val_loss: 0.3364 - val_acc: 0.8354\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.2844 - acc: 0.8716 - val_loss: 0.3434 - val_acc: 0.8379\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.2798 - acc: 0.8758 - val_loss: 0.3364 - val_acc: 0.8304\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 1s - loss: 0.2850 - acc: 0.8583 - val_loss: 0.3296 - val_acc: 0.8379\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.2677 - acc: 0.8822 - val_loss: 0.3413 - val_acc: 0.8279\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.2824 - acc: 0.8800 - val_loss: 0.3327 - val_acc: 0.8379\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss improved from 0.32160 to 0.32032, saving model to best_m.h5\n",
      " - 1s - loss: 0.2796 - acc: 0.8700 - val_loss: 0.3203 - val_acc: 0.8454\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.3092 - acc: 0.8528 - val_loss: 0.3268 - val_acc: 0.8354\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.2706 - acc: 0.8725 - val_loss: 0.3353 - val_acc: 0.8304\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss improved from 0.32032 to 0.31988, saving model to best_m.h5\n",
      " - 1s - loss: 0.2900 - acc: 0.8708 - val_loss: 0.3199 - val_acc: 0.8379\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3017 - acc: 0.8600 - val_loss: 0.3247 - val_acc: 0.8304\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.2588 - acc: 0.8883 - val_loss: 0.3377 - val_acc: 0.8304\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69006, saving model to best_m.h5\n",
      " - 4s - loss: 0.6946 - acc: 0.5097 - val_loss: 0.6901 - val_acc: 0.5736\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69006 to 0.68835, saving model to best_m.h5\n",
      " - 1s - loss: 0.6924 - acc: 0.5139 - val_loss: 0.6884 - val_acc: 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 1s - loss: 0.6955 - acc: 0.5059 - val_loss: 0.6891 - val_acc: 0.5736\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68835 to 0.68791, saving model to best_m.h5\n",
      " - 1s - loss: 0.6933 - acc: 0.4951 - val_loss: 0.6879 - val_acc: 0.5736\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68791 to 0.68686, saving model to best_m.h5\n",
      " - 1s - loss: 0.6932 - acc: 0.4955 - val_loss: 0.6869 - val_acc: 0.5736\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.68686 to 0.68621, saving model to best_m.h5\n",
      " - 1s - loss: 0.6929 - acc: 0.5301 - val_loss: 0.6862 - val_acc: 0.5736\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.6926 - acc: 0.5247 - val_loss: 0.6885 - val_acc: 0.5736\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.6933 - acc: 0.5109 - val_loss: 0.6916 - val_acc: 0.5736\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.6927 - acc: 0.5347 - val_loss: 0.6894 - val_acc: 0.5736\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6934 - acc: 0.5170 - val_loss: 0.6886 - val_acc: 0.5736\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.6920 - acc: 0.5264 - val_loss: 0.6869 - val_acc: 0.5736\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.6939 - acc: 0.5074 - val_loss: 0.6892 - val_acc: 0.5736\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.6931 - acc: 0.5128 - val_loss: 0.6887 - val_acc: 0.5636\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.6934 - acc: 0.5117 - val_loss: 0.6912 - val_acc: 0.6434\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.6934 - acc: 0.5294 - val_loss: 0.6875 - val_acc: 0.5736\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.6933 - acc: 0.5136 - val_loss: 0.6889 - val_acc: 0.5736\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.6929 - acc: 0.5108 - val_loss: 0.6893 - val_acc: 0.5736\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.6917 - acc: 0.5317 - val_loss: 0.6875 - val_acc: 0.5736\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.68621 to 0.64925, saving model to best_m.h5\n",
      " - 1s - loss: 0.6921 - acc: 0.4945 - val_loss: 0.6492 - val_acc: 0.5736\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.6904 - acc: 0.5636 - val_loss: 0.6736 - val_acc: 0.6509\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.6725 - acc: 0.5891 - val_loss: 0.6705 - val_acc: 0.6035\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.64925 to 0.59641, saving model to best_m.h5\n",
      " - 1s - loss: 0.6400 - acc: 0.6258 - val_loss: 0.5964 - val_acc: 0.6708\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.59641 to 0.56538, saving model to best_m.h5\n",
      " - 1s - loss: 0.6104 - acc: 0.6372 - val_loss: 0.5654 - val_acc: 0.6808\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.6120 - acc: 0.6583 - val_loss: 0.5774 - val_acc: 0.6534\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.56538 to 0.56333, saving model to best_m.h5\n",
      " - 1s - loss: 0.5962 - acc: 0.6631 - val_loss: 0.5633 - val_acc: 0.7032\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.56333 to 0.55253, saving model to best_m.h5\n",
      " - 1s - loss: 0.6044 - acc: 0.6692 - val_loss: 0.5525 - val_acc: 0.7032\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.55253 to 0.54920, saving model to best_m.h5\n",
      " - 1s - loss: 0.5932 - acc: 0.6728 - val_loss: 0.5492 - val_acc: 0.6808\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.54920 to 0.53612, saving model to best_m.h5\n",
      " - 1s - loss: 0.5953 - acc: 0.6595 - val_loss: 0.5361 - val_acc: 0.7057\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.5798 - acc: 0.6981 - val_loss: 0.5389 - val_acc: 0.6958\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.53612 to 0.51911, saving model to best_m.h5\n",
      " - 1s - loss: 0.5680 - acc: 0.7066 - val_loss: 0.5191 - val_acc: 0.7382\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.51911 to 0.51140, saving model to best_m.h5\n",
      " - 1s - loss: 0.5653 - acc: 0.6926 - val_loss: 0.5114 - val_acc: 0.7307\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.5492 - acc: 0.7131 - val_loss: 0.5557 - val_acc: 0.6708\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss improved from 0.51140 to 0.47303, saving model to best_m.h5\n",
      " - 1s - loss: 0.5691 - acc: 0.6900 - val_loss: 0.4730 - val_acc: 0.7531\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.5301 - acc: 0.7239 - val_loss: 0.5340 - val_acc: 0.7132\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.5169 - acc: 0.7558 - val_loss: 0.4757 - val_acc: 0.7531\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.47303 to 0.41212, saving model to best_m.h5\n",
      " - 1s - loss: 0.4976 - acc: 0.7600 - val_loss: 0.4121 - val_acc: 0.8105\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.5176 - acc: 0.7345 - val_loss: 0.4161 - val_acc: 0.8229\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.41212 to 0.39406, saving model to best_m.h5\n",
      " - 1s - loss: 0.4900 - acc: 0.7731 - val_loss: 0.3941 - val_acc: 0.8254\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.4684 - acc: 0.7717 - val_loss: 0.3955 - val_acc: 0.8204\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.4906 - acc: 0.7700 - val_loss: 0.3942 - val_acc: 0.8204\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.39406 to 0.38418, saving model to best_m.h5\n",
      " - 1s - loss: 0.4543 - acc: 0.7950 - val_loss: 0.3842 - val_acc: 0.8254\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.4397 - acc: 0.7914 - val_loss: 0.4311 - val_acc: 0.8055\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.38418 to 0.36552, saving model to best_m.h5\n",
      " - 1s - loss: 0.4360 - acc: 0.8024 - val_loss: 0.3655 - val_acc: 0.8254\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4384 - acc: 0.7983 - val_loss: 0.3754 - val_acc: 0.8229\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.4186 - acc: 0.7972 - val_loss: 0.4102 - val_acc: 0.8329\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.4413 - acc: 0.7908 - val_loss: 0.3859 - val_acc: 0.8279\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.36552 to 0.35221, saving model to best_m.h5\n",
      " - 1s - loss: 0.3941 - acc: 0.8100 - val_loss: 0.3522 - val_acc: 0.8454\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.4452 - acc: 0.7850 - val_loss: 0.3759 - val_acc: 0.8279\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.35221 to 0.32999, saving model to best_m.h5\n",
      " - 1s - loss: 0.3690 - acc: 0.8158 - val_loss: 0.3300 - val_acc: 0.8379\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.4223 - acc: 0.8025 - val_loss: 0.3781 - val_acc: 0.8229\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 1s - loss: 0.3983 - acc: 0.7950 - val_loss: 0.3426 - val_acc: 0.8379\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.32999 to 0.32849, saving model to best_m.h5\n",
      " - 1s - loss: 0.4127 - acc: 0.8097 - val_loss: 0.3285 - val_acc: 0.8379\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 1s - loss: 0.3953 - acc: 0.8067 - val_loss: 0.3425 - val_acc: 0.8454\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.3761 - acc: 0.8222 - val_loss: 0.3472 - val_acc: 0.8354\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3931 - acc: 0.8150 - val_loss: 0.3614 - val_acc: 0.8329\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.3915 - acc: 0.8141 - val_loss: 0.4006 - val_acc: 0.8130\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss improved from 0.32849 to 0.32533, saving model to best_m.h5\n",
      " - 1s - loss: 0.3847 - acc: 0.8216 - val_loss: 0.3253 - val_acc: 0.8404\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 1s - loss: 0.3888 - acc: 0.8117 - val_loss: 0.3332 - val_acc: 0.8429\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3727 - acc: 0.8283 - val_loss: 0.3508 - val_acc: 0.8379\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 1s - loss: 0.3950 - acc: 0.8105 - val_loss: 0.3619 - val_acc: 0.8105\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.32533 to 0.31769, saving model to best_m.h5\n",
      " - 1s - loss: 0.3946 - acc: 0.8014 - val_loss: 0.3177 - val_acc: 0.8579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3859 - acc: 0.8108 - val_loss: 0.3191 - val_acc: 0.8554\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.31769 to 0.30096, saving model to best_m.h5\n",
      " - 1s - loss: 0.3556 - acc: 0.8266 - val_loss: 0.3010 - val_acc: 0.8504\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 1s - loss: 0.4058 - acc: 0.8056 - val_loss: 0.3745 - val_acc: 0.8105\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3560 - acc: 0.8266 - val_loss: 0.3103 - val_acc: 0.8603\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss improved from 0.30096 to 0.29668, saving model to best_m.h5\n",
      " - 1s - loss: 0.3539 - acc: 0.8397 - val_loss: 0.2967 - val_acc: 0.8603\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3760 - acc: 0.8224 - val_loss: 0.3119 - val_acc: 0.8678\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3483 - acc: 0.8333 - val_loss: 0.2994 - val_acc: 0.8628\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3705 - acc: 0.8297 - val_loss: 0.3001 - val_acc: 0.8554\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 1s - loss: 0.3685 - acc: 0.8089 - val_loss: 0.3224 - val_acc: 0.8529\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 1s - loss: 0.3544 - acc: 0.8339 - val_loss: 0.3123 - val_acc: 0.8454\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 1s - loss: 0.3378 - acc: 0.8275 - val_loss: 0.2967 - val_acc: 0.8653\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss improved from 0.29668 to 0.29352, saving model to best_m.h5\n",
      " - 1s - loss: 0.3223 - acc: 0.8450 - val_loss: 0.2935 - val_acc: 0.8703\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.29352 to 0.28919, saving model to best_m.h5\n",
      " - 1s - loss: 0.3389 - acc: 0.8350 - val_loss: 0.2892 - val_acc: 0.8728\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3528 - acc: 0.8291 - val_loss: 0.3005 - val_acc: 0.8554\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3409 - acc: 0.8356 - val_loss: 0.2951 - val_acc: 0.8753\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.3359 - acc: 0.8208 - val_loss: 0.2908 - val_acc: 0.8703\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.3368 - acc: 0.8300 - val_loss: 0.2904 - val_acc: 0.8778\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.28919 to 0.28818, saving model to best_m.h5\n",
      " - 1s - loss: 0.3450 - acc: 0.8372 - val_loss: 0.2882 - val_acc: 0.8728\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss improved from 0.28818 to 0.28252, saving model to best_m.h5\n",
      " - 1s - loss: 0.3245 - acc: 0.8441 - val_loss: 0.2825 - val_acc: 0.8653\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3344 - acc: 0.8358 - val_loss: 0.2868 - val_acc: 0.8728\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.3283 - acc: 0.8339 - val_loss: 0.3130 - val_acc: 0.8504\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 1s - loss: 0.3232 - acc: 0.8508 - val_loss: 0.2940 - val_acc: 0.8653\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss improved from 0.28252 to 0.28166, saving model to best_m.h5\n",
      " - 1s - loss: 0.3434 - acc: 0.8341 - val_loss: 0.2817 - val_acc: 0.8753\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3346 - acc: 0.8456 - val_loss: 0.2917 - val_acc: 0.8678\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.3218 - acc: 0.8406 - val_loss: 0.2820 - val_acc: 0.8778\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.3275 - acc: 0.8497 - val_loss: 0.3077 - val_acc: 0.8653\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.3281 - acc: 0.8383 - val_loss: 0.2847 - val_acc: 0.8753\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.28166 to 0.28161, saving model to best_m.h5\n",
      " - 1s - loss: 0.3300 - acc: 0.8458 - val_loss: 0.2816 - val_acc: 0.8753\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.3284 - acc: 0.8539 - val_loss: 0.2962 - val_acc: 0.8678\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.3079 - acc: 0.8525 - val_loss: 0.2826 - val_acc: 0.8853\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss improved from 0.28161 to 0.27887, saving model to best_m.h5\n",
      " - 1s - loss: 0.3291 - acc: 0.8441 - val_loss: 0.2789 - val_acc: 0.8728\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3085 - acc: 0.8491 - val_loss: 0.2807 - val_acc: 0.8703\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss improved from 0.27887 to 0.27764, saving model to best_m.h5\n",
      " - 1s - loss: 0.3395 - acc: 0.8391 - val_loss: 0.2776 - val_acc: 0.8853\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.3229 - acc: 0.8508 - val_loss: 0.2933 - val_acc: 0.8778\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3278 - acc: 0.8533 - val_loss: 0.2823 - val_acc: 0.8803\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 1s - loss: 0.3196 - acc: 0.8500 - val_loss: 0.2867 - val_acc: 0.8778\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.2992 - acc: 0.8592 - val_loss: 0.2873 - val_acc: 0.8678\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3143 - acc: 0.8497 - val_loss: 0.2853 - val_acc: 0.8753\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.3303 - acc: 0.8372 - val_loss: 0.2898 - val_acc: 0.8753\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 1s - loss: 0.3046 - acc: 0.8525 - val_loss: 0.2818 - val_acc: 0.8803\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.3246 - acc: 0.8492 - val_loss: 0.2810 - val_acc: 0.8878\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss improved from 0.27764 to 0.27382, saving model to best_m.h5\n",
      " - 1s - loss: 0.3266 - acc: 0.8522 - val_loss: 0.2738 - val_acc: 0.8828\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.3429 - acc: 0.8314 - val_loss: 0.2884 - val_acc: 0.8753\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss improved from 0.27382 to 0.27158, saving model to best_m.h5\n",
      " - 1s - loss: 0.3161 - acc: 0.8466 - val_loss: 0.2716 - val_acc: 0.8778\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.3319 - acc: 0.8450 - val_loss: 0.2958 - val_acc: 0.8653\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.3234 - acc: 0.8422 - val_loss: 0.2776 - val_acc: 0.8728\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.3112 - acc: 0.8483 - val_loss: 0.2770 - val_acc: 0.8753\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3174 - acc: 0.8625 - val_loss: 0.2783 - val_acc: 0.8778\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.3391 - acc: 0.8267 - val_loss: 0.2821 - val_acc: 0.8778\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.3488 - acc: 0.8345 - val_loss: 0.2782 - val_acc: 0.8728\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 1s - loss: 0.3205 - acc: 0.8464 - val_loss: 0.2922 - val_acc: 0.8753\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.2987 - acc: 0.8606 - val_loss: 0.2850 - val_acc: 0.8753\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.3198 - acc: 0.8400 - val_loss: 0.2933 - val_acc: 0.8678\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 1s - loss: 0.3239 - acc: 0.8366 - val_loss: 0.2827 - val_acc: 0.8778\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.3224 - acc: 0.8525 - val_loss: 0.2906 - val_acc: 0.8753\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.3055 - acc: 0.8608 - val_loss: 0.2826 - val_acc: 0.8728\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3306 - acc: 0.8470 - val_loss: 0.2780 - val_acc: 0.8728\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.3184 - acc: 0.8650 - val_loss: 0.2858 - val_acc: 0.8653\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.3334 - acc: 0.8416 - val_loss: 0.2887 - val_acc: 0.8678\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69993, saving model to best_m.h5\n",
      " - 4s - loss: 0.6929 - acc: 0.5278 - val_loss: 0.6999 - val_acc: 0.5062\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69993 to 0.69790, saving model to best_m.h5\n",
      " - 1s - loss: 0.6867 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.5062\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69790 to 0.69244, saving model to best_m.h5\n",
      " - 1s - loss: 0.6910 - acc: 0.5375 - val_loss: 0.6924 - val_acc: 0.5062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.69244 to 0.69087, saving model to best_m.h5\n",
      " - 1s - loss: 0.6919 - acc: 0.5256 - val_loss: 0.6909 - val_acc: 0.5062\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.69087 to 0.62288, saving model to best_m.h5\n",
      " - 1s - loss: 0.6632 - acc: 0.6062 - val_loss: 0.6229 - val_acc: 0.6833\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.62288 to 0.60692, saving model to best_m.h5\n",
      " - 1s - loss: 0.6584 - acc: 0.5926 - val_loss: 0.6069 - val_acc: 0.5960\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.60692 to 0.59364, saving model to best_m.h5\n",
      " - 1s - loss: 0.6319 - acc: 0.6122 - val_loss: 0.5936 - val_acc: 0.6783\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.59364 to 0.56257, saving model to best_m.h5\n",
      " - 1s - loss: 0.6100 - acc: 0.6708 - val_loss: 0.5626 - val_acc: 0.7007\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.5938 - acc: 0.6837 - val_loss: 0.5702 - val_acc: 0.6733\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.6053 - acc: 0.6616 - val_loss: 0.6286 - val_acc: 0.5985\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.5762 - acc: 0.6975 - val_loss: 0.6815 - val_acc: 0.6135\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.5855 - acc: 0.6678 - val_loss: 0.5908 - val_acc: 0.6559\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.56257 to 0.51214, saving model to best_m.h5\n",
      " - 1s - loss: 0.5678 - acc: 0.7022 - val_loss: 0.5121 - val_acc: 0.7456\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.5537 - acc: 0.7325 - val_loss: 0.5676 - val_acc: 0.7157\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.5598 - acc: 0.7041 - val_loss: 0.5519 - val_acc: 0.6958\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.5336 - acc: 0.7170 - val_loss: 0.5167 - val_acc: 0.7506\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.5614 - acc: 0.7070 - val_loss: 0.5410 - val_acc: 0.6908\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss improved from 0.51214 to 0.48543, saving model to best_m.h5\n",
      " - 1s - loss: 0.5417 - acc: 0.7178 - val_loss: 0.4854 - val_acc: 0.7781\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.5143 - acc: 0.7564 - val_loss: 0.4930 - val_acc: 0.7731\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.48543 to 0.45168, saving model to best_m.h5\n",
      " - 1s - loss: 0.4954 - acc: 0.7650 - val_loss: 0.4517 - val_acc: 0.7980\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.45168 to 0.43593, saving model to best_m.h5\n",
      " - 1s - loss: 0.5028 - acc: 0.7616 - val_loss: 0.4359 - val_acc: 0.7905\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.4772 - acc: 0.7842 - val_loss: 0.4403 - val_acc: 0.7930\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.43593 to 0.41919, saving model to best_m.h5\n",
      " - 1s - loss: 0.4735 - acc: 0.7639 - val_loss: 0.4192 - val_acc: 0.8080\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.4767 - acc: 0.7778 - val_loss: 0.4695 - val_acc: 0.7731\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.4363 - acc: 0.7983 - val_loss: 0.4369 - val_acc: 0.8005\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.41919 to 0.41122, saving model to best_m.h5\n",
      " - 1s - loss: 0.4371 - acc: 0.8083 - val_loss: 0.4112 - val_acc: 0.8055\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.4460 - acc: 0.7951 - val_loss: 0.4159 - val_acc: 0.8080\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.4606 - acc: 0.7808 - val_loss: 0.4218 - val_acc: 0.7980\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.4291 - acc: 0.7999 - val_loss: 0.4117 - val_acc: 0.8055\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.41122 to 0.39613, saving model to best_m.h5\n",
      " - 1s - loss: 0.4303 - acc: 0.7872 - val_loss: 0.3961 - val_acc: 0.8254\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.4275 - acc: 0.7933 - val_loss: 0.4054 - val_acc: 0.8155\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.4293 - acc: 0.7964 - val_loss: 0.4108 - val_acc: 0.8130\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.4282 - acc: 0.7980 - val_loss: 0.3984 - val_acc: 0.8204\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss improved from 0.39613 to 0.37975, saving model to best_m.h5\n",
      " - 1s - loss: 0.4166 - acc: 0.8075 - val_loss: 0.3797 - val_acc: 0.8130\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.37975 to 0.37923, saving model to best_m.h5\n",
      " - 1s - loss: 0.4153 - acc: 0.8156 - val_loss: 0.3792 - val_acc: 0.8155\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.37923 to 0.36979, saving model to best_m.h5\n",
      " - 1s - loss: 0.3873 - acc: 0.8283 - val_loss: 0.3698 - val_acc: 0.8180\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.4085 - acc: 0.8066 - val_loss: 0.4217 - val_acc: 0.8005\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.36979 to 0.36871, saving model to best_m.h5\n",
      " - 1s - loss: 0.4223 - acc: 0.7997 - val_loss: 0.3687 - val_acc: 0.8229\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.36871 to 0.36465, saving model to best_m.h5\n",
      " - 1s - loss: 0.4244 - acc: 0.7961 - val_loss: 0.3647 - val_acc: 0.8204\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.3983 - acc: 0.8142 - val_loss: 0.3904 - val_acc: 0.8030\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.3942 - acc: 0.8133 - val_loss: 0.3837 - val_acc: 0.8254\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.36465 to 0.36385, saving model to best_m.h5\n",
      " - 1s - loss: 0.3827 - acc: 0.8116 - val_loss: 0.3638 - val_acc: 0.8204\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.3785 - acc: 0.8331 - val_loss: 0.3664 - val_acc: 0.8155\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.4194 - acc: 0.7881 - val_loss: 0.3689 - val_acc: 0.8329\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.3785 - acc: 0.8222 - val_loss: 0.3847 - val_acc: 0.8229\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.36385 to 0.36117, saving model to best_m.h5\n",
      " - 1s - loss: 0.4223 - acc: 0.7875 - val_loss: 0.3612 - val_acc: 0.8454\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.3737 - acc: 0.8275 - val_loss: 0.3737 - val_acc: 0.8130\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.3829 - acc: 0.8231 - val_loss: 0.3632 - val_acc: 0.8279\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.3861 - acc: 0.8192 - val_loss: 0.3648 - val_acc: 0.8404\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.3584 - acc: 0.8408 - val_loss: 0.3641 - val_acc: 0.8354\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss improved from 0.36117 to 0.34589, saving model to best_m.h5\n",
      " - 1s - loss: 0.3770 - acc: 0.8166 - val_loss: 0.3459 - val_acc: 0.8429\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.34589 to 0.34390, saving model to best_m.h5\n",
      " - 1s - loss: 0.3872 - acc: 0.8158 - val_loss: 0.3439 - val_acc: 0.8254\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.34390 to 0.32615, saving model to best_m.h5\n",
      " - 1s - loss: 0.3716 - acc: 0.8258 - val_loss: 0.3261 - val_acc: 0.8404\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 1s - loss: 0.3492 - acc: 0.8458 - val_loss: 0.3349 - val_acc: 0.8304\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 1s - loss: 0.3580 - acc: 0.8281 - val_loss: 0.3414 - val_acc: 0.8279\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 1s - loss: 0.3913 - acc: 0.8097 - val_loss: 0.3626 - val_acc: 0.8379\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 1s - loss: 0.3892 - acc: 0.8142 - val_loss: 0.3359 - val_acc: 0.8354\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 1s - loss: 0.3653 - acc: 0.8275 - val_loss: 0.3312 - val_acc: 0.8454\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 1s - loss: 0.3590 - acc: 0.8266 - val_loss: 0.3531 - val_acc: 0.8479\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss improved from 0.32615 to 0.32339, saving model to best_m.h5\n",
      " - 1s - loss: 0.3396 - acc: 0.8483 - val_loss: 0.3234 - val_acc: 0.8379\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 1s - loss: 0.3668 - acc: 0.8364 - val_loss: 0.3399 - val_acc: 0.8529\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 1s - loss: 0.3805 - acc: 0.8272 - val_loss: 0.3326 - val_acc: 0.8329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.32339 to 0.31223, saving model to best_m.h5\n",
      " - 1s - loss: 0.3534 - acc: 0.8397 - val_loss: 0.3122 - val_acc: 0.8454\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss improved from 0.31223 to 0.30920, saving model to best_m.h5\n",
      " - 1s - loss: 0.3608 - acc: 0.8358 - val_loss: 0.3092 - val_acc: 0.8454\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 1s - loss: 0.3452 - acc: 0.8356 - val_loss: 0.3476 - val_acc: 0.8454\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 1s - loss: 0.3455 - acc: 0.8308 - val_loss: 0.3229 - val_acc: 0.8429\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 1s - loss: 0.3361 - acc: 0.8366 - val_loss: 0.3170 - val_acc: 0.8504\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 1s - loss: 0.3644 - acc: 0.8212 - val_loss: 0.3189 - val_acc: 0.8429\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 1s - loss: 0.3689 - acc: 0.8297 - val_loss: 0.3512 - val_acc: 0.8354\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.30920 to 0.30837, saving model to best_m.h5\n",
      " - 1s - loss: 0.3201 - acc: 0.8512 - val_loss: 0.3084 - val_acc: 0.8479\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 1s - loss: 0.3144 - acc: 0.8492 - val_loss: 0.3251 - val_acc: 0.8354\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.30837 to 0.29558, saving model to best_m.h5\n",
      " - 1s - loss: 0.3372 - acc: 0.8483 - val_loss: 0.2956 - val_acc: 0.8603\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 1s - loss: 0.3152 - acc: 0.8533 - val_loss: 0.2997 - val_acc: 0.8454\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 1s - loss: 0.2914 - acc: 0.8658 - val_loss: 0.3163 - val_acc: 0.8504\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 1s - loss: 0.3052 - acc: 0.8600 - val_loss: 0.3165 - val_acc: 0.8529\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 1s - loss: 0.3121 - acc: 0.8591 - val_loss: 0.2990 - val_acc: 0.8454\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 1s - loss: 0.2977 - acc: 0.8700 - val_loss: 0.3057 - val_acc: 0.8554\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 1s - loss: 0.2977 - acc: 0.8608 - val_loss: 0.3040 - val_acc: 0.8454\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 1s - loss: 0.3017 - acc: 0.8583 - val_loss: 0.3014 - val_acc: 0.8504\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 1s - loss: 0.2953 - acc: 0.8691 - val_loss: 0.2995 - val_acc: 0.8554\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 1s - loss: 0.3020 - acc: 0.8598 - val_loss: 0.3004 - val_acc: 0.8529\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 1s - loss: 0.2972 - acc: 0.8575 - val_loss: 0.3008 - val_acc: 0.8404\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 1s - loss: 0.2850 - acc: 0.8708 - val_loss: 0.3016 - val_acc: 0.8529\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 1s - loss: 0.2839 - acc: 0.8681 - val_loss: 0.3145 - val_acc: 0.8504\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 1s - loss: 0.3080 - acc: 0.8564 - val_loss: 0.2970 - val_acc: 0.8554\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 1s - loss: 0.2996 - acc: 0.8508 - val_loss: 0.3007 - val_acc: 0.8554\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 1s - loss: 0.3195 - acc: 0.8514 - val_loss: 0.3063 - val_acc: 0.8529\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 1s - loss: 0.2868 - acc: 0.8741 - val_loss: 0.3015 - val_acc: 0.8504\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 1s - loss: 0.2891 - acc: 0.8758 - val_loss: 0.3271 - val_acc: 0.8479\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 1s - loss: 0.2999 - acc: 0.8772 - val_loss: 0.2984 - val_acc: 0.8504\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 1s - loss: 0.3127 - acc: 0.8517 - val_loss: 0.3009 - val_acc: 0.8529\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 1s - loss: 0.2825 - acc: 0.8758 - val_loss: 0.3009 - val_acc: 0.8554\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 1s - loss: 0.3006 - acc: 0.8633 - val_loss: 0.3002 - val_acc: 0.8554\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 1s - loss: 0.2812 - acc: 0.8667 - val_loss: 0.3087 - val_acc: 0.8579\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 1s - loss: 0.2896 - acc: 0.8714 - val_loss: 0.3029 - val_acc: 0.8579\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 1s - loss: 0.3074 - acc: 0.8664 - val_loss: 0.2991 - val_acc: 0.8479\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 1s - loss: 0.2679 - acc: 0.8825 - val_loss: 0.3120 - val_acc: 0.8579\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 1s - loss: 0.2639 - acc: 0.8767 - val_loss: 0.3162 - val_acc: 0.8479\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 1s - loss: 0.3165 - acc: 0.8583 - val_loss: 0.3022 - val_acc: 0.8504\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 1s - loss: 0.2991 - acc: 0.8614 - val_loss: 0.3053 - val_acc: 0.8404\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss improved from 0.29558 to 0.29496, saving model to best_m.h5\n",
      " - 1s - loss: 0.2840 - acc: 0.8706 - val_loss: 0.2950 - val_acc: 0.8603\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 1s - loss: 0.2921 - acc: 0.8606 - val_loss: 0.2965 - val_acc: 0.8504\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss improved from 0.29496 to 0.29342, saving model to best_m.h5\n",
      " - 1s - loss: 0.2922 - acc: 0.8642 - val_loss: 0.2934 - val_acc: 0.8529\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 1s - loss: 0.2775 - acc: 0.8775 - val_loss: 0.3050 - val_acc: 0.8579\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 1s - loss: 0.2945 - acc: 0.8667 - val_loss: 0.3139 - val_acc: 0.8579\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 1s - loss: 0.2855 - acc: 0.8656 - val_loss: 0.3100 - val_acc: 0.8529\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 1s - loss: 0.2947 - acc: 0.8508 - val_loss: 0.2981 - val_acc: 0.8603\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 1s - loss: 0.2817 - acc: 0.8700 - val_loss: 0.3314 - val_acc: 0.8529\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 1s - loss: 0.3011 - acc: 0.8700 - val_loss: 0.3087 - val_acc: 0.8504\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 1s - loss: 0.2839 - acc: 0.8698 - val_loss: 0.3013 - val_acc: 0.8579\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 1s - loss: 0.2725 - acc: 0.8806 - val_loss: 0.2981 - val_acc: 0.8454\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 1s - loss: 0.2769 - acc: 0.8741 - val_loss: 0.3002 - val_acc: 0.8579\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 1s - loss: 0.2911 - acc: 0.8733 - val_loss: 0.2961 - val_acc: 0.8554\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 1s - loss: 0.3038 - acc: 0.8650 - val_loss: 0.2996 - val_acc: 0.8579\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 1s - loss: 0.2711 - acc: 0.8808 - val_loss: 0.2981 - val_acc: 0.8603\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 1s - loss: 0.2806 - acc: 0.8825 - val_loss: 0.2952 - val_acc: 0.8579\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 1s - loss: 0.2909 - acc: 0.8667 - val_loss: 0.3063 - val_acc: 0.8504\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 1s - loss: 0.3019 - acc: 0.8575 - val_loss: 0.3000 - val_acc: 0.8504\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 1s - loss: 0.2808 - acc: 0.8864 - val_loss: 0.2954 - val_acc: 0.8579\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 1s - loss: 0.2780 - acc: 0.8756 - val_loss: 0.2967 - val_acc: 0.8579\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=428):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.307305449119\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.638850\n",
      "1  4023181e    0.498615\n",
      "2  b20200e4    0.065239\n",
      "3  e7f018bb    0.965096\n",
      "4  4371c8c3    0.293843\n"
     ]
    }
   ],
   "source": [
    "with open('../features/cnn_2_aug_skimage_preprocess_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "\n",
    "# this 2728\n",
    "# skimage 2710\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_2_aug_skimage_preprocess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model=Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69345, saving model to best_m.h5\n",
      " - 5s - loss: 0.6978 - acc: 0.5205 - val_loss: 0.6935 - val_acc: 0.5087\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69345 to 0.69145, saving model to best_m.h5\n",
      " - 2s - loss: 0.6885 - acc: 0.5347 - val_loss: 0.6914 - val_acc: 0.5087\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69145 to 0.68975, saving model to best_m.h5\n",
      " - 2s - loss: 0.6766 - acc: 0.5714 - val_loss: 0.6898 - val_acc: 0.5087\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68975 to 0.67581, saving model to best_m.h5\n",
      " - 2s - loss: 0.6719 - acc: 0.5847 - val_loss: 0.6758 - val_acc: 0.5087\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.67581 to 0.60508, saving model to best_m.h5\n",
      " - 2s - loss: 0.6295 - acc: 0.6197 - val_loss: 0.6051 - val_acc: 0.6983\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.60508 to 0.57414, saving model to best_m.h5\n",
      " - 2s - loss: 0.6258 - acc: 0.6322 - val_loss: 0.5741 - val_acc: 0.7207\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.6106 - acc: 0.6467 - val_loss: 0.5976 - val_acc: 0.6808\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.6058 - acc: 0.6663 - val_loss: 0.5824 - val_acc: 0.6883\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.5947 - acc: 0.6639 - val_loss: 0.5756 - val_acc: 0.7132\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.57414 to 0.56023, saving model to best_m.h5\n",
      " - 2s - loss: 0.6040 - acc: 0.6499 - val_loss: 0.5602 - val_acc: 0.7207\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.5939 - acc: 0.6651 - val_loss: 0.6825 - val_acc: 0.6608\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.6068 - acc: 0.6631 - val_loss: 0.5700 - val_acc: 0.6958\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.5918 - acc: 0.6733 - val_loss: 0.5712 - val_acc: 0.7007\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.56023 to 0.55078, saving model to best_m.h5\n",
      " - 2s - loss: 0.5755 - acc: 0.6778 - val_loss: 0.5508 - val_acc: 0.7157\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.55078 to 0.53181, saving model to best_m.h5\n",
      " - 2s - loss: 0.5725 - acc: 0.6947 - val_loss: 0.5318 - val_acc: 0.7382\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.5787 - acc: 0.6870 - val_loss: 0.5412 - val_acc: 0.7382\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.5442 - acc: 0.7281 - val_loss: 0.5447 - val_acc: 0.7207\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.5770 - acc: 0.6887 - val_loss: 0.5353 - val_acc: 0.7257\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.53181 to 0.49567, saving model to best_m.h5\n",
      " - 2s - loss: 0.5479 - acc: 0.7183 - val_loss: 0.4957 - val_acc: 0.7631\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.5663 - acc: 0.7064 - val_loss: 0.5801 - val_acc: 0.6908\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.49567 to 0.48448, saving model to best_m.h5\n",
      " - 2s - loss: 0.5517 - acc: 0.7097 - val_loss: 0.4845 - val_acc: 0.7830\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.48448 to 0.46548, saving model to best_m.h5\n",
      " - 2s - loss: 0.5361 - acc: 0.7414 - val_loss: 0.4655 - val_acc: 0.7855\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.46548 to 0.46537, saving model to best_m.h5\n",
      " - 2s - loss: 0.5126 - acc: 0.7533 - val_loss: 0.4654 - val_acc: 0.7805\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.46537 to 0.45016, saving model to best_m.h5\n",
      " - 2s - loss: 0.5100 - acc: 0.7491 - val_loss: 0.4502 - val_acc: 0.7905\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.45016 to 0.44626, saving model to best_m.h5\n",
      " - 2s - loss: 0.5110 - acc: 0.7470 - val_loss: 0.4463 - val_acc: 0.7955\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.4991 - acc: 0.7658 - val_loss: 0.4463 - val_acc: 0.8055\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.44626 to 0.44356, saving model to best_m.h5\n",
      " - 2s - loss: 0.5029 - acc: 0.7566 - val_loss: 0.4436 - val_acc: 0.7930\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.5223 - acc: 0.7337 - val_loss: 0.4439 - val_acc: 0.7955\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.44356 to 0.44185, saving model to best_m.h5\n",
      " - 2s - loss: 0.5361 - acc: 0.7495 - val_loss: 0.4418 - val_acc: 0.7905\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.4813 - acc: 0.7700 - val_loss: 0.4545 - val_acc: 0.7955\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.44185 to 0.41489, saving model to best_m.h5\n",
      " - 2s - loss: 0.4946 - acc: 0.7564 - val_loss: 0.4149 - val_acc: 0.8180\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.4871 - acc: 0.7675 - val_loss: 0.4250 - val_acc: 0.8130\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.5261 - acc: 0.7425 - val_loss: 0.4296 - val_acc: 0.8105\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.4810 - acc: 0.7622 - val_loss: 0.4521 - val_acc: 0.7830\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.4633 - acc: 0.7866 - val_loss: 0.4450 - val_acc: 0.7980\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.41489 to 0.40961, saving model to best_m.h5\n",
      " - 2s - loss: 0.4957 - acc: 0.7617 - val_loss: 0.4096 - val_acc: 0.8105\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.4753 - acc: 0.7850 - val_loss: 0.4183 - val_acc: 0.8130\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.40961 to 0.39156, saving model to best_m.h5\n",
      " - 2s - loss: 0.4639 - acc: 0.7689 - val_loss: 0.3916 - val_acc: 0.8279\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.4877 - acc: 0.7691 - val_loss: 0.4133 - val_acc: 0.8105\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss improved from 0.39156 to 0.38826, saving model to best_m.h5\n",
      " - 2s - loss: 0.4802 - acc: 0.7731 - val_loss: 0.3883 - val_acc: 0.8254\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.38826 to 0.38409, saving model to best_m.h5\n",
      " - 2s - loss: 0.4716 - acc: 0.7639 - val_loss: 0.3841 - val_acc: 0.8279\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.4590 - acc: 0.7820 - val_loss: 0.4486 - val_acc: 0.7805\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.4634 - acc: 0.7858 - val_loss: 0.4005 - val_acc: 0.8254\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.4760 - acc: 0.7714 - val_loss: 0.3880 - val_acc: 0.8279\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.38409 to 0.36897, saving model to best_m.h5\n",
      " - 2s - loss: 0.4535 - acc: 0.7803 - val_loss: 0.3690 - val_acc: 0.8404\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.4474 - acc: 0.7883 - val_loss: 0.3695 - val_acc: 0.8329\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.4640 - acc: 0.7766 - val_loss: 0.3713 - val_acc: 0.8304\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.4645 - acc: 0.7666 - val_loss: 0.3980 - val_acc: 0.8204\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.4289 - acc: 0.8016 - val_loss: 0.4321 - val_acc: 0.8005\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.4510 - acc: 0.7830 - val_loss: 0.3798 - val_acc: 0.8229\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.4389 - acc: 0.7828 - val_loss: 0.4033 - val_acc: 0.8080\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.36897 to 0.35582, saving model to best_m.h5\n",
      " - 2s - loss: 0.4426 - acc: 0.7842 - val_loss: 0.3558 - val_acc: 0.8354\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.4633 - acc: 0.7589 - val_loss: 0.4037 - val_acc: 0.8254\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.4210 - acc: 0.8000 - val_loss: 0.4029 - val_acc: 0.8080\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.4516 - acc: 0.7908 - val_loss: 0.3598 - val_acc: 0.8279\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.4475 - acc: 0.7697 - val_loss: 0.3621 - val_acc: 0.8379\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss improved from 0.35582 to 0.35494, saving model to best_m.h5\n",
      " - 2s - loss: 0.4439 - acc: 0.7972 - val_loss: 0.3549 - val_acc: 0.8329\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss improved from 0.35494 to 0.34878, saving model to best_m.h5\n",
      " - 2s - loss: 0.4554 - acc: 0.7731 - val_loss: 0.3488 - val_acc: 0.8279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.34878 to 0.34851, saving model to best_m.h5\n",
      " - 2s - loss: 0.4260 - acc: 0.7967 - val_loss: 0.3485 - val_acc: 0.8404\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.4239 - acc: 0.7858 - val_loss: 0.3697 - val_acc: 0.8254\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.34851 to 0.32928, saving model to best_m.h5\n",
      " - 2s - loss: 0.4117 - acc: 0.7922 - val_loss: 0.3293 - val_acc: 0.8429\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.4283 - acc: 0.7858 - val_loss: 0.3451 - val_acc: 0.8479\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.4130 - acc: 0.8100 - val_loss: 0.3437 - val_acc: 0.8354\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.4327 - acc: 0.7925 - val_loss: 0.3361 - val_acc: 0.8354\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.4110 - acc: 0.8097 - val_loss: 0.3529 - val_acc: 0.8379\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.4170 - acc: 0.8000 - val_loss: 0.3314 - val_acc: 0.8429\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.3996 - acc: 0.8106 - val_loss: 0.3700 - val_acc: 0.8204\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.4168 - acc: 0.7914 - val_loss: 0.3316 - val_acc: 0.8354\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.3905 - acc: 0.8191 - val_loss: 0.3577 - val_acc: 0.8229\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.4093 - acc: 0.7953 - val_loss: 0.3386 - val_acc: 0.8454\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.32928 to 0.32272, saving model to best_m.h5\n",
      " - 2s - loss: 0.3921 - acc: 0.8075 - val_loss: 0.3227 - val_acc: 0.8379\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.3775 - acc: 0.8150 - val_loss: 0.3279 - val_acc: 0.8354\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.3889 - acc: 0.8175 - val_loss: 0.3293 - val_acc: 0.8354\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.32272 to 0.32041, saving model to best_m.h5\n",
      " - 2s - loss: 0.3757 - acc: 0.8225 - val_loss: 0.3204 - val_acc: 0.8454\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.3801 - acc: 0.8216 - val_loss: 0.3249 - val_acc: 0.8379\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss improved from 0.32041 to 0.31794, saving model to best_m.h5\n",
      " - 2s - loss: 0.3773 - acc: 0.8208 - val_loss: 0.3179 - val_acc: 0.8429\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.3827 - acc: 0.8056 - val_loss: 0.3192 - val_acc: 0.8379\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss improved from 0.31794 to 0.30967, saving model to best_m.h5\n",
      " - 2s - loss: 0.3730 - acc: 0.8316 - val_loss: 0.3097 - val_acc: 0.8379\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.3868 - acc: 0.8183 - val_loss: 0.3157 - val_acc: 0.8379\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.3933 - acc: 0.8064 - val_loss: 0.3157 - val_acc: 0.8404\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.3708 - acc: 0.8272 - val_loss: 0.3136 - val_acc: 0.8379\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.3674 - acc: 0.8333 - val_loss: 0.3165 - val_acc: 0.8429\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.3779 - acc: 0.8172 - val_loss: 0.3156 - val_acc: 0.8429\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.3937 - acc: 0.7947 - val_loss: 0.3319 - val_acc: 0.8254\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.3833 - acc: 0.8133 - val_loss: 0.3219 - val_acc: 0.8329\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.3421 - acc: 0.8291 - val_loss: 0.3207 - val_acc: 0.8379\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss improved from 0.30967 to 0.30469, saving model to best_m.h5\n",
      " - 2s - loss: 0.3904 - acc: 0.8072 - val_loss: 0.3047 - val_acc: 0.8429\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.3814 - acc: 0.8233 - val_loss: 0.3077 - val_acc: 0.8454\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.3991 - acc: 0.8122 - val_loss: 0.3094 - val_acc: 0.8529\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.3864 - acc: 0.8081 - val_loss: 0.3105 - val_acc: 0.8504\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.3781 - acc: 0.8189 - val_loss: 0.3157 - val_acc: 0.8429\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.3925 - acc: 0.8133 - val_loss: 0.3136 - val_acc: 0.8454\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.3725 - acc: 0.8325 - val_loss: 0.3105 - val_acc: 0.8504\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.3779 - acc: 0.8112 - val_loss: 0.3099 - val_acc: 0.8554\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.3728 - acc: 0.8208 - val_loss: 0.3146 - val_acc: 0.8504\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.3867 - acc: 0.8187 - val_loss: 0.3121 - val_acc: 0.8529\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.3515 - acc: 0.8350 - val_loss: 0.3169 - val_acc: 0.8479\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.3642 - acc: 0.8164 - val_loss: 0.3091 - val_acc: 0.8703\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.3832 - acc: 0.8183 - val_loss: 0.3093 - val_acc: 0.8554\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.3518 - acc: 0.8400 - val_loss: 0.3104 - val_acc: 0.8529\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.3631 - acc: 0.8225 - val_loss: 0.3077 - val_acc: 0.8529\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.3458 - acc: 0.8375 - val_loss: 0.3222 - val_acc: 0.8454\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.3675 - acc: 0.8225 - val_loss: 0.3116 - val_acc: 0.8554\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.3678 - acc: 0.8216 - val_loss: 0.3113 - val_acc: 0.8554\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.3505 - acc: 0.8316 - val_loss: 0.3169 - val_acc: 0.8579\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.3496 - acc: 0.8392 - val_loss: 0.3086 - val_acc: 0.8653\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.3531 - acc: 0.8247 - val_loss: 0.3171 - val_acc: 0.8728\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss improved from 0.30469 to 0.30335, saving model to best_m.h5\n",
      " - 2s - loss: 0.3553 - acc: 0.8439 - val_loss: 0.3034 - val_acc: 0.8554\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.3912 - acc: 0.8072 - val_loss: 0.3114 - val_acc: 0.8404\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.3333 - acc: 0.8333 - val_loss: 0.3095 - val_acc: 0.8554\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.3506 - acc: 0.8241 - val_loss: 0.3047 - val_acc: 0.8628\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.3783 - acc: 0.8064 - val_loss: 0.3143 - val_acc: 0.8504\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.3539 - acc: 0.8225 - val_loss: 0.3110 - val_acc: 0.8628\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.3198 - acc: 0.8437 - val_loss: 0.3389 - val_acc: 0.8329\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss improved from 0.30335 to 0.30335, saving model to best_m.h5\n",
      " - 2s - loss: 0.3780 - acc: 0.8233 - val_loss: 0.3033 - val_acc: 0.8678\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.3690 - acc: 0.8217 - val_loss: 0.3072 - val_acc: 0.8554\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.3329 - acc: 0.8368 - val_loss: 0.3104 - val_acc: 0.8628\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss improved from 0.30335 to 0.30064, saving model to best_m.h5\n",
      " - 2s - loss: 0.3661 - acc: 0.8292 - val_loss: 0.3006 - val_acc: 0.8628\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.3476 - acc: 0.8239 - val_loss: 0.3084 - val_acc: 0.8579\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.3486 - acc: 0.8281 - val_loss: 0.3062 - val_acc: 0.8728\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69022, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.6970 - acc: 0.5078 - val_loss: 0.6902 - val_acc: 0.5461\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6928 - acc: 0.5220 - val_loss: 0.6907 - val_acc: 0.5461\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69022 to 0.68953, saving model to best_m.h5\n",
      " - 2s - loss: 0.6909 - acc: 0.5447 - val_loss: 0.6895 - val_acc: 0.5461\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68953 to 0.68952, saving model to best_m.h5\n",
      " - 2s - loss: 0.6923 - acc: 0.5183 - val_loss: 0.6895 - val_acc: 0.5461\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.68952 to 0.68798, saving model to best_m.h5\n",
      " - 2s - loss: 0.6957 - acc: 0.5125 - val_loss: 0.6880 - val_acc: 0.5461\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.6868 - acc: 0.5264 - val_loss: 0.6913 - val_acc: 0.5461\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.6937 - acc: 0.5155 - val_loss: 0.6890 - val_acc: 0.5461\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.6880 - acc: 0.5322 - val_loss: 0.6911 - val_acc: 0.5461\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.68798 to 0.68783, saving model to best_m.h5\n",
      " - 2s - loss: 0.6891 - acc: 0.5311 - val_loss: 0.6878 - val_acc: 0.5461\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.68783 to 0.66114, saving model to best_m.h5\n",
      " - 2s - loss: 0.6872 - acc: 0.5636 - val_loss: 0.6611 - val_acc: 0.5461\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.6617 - acc: 0.5116 - val_loss: 0.6942 - val_acc: 0.4539\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.6913 - acc: 0.5311 - val_loss: 0.6870 - val_acc: 0.5436\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.6841 - acc: 0.5561 - val_loss: 0.6843 - val_acc: 0.5461\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.6660 - acc: 0.5374 - val_loss: 0.6941 - val_acc: 0.4539\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.6931 - acc: 0.4989 - val_loss: 0.6921 - val_acc: 0.5461\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.6848 - acc: 0.6125 - val_loss: 0.6685 - val_acc: 0.5636\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.66114 to 0.61308, saving model to best_m.h5\n",
      " - 2s - loss: 0.6568 - acc: 0.6134 - val_loss: 0.6131 - val_acc: 0.7007\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.6039 - acc: 0.6689 - val_loss: 0.6216 - val_acc: 0.6284\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.6505 - acc: 0.6067 - val_loss: 0.6656 - val_acc: 0.5312\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.61308 to 0.60790, saving model to best_m.h5\n",
      " - 2s - loss: 0.6165 - acc: 0.6456 - val_loss: 0.6079 - val_acc: 0.6733\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.60790 to 0.57308, saving model to best_m.h5\n",
      " - 2s - loss: 0.6084 - acc: 0.6641 - val_loss: 0.5731 - val_acc: 0.6758\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.57308 to 0.56876, saving model to best_m.h5\n",
      " - 2s - loss: 0.6086 - acc: 0.6614 - val_loss: 0.5688 - val_acc: 0.6758\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.56876 to 0.56721, saving model to best_m.h5\n",
      " - 2s - loss: 0.5946 - acc: 0.6905 - val_loss: 0.5672 - val_acc: 0.6808\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.56721 to 0.56514, saving model to best_m.h5\n",
      " - 2s - loss: 0.5971 - acc: 0.6931 - val_loss: 0.5651 - val_acc: 0.6833\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.6142 - acc: 0.6545 - val_loss: 0.5702 - val_acc: 0.6833\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.5786 - acc: 0.6883 - val_loss: 0.5784 - val_acc: 0.6933\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.5906 - acc: 0.6836 - val_loss: 0.5710 - val_acc: 0.6933\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.5837 - acc: 0.7006 - val_loss: 0.5983 - val_acc: 0.6534\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.5977 - acc: 0.6817 - val_loss: 0.5801 - val_acc: 0.6808\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.56514 to 0.55609, saving model to best_m.h5\n",
      " - 2s - loss: 0.5815 - acc: 0.6884 - val_loss: 0.5561 - val_acc: 0.6858\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss improved from 0.55609 to 0.55291, saving model to best_m.h5\n",
      " - 2s - loss: 0.5949 - acc: 0.6725 - val_loss: 0.5529 - val_acc: 0.6983\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.55291 to 0.54715, saving model to best_m.h5\n",
      " - 2s - loss: 0.5755 - acc: 0.6864 - val_loss: 0.5472 - val_acc: 0.6933\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.5942 - acc: 0.6537 - val_loss: 0.5859 - val_acc: 0.6384\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.5832 - acc: 0.7031 - val_loss: 0.5557 - val_acc: 0.6983\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.5672 - acc: 0.7007 - val_loss: 0.5769 - val_acc: 0.6608\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.5859 - acc: 0.6875 - val_loss: 0.5499 - val_acc: 0.6983\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.5744 - acc: 0.6908 - val_loss: 0.5928 - val_acc: 0.6284\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.54715 to 0.53816, saving model to best_m.h5\n",
      " - 2s - loss: 0.5808 - acc: 0.6937 - val_loss: 0.5382 - val_acc: 0.6983\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.53816 to 0.53786, saving model to best_m.h5\n",
      " - 2s - loss: 0.5737 - acc: 0.7039 - val_loss: 0.5379 - val_acc: 0.7007\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.5577 - acc: 0.7056 - val_loss: 0.5445 - val_acc: 0.7157\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.53786 to 0.52373, saving model to best_m.h5\n",
      " - 2s - loss: 0.5461 - acc: 0.7081 - val_loss: 0.5237 - val_acc: 0.7207\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.5806 - acc: 0.6817 - val_loss: 0.5377 - val_acc: 0.7057\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.5551 - acc: 0.7103 - val_loss: 0.5239 - val_acc: 0.7132\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.5428 - acc: 0.7183 - val_loss: 0.5690 - val_acc: 0.6933\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.5593 - acc: 0.6938 - val_loss: 0.5295 - val_acc: 0.6983\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.52373 to 0.50738, saving model to best_m.h5\n",
      " - 2s - loss: 0.5700 - acc: 0.6900 - val_loss: 0.5074 - val_acc: 0.7332\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.50738 to 0.49393, saving model to best_m.h5\n",
      " - 2s - loss: 0.5628 - acc: 0.6851 - val_loss: 0.4939 - val_acc: 0.7431\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.5464 - acc: 0.7289 - val_loss: 0.5041 - val_acc: 0.7232\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.49393 to 0.48064, saving model to best_m.h5\n",
      " - 2s - loss: 0.5287 - acc: 0.7231 - val_loss: 0.4806 - val_acc: 0.7531\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.5198 - acc: 0.7281 - val_loss: 0.4917 - val_acc: 0.7606\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.5235 - acc: 0.7425 - val_loss: 0.5260 - val_acc: 0.7332\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.48064 to 0.47320, saving model to best_m.h5\n",
      " - 2s - loss: 0.5376 - acc: 0.7291 - val_loss: 0.4732 - val_acc: 0.7855\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.5110 - acc: 0.7367 - val_loss: 0.5861 - val_acc: 0.6858\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.5468 - acc: 0.7142 - val_loss: 0.4772 - val_acc: 0.7656\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.5001 - acc: 0.7541 - val_loss: 0.4736 - val_acc: 0.7855\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.47320 to 0.44556, saving model to best_m.h5\n",
      " - 2s - loss: 0.5076 - acc: 0.7425 - val_loss: 0.4456 - val_acc: 0.7905\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.4872 - acc: 0.7539 - val_loss: 0.4505 - val_acc: 0.7830\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.5036 - acc: 0.7433 - val_loss: 0.4503 - val_acc: 0.7930\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.44556 to 0.42931, saving model to best_m.h5\n",
      " - 2s - loss: 0.5043 - acc: 0.7397 - val_loss: 0.4293 - val_acc: 0.8055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.4724 - acc: 0.7733 - val_loss: 0.4417 - val_acc: 0.7756\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.4981 - acc: 0.7464 - val_loss: 0.4392 - val_acc: 0.7980\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.4738 - acc: 0.7675 - val_loss: 0.4470 - val_acc: 0.7930\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.4676 - acc: 0.7706 - val_loss: 0.4828 - val_acc: 0.7506\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.5008 - acc: 0.7472 - val_loss: 0.4589 - val_acc: 0.7706\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.4687 - acc: 0.7697 - val_loss: 0.4377 - val_acc: 0.7805\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss improved from 0.42931 to 0.42602, saving model to best_m.h5\n",
      " - 2s - loss: 0.4928 - acc: 0.7591 - val_loss: 0.4260 - val_acc: 0.8155\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss improved from 0.42602 to 0.42240, saving model to best_m.h5\n",
      " - 2s - loss: 0.4590 - acc: 0.7666 - val_loss: 0.4224 - val_acc: 0.8105\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.4862 - acc: 0.7547 - val_loss: 0.5894 - val_acc: 0.6658\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.4472 - acc: 0.7858 - val_loss: 0.4461 - val_acc: 0.7930\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.42240 to 0.40542, saving model to best_m.h5\n",
      " - 2s - loss: 0.4375 - acc: 0.7981 - val_loss: 0.4054 - val_acc: 0.8155\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.40542 to 0.40116, saving model to best_m.h5\n",
      " - 2s - loss: 0.4316 - acc: 0.7831 - val_loss: 0.4012 - val_acc: 0.8030\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.4038 - acc: 0.8081 - val_loss: 0.4165 - val_acc: 0.7905\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.4225 - acc: 0.7981 - val_loss: 0.4292 - val_acc: 0.7805\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.40116 to 0.39388, saving model to best_m.h5\n",
      " - 2s - loss: 0.4252 - acc: 0.7966 - val_loss: 0.3939 - val_acc: 0.8105\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.4243 - acc: 0.7914 - val_loss: 0.3949 - val_acc: 0.8130\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.4069 - acc: 0.8041 - val_loss: 0.4105 - val_acc: 0.7930\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss improved from 0.39388 to 0.39388, saving model to best_m.h5\n",
      " - 2s - loss: 0.4106 - acc: 0.7906 - val_loss: 0.3939 - val_acc: 0.8105\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.4358 - acc: 0.8017 - val_loss: 0.3973 - val_acc: 0.8080\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.4129 - acc: 0.8080 - val_loss: 0.3950 - val_acc: 0.8105\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.4127 - acc: 0.8056 - val_loss: 0.4023 - val_acc: 0.8005\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.4073 - acc: 0.7997 - val_loss: 0.3967 - val_acc: 0.8005\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.4115 - acc: 0.8058 - val_loss: 0.4071 - val_acc: 0.8080\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.4115 - acc: 0.8016 - val_loss: 0.3978 - val_acc: 0.8055\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.4031 - acc: 0.8083 - val_loss: 0.3946 - val_acc: 0.8180\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.4105 - acc: 0.8025 - val_loss: 0.4008 - val_acc: 0.7955\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.39388 to 0.38518, saving model to best_m.h5\n",
      " - 2s - loss: 0.4139 - acc: 0.7997 - val_loss: 0.3852 - val_acc: 0.8180\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.4112 - acc: 0.8041 - val_loss: 0.3894 - val_acc: 0.8155\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss improved from 0.38518 to 0.37394, saving model to best_m.h5\n",
      " - 2s - loss: 0.4160 - acc: 0.7925 - val_loss: 0.3739 - val_acc: 0.8254\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.3913 - acc: 0.8158 - val_loss: 0.3865 - val_acc: 0.8279\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.4227 - acc: 0.7958 - val_loss: 0.4016 - val_acc: 0.7930\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.3988 - acc: 0.8172 - val_loss: 0.4146 - val_acc: 0.7830\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.4144 - acc: 0.8058 - val_loss: 0.3920 - val_acc: 0.8155\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.4138 - acc: 0.7997 - val_loss: 0.3867 - val_acc: 0.8130\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.4011 - acc: 0.8158 - val_loss: 0.3747 - val_acc: 0.8180\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.4000 - acc: 0.8075 - val_loss: 0.3990 - val_acc: 0.8204\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.4135 - acc: 0.7983 - val_loss: 0.3801 - val_acc: 0.8130\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.4052 - acc: 0.8125 - val_loss: 0.3828 - val_acc: 0.8254\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.4187 - acc: 0.7970 - val_loss: 0.3814 - val_acc: 0.8204\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.4031 - acc: 0.8158 - val_loss: 0.3813 - val_acc: 0.8254\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss improved from 0.37394 to 0.36950, saving model to best_m.h5\n",
      " - 2s - loss: 0.3929 - acc: 0.8142 - val_loss: 0.3695 - val_acc: 0.8279\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.3991 - acc: 0.8083 - val_loss: 0.3927 - val_acc: 0.8130\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.4092 - acc: 0.7926 - val_loss: 0.3791 - val_acc: 0.8229\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.3825 - acc: 0.8267 - val_loss: 0.3958 - val_acc: 0.8155\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.4230 - acc: 0.7895 - val_loss: 0.3859 - val_acc: 0.8180\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.3913 - acc: 0.8133 - val_loss: 0.3815 - val_acc: 0.8204\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.3866 - acc: 0.8125 - val_loss: 0.3730 - val_acc: 0.8329\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.4196 - acc: 0.7983 - val_loss: 0.3703 - val_acc: 0.8304\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss improved from 0.36950 to 0.36615, saving model to best_m.h5\n",
      " - 2s - loss: 0.3900 - acc: 0.8042 - val_loss: 0.3662 - val_acc: 0.8204\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.3841 - acc: 0.8166 - val_loss: 0.3725 - val_acc: 0.8254\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.4090 - acc: 0.7984 - val_loss: 0.3851 - val_acc: 0.8180\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.3712 - acc: 0.8208 - val_loss: 0.3874 - val_acc: 0.8105\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.4183 - acc: 0.7906 - val_loss: 0.3879 - val_acc: 0.8180\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.3817 - acc: 0.8239 - val_loss: 0.3751 - val_acc: 0.8279\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss improved from 0.36615 to 0.36432, saving model to best_m.h5\n",
      " - 2s - loss: 0.3954 - acc: 0.8131 - val_loss: 0.3643 - val_acc: 0.8254\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.3820 - acc: 0.8156 - val_loss: 0.3675 - val_acc: 0.8354\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss improved from 0.36432 to 0.36353, saving model to best_m.h5\n",
      " - 2s - loss: 0.3984 - acc: 0.8125 - val_loss: 0.3635 - val_acc: 0.8229\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.3701 - acc: 0.8391 - val_loss: 0.3683 - val_acc: 0.8329\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss improved from 0.36353 to 0.36148, saving model to best_m.h5\n",
      " - 2s - loss: 0.3896 - acc: 0.8133 - val_loss: 0.3615 - val_acc: 0.8429\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.3863 - acc: 0.8125 - val_loss: 0.3678 - val_acc: 0.8304\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.3795 - acc: 0.8283 - val_loss: 0.3808 - val_acc: 0.8204\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69242, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.6966 - acc: 0.4951 - val_loss: 0.6924 - val_acc: 0.6559\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.69242 to 0.69130, saving model to best_m.h5\n",
      " - 2s - loss: 0.6896 - acc: 0.5422 - val_loss: 0.6913 - val_acc: 0.5611\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69130 to 0.68928, saving model to best_m.h5\n",
      " - 2s - loss: 0.6945 - acc: 0.5034 - val_loss: 0.6893 - val_acc: 0.5611\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68928 to 0.66531, saving model to best_m.h5\n",
      " - 2s - loss: 0.6886 - acc: 0.5422 - val_loss: 0.6653 - val_acc: 0.6434\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.66531 to 0.61947, saving model to best_m.h5\n",
      " - 2s - loss: 0.6550 - acc: 0.5997 - val_loss: 0.6195 - val_acc: 0.6534\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.61947 to 0.60715, saving model to best_m.h5\n",
      " - 2s - loss: 0.6525 - acc: 0.6233 - val_loss: 0.6071 - val_acc: 0.6858\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.60715 to 0.58749, saving model to best_m.h5\n",
      " - 2s - loss: 0.6342 - acc: 0.6416 - val_loss: 0.5875 - val_acc: 0.6633\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.6161 - acc: 0.6616 - val_loss: 0.5958 - val_acc: 0.6459\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.6086 - acc: 0.6708 - val_loss: 0.5917 - val_acc: 0.6608\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.58749 to 0.57564, saving model to best_m.h5\n",
      " - 2s - loss: 0.6327 - acc: 0.6524 - val_loss: 0.5756 - val_acc: 0.6958\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.57564 to 0.55271, saving model to best_m.h5\n",
      " - 2s - loss: 0.6004 - acc: 0.6725 - val_loss: 0.5527 - val_acc: 0.7182\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.5973 - acc: 0.6719 - val_loss: 0.5549 - val_acc: 0.6933\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.5900 - acc: 0.6775 - val_loss: 0.5874 - val_acc: 0.6534\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.55271 to 0.55196, saving model to best_m.h5\n",
      " - 2s - loss: 0.6056 - acc: 0.6564 - val_loss: 0.5520 - val_acc: 0.6983\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.55196 to 0.54887, saving model to best_m.h5\n",
      " - 2s - loss: 0.6012 - acc: 0.6839 - val_loss: 0.5489 - val_acc: 0.7032\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.5787 - acc: 0.6862 - val_loss: 0.5748 - val_acc: 0.6683\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.5802 - acc: 0.6908 - val_loss: 0.5729 - val_acc: 0.6908\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.5889 - acc: 0.6858 - val_loss: 0.5668 - val_acc: 0.6908\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.5624 - acc: 0.7049 - val_loss: 0.5605 - val_acc: 0.6808\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.54887 to 0.53176, saving model to best_m.h5\n",
      " - 2s - loss: 0.5896 - acc: 0.6708 - val_loss: 0.5318 - val_acc: 0.7232\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.53176 to 0.52151, saving model to best_m.h5\n",
      " - 2s - loss: 0.5494 - acc: 0.7189 - val_loss: 0.5215 - val_acc: 0.7207\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.52151 to 0.51460, saving model to best_m.h5\n",
      " - 2s - loss: 0.5380 - acc: 0.7128 - val_loss: 0.5146 - val_acc: 0.7257\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.51460 to 0.51204, saving model to best_m.h5\n",
      " - 2s - loss: 0.5319 - acc: 0.7381 - val_loss: 0.5120 - val_acc: 0.7257\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.51204 to 0.50573, saving model to best_m.h5\n",
      " - 2s - loss: 0.5485 - acc: 0.7112 - val_loss: 0.5057 - val_acc: 0.7456\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.50573 to 0.50368, saving model to best_m.h5\n",
      " - 2s - loss: 0.5093 - acc: 0.7408 - val_loss: 0.5037 - val_acc: 0.7282\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.50368 to 0.46881, saving model to best_m.h5\n",
      " - 2s - loss: 0.5019 - acc: 0.7406 - val_loss: 0.4688 - val_acc: 0.7656\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.5177 - acc: 0.7458 - val_loss: 0.4835 - val_acc: 0.7556\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.4920 - acc: 0.7580 - val_loss: 0.4806 - val_acc: 0.7656\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss improved from 0.46881 to 0.46876, saving model to best_m.h5\n",
      " - 2s - loss: 0.4945 - acc: 0.7650 - val_loss: 0.4688 - val_acc: 0.7606\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss improved from 0.46876 to 0.42931, saving model to best_m.h5\n",
      " - 2s - loss: 0.4664 - acc: 0.7720 - val_loss: 0.4293 - val_acc: 0.7781\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.4828 - acc: 0.7616 - val_loss: 0.4501 - val_acc: 0.7681\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.5047 - acc: 0.7467 - val_loss: 0.4419 - val_acc: 0.7855\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.4647 - acc: 0.7800 - val_loss: 0.5585 - val_acc: 0.7481\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.4482 - acc: 0.7900 - val_loss: 0.4311 - val_acc: 0.7905\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.42931 to 0.41580, saving model to best_m.h5\n",
      " - 2s - loss: 0.4646 - acc: 0.7762 - val_loss: 0.4158 - val_acc: 0.7930\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.4375 - acc: 0.7797 - val_loss: 0.4734 - val_acc: 0.7282\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.4961 - acc: 0.7592 - val_loss: 0.4208 - val_acc: 0.7955\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.4402 - acc: 0.7908 - val_loss: 0.4200 - val_acc: 0.7955\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.41580 to 0.40626, saving model to best_m.h5\n",
      " - 2s - loss: 0.4416 - acc: 0.7766 - val_loss: 0.4063 - val_acc: 0.7955\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.4338 - acc: 0.8000 - val_loss: 0.4542 - val_acc: 0.7581\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.40626 to 0.40136, saving model to best_m.h5\n",
      " - 2s - loss: 0.4430 - acc: 0.7767 - val_loss: 0.4014 - val_acc: 0.8030\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.4181 - acc: 0.7922 - val_loss: 0.4174 - val_acc: 0.8030\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.40136 to 0.39488, saving model to best_m.h5\n",
      " - 2s - loss: 0.4308 - acc: 0.7825 - val_loss: 0.3949 - val_acc: 0.8005\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.4109 - acc: 0.8066 - val_loss: 0.4030 - val_acc: 0.8130\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.39488 to 0.37683, saving model to best_m.h5\n",
      " - 2s - loss: 0.4090 - acc: 0.8058 - val_loss: 0.3768 - val_acc: 0.8155\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss improved from 0.37683 to 0.37265, saving model to best_m.h5\n",
      " - 2s - loss: 0.4232 - acc: 0.7875 - val_loss: 0.3727 - val_acc: 0.8080\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.4106 - acc: 0.8116 - val_loss: 0.3758 - val_acc: 0.8180\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.4166 - acc: 0.8022 - val_loss: 0.3818 - val_acc: 0.8080\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.37265 to 0.36581, saving model to best_m.h5\n",
      " - 2s - loss: 0.4325 - acc: 0.7842 - val_loss: 0.3658 - val_acc: 0.8254\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.4486 - acc: 0.7731 - val_loss: 0.3976 - val_acc: 0.8055\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.3981 - acc: 0.8047 - val_loss: 0.3836 - val_acc: 0.8030\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.4296 - acc: 0.7781 - val_loss: 0.3929 - val_acc: 0.8005\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.36581 to 0.36147, saving model to best_m.h5\n",
      " - 2s - loss: 0.3884 - acc: 0.8028 - val_loss: 0.3615 - val_acc: 0.8254\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.4083 - acc: 0.7992 - val_loss: 0.3939 - val_acc: 0.7905\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss improved from 0.36147 to 0.34211, saving model to best_m.h5\n",
      " - 2s - loss: 0.3622 - acc: 0.8191 - val_loss: 0.3421 - val_acc: 0.8279\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss improved from 0.34211 to 0.32738, saving model to best_m.h5\n",
      " - 2s - loss: 0.3685 - acc: 0.8256 - val_loss: 0.3274 - val_acc: 0.8454\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.4085 - acc: 0.8033 - val_loss: 0.3445 - val_acc: 0.8229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.3986 - acc: 0.8039 - val_loss: 0.4420 - val_acc: 0.7830\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.4017 - acc: 0.7997 - val_loss: 0.3424 - val_acc: 0.8254\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.3726 - acc: 0.8283 - val_loss: 0.3439 - val_acc: 0.8279\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.3818 - acc: 0.8174 - val_loss: 0.3619 - val_acc: 0.8279\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.3784 - acc: 0.8175 - val_loss: 0.3296 - val_acc: 0.8429\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.3928 - acc: 0.8106 - val_loss: 0.3854 - val_acc: 0.8329\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.3976 - acc: 0.8197 - val_loss: 0.3930 - val_acc: 0.8254\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.3815 - acc: 0.8070 - val_loss: 0.3440 - val_acc: 0.8155\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.3931 - acc: 0.8183 - val_loss: 0.3421 - val_acc: 0.8329\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.3648 - acc: 0.8291 - val_loss: 0.3345 - val_acc: 0.8429\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.3712 - acc: 0.8217 - val_loss: 0.3521 - val_acc: 0.8404\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.3966 - acc: 0.8072 - val_loss: 0.3378 - val_acc: 0.8254\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss improved from 0.32738 to 0.31770, saving model to best_m.h5\n",
      " - 2s - loss: 0.3484 - acc: 0.8325 - val_loss: 0.3177 - val_acc: 0.8354\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.31770 to 0.31399, saving model to best_m.h5\n",
      " - 2s - loss: 0.3346 - acc: 0.8425 - val_loss: 0.3140 - val_acc: 0.8304\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.3351 - acc: 0.8442 - val_loss: 0.3389 - val_acc: 0.8304\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss improved from 0.31399 to 0.30895, saving model to best_m.h5\n",
      " - 2s - loss: 0.3373 - acc: 0.8333 - val_loss: 0.3089 - val_acc: 0.8429\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.3292 - acc: 0.8466 - val_loss: 0.3222 - val_acc: 0.8354\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.3418 - acc: 0.8350 - val_loss: 0.3209 - val_acc: 0.8329\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.3480 - acc: 0.8281 - val_loss: 0.3268 - val_acc: 0.8304\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss improved from 0.30895 to 0.30832, saving model to best_m.h5\n",
      " - 2s - loss: 0.3350 - acc: 0.8389 - val_loss: 0.3083 - val_acc: 0.8454\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.3333 - acc: 0.8541 - val_loss: 0.3146 - val_acc: 0.8454\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.3269 - acc: 0.8497 - val_loss: 0.3132 - val_acc: 0.8404\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.3273 - acc: 0.8500 - val_loss: 0.3164 - val_acc: 0.8429\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.3396 - acc: 0.8508 - val_loss: 0.3112 - val_acc: 0.8454\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.3398 - acc: 0.8508 - val_loss: 0.3222 - val_acc: 0.8329\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.3287 - acc: 0.8483 - val_loss: 0.3088 - val_acc: 0.8404\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.3326 - acc: 0.8433 - val_loss: 0.3126 - val_acc: 0.8479\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.3172 - acc: 0.8522 - val_loss: 0.3096 - val_acc: 0.8404\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss improved from 0.30832 to 0.30577, saving model to best_m.h5\n",
      " - 2s - loss: 0.3152 - acc: 0.8541 - val_loss: 0.3058 - val_acc: 0.8504\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.3407 - acc: 0.8322 - val_loss: 0.3097 - val_acc: 0.8479\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.3201 - acc: 0.8566 - val_loss: 0.3084 - val_acc: 0.8454\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.3524 - acc: 0.8491 - val_loss: 0.3095 - val_acc: 0.8429\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss improved from 0.30577 to 0.29924, saving model to best_m.h5\n",
      " - 2s - loss: 0.3112 - acc: 0.8492 - val_loss: 0.2992 - val_acc: 0.8454\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.3257 - acc: 0.8431 - val_loss: 0.3370 - val_acc: 0.8304\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.3019 - acc: 0.8497 - val_loss: 0.3064 - val_acc: 0.8554\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss improved from 0.29924 to 0.29900, saving model to best_m.h5\n",
      " - 2s - loss: 0.3056 - acc: 0.8658 - val_loss: 0.2990 - val_acc: 0.8579\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.3338 - acc: 0.8433 - val_loss: 0.3062 - val_acc: 0.8479\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.3389 - acc: 0.8387 - val_loss: 0.3029 - val_acc: 0.8404\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.3391 - acc: 0.8441 - val_loss: 0.3092 - val_acc: 0.8429\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.3297 - acc: 0.8333 - val_loss: 0.3146 - val_acc: 0.8429\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.3247 - acc: 0.8391 - val_loss: 0.3047 - val_acc: 0.8529\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.3145 - acc: 0.8481 - val_loss: 0.3050 - val_acc: 0.8429\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.3406 - acc: 0.8333 - val_loss: 0.3038 - val_acc: 0.8603\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.3162 - acc: 0.8466 - val_loss: 0.3007 - val_acc: 0.8554\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.3163 - acc: 0.8531 - val_loss: 0.3022 - val_acc: 0.8579\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.3182 - acc: 0.8550 - val_loss: 0.3454 - val_acc: 0.8379\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.3376 - acc: 0.8464 - val_loss: 0.3217 - val_acc: 0.8379\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.3210 - acc: 0.8483 - val_loss: 0.3080 - val_acc: 0.8504\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.3355 - acc: 0.8381 - val_loss: 0.3012 - val_acc: 0.8504\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.3193 - acc: 0.8541 - val_loss: 0.3051 - val_acc: 0.8454\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.3278 - acc: 0.8416 - val_loss: 0.3094 - val_acc: 0.8429\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.3109 - acc: 0.8500 - val_loss: 0.3015 - val_acc: 0.8429\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss improved from 0.29900 to 0.29680, saving model to best_m.h5\n",
      " - 2s - loss: 0.3324 - acc: 0.8366 - val_loss: 0.2968 - val_acc: 0.8554\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.3409 - acc: 0.8450 - val_loss: 0.2993 - val_acc: 0.8554\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss improved from 0.29680 to 0.28892, saving model to best_m.h5\n",
      " - 2s - loss: 0.3064 - acc: 0.8497 - val_loss: 0.2889 - val_acc: 0.8479\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.3103 - acc: 0.8575 - val_loss: 0.2958 - val_acc: 0.8603\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.3197 - acc: 0.8517 - val_loss: 0.3090 - val_acc: 0.8479\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.3168 - acc: 0.8547 - val_loss: 0.2969 - val_acc: 0.8554\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.2999 - acc: 0.8667 - val_loss: 0.3017 - val_acc: 0.8479\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.3370 - acc: 0.8437 - val_loss: 0.3076 - val_acc: 0.8379\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.3057 - acc: 0.8567 - val_loss: 0.2998 - val_acc: 0.8603\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.3313 - acc: 0.8359 - val_loss: 0.3052 - val_acc: 0.8504\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.3293 - acc: 0.8541 - val_loss: 0.3127 - val_acc: 0.8429\n",
      "============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.69030, saving model to best_m.h5\n",
      " - 5s - loss: 0.6938 - acc: 0.5433 - val_loss: 0.6903 - val_acc: 0.5062\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6771 - acc: 0.5322 - val_loss: 0.6909 - val_acc: 0.5062\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.69030 to 0.63921, saving model to best_m.h5\n",
      " - 2s - loss: 0.6435 - acc: 0.6187 - val_loss: 0.6392 - val_acc: 0.6484\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.6333 - acc: 0.6370 - val_loss: 0.6505 - val_acc: 0.6808\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.6370 - acc: 0.5997 - val_loss: 0.6904 - val_acc: 0.5062\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.63921 to 0.59358, saving model to best_m.h5\n",
      " - 2s - loss: 0.6343 - acc: 0.5983 - val_loss: 0.5936 - val_acc: 0.6858\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.59358 to 0.59138, saving model to best_m.h5\n",
      " - 2s - loss: 0.5995 - acc: 0.6800 - val_loss: 0.5914 - val_acc: 0.6808\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.59138 to 0.58810, saving model to best_m.h5\n",
      " - 2s - loss: 0.5985 - acc: 0.6747 - val_loss: 0.5881 - val_acc: 0.6908\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.58810 to 0.58288, saving model to best_m.h5\n",
      " - 2s - loss: 0.5911 - acc: 0.6800 - val_loss: 0.5829 - val_acc: 0.6908\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.58288 to 0.56466, saving model to best_m.h5\n",
      " - 2s - loss: 0.6161 - acc: 0.6549 - val_loss: 0.5647 - val_acc: 0.6883\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.5808 - acc: 0.6731 - val_loss: 0.6228 - val_acc: 0.6559\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.5850 - acc: 0.6870 - val_loss: 0.6679 - val_acc: 0.5835\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.5880 - acc: 0.6756 - val_loss: 0.5769 - val_acc: 0.6883\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.5816 - acc: 0.6856 - val_loss: 0.5718 - val_acc: 0.7032\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.6055 - acc: 0.6614 - val_loss: 0.5830 - val_acc: 0.6958\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.5870 - acc: 0.6900 - val_loss: 0.5807 - val_acc: 0.6983\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.56466 to 0.55474, saving model to best_m.h5\n",
      " - 2s - loss: 0.5652 - acc: 0.6917 - val_loss: 0.5547 - val_acc: 0.7032\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.5899 - acc: 0.6955 - val_loss: 0.5571 - val_acc: 0.6983\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.55474 to 0.50588, saving model to best_m.h5\n",
      " - 2s - loss: 0.5575 - acc: 0.6958 - val_loss: 0.5059 - val_acc: 0.7357\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.5574 - acc: 0.7047 - val_loss: 0.5442 - val_acc: 0.6858\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.5430 - acc: 0.7011 - val_loss: 0.5077 - val_acc: 0.7257\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.50588 to 0.50105, saving model to best_m.h5\n",
      " - 2s - loss: 0.5396 - acc: 0.7325 - val_loss: 0.5010 - val_acc: 0.7307\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.50105 to 0.49199, saving model to best_m.h5\n",
      " - 2s - loss: 0.5035 - acc: 0.7366 - val_loss: 0.4920 - val_acc: 0.7406\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.49199 to 0.48049, saving model to best_m.h5\n",
      " - 2s - loss: 0.5279 - acc: 0.7345 - val_loss: 0.4805 - val_acc: 0.7382\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.4898 - acc: 0.7558 - val_loss: 0.4811 - val_acc: 0.7481\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.48049 to 0.45782, saving model to best_m.h5\n",
      " - 2s - loss: 0.4963 - acc: 0.7514 - val_loss: 0.4578 - val_acc: 0.7781\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.45782 to 0.44939, saving model to best_m.h5\n",
      " - 2s - loss: 0.4944 - acc: 0.7383 - val_loss: 0.4494 - val_acc: 0.7731\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss improved from 0.44939 to 0.44093, saving model to best_m.h5\n",
      " - 2s - loss: 0.4775 - acc: 0.7522 - val_loss: 0.4409 - val_acc: 0.7880\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.4817 - acc: 0.7561 - val_loss: 0.4610 - val_acc: 0.7805\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.4827 - acc: 0.7533 - val_loss: 0.4514 - val_acc: 0.7731\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.4720 - acc: 0.7689 - val_loss: 0.4770 - val_acc: 0.7606\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.44093 to 0.41232, saving model to best_m.h5\n",
      " - 2s - loss: 0.4710 - acc: 0.7583 - val_loss: 0.4123 - val_acc: 0.8030\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.4510 - acc: 0.7691 - val_loss: 0.4249 - val_acc: 0.7930\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.4457 - acc: 0.7756 - val_loss: 0.4365 - val_acc: 0.7955\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.41232 to 0.40512, saving model to best_m.h5\n",
      " - 2s - loss: 0.4425 - acc: 0.7814 - val_loss: 0.4051 - val_acc: 0.8180\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.4009 - acc: 0.8114 - val_loss: 0.4955 - val_acc: 0.7581\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.4653 - acc: 0.7558 - val_loss: 0.4202 - val_acc: 0.7980\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss improved from 0.40512 to 0.38824, saving model to best_m.h5\n",
      " - 2s - loss: 0.4064 - acc: 0.8041 - val_loss: 0.3882 - val_acc: 0.8130\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.4419 - acc: 0.7697 - val_loss: 0.4189 - val_acc: 0.7855\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.4056 - acc: 0.8100 - val_loss: 0.3892 - val_acc: 0.8155\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.4258 - acc: 0.7899 - val_loss: 0.4045 - val_acc: 0.8105\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.4372 - acc: 0.7908 - val_loss: 0.3899 - val_acc: 0.8254\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.38824 to 0.37354, saving model to best_m.h5\n",
      " - 2s - loss: 0.3993 - acc: 0.8008 - val_loss: 0.3735 - val_acc: 0.8379\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.4289 - acc: 0.7862 - val_loss: 0.4363 - val_acc: 0.7805\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.4066 - acc: 0.8166 - val_loss: 0.3843 - val_acc: 0.8354\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.4256 - acc: 0.7975 - val_loss: 0.4072 - val_acc: 0.8005\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.4467 - acc: 0.7789 - val_loss: 0.3986 - val_acc: 0.8130\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.3960 - acc: 0.7903 - val_loss: 0.3752 - val_acc: 0.8329\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.4045 - acc: 0.8050 - val_loss: 0.3997 - val_acc: 0.7905\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.3952 - acc: 0.8097 - val_loss: 0.3919 - val_acc: 0.7955\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.3812 - acc: 0.8108 - val_loss: 0.3823 - val_acc: 0.8080\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss improved from 0.37354 to 0.37265, saving model to best_m.h5\n",
      " - 2s - loss: 0.3923 - acc: 0.7989 - val_loss: 0.3726 - val_acc: 0.8279\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.3752 - acc: 0.8142 - val_loss: 0.4694 - val_acc: 0.7706\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.3985 - acc: 0.8137 - val_loss: 0.3895 - val_acc: 0.7880\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss improved from 0.37265 to 0.36024, saving model to best_m.h5\n",
      " - 2s - loss: 0.3825 - acc: 0.8039 - val_loss: 0.3602 - val_acc: 0.8229\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.3924 - acc: 0.8162 - val_loss: 0.3748 - val_acc: 0.8180\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.3911 - acc: 0.8041 - val_loss: 0.3761 - val_acc: 0.8279\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.3593 - acc: 0.8222 - val_loss: 0.3721 - val_acc: 0.8130\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.3776 - acc: 0.8166 - val_loss: 0.3631 - val_acc: 0.8254\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.3704 - acc: 0.8275 - val_loss: 0.4107 - val_acc: 0.7731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.36024 to 0.35405, saving model to best_m.h5\n",
      " - 2s - loss: 0.3495 - acc: 0.8239 - val_loss: 0.3540 - val_acc: 0.8404\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.3404 - acc: 0.8383 - val_loss: 0.3595 - val_acc: 0.8354\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.35405 to 0.34730, saving model to best_m.h5\n",
      " - 2s - loss: 0.3592 - acc: 0.8316 - val_loss: 0.3473 - val_acc: 0.8329\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.3710 - acc: 0.8289 - val_loss: 0.3869 - val_acc: 0.7880\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss improved from 0.34730 to 0.34210, saving model to best_m.h5\n",
      " - 2s - loss: 0.3711 - acc: 0.8133 - val_loss: 0.3421 - val_acc: 0.8479\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.3604 - acc: 0.8358 - val_loss: 0.3458 - val_acc: 0.8254\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.3396 - acc: 0.8425 - val_loss: 0.3555 - val_acc: 0.8329\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.3598 - acc: 0.8383 - val_loss: 0.4592 - val_acc: 0.7581\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.3770 - acc: 0.8150 - val_loss: 0.3579 - val_acc: 0.8229\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.3579 - acc: 0.8322 - val_loss: 0.3678 - val_acc: 0.8080\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.3179 - acc: 0.8600 - val_loss: 0.3484 - val_acc: 0.8404\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.3397 - acc: 0.8431 - val_loss: 0.3489 - val_acc: 0.8279\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.3094 - acc: 0.8416 - val_loss: 0.3502 - val_acc: 0.8279\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.34210 to 0.33883, saving model to best_m.h5\n",
      " - 2s - loss: 0.3159 - acc: 0.8500 - val_loss: 0.3388 - val_acc: 0.8479\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.3326 - acc: 0.8425 - val_loss: 0.3419 - val_acc: 0.8404\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.3056 - acc: 0.8533 - val_loss: 0.3484 - val_acc: 0.8279\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.3188 - acc: 0.8633 - val_loss: 0.3420 - val_acc: 0.8379\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.3239 - acc: 0.8506 - val_loss: 0.3429 - val_acc: 0.8354\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.33883 to 0.33515, saving model to best_m.h5\n",
      " - 2s - loss: 0.3299 - acc: 0.8558 - val_loss: 0.3351 - val_acc: 0.8504\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.3366 - acc: 0.8466 - val_loss: 0.3398 - val_acc: 0.8404\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.3105 - acc: 0.8716 - val_loss: 0.3482 - val_acc: 0.8229\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss improved from 0.33515 to 0.33060, saving model to best_m.h5\n",
      " - 2s - loss: 0.3172 - acc: 0.8550 - val_loss: 0.3306 - val_acc: 0.8379\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.3158 - acc: 0.8598 - val_loss: 0.3322 - val_acc: 0.8479\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.3054 - acc: 0.8673 - val_loss: 0.3316 - val_acc: 0.8329\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.3125 - acc: 0.8583 - val_loss: 0.3721 - val_acc: 0.8080\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.3433 - acc: 0.8362 - val_loss: 0.3391 - val_acc: 0.8304\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.3127 - acc: 0.8475 - val_loss: 0.3603 - val_acc: 0.8229\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.3171 - acc: 0.8483 - val_loss: 0.3356 - val_acc: 0.8479\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.3186 - acc: 0.8589 - val_loss: 0.3558 - val_acc: 0.8155\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.3165 - acc: 0.8500 - val_loss: 0.3376 - val_acc: 0.8329\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.3001 - acc: 0.8733 - val_loss: 0.3340 - val_acc: 0.8554\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.3194 - acc: 0.8531 - val_loss: 0.3347 - val_acc: 0.8479\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.3088 - acc: 0.8416 - val_loss: 0.3479 - val_acc: 0.8379\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.3026 - acc: 0.8675 - val_loss: 0.3519 - val_acc: 0.8304\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.2862 - acc: 0.8708 - val_loss: 0.3452 - val_acc: 0.8304\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.3077 - acc: 0.8564 - val_loss: 0.3356 - val_acc: 0.8404\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.3206 - acc: 0.8467 - val_loss: 0.3415 - val_acc: 0.8254\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.3192 - acc: 0.8497 - val_loss: 0.3419 - val_acc: 0.8304\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.2826 - acc: 0.8650 - val_loss: 0.3310 - val_acc: 0.8454\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.3227 - acc: 0.8475 - val_loss: 0.3836 - val_acc: 0.7980\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.3137 - acc: 0.8453 - val_loss: 0.3527 - val_acc: 0.8180\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.3094 - acc: 0.8522 - val_loss: 0.3335 - val_acc: 0.8379\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.3058 - acc: 0.8464 - val_loss: 0.3387 - val_acc: 0.8130\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.3026 - acc: 0.8570 - val_loss: 0.3557 - val_acc: 0.8030\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.2903 - acc: 0.8708 - val_loss: 0.3387 - val_acc: 0.8404\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.3209 - acc: 0.8447 - val_loss: 0.3392 - val_acc: 0.8080\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.2880 - acc: 0.8648 - val_loss: 0.3507 - val_acc: 0.8204\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.2892 - acc: 0.8692 - val_loss: 0.3519 - val_acc: 0.8130\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.2975 - acc: 0.8656 - val_loss: 0.3330 - val_acc: 0.8379\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss improved from 0.33060 to 0.32981, saving model to best_m.h5\n",
      " - 2s - loss: 0.2851 - acc: 0.8622 - val_loss: 0.3298 - val_acc: 0.8354\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.2996 - acc: 0.8564 - val_loss: 0.3343 - val_acc: 0.8254\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.2873 - acc: 0.8589 - val_loss: 0.3368 - val_acc: 0.8254\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.3065 - acc: 0.8608 - val_loss: 0.3328 - val_acc: 0.8404\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.2797 - acc: 0.8608 - val_loss: 0.3456 - val_acc: 0.8155\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.2890 - acc: 0.8714 - val_loss: 0.3303 - val_acc: 0.8379\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.3093 - acc: 0.8550 - val_loss: 0.3471 - val_acc: 0.8030\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.3007 - acc: 0.8566 - val_loss: 0.3335 - val_acc: 0.8354\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.3002 - acc: 0.8533 - val_loss: 0.3325 - val_acc: 0.8254\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss improved from 0.32981 to 0.32658, saving model to best_m.h5\n",
      " - 2s - loss: 0.2879 - acc: 0.8633 - val_loss: 0.3266 - val_acc: 0.8504\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.2928 - acc: 0.8639 - val_loss: 0.3432 - val_acc: 0.8130\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.319404888954\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.597344\n",
      "1  4023181e    0.505602\n",
      "2  b20200e4    0.201883\n",
      "3  e7f018bb    0.984903\n",
      "4  4371c8c3    0.580867\n"
     ]
    }
   ],
   "source": [
    "with open('../features/cnn_3_aug_skimage_preprocess_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "\n",
    "# this 2737\n",
    "# new  2509\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_3_aug_skimage_preprocess.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "    ConvBlock(model, 1, 32)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 4x4x128\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.82608, saving model to best_m.h5\n",
      " - 6s - loss: 0.7381 - acc: 0.6539 - val_loss: 0.8261 - val_acc: 0.5087\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6385 - acc: 0.6970 - val_loss: 1.1154 - val_acc: 0.5087\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.5527 - acc: 0.7522 - val_loss: 0.9179 - val_acc: 0.5087\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.4885 - acc: 0.7608 - val_loss: 1.5764 - val_acc: 0.5087\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.4782 - acc: 0.7733 - val_loss: 1.4799 - val_acc: 0.5112\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.82608 to 0.81601, saving model to best_m.h5\n",
      " - 2s - loss: 0.5424 - acc: 0.7317 - val_loss: 0.8160 - val_acc: 0.5885\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.81601 to 0.81540, saving model to best_m.h5\n",
      " - 2s - loss: 0.4869 - acc: 0.7526 - val_loss: 0.8154 - val_acc: 0.6384\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.81540 to 0.79209, saving model to best_m.h5\n",
      " - 2s - loss: 0.5190 - acc: 0.7545 - val_loss: 0.7921 - val_acc: 0.6908\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.79209 to 0.62636, saving model to best_m.h5\n",
      " - 2s - loss: 0.4870 - acc: 0.7622 - val_loss: 0.6264 - val_acc: 0.7082\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.62636 to 0.61235, saving model to best_m.h5\n",
      " - 2s - loss: 0.4687 - acc: 0.7722 - val_loss: 0.6123 - val_acc: 0.7382\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.61235 to 0.36161, saving model to best_m.h5\n",
      " - 3s - loss: 0.4228 - acc: 0.7987 - val_loss: 0.3616 - val_acc: 0.8204\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.4340 - acc: 0.7941 - val_loss: 0.3970 - val_acc: 0.8180\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.4606 - acc: 0.7803 - val_loss: 0.7901 - val_acc: 0.7182\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.4042 - acc: 0.8091 - val_loss: 0.7358 - val_acc: 0.7032\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.4103 - acc: 0.7900 - val_loss: 0.3866 - val_acc: 0.8404\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.3737 - acc: 0.8272 - val_loss: 0.8767 - val_acc: 0.6584\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.3772 - acc: 0.8297 - val_loss: 0.4097 - val_acc: 0.7930\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.4097 - acc: 0.8047 - val_loss: 0.3623 - val_acc: 0.8429\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.3695 - acc: 0.8283 - val_loss: 0.4772 - val_acc: 0.7781\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3621 - acc: 0.8231 - val_loss: 1.5723 - val_acc: 0.5810\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.36161 to 0.34007, saving model to best_m.h5\n",
      " - 2s - loss: 0.3302 - acc: 0.8400 - val_loss: 0.3401 - val_acc: 0.8603\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.3249 - acc: 0.8547 - val_loss: 0.8627 - val_acc: 0.7082\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.34007 to 0.32679, saving model to best_m.h5\n",
      " - 2s - loss: 0.3214 - acc: 0.8472 - val_loss: 0.3268 - val_acc: 0.8678\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.3156 - acc: 0.8533 - val_loss: 0.5115 - val_acc: 0.8080\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.32679 to 0.29094, saving model to best_m.h5\n",
      " - 2s - loss: 0.3008 - acc: 0.8575 - val_loss: 0.2909 - val_acc: 0.8653\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.3355 - acc: 0.8506 - val_loss: 0.4945 - val_acc: 0.7805\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.3054 - acc: 0.8589 - val_loss: 0.5432 - val_acc: 0.7855\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.3196 - acc: 0.8475 - val_loss: 0.6732 - val_acc: 0.7556\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.3252 - acc: 0.8456 - val_loss: 0.7705 - val_acc: 0.6683\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.3221 - acc: 0.8466 - val_loss: 0.9413 - val_acc: 0.6559\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2803 - acc: 0.8725 - val_loss: 0.4667 - val_acc: 0.8005\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.3341 - acc: 0.8453 - val_loss: 0.3506 - val_acc: 0.8479\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.3099 - acc: 0.8533 - val_loss: 0.3497 - val_acc: 0.8628\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2774 - acc: 0.8698 - val_loss: 0.3617 - val_acc: 0.8728\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2924 - acc: 0.8589 - val_loss: 0.4055 - val_acc: 0.8279\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2975 - acc: 0.8717 - val_loss: 0.6624 - val_acc: 0.7207\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2944 - acc: 0.8697 - val_loss: 0.3770 - val_acc: 0.8628\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.3055 - acc: 0.8581 - val_loss: 0.3203 - val_acc: 0.8354\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2928 - acc: 0.8708 - val_loss: 0.4150 - val_acc: 0.8479\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2726 - acc: 0.8892 - val_loss: 0.3513 - val_acc: 0.8703\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2917 - acc: 0.8723 - val_loss: 0.3075 - val_acc: 0.8529\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.3095 - acc: 0.8531 - val_loss: 0.3878 - val_acc: 0.8479\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2557 - acc: 0.8764 - val_loss: 0.7369 - val_acc: 0.7007\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2575 - acc: 0.8867 - val_loss: 0.3203 - val_acc: 0.8728\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2874 - acc: 0.8689 - val_loss: 0.6912 - val_acc: 0.7506\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 3s - loss: 0.2532 - acc: 0.8792 - val_loss: 0.5210 - val_acc: 0.7481\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2679 - acc: 0.8775 - val_loss: 0.9691 - val_acc: 0.6983\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2496 - acc: 0.8864 - val_loss: 0.3436 - val_acc: 0.8603\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss improved from 0.29094 to 0.27671, saving model to best_m.h5\n",
      " - 3s - loss: 0.2439 - acc: 0.8831 - val_loss: 0.2767 - val_acc: 0.8728\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 3s - loss: 0.2435 - acc: 0.8950 - val_loss: 0.4375 - val_acc: 0.8254\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2657 - acc: 0.8800 - val_loss: 0.4160 - val_acc: 0.8229\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2530 - acc: 0.8892 - val_loss: 0.3175 - val_acc: 0.8554\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2432 - acc: 0.8967 - val_loss: 0.3437 - val_acc: 0.8878\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.2385 - acc: 0.9006 - val_loss: 0.3648 - val_acc: 0.8080\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 3s - loss: 0.2758 - acc: 0.8831 - val_loss: 0.4130 - val_acc: 0.8180\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 3s - loss: 0.2803 - acc: 0.8808 - val_loss: 0.4218 - val_acc: 0.8404\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 3s - loss: 0.2570 - acc: 0.8892 - val_loss: 0.4444 - val_acc: 0.8080\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 3s - loss: 0.2880 - acc: 0.8681 - val_loss: 0.2858 - val_acc: 0.8753\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2294 - acc: 0.8906 - val_loss: 0.4235 - val_acc: 0.8354\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2691 - acc: 0.8883 - val_loss: 0.2971 - val_acc: 0.8703\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss improved from 0.27671 to 0.24585, saving model to best_m.h5\n",
      " - 2s - loss: 0.2406 - acc: 0.8942 - val_loss: 0.2459 - val_acc: 0.8878\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 3s - loss: 0.2588 - acc: 0.8866 - val_loss: 0.4584 - val_acc: 0.7756\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.2236 - acc: 0.9117 - val_loss: 0.3485 - val_acc: 0.8554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2150 - acc: 0.9117 - val_loss: 0.5975 - val_acc: 0.8155\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.2390 - acc: 0.9025 - val_loss: 0.5260 - val_acc: 0.8005\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.2383 - acc: 0.8989 - val_loss: 0.3033 - val_acc: 0.8778\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2524 - acc: 0.8992 - val_loss: 0.4448 - val_acc: 0.8180\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.2332 - acc: 0.9025 - val_loss: 0.2681 - val_acc: 0.8703\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2343 - acc: 0.8925 - val_loss: 0.4769 - val_acc: 0.7930\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2157 - acc: 0.9033 - val_loss: 0.4707 - val_acc: 0.7656\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.1914 - acc: 0.9273 - val_loss: 0.3855 - val_acc: 0.8479\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.1973 - acc: 0.9175 - val_loss: 0.2970 - val_acc: 0.8703\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.1870 - acc: 0.9167 - val_loss: 0.2788 - val_acc: 0.8554\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.1971 - acc: 0.9106 - val_loss: 0.3156 - val_acc: 0.8603\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1638 - acc: 0.9325 - val_loss: 0.3029 - val_acc: 0.8853\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.1644 - acc: 0.9300 - val_loss: 0.2851 - val_acc: 0.8728\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.1683 - acc: 0.9283 - val_loss: 0.3763 - val_acc: 0.8579\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.1941 - acc: 0.9183 - val_loss: 0.2670 - val_acc: 0.8878\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.1828 - acc: 0.9325 - val_loss: 0.2723 - val_acc: 0.8828\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.1663 - acc: 0.9389 - val_loss: 0.3049 - val_acc: 0.8753\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.1785 - acc: 0.9267 - val_loss: 0.3319 - val_acc: 0.8728\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.1844 - acc: 0.9308 - val_loss: 0.3029 - val_acc: 0.8828\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.1732 - acc: 0.9350 - val_loss: 0.3055 - val_acc: 0.8728\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.1790 - acc: 0.9197 - val_loss: 0.3173 - val_acc: 0.8603\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.1726 - acc: 0.9175 - val_loss: 0.2733 - val_acc: 0.8778\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1768 - acc: 0.9216 - val_loss: 0.2842 - val_acc: 0.8953\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.1811 - acc: 0.9248 - val_loss: 0.3382 - val_acc: 0.8628\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.1582 - acc: 0.9300 - val_loss: 0.2894 - val_acc: 0.8554\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.1618 - acc: 0.9383 - val_loss: 0.2791 - val_acc: 0.8703\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.1507 - acc: 0.9358 - val_loss: 0.2762 - val_acc: 0.8803\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.1601 - acc: 0.9333 - val_loss: 0.2876 - val_acc: 0.8828\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.1511 - acc: 0.9425 - val_loss: 0.2724 - val_acc: 0.8928\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.1640 - acc: 0.9300 - val_loss: 0.3067 - val_acc: 0.8703\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.1546 - acc: 0.9350 - val_loss: 0.2584 - val_acc: 0.8928\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.1527 - acc: 0.9358 - val_loss: 0.3336 - val_acc: 0.8479\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.1678 - acc: 0.9342 - val_loss: 0.2831 - val_acc: 0.8878\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.1533 - acc: 0.9367 - val_loss: 0.2747 - val_acc: 0.8903\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.1710 - acc: 0.9317 - val_loss: 0.2670 - val_acc: 0.8828\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.1563 - acc: 0.9392 - val_loss: 0.2644 - val_acc: 0.8728\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.1554 - acc: 0.9325 - val_loss: 0.3074 - val_acc: 0.8703\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.1944 - acc: 0.9320 - val_loss: 0.2856 - val_acc: 0.8753\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.1452 - acc: 0.9417 - val_loss: 0.3605 - val_acc: 0.8579\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.1470 - acc: 0.9406 - val_loss: 0.3468 - val_acc: 0.8728\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.1702 - acc: 0.9267 - val_loss: 0.2910 - val_acc: 0.8778\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.1445 - acc: 0.9442 - val_loss: 0.3305 - val_acc: 0.8653\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.1539 - acc: 0.9317 - val_loss: 0.4879 - val_acc: 0.8304\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.1760 - acc: 0.9258 - val_loss: 0.3224 - val_acc: 0.8703\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.1440 - acc: 0.9450 - val_loss: 0.2837 - val_acc: 0.8853\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.1456 - acc: 0.9306 - val_loss: 0.3254 - val_acc: 0.8778\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.1595 - acc: 0.9375 - val_loss: 0.3593 - val_acc: 0.8579\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.1335 - acc: 0.9450 - val_loss: 0.3713 - val_acc: 0.8653\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.1419 - acc: 0.9400 - val_loss: 0.3426 - val_acc: 0.8653\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.1389 - acc: 0.9392 - val_loss: 0.3189 - val_acc: 0.8703\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.1300 - acc: 0.9458 - val_loss: 0.2980 - val_acc: 0.8828\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.1707 - acc: 0.9279 - val_loss: 0.4102 - val_acc: 0.8304\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.1474 - acc: 0.9358 - val_loss: 0.3848 - val_acc: 0.8529\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.1649 - acc: 0.9400 - val_loss: 0.3086 - val_acc: 0.8703\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.1493 - acc: 0.9375 - val_loss: 0.3035 - val_acc: 0.8878\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.1350 - acc: 0.9439 - val_loss: 0.4774 - val_acc: 0.8155\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.1469 - acc: 0.9383 - val_loss: 0.3854 - val_acc: 0.8454\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.68637, saving model to best_m.h5\n",
      " - 6s - loss: 0.7617 - acc: 0.6581 - val_loss: 0.6864 - val_acc: 0.5461\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.5393 - acc: 0.7316 - val_loss: 1.4506 - val_acc: 0.5461\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.5447 - acc: 0.7462 - val_loss: 3.3928 - val_acc: 0.5461\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.5092 - acc: 0.7547 - val_loss: 2.6627 - val_acc: 0.5461\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.5175 - acc: 0.7437 - val_loss: 2.8091 - val_acc: 0.5461\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4835 - acc: 0.7631 - val_loss: 3.8592 - val_acc: 0.5486\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4129 - acc: 0.8006 - val_loss: 2.0882 - val_acc: 0.5736\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.68637 to 0.44988, saving model to best_m.h5\n",
      " - 2s - loss: 0.4240 - acc: 0.8092 - val_loss: 0.4499 - val_acc: 0.7681\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.4810 - acc: 0.7678 - val_loss: 0.8448 - val_acc: 0.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.4516 - acc: 0.7750 - val_loss: 0.4673 - val_acc: 0.7656\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.44988 to 0.39803, saving model to best_m.h5\n",
      " - 2s - loss: 0.3974 - acc: 0.8200 - val_loss: 0.3980 - val_acc: 0.8180\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3939 - acc: 0.8131 - val_loss: 0.4968 - val_acc: 0.7830\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.4283 - acc: 0.8025 - val_loss: 0.4781 - val_acc: 0.7805\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.39803 to 0.37604, saving model to best_m.h5\n",
      " - 2s - loss: 0.4278 - acc: 0.8025 - val_loss: 0.3760 - val_acc: 0.8279\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.4087 - acc: 0.8206 - val_loss: 1.3595 - val_acc: 0.6758\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.4369 - acc: 0.7991 - val_loss: 0.6247 - val_acc: 0.7232\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss improved from 0.37604 to 0.35460, saving model to best_m.h5\n",
      " - 2s - loss: 0.3858 - acc: 0.8250 - val_loss: 0.3546 - val_acc: 0.8379\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.3352 - acc: 0.8558 - val_loss: 0.3951 - val_acc: 0.8229\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.3748 - acc: 0.8270 - val_loss: 0.4088 - val_acc: 0.7930\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.35460 to 0.33862, saving model to best_m.h5\n",
      " - 2s - loss: 0.3713 - acc: 0.8325 - val_loss: 0.3386 - val_acc: 0.8304\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.3668 - acc: 0.8384 - val_loss: 0.4667 - val_acc: 0.7855\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.3260 - acc: 0.8467 - val_loss: 0.4319 - val_acc: 0.7880\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.3166 - acc: 0.8650 - val_loss: 0.4131 - val_acc: 0.8030\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.3116 - acc: 0.8589 - val_loss: 0.4045 - val_acc: 0.8204\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.33862 to 0.30473, saving model to best_m.h5\n",
      " - 2s - loss: 0.3054 - acc: 0.8708 - val_loss: 0.3047 - val_acc: 0.8529\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.30473 to 0.29412, saving model to best_m.h5\n",
      " - 2s - loss: 0.2990 - acc: 0.8658 - val_loss: 0.2941 - val_acc: 0.8479\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2970 - acc: 0.8631 - val_loss: 0.7550 - val_acc: 0.7057\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2971 - acc: 0.8633 - val_loss: 0.3091 - val_acc: 0.8504\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.3201 - acc: 0.8595 - val_loss: 0.3096 - val_acc: 0.8529\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.3161 - acc: 0.8620 - val_loss: 0.3809 - val_acc: 0.8254\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.3294 - acc: 0.8466 - val_loss: 0.3379 - val_acc: 0.8354\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2749 - acc: 0.8789 - val_loss: 0.3511 - val_acc: 0.8204\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.3227 - acc: 0.8562 - val_loss: 0.9110 - val_acc: 0.6758\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2757 - acc: 0.8783 - val_loss: 0.8486 - val_acc: 0.6833\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2893 - acc: 0.8750 - val_loss: 0.3017 - val_acc: 0.8653\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2923 - acc: 0.8687 - val_loss: 0.7877 - val_acc: 0.6983\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2671 - acc: 0.8775 - val_loss: 0.3429 - val_acc: 0.8304\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2939 - acc: 0.8631 - val_loss: 0.3279 - val_acc: 0.8454\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2736 - acc: 0.8758 - val_loss: 1.5136 - val_acc: 0.5786\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 3s - loss: 0.2934 - acc: 0.8631 - val_loss: 0.3137 - val_acc: 0.8504\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2479 - acc: 0.8875 - val_loss: 0.3729 - val_acc: 0.8229\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2577 - acc: 0.8756 - val_loss: 0.3501 - val_acc: 0.8429\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2407 - acc: 0.8925 - val_loss: 0.5630 - val_acc: 0.7506\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2607 - acc: 0.8975 - val_loss: 0.5593 - val_acc: 0.7406\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2548 - acc: 0.8833 - val_loss: 0.3599 - val_acc: 0.8379\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2380 - acc: 0.9025 - val_loss: 0.3712 - val_acc: 0.8229\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2529 - acc: 0.8789 - val_loss: 0.2955 - val_acc: 0.8703\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2464 - acc: 0.8925 - val_loss: 0.5100 - val_acc: 0.7805\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2586 - acc: 0.8883 - val_loss: 0.3435 - val_acc: 0.8504\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2462 - acc: 0.8933 - val_loss: 0.3472 - val_acc: 0.8429\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2434 - acc: 0.9008 - val_loss: 0.3002 - val_acc: 0.8504\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2220 - acc: 0.9039 - val_loss: 0.3200 - val_acc: 0.8304\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss improved from 0.29412 to 0.28429, saving model to best_m.h5\n",
      " - 2s - loss: 0.2666 - acc: 0.8833 - val_loss: 0.2843 - val_acc: 0.8678\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2291 - acc: 0.8875 - val_loss: 0.3438 - val_acc: 0.8454\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.2698 - acc: 0.8831 - val_loss: 0.2971 - val_acc: 0.8753\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2402 - acc: 0.8983 - val_loss: 0.3462 - val_acc: 0.8479\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.2327 - acc: 0.8950 - val_loss: 0.2876 - val_acc: 0.8753\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2179 - acc: 0.9058 - val_loss: 0.4156 - val_acc: 0.8080\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2422 - acc: 0.9017 - val_loss: 0.4613 - val_acc: 0.8080\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2662 - acc: 0.8837 - val_loss: 1.0605 - val_acc: 0.6758\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2548 - acc: 0.8867 - val_loss: 0.6567 - val_acc: 0.7631\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2196 - acc: 0.9092 - val_loss: 0.3915 - val_acc: 0.8279\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.28429 to 0.28297, saving model to best_m.h5\n",
      " - 3s - loss: 0.2659 - acc: 0.8887 - val_loss: 0.2830 - val_acc: 0.8728\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2584 - acc: 0.8856 - val_loss: 0.3915 - val_acc: 0.8429\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 3s - loss: 0.2126 - acc: 0.9133 - val_loss: 0.3070 - val_acc: 0.8628\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 3s - loss: 0.2147 - acc: 0.9117 - val_loss: 0.4098 - val_acc: 0.8130\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2080 - acc: 0.9158 - val_loss: 0.2954 - val_acc: 0.8703\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.2483 - acc: 0.8908 - val_loss: 0.3890 - val_acc: 0.8204\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.1831 - acc: 0.9208 - val_loss: 0.3903 - val_acc: 0.8479\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2408 - acc: 0.9006 - val_loss: 0.8546 - val_acc: 0.7481\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.2198 - acc: 0.9000 - val_loss: 0.3213 - val_acc: 0.8703\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.1924 - acc: 0.9233 - val_loss: 0.3101 - val_acc: 0.8628\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.1713 - acc: 0.9300 - val_loss: 0.3206 - val_acc: 0.8579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.1859 - acc: 0.9214 - val_loss: 0.4701 - val_acc: 0.8254\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1847 - acc: 0.9208 - val_loss: 0.3075 - val_acc: 0.8653\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.1874 - acc: 0.9192 - val_loss: 0.3100 - val_acc: 0.8678\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.1922 - acc: 0.9189 - val_loss: 0.3129 - val_acc: 0.8603\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.1767 - acc: 0.9256 - val_loss: 0.3465 - val_acc: 0.8554\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.1744 - acc: 0.9275 - val_loss: 0.2999 - val_acc: 0.8828\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.1629 - acc: 0.9325 - val_loss: 0.3058 - val_acc: 0.8728\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.1569 - acc: 0.9433 - val_loss: 0.2975 - val_acc: 0.8878\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.1755 - acc: 0.9325 - val_loss: 0.3253 - val_acc: 0.8603\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.1791 - acc: 0.9289 - val_loss: 0.3335 - val_acc: 0.8504\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.1791 - acc: 0.9281 - val_loss: 0.3094 - val_acc: 0.8803\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.1950 - acc: 0.9164 - val_loss: 0.3118 - val_acc: 0.8678\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1661 - acc: 0.9317 - val_loss: 0.3229 - val_acc: 0.8628\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 3s - loss: 0.1569 - acc: 0.9417 - val_loss: 0.3807 - val_acc: 0.8479\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.1629 - acc: 0.9325 - val_loss: 0.3147 - val_acc: 0.8653\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.1663 - acc: 0.9310 - val_loss: 0.3157 - val_acc: 0.8429\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.1686 - acc: 0.9314 - val_loss: 0.3369 - val_acc: 0.8504\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.1681 - acc: 0.9267 - val_loss: 0.3302 - val_acc: 0.8554\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.1406 - acc: 0.9450 - val_loss: 0.3334 - val_acc: 0.8603\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.1679 - acc: 0.9292 - val_loss: 0.3465 - val_acc: 0.8554\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.1604 - acc: 0.9348 - val_loss: 0.3403 - val_acc: 0.8504\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.1449 - acc: 0.9367 - val_loss: 0.3231 - val_acc: 0.8628\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.1571 - acc: 0.9383 - val_loss: 0.3099 - val_acc: 0.8728\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.1475 - acc: 0.9367 - val_loss: 0.3441 - val_acc: 0.8504\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.1277 - acc: 0.9433 - val_loss: 0.3360 - val_acc: 0.8579\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.1454 - acc: 0.9408 - val_loss: 0.4101 - val_acc: 0.8379\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.1493 - acc: 0.9364 - val_loss: 0.3787 - val_acc: 0.8454\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.1502 - acc: 0.9350 - val_loss: 0.3753 - val_acc: 0.8304\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.1583 - acc: 0.9300 - val_loss: 0.3388 - val_acc: 0.8554\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.1455 - acc: 0.9400 - val_loss: 0.3100 - val_acc: 0.8778\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.1480 - acc: 0.9356 - val_loss: 0.3382 - val_acc: 0.8479\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.1374 - acc: 0.9500 - val_loss: 0.3240 - val_acc: 0.8703\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.1489 - acc: 0.9439 - val_loss: 0.3174 - val_acc: 0.8653\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.1434 - acc: 0.9389 - val_loss: 0.3224 - val_acc: 0.8753\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.1529 - acc: 0.9392 - val_loss: 0.3653 - val_acc: 0.8404\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.1322 - acc: 0.9442 - val_loss: 0.3213 - val_acc: 0.8628\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.1454 - acc: 0.9381 - val_loss: 0.3156 - val_acc: 0.8803\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.1511 - acc: 0.9408 - val_loss: 0.3463 - val_acc: 0.8479\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.1363 - acc: 0.9458 - val_loss: 0.3538 - val_acc: 0.8529\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.1554 - acc: 0.9423 - val_loss: 0.3120 - val_acc: 0.8828\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.1387 - acc: 0.9500 - val_loss: 0.3087 - val_acc: 0.8903\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.1536 - acc: 0.9308 - val_loss: 0.3740 - val_acc: 0.8504\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.1244 - acc: 0.9517 - val_loss: 0.3330 - val_acc: 0.8554\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 2s - loss: 0.1275 - acc: 0.9567 - val_loss: 0.3413 - val_acc: 0.8579\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.1490 - acc: 0.9308 - val_loss: 0.3368 - val_acc: 0.8628\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.1562 - acc: 0.9317 - val_loss: 0.3226 - val_acc: 0.8628\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.1303 - acc: 0.9467 - val_loss: 0.3205 - val_acc: 0.8653\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.73356, saving model to best_m.h5\n",
      " - 7s - loss: 0.6793 - acc: 0.6864 - val_loss: 0.7336 - val_acc: 0.4389\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6335 - acc: 0.7028 - val_loss: 1.0314 - val_acc: 0.4389\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.73356 to 0.68999, saving model to best_m.h5\n",
      " - 2s - loss: 0.5219 - acc: 0.7489 - val_loss: 0.6900 - val_acc: 0.5611\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss improved from 0.68999 to 0.65838, saving model to best_m.h5\n",
      " - 2s - loss: 0.5315 - acc: 0.7491 - val_loss: 0.6584 - val_acc: 0.6584\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.5214 - acc: 0.7701 - val_loss: 0.8348 - val_acc: 0.5511\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.65838 to 0.57292, saving model to best_m.h5\n",
      " - 2s - loss: 0.4823 - acc: 0.7706 - val_loss: 0.5729 - val_acc: 0.6259\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4852 - acc: 0.7747 - val_loss: 0.6252 - val_acc: 0.6584\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.4766 - acc: 0.7581 - val_loss: 0.8596 - val_acc: 0.6160\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.4656 - acc: 0.7672 - val_loss: 0.9375 - val_acc: 0.6234\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.57292 to 0.42375, saving model to best_m.h5\n",
      " - 3s - loss: 0.4626 - acc: 0.7803 - val_loss: 0.4238 - val_acc: 0.8030\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss improved from 0.42375 to 0.37503, saving model to best_m.h5\n",
      " - 2s - loss: 0.4199 - acc: 0.8067 - val_loss: 0.3750 - val_acc: 0.8304\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 3s - loss: 0.4105 - acc: 0.7995 - val_loss: 0.3868 - val_acc: 0.8155\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.3738 - acc: 0.8114 - val_loss: 0.4590 - val_acc: 0.7980\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 3s - loss: 0.4231 - acc: 0.7947 - val_loss: 0.3875 - val_acc: 0.7955\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 3s - loss: 0.4297 - acc: 0.7983 - val_loss: 0.8379 - val_acc: 0.6733\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.4061 - acc: 0.8012 - val_loss: 0.3859 - val_acc: 0.8229\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.4022 - acc: 0.8183 - val_loss: 0.5186 - val_acc: 0.7880\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.3543 - acc: 0.8366 - val_loss: 0.3872 - val_acc: 0.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.3736 - acc: 0.8333 - val_loss: 0.5297 - val_acc: 0.7681\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3594 - acc: 0.8331 - val_loss: 0.3884 - val_acc: 0.8254\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.37503 to 0.37337, saving model to best_m.h5\n",
      " - 2s - loss: 0.3454 - acc: 0.8400 - val_loss: 0.3734 - val_acc: 0.8080\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.37337 to 0.35807, saving model to best_m.h5\n",
      " - 2s - loss: 0.3231 - acc: 0.8566 - val_loss: 0.3581 - val_acc: 0.8454\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.3223 - acc: 0.8516 - val_loss: 0.9077 - val_acc: 0.7382\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.3624 - acc: 0.8347 - val_loss: 0.5514 - val_acc: 0.7731\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.35807 to 0.31184, saving model to best_m.h5\n",
      " - 2s - loss: 0.3185 - acc: 0.8539 - val_loss: 0.3118 - val_acc: 0.8728\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.3384 - acc: 0.8417 - val_loss: 0.3370 - val_acc: 0.8653\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.3025 - acc: 0.8506 - val_loss: 0.3156 - val_acc: 0.8529\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.3289 - acc: 0.8581 - val_loss: 0.3293 - val_acc: 0.8579\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.3129 - acc: 0.8608 - val_loss: 0.3541 - val_acc: 0.8329\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.3324 - acc: 0.8506 - val_loss: 0.3218 - val_acc: 0.8504\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.3038 - acc: 0.8692 - val_loss: 0.4235 - val_acc: 0.8254\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.3271 - acc: 0.8545 - val_loss: 0.3557 - val_acc: 0.8229\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2965 - acc: 0.8675 - val_loss: 0.3519 - val_acc: 0.8678\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.3053 - acc: 0.8623 - val_loss: 0.4506 - val_acc: 0.7930\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.3010 - acc: 0.8616 - val_loss: 0.4293 - val_acc: 0.8204\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.31184 to 0.30248, saving model to best_m.h5\n",
      " - 2s - loss: 0.2709 - acc: 0.8783 - val_loss: 0.3025 - val_acc: 0.8579\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2877 - acc: 0.8706 - val_loss: 0.4260 - val_acc: 0.8229\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.3272 - acc: 0.8539 - val_loss: 0.4426 - val_acc: 0.8279\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2953 - acc: 0.8808 - val_loss: 0.3478 - val_acc: 0.8529\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2884 - acc: 0.8825 - val_loss: 0.3964 - val_acc: 0.8130\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2635 - acc: 0.8892 - val_loss: 0.3065 - val_acc: 0.8728\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2640 - acc: 0.8783 - val_loss: 0.4137 - val_acc: 0.8429\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2560 - acc: 0.8917 - val_loss: 0.3661 - val_acc: 0.8628\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2990 - acc: 0.8720 - val_loss: 0.4045 - val_acc: 0.8429\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss improved from 0.30248 to 0.29262, saving model to best_m.h5\n",
      " - 2s - loss: 0.2768 - acc: 0.8733 - val_loss: 0.2926 - val_acc: 0.8628\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2784 - acc: 0.8691 - val_loss: 0.4138 - val_acc: 0.8454\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2941 - acc: 0.8625 - val_loss: 0.3511 - val_acc: 0.8429\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2659 - acc: 0.8889 - val_loss: 0.2944 - val_acc: 0.8579\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2610 - acc: 0.8833 - val_loss: 0.3314 - val_acc: 0.8554\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2885 - acc: 0.8775 - val_loss: 0.4184 - val_acc: 0.8254\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2704 - acc: 0.8783 - val_loss: 0.4801 - val_acc: 0.8254\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2594 - acc: 0.9014 - val_loss: 1.0602 - val_acc: 0.6733\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2565 - acc: 0.8864 - val_loss: 0.3352 - val_acc: 0.8379\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2750 - acc: 0.8900 - val_loss: 0.3574 - val_acc: 0.8379\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.2447 - acc: 0.8922 - val_loss: 0.4507 - val_acc: 0.8229\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2568 - acc: 0.8789 - val_loss: 0.3811 - val_acc: 0.8329\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.2753 - acc: 0.8867 - val_loss: 0.5075 - val_acc: 0.7880\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2468 - acc: 0.8831 - val_loss: 0.3413 - val_acc: 0.8728\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2527 - acc: 0.8841 - val_loss: 0.3844 - val_acc: 0.8229\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2335 - acc: 0.8900 - val_loss: 0.4686 - val_acc: 0.8304\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2809 - acc: 0.8754 - val_loss: 0.3274 - val_acc: 0.8828\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2377 - acc: 0.9050 - val_loss: 0.3272 - val_acc: 0.8329\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss improved from 0.29262 to 0.28720, saving model to best_m.h5\n",
      " - 2s - loss: 0.2314 - acc: 0.8942 - val_loss: 0.2872 - val_acc: 0.8728\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2299 - acc: 0.9025 - val_loss: 0.3261 - val_acc: 0.8603\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss improved from 0.28720 to 0.28680, saving model to best_m.h5\n",
      " - 2s - loss: 0.2250 - acc: 0.9042 - val_loss: 0.2868 - val_acc: 0.8828\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss improved from 0.28680 to 0.27315, saving model to best_m.h5\n",
      " - 2s - loss: 0.2321 - acc: 0.9083 - val_loss: 0.2731 - val_acc: 0.8978\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2309 - acc: 0.9075 - val_loss: 0.3074 - val_acc: 0.8653\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss improved from 0.27315 to 0.26832, saving model to best_m.h5\n",
      " - 2s - loss: 0.2122 - acc: 0.9075 - val_loss: 0.2683 - val_acc: 0.8878\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2091 - acc: 0.9075 - val_loss: 0.3169 - val_acc: 0.8504\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2184 - acc: 0.9050 - val_loss: 0.4343 - val_acc: 0.8479\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.26832 to 0.26823, saving model to best_m.h5\n",
      " - 2s - loss: 0.2049 - acc: 0.9039 - val_loss: 0.2682 - val_acc: 0.8778\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.26823 to 0.26080, saving model to best_m.h5\n",
      " - 2s - loss: 0.1880 - acc: 0.9122 - val_loss: 0.2608 - val_acc: 0.8903\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.2065 - acc: 0.9150 - val_loss: 0.2797 - val_acc: 0.8803\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.1799 - acc: 0.9208 - val_loss: 0.3083 - val_acc: 0.8753\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1610 - acc: 0.9267 - val_loss: 0.2725 - val_acc: 0.8878\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.1902 - acc: 0.9206 - val_loss: 0.2851 - val_acc: 0.8703\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.1890 - acc: 0.9214 - val_loss: 0.2746 - val_acc: 0.8828\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.1649 - acc: 0.9275 - val_loss: 0.2870 - val_acc: 0.8753\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.1779 - acc: 0.9242 - val_loss: 0.2829 - val_acc: 0.8778\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.1787 - acc: 0.9250 - val_loss: 0.2931 - val_acc: 0.8928\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss improved from 0.26080 to 0.25692, saving model to best_m.h5\n",
      " - 2s - loss: 0.1669 - acc: 0.9267 - val_loss: 0.2569 - val_acc: 0.9052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.1803 - acc: 0.9242 - val_loss: 0.2583 - val_acc: 0.9027\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 3s - loss: 0.1958 - acc: 0.9156 - val_loss: 0.2877 - val_acc: 0.8828\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.1782 - acc: 0.9267 - val_loss: 0.2711 - val_acc: 0.8803\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.1736 - acc: 0.9298 - val_loss: 0.2672 - val_acc: 0.8803\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1778 - acc: 0.9298 - val_loss: 0.2820 - val_acc: 0.8753\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.1783 - acc: 0.9242 - val_loss: 0.2836 - val_acc: 0.8853\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.1687 - acc: 0.9200 - val_loss: 0.2791 - val_acc: 0.8903\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss improved from 0.25692 to 0.25051, saving model to best_m.h5\n",
      " - 2s - loss: 0.1641 - acc: 0.9367 - val_loss: 0.2505 - val_acc: 0.8803\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.1725 - acc: 0.9233 - val_loss: 0.2630 - val_acc: 0.8928\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.1784 - acc: 0.9264 - val_loss: 0.2814 - val_acc: 0.8928\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.1632 - acc: 0.9281 - val_loss: 0.2658 - val_acc: 0.8903\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.1539 - acc: 0.9350 - val_loss: 0.3380 - val_acc: 0.8728\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.1754 - acc: 0.9233 - val_loss: 0.2694 - val_acc: 0.8978\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.1667 - acc: 0.9317 - val_loss: 0.2725 - val_acc: 0.8853\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.1374 - acc: 0.9450 - val_loss: 0.2681 - val_acc: 0.8878\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.1702 - acc: 0.9256 - val_loss: 0.2605 - val_acc: 0.8953\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.1704 - acc: 0.9323 - val_loss: 0.3308 - val_acc: 0.8828\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.1706 - acc: 0.9283 - val_loss: 0.2704 - val_acc: 0.8953\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.1527 - acc: 0.9375 - val_loss: 0.2583 - val_acc: 0.8853\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.1630 - acc: 0.9264 - val_loss: 0.3030 - val_acc: 0.8978\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.1487 - acc: 0.9392 - val_loss: 0.2637 - val_acc: 0.8853\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.1637 - acc: 0.9333 - val_loss: 0.2794 - val_acc: 0.8928\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 3s - loss: 0.1509 - acc: 0.9431 - val_loss: 0.2758 - val_acc: 0.8978\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss improved from 0.25051 to 0.24968, saving model to best_m.h5\n",
      " - 2s - loss: 0.1581 - acc: 0.9325 - val_loss: 0.2497 - val_acc: 0.9077\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss improved from 0.24968 to 0.24948, saving model to best_m.h5\n",
      " - 2s - loss: 0.1522 - acc: 0.9492 - val_loss: 0.2495 - val_acc: 0.9002\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.1363 - acc: 0.9458 - val_loss: 0.2650 - val_acc: 0.8878\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.1549 - acc: 0.9341 - val_loss: 0.2705 - val_acc: 0.8878\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 3s - loss: 0.1380 - acc: 0.9492 - val_loss: 0.2915 - val_acc: 0.8828\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.1564 - acc: 0.9342 - val_loss: 0.2582 - val_acc: 0.8853\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.1362 - acc: 0.9414 - val_loss: 0.2611 - val_acc: 0.8903\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.1543 - acc: 0.9298 - val_loss: 0.2873 - val_acc: 0.8878\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.1566 - acc: 0.9317 - val_loss: 0.2610 - val_acc: 0.8878\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.1566 - acc: 0.9214 - val_loss: 0.2692 - val_acc: 0.8853\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.1297 - acc: 0.9525 - val_loss: 0.2775 - val_acc: 0.8828\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 3s - loss: 0.1366 - acc: 0.9475 - val_loss: 0.2731 - val_acc: 0.8803\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 3s - loss: 0.1366 - acc: 0.9367 - val_loss: 0.2775 - val_acc: 0.8753\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.1408 - acc: 0.9458 - val_loss: 0.2578 - val_acc: 0.8928\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.1509 - acc: 0.9323 - val_loss: 0.2585 - val_acc: 0.8903\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.1577 - acc: 0.9408 - val_loss: 0.2776 - val_acc: 0.8903\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.82816, saving model to best_m.h5\n",
      " - 7s - loss: 0.6965 - acc: 0.6758 - val_loss: 0.8282 - val_acc: 0.4938\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.82816 to 0.75862, saving model to best_m.h5\n",
      " - 2s - loss: 0.6092 - acc: 0.7122 - val_loss: 0.7586 - val_acc: 0.4938\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.75862 to 0.70227, saving model to best_m.h5\n",
      " - 3s - loss: 0.5209 - acc: 0.7441 - val_loss: 0.7023 - val_acc: 0.5686\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.5236 - acc: 0.7556 - val_loss: 0.8566 - val_acc: 0.5037\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss improved from 0.70227 to 0.63602, saving model to best_m.h5\n",
      " - 2s - loss: 0.4992 - acc: 0.7641 - val_loss: 0.6360 - val_acc: 0.5835\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4393 - acc: 0.7925 - val_loss: 1.1982 - val_acc: 0.5312\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4380 - acc: 0.7822 - val_loss: 0.8618 - val_acc: 0.6185\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.63602 to 0.40488, saving model to best_m.h5\n",
      " - 2s - loss: 0.4588 - acc: 0.7837 - val_loss: 0.4049 - val_acc: 0.7955\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.4783 - acc: 0.7716 - val_loss: 0.8112 - val_acc: 0.6035\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.4271 - acc: 0.7925 - val_loss: 0.4481 - val_acc: 0.8005\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.4026 - acc: 0.8125 - val_loss: 0.5025 - val_acc: 0.7456\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3825 - acc: 0.8178 - val_loss: 0.5498 - val_acc: 0.7182\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.3467 - acc: 0.8300 - val_loss: 0.4847 - val_acc: 0.7930\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.40488 to 0.36648, saving model to best_m.h5\n",
      " - 2s - loss: 0.4292 - acc: 0.8031 - val_loss: 0.3665 - val_acc: 0.8254\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.3780 - acc: 0.8197 - val_loss: 0.4458 - val_acc: 0.7905\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.4190 - acc: 0.8058 - val_loss: 0.3781 - val_acc: 0.8204\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.3993 - acc: 0.8089 - val_loss: 0.4768 - val_acc: 0.8055\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.3865 - acc: 0.8200 - val_loss: 0.4884 - val_acc: 0.8130\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.3865 - acc: 0.8164 - val_loss: 0.5404 - val_acc: 0.7431\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3469 - acc: 0.8314 - val_loss: 0.7640 - val_acc: 0.7132\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.36648 to 0.36608, saving model to best_m.h5\n",
      " - 2s - loss: 0.3469 - acc: 0.8342 - val_loss: 0.3661 - val_acc: 0.8354\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.36608 to 0.35006, saving model to best_m.h5\n",
      " - 2s - loss: 0.3276 - acc: 0.8589 - val_loss: 0.3501 - val_acc: 0.8504\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.3019 - acc: 0.8600 - val_loss: 0.4096 - val_acc: 0.8180\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.3029 - acc: 0.8497 - val_loss: 0.3774 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2920 - acc: 0.8623 - val_loss: 0.4282 - val_acc: 0.8279\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2914 - acc: 0.8775 - val_loss: 0.3665 - val_acc: 0.8180\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2786 - acc: 0.8683 - val_loss: 0.7698 - val_acc: 0.6958\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2927 - acc: 0.8637 - val_loss: 0.4671 - val_acc: 0.7930\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2929 - acc: 0.8692 - val_loss: 0.5753 - val_acc: 0.7631\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.3028 - acc: 0.8623 - val_loss: 0.4161 - val_acc: 0.8254\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2863 - acc: 0.8725 - val_loss: 0.3863 - val_acc: 0.8429\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.3111 - acc: 0.8512 - val_loss: 0.3908 - val_acc: 0.8130\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2885 - acc: 0.8708 - val_loss: 0.3700 - val_acc: 0.8579\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 3s - loss: 0.3027 - acc: 0.8493 - val_loss: 0.3893 - val_acc: 0.8429\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss improved from 0.35006 to 0.32441, saving model to best_m.h5\n",
      " - 3s - loss: 0.2605 - acc: 0.8892 - val_loss: 0.3244 - val_acc: 0.8653\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2445 - acc: 0.8933 - val_loss: 0.7830 - val_acc: 0.7257\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2823 - acc: 0.8789 - val_loss: 0.4503 - val_acc: 0.8105\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2864 - acc: 0.8664 - val_loss: 0.3718 - val_acc: 0.8155\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2487 - acc: 0.8917 - val_loss: 0.4493 - val_acc: 0.8105\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2748 - acc: 0.8764 - val_loss: 0.5511 - val_acc: 0.8105\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2651 - acc: 0.8942 - val_loss: 0.4425 - val_acc: 0.8254\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2338 - acc: 0.9000 - val_loss: 0.4896 - val_acc: 0.7880\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2322 - acc: 0.9050 - val_loss: 0.3883 - val_acc: 0.8429\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2572 - acc: 0.8839 - val_loss: 0.4168 - val_acc: 0.8130\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 3s - loss: 0.2273 - acc: 0.8958 - val_loss: 0.4730 - val_acc: 0.7955\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2174 - acc: 0.9008 - val_loss: 0.3931 - val_acc: 0.8429\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2180 - acc: 0.8981 - val_loss: 0.6927 - val_acc: 0.7581\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2406 - acc: 0.8892 - val_loss: 0.4414 - val_acc: 0.8279\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2704 - acc: 0.8814 - val_loss: 0.4652 - val_acc: 0.8429\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2229 - acc: 0.9042 - val_loss: 0.4266 - val_acc: 0.8229\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2438 - acc: 0.8898 - val_loss: 0.3761 - val_acc: 0.8479\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2171 - acc: 0.9075 - val_loss: 0.3568 - val_acc: 0.8529\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2041 - acc: 0.9125 - val_loss: 0.4880 - val_acc: 0.7980\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2302 - acc: 0.9056 - val_loss: 0.3930 - val_acc: 0.8479\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.2111 - acc: 0.9033 - val_loss: 0.4033 - val_acc: 0.8554\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2190 - acc: 0.9114 - val_loss: 0.4407 - val_acc: 0.8180\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.2029 - acc: 0.9166 - val_loss: 0.4703 - val_acc: 0.8055\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2160 - acc: 0.8950 - val_loss: 0.4938 - val_acc: 0.8304\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2335 - acc: 0.9058 - val_loss: 0.3896 - val_acc: 0.8055\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.1978 - acc: 0.9133 - val_loss: 0.4321 - val_acc: 0.8379\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.1944 - acc: 0.9217 - val_loss: 0.5339 - val_acc: 0.7980\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2093 - acc: 0.9089 - val_loss: 0.5269 - val_acc: 0.8030\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.2018 - acc: 0.9100 - val_loss: 0.4364 - val_acc: 0.8554\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2040 - acc: 0.9225 - val_loss: 0.4626 - val_acc: 0.8254\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 3s - loss: 0.1817 - acc: 0.9250 - val_loss: 0.4247 - val_acc: 0.8180\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.2116 - acc: 0.9047 - val_loss: 0.4620 - val_acc: 0.8454\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2122 - acc: 0.9050 - val_loss: 1.0455 - val_acc: 0.7182\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.2066 - acc: 0.9092 - val_loss: 0.4433 - val_acc: 0.8429\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.1745 - acc: 0.9200 - val_loss: 0.5164 - val_acc: 0.8304\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.1976 - acc: 0.9167 - val_loss: 0.5513 - val_acc: 0.8180\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.1741 - acc: 0.9317 - val_loss: 0.3886 - val_acc: 0.8554\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.1678 - acc: 0.9289 - val_loss: 0.4203 - val_acc: 0.8603\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 3s - loss: 0.1628 - acc: 0.9292 - val_loss: 0.3879 - val_acc: 0.8678\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.1580 - acc: 0.9333 - val_loss: 0.4345 - val_acc: 0.8529\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1440 - acc: 0.9392 - val_loss: 0.4143 - val_acc: 0.8603\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.1652 - acc: 0.9308 - val_loss: 0.4622 - val_acc: 0.8479\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.1248 - acc: 0.9458 - val_loss: 0.4127 - val_acc: 0.8603\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.1484 - acc: 0.9450 - val_loss: 0.4652 - val_acc: 0.8529\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.1666 - acc: 0.9339 - val_loss: 0.3775 - val_acc: 0.8678\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.1503 - acc: 0.9400 - val_loss: 0.4099 - val_acc: 0.8653\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.1531 - acc: 0.9383 - val_loss: 0.4297 - val_acc: 0.8529\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.1534 - acc: 0.9331 - val_loss: 0.4709 - val_acc: 0.8454\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.1341 - acc: 0.9448 - val_loss: 0.4520 - val_acc: 0.8429\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.1407 - acc: 0.9417 - val_loss: 0.4325 - val_acc: 0.8454\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.1376 - acc: 0.9483 - val_loss: 0.4108 - val_acc: 0.8529\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1159 - acc: 0.9575 - val_loss: 0.4038 - val_acc: 0.8554\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.1362 - acc: 0.9433 - val_loss: 0.4128 - val_acc: 0.8429\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.1280 - acc: 0.9508 - val_loss: 0.4128 - val_acc: 0.8504\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.1440 - acc: 0.9350 - val_loss: 0.4011 - val_acc: 0.8579\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.1321 - acc: 0.9467 - val_loss: 0.4463 - val_acc: 0.8429\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.1352 - acc: 0.9483 - val_loss: 0.4324 - val_acc: 0.8554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 4s - loss: 0.1344 - acc: 0.9550 - val_loss: 0.4127 - val_acc: 0.8653\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 5s - loss: 0.1302 - acc: 0.9406 - val_loss: 0.4254 - val_acc: 0.8653\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 3s - loss: 0.1060 - acc: 0.9525 - val_loss: 0.4108 - val_acc: 0.8678\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.1316 - acc: 0.9483 - val_loss: 0.4130 - val_acc: 0.8628\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.1409 - acc: 0.9342 - val_loss: 0.3963 - val_acc: 0.8728\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.1226 - acc: 0.9464 - val_loss: 0.4022 - val_acc: 0.8728\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.1335 - acc: 0.9448 - val_loss: 0.4483 - val_acc: 0.8529\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.1173 - acc: 0.9517 - val_loss: 0.4491 - val_acc: 0.8628\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.1307 - acc: 0.9408 - val_loss: 0.3970 - val_acc: 0.8703\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 2s - loss: 0.1234 - acc: 0.9483 - val_loss: 0.4588 - val_acc: 0.8379\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 2s - loss: 0.1519 - acc: 0.9317 - val_loss: 0.4162 - val_acc: 0.8653\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 2s - loss: 0.1215 - acc: 0.9517 - val_loss: 0.4466 - val_acc: 0.8454\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 2s - loss: 0.1397 - acc: 0.9345 - val_loss: 0.4264 - val_acc: 0.8603\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 2s - loss: 0.1234 - acc: 0.9492 - val_loss: 0.4926 - val_acc: 0.8504\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 2s - loss: 0.1242 - acc: 0.9517 - val_loss: 0.4328 - val_acc: 0.8554\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 2s - loss: 0.1312 - acc: 0.9448 - val_loss: 0.4284 - val_acc: 0.8703\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 2s - loss: 0.1539 - acc: 0.9331 - val_loss: 0.4509 - val_acc: 0.8529\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 2s - loss: 0.1409 - acc: 0.9456 - val_loss: 0.4286 - val_acc: 0.8603\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 2s - loss: 0.1056 - acc: 0.9575 - val_loss: 0.4512 - val_acc: 0.8628\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 2s - loss: 0.1275 - acc: 0.9500 - val_loss: 0.4401 - val_acc: 0.8628\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 2s - loss: 0.1127 - acc: 0.9592 - val_loss: 0.5039 - val_acc: 0.8429\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 2s - loss: 0.1214 - acc: 0.9433 - val_loss: 0.4784 - val_acc: 0.8354\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 2s - loss: 0.1059 - acc: 0.9608 - val_loss: 0.4690 - val_acc: 0.8354\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 2s - loss: 0.1417 - acc: 0.9404 - val_loss: 0.5011 - val_acc: 0.8379\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 2s - loss: 0.1272 - acc: 0.9525 - val_loss: 0.5054 - val_acc: 0.8204\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 3s - loss: 0.1074 - acc: 0.9567 - val_loss: 0.4967 - val_acc: 0.8404\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 2s - loss: 0.1118 - acc: 0.9583 - val_loss: 0.4452 - val_acc: 0.8529\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 2s - loss: 0.1068 - acc: 0.9592 - val_loss: 0.5255 - val_acc: 0.8279\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 2s - loss: 0.1054 - acc: 0.9583 - val_loss: 0.6022 - val_acc: 0.8279\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275677288674\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.153425\n",
      "1  4023181e    0.503719\n",
      "2  b20200e4    0.210857\n",
      "3  e7f018bb    0.907126\n",
      "4  4371c8c3    0.691860\n"
     ]
    }
   ],
   "source": [
    "with open('../features/cnn_4_aug_skimage_preprocess_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_4_aug_skimage_preprocess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model=Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), input_shape=(75, 75, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.87364, saving model to best_m.h5\n",
      " - 10s - loss: 0.6705 - acc: 0.6205 - val_loss: 0.8736 - val_acc: 0.5087\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 3s - loss: 0.5852 - acc: 0.6700 - val_loss: 2.7320 - val_acc: 0.5087\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 4s - loss: 0.5685 - acc: 0.7041 - val_loss: 1.4383 - val_acc: 0.5087\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 5s - loss: 0.5363 - acc: 0.7212 - val_loss: 2.9665 - val_acc: 0.5087\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 4s - loss: 0.5295 - acc: 0.7406 - val_loss: 1.6610 - val_acc: 0.5087\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 3s - loss: 0.4848 - acc: 0.7456 - val_loss: 1.7407 - val_acc: 0.5087\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.87364 to 0.85097, saving model to best_m.h5\n",
      " - 3s - loss: 0.4987 - acc: 0.7666 - val_loss: 0.8510 - val_acc: 0.5087\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 3s - loss: 0.4797 - acc: 0.7766 - val_loss: 1.2944 - val_acc: 0.5087\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 3s - loss: 0.4765 - acc: 0.7714 - val_loss: 1.0105 - val_acc: 0.6035\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.85097 to 0.40976, saving model to best_m.h5\n",
      " - 4s - loss: 0.4792 - acc: 0.7642 - val_loss: 0.4098 - val_acc: 0.8354\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 3s - loss: 0.4880 - acc: 0.7667 - val_loss: 0.4998 - val_acc: 0.7481\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.4612 - acc: 0.7775 - val_loss: 1.0426 - val_acc: 0.6060\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss improved from 0.40976 to 0.32478, saving model to best_m.h5\n",
      " - 4s - loss: 0.4493 - acc: 0.7841 - val_loss: 0.3248 - val_acc: 0.8254\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 3s - loss: 0.4335 - acc: 0.7889 - val_loss: 0.6746 - val_acc: 0.7357\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 3s - loss: 0.4418 - acc: 0.7856 - val_loss: 0.4194 - val_acc: 0.7880\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 3s - loss: 0.4359 - acc: 0.7987 - val_loss: 1.2232 - val_acc: 0.5237\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 3s - loss: 0.3869 - acc: 0.8131 - val_loss: 1.1339 - val_acc: 0.5935\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 0.4455 - acc: 0.7895 - val_loss: 1.0134 - val_acc: 0.5835\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 3s - loss: 0.4226 - acc: 0.7683 - val_loss: 0.3854 - val_acc: 0.8429\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.4205 - acc: 0.7828 - val_loss: 0.3565 - val_acc: 0.8329\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.3829 - acc: 0.8183 - val_loss: 0.3767 - val_acc: 0.8204\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 3s - loss: 0.3869 - acc: 0.8131 - val_loss: 0.3853 - val_acc: 0.7880\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss improved from 0.32478 to 0.30335, saving model to best_m.h5\n",
      " - 4s - loss: 0.3786 - acc: 0.8308 - val_loss: 0.3034 - val_acc: 0.8279\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.3734 - acc: 0.8116 - val_loss: 0.3301 - val_acc: 0.8454\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.30335 to 0.28923, saving model to best_m.h5\n",
      " - 4s - loss: 0.3700 - acc: 0.8300 - val_loss: 0.2892 - val_acc: 0.8753\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.28923 to 0.27221, saving model to best_m.h5\n",
      " - 3s - loss: 0.3886 - acc: 0.8097 - val_loss: 0.2722 - val_acc: 0.8878\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 3s - loss: 0.3778 - acc: 0.8216 - val_loss: 0.3254 - val_acc: 0.8454\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.3738 - acc: 0.8142 - val_loss: 0.3890 - val_acc: 0.8504\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 3s - loss: 0.3860 - acc: 0.8181 - val_loss: 0.9154 - val_acc: 0.6284\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 3s - loss: 0.3967 - acc: 0.8112 - val_loss: 0.3816 - val_acc: 0.8229\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 3s - loss: 0.3734 - acc: 0.8183 - val_loss: 0.3105 - val_acc: 0.8703\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 3s - loss: 0.3498 - acc: 0.8300 - val_loss: 0.4283 - val_acc: 0.8279\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.3684 - acc: 0.8289 - val_loss: 0.4761 - val_acc: 0.7805\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.3443 - acc: 0.8383 - val_loss: 0.3200 - val_acc: 0.8603\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 3s - loss: 0.3244 - acc: 0.8539 - val_loss: 0.4084 - val_acc: 0.8329\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 3s - loss: 0.3857 - acc: 0.8178 - val_loss: 0.3105 - val_acc: 0.8778\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.3488 - acc: 0.8425 - val_loss: 0.3773 - val_acc: 0.8254\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 3s - loss: 0.3491 - acc: 0.8416 - val_loss: 0.3894 - val_acc: 0.8254\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.27221 to 0.27108, saving model to best_m.h5\n",
      " - 4s - loss: 0.3492 - acc: 0.8347 - val_loss: 0.2711 - val_acc: 0.8628\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss improved from 0.27108 to 0.25937, saving model to best_m.h5\n",
      " - 4s - loss: 0.3527 - acc: 0.8274 - val_loss: 0.2594 - val_acc: 0.8653\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 3s - loss: 0.3733 - acc: 0.8166 - val_loss: 0.3700 - val_acc: 0.8204\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 3s - loss: 0.3857 - acc: 0.8178 - val_loss: 0.2889 - val_acc: 0.8728\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 3s - loss: 0.3605 - acc: 0.8283 - val_loss: 0.3089 - val_acc: 0.8803\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 3s - loss: 0.3387 - acc: 0.8456 - val_loss: 1.2760 - val_acc: 0.5511\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 3s - loss: 0.3359 - acc: 0.8400 - val_loss: 0.4212 - val_acc: 0.7980\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 3s - loss: 0.3582 - acc: 0.8289 - val_loss: 0.3273 - val_acc: 0.8354\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.3465 - acc: 0.8350 - val_loss: 0.5139 - val_acc: 0.7556\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.3344 - acc: 0.8483 - val_loss: 0.3034 - val_acc: 0.8678\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 3s - loss: 0.3398 - acc: 0.8550 - val_loss: 0.3482 - val_acc: 0.8429\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.3653 - acc: 0.8354 - val_loss: 0.9898 - val_acc: 0.6359\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 3s - loss: 0.3921 - acc: 0.8109 - val_loss: 0.2846 - val_acc: 0.8928\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 3s - loss: 0.3504 - acc: 0.8445 - val_loss: 0.3654 - val_acc: 0.8254\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.3378 - acc: 0.8391 - val_loss: 0.8342 - val_acc: 0.6908\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.3529 - acc: 0.8292 - val_loss: 0.5865 - val_acc: 0.7756\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 3s - loss: 0.3459 - acc: 0.8322 - val_loss: 0.3391 - val_acc: 0.8204\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.3372 - acc: 0.8489 - val_loss: 0.3060 - val_acc: 0.8229\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 3s - loss: 0.3267 - acc: 0.8475 - val_loss: 0.2668 - val_acc: 0.8878\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 3s - loss: 0.3198 - acc: 0.8508 - val_loss: 0.3418 - val_acc: 0.8329\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 4s - loss: 0.3530 - acc: 0.8341 - val_loss: 0.2819 - val_acc: 0.8903\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 3s - loss: 0.3041 - acc: 0.8575 - val_loss: 0.3552 - val_acc: 0.8130\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 3s - loss: 0.3203 - acc: 0.8583 - val_loss: 0.7788 - val_acc: 0.6858\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.3710 - acc: 0.8487 - val_loss: 0.2830 - val_acc: 0.8828\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 4s - loss: 0.3362 - acc: 0.8383 - val_loss: 0.3260 - val_acc: 0.8155\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 3s - loss: 0.3332 - acc: 0.8466 - val_loss: 0.2737 - val_acc: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 4s - loss: 0.3200 - acc: 0.8470 - val_loss: 0.4260 - val_acc: 0.8304\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 5s - loss: 0.3514 - acc: 0.8422 - val_loss: 0.2968 - val_acc: 0.8603\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 4s - loss: 0.3104 - acc: 0.8750 - val_loss: 0.3034 - val_acc: 0.8454\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 3s - loss: 0.3172 - acc: 0.8633 - val_loss: 0.2741 - val_acc: 0.8953\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 3s - loss: 0.3127 - acc: 0.8575 - val_loss: 0.4033 - val_acc: 0.8055\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 3s - loss: 0.3436 - acc: 0.8514 - val_loss: 0.4186 - val_acc: 0.7930\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 3s - loss: 0.3181 - acc: 0.8641 - val_loss: 0.2686 - val_acc: 0.8653\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 3s - loss: 0.2834 - acc: 0.8775 - val_loss: 0.3437 - val_acc: 0.8429\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 3s - loss: 0.3146 - acc: 0.8497 - val_loss: 0.3177 - val_acc: 0.8579\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 3s - loss: 0.3120 - acc: 0.8633 - val_loss: 0.3444 - val_acc: 0.8529\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 3s - loss: 0.2873 - acc: 0.8783 - val_loss: 0.3059 - val_acc: 0.8678\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 3s - loss: 0.2757 - acc: 0.8825 - val_loss: 0.3751 - val_acc: 0.8479\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss improved from 0.25937 to 0.25918, saving model to best_m.h5\n",
      " - 4s - loss: 0.2953 - acc: 0.8741 - val_loss: 0.2592 - val_acc: 0.8828\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss improved from 0.25918 to 0.25266, saving model to best_m.h5\n",
      " - 4s - loss: 0.2849 - acc: 0.8741 - val_loss: 0.2527 - val_acc: 0.8878\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 3s - loss: 0.2950 - acc: 0.8658 - val_loss: 0.2712 - val_acc: 0.8728\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss improved from 0.25266 to 0.24889, saving model to best_m.h5\n",
      " - 3s - loss: 0.3130 - acc: 0.8662 - val_loss: 0.2489 - val_acc: 0.8903\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 3s - loss: 0.2693 - acc: 0.8858 - val_loss: 0.2724 - val_acc: 0.8703\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 4s - loss: 0.2689 - acc: 0.8867 - val_loss: 0.3087 - val_acc: 0.8579\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 3s - loss: 0.2897 - acc: 0.8775 - val_loss: 0.2516 - val_acc: 0.8853\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 3s - loss: 0.3076 - acc: 0.8620 - val_loss: 0.2506 - val_acc: 0.8828\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 3s - loss: 0.2962 - acc: 0.8617 - val_loss: 0.2498 - val_acc: 0.8828\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 4s - loss: 0.3008 - acc: 0.8593 - val_loss: 0.2670 - val_acc: 0.8628\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 3s - loss: 0.2834 - acc: 0.8792 - val_loss: 0.2532 - val_acc: 0.8803\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss improved from 0.24889 to 0.24542, saving model to best_m.h5\n",
      " - 3s - loss: 0.2922 - acc: 0.8620 - val_loss: 0.2454 - val_acc: 0.8903\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 3s - loss: 0.2975 - acc: 0.8742 - val_loss: 0.3048 - val_acc: 0.8579\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 3s - loss: 0.2707 - acc: 0.8864 - val_loss: 0.3358 - val_acc: 0.8479\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.2901 - acc: 0.8692 - val_loss: 0.2662 - val_acc: 0.8653\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 3s - loss: 0.2660 - acc: 0.8833 - val_loss: 0.2507 - val_acc: 0.8828\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 4s - loss: 0.3041 - acc: 0.8564 - val_loss: 0.2567 - val_acc: 0.8903\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 3s - loss: 0.2930 - acc: 0.8754 - val_loss: 0.2839 - val_acc: 0.8554\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 3s - loss: 0.2706 - acc: 0.8883 - val_loss: 0.2637 - val_acc: 0.8653\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 3s - loss: 0.2702 - acc: 0.8808 - val_loss: 0.2861 - val_acc: 0.8678\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 3s - loss: 0.3089 - acc: 0.8714 - val_loss: 0.2969 - val_acc: 0.8603\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 3s - loss: 0.2705 - acc: 0.8748 - val_loss: 0.2575 - val_acc: 0.8728\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 3s - loss: 0.2795 - acc: 0.8741 - val_loss: 0.2603 - val_acc: 0.8753\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss improved from 0.24542 to 0.24345, saving model to best_m.h5\n",
      " - 3s - loss: 0.2932 - acc: 0.8629 - val_loss: 0.2434 - val_acc: 0.8803\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 3s - loss: 0.2676 - acc: 0.8875 - val_loss: 0.2789 - val_acc: 0.8753\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 4s - loss: 0.2916 - acc: 0.8658 - val_loss: 0.2942 - val_acc: 0.8603\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 3s - loss: 0.2849 - acc: 0.8797 - val_loss: 0.2704 - val_acc: 0.8728\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 4s - loss: 0.2613 - acc: 0.8833 - val_loss: 0.3327 - val_acc: 0.8603\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 4s - loss: 0.2789 - acc: 0.8683 - val_loss: 0.2583 - val_acc: 0.8753\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 4s - loss: 0.3073 - acc: 0.8750 - val_loss: 0.2573 - val_acc: 0.8803\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 4s - loss: 0.2839 - acc: 0.8853 - val_loss: 0.3156 - val_acc: 0.8579\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 3s - loss: 0.2902 - acc: 0.8639 - val_loss: 0.2722 - val_acc: 0.8653\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 3s - loss: 0.2582 - acc: 0.8942 - val_loss: 0.2593 - val_acc: 0.8728\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 3s - loss: 0.2831 - acc: 0.8708 - val_loss: 0.2590 - val_acc: 0.8803\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 3s - loss: 0.2585 - acc: 0.8850 - val_loss: 0.2993 - val_acc: 0.8653\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 3s - loss: 0.2784 - acc: 0.8723 - val_loss: 0.2497 - val_acc: 0.8828\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.2844 - acc: 0.8700 - val_loss: 0.2442 - val_acc: 0.8803\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 3s - loss: 0.2936 - acc: 0.8741 - val_loss: 0.2872 - val_acc: 0.8653\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 3s - loss: 0.2783 - acc: 0.8742 - val_loss: 0.2461 - val_acc: 0.8803\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 4s - loss: 0.2695 - acc: 0.8789 - val_loss: 0.2979 - val_acc: 0.8678\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 3s - loss: 0.2853 - acc: 0.8817 - val_loss: 0.3060 - val_acc: 0.8653\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.2836 - acc: 0.8795 - val_loss: 0.3206 - val_acc: 0.8603\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 3s - loss: 0.2738 - acc: 0.8875 - val_loss: 0.2648 - val_acc: 0.8753\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 3s - loss: 0.2790 - acc: 0.8781 - val_loss: 0.2679 - val_acc: 0.8753\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.67515, saving model to best_m.h5\n",
      " - 9s - loss: 0.7050 - acc: 0.5984 - val_loss: 0.6752 - val_acc: 0.6309\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 3s - loss: 0.5858 - acc: 0.6791 - val_loss: 0.8388 - val_acc: 0.5461\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss improved from 0.67515 to 0.62806, saving model to best_m.h5\n",
      " - 4s - loss: 0.5786 - acc: 0.6947 - val_loss: 0.6281 - val_acc: 0.6434\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 3s - loss: 0.5330 - acc: 0.7078 - val_loss: 1.0678 - val_acc: 0.5461\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 3s - loss: 0.5185 - acc: 0.7489 - val_loss: 0.8049 - val_acc: 0.5511\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 3s - loss: 0.5054 - acc: 0.7578 - val_loss: 1.0474 - val_acc: 0.5536\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.62806 to 0.51432, saving model to best_m.h5\n",
      " - 3s - loss: 0.4940 - acc: 0.7414 - val_loss: 0.5143 - val_acc: 0.7456\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 3s - loss: 0.4814 - acc: 0.7795 - val_loss: 0.6553 - val_acc: 0.6010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.51432 to 0.43880, saving model to best_m.h5\n",
      " - 4s - loss: 0.4865 - acc: 0.7575 - val_loss: 0.4388 - val_acc: 0.7955\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss improved from 0.43880 to 0.38927, saving model to best_m.h5\n",
      " - 4s - loss: 0.4647 - acc: 0.7764 - val_loss: 0.3893 - val_acc: 0.8105\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 3s - loss: 0.4429 - acc: 0.7883 - val_loss: 0.3903 - val_acc: 0.8204\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 3s - loss: 0.4629 - acc: 0.7747 - val_loss: 0.4256 - val_acc: 0.8030\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 3s - loss: 0.4455 - acc: 0.7708 - val_loss: 0.4726 - val_acc: 0.7456\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss improved from 0.38927 to 0.38919, saving model to best_m.h5\n",
      " - 4s - loss: 0.4105 - acc: 0.7922 - val_loss: 0.3892 - val_acc: 0.8005\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss improved from 0.38919 to 0.37960, saving model to best_m.h5\n",
      " - 4s - loss: 0.4162 - acc: 0.7981 - val_loss: 0.3796 - val_acc: 0.8254\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 3s - loss: 0.4446 - acc: 0.7947 - val_loss: 0.4972 - val_acc: 0.7406\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 3s - loss: 0.4512 - acc: 0.7856 - val_loss: 1.0070 - val_acc: 0.5387\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 0.4009 - acc: 0.8100 - val_loss: 0.4087 - val_acc: 0.7805\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.37960 to 0.37529, saving model to best_m.h5\n",
      " - 4s - loss: 0.4090 - acc: 0.8125 - val_loss: 0.3753 - val_acc: 0.7930\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.4151 - acc: 0.8022 - val_loss: 0.4422 - val_acc: 0.7880\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss improved from 0.37529 to 0.36195, saving model to best_m.h5\n",
      " - 4s - loss: 0.4153 - acc: 0.8082 - val_loss: 0.3620 - val_acc: 0.8204\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.4046 - acc: 0.8012 - val_loss: 0.5800 - val_acc: 0.7057\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.4020 - acc: 0.8200 - val_loss: 0.3696 - val_acc: 0.8105\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss improved from 0.36195 to 0.34135, saving model to best_m.h5\n",
      " - 3s - loss: 0.3701 - acc: 0.8289 - val_loss: 0.3414 - val_acc: 0.8254\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 3s - loss: 0.3926 - acc: 0.8172 - val_loss: 0.4697 - val_acc: 0.7431\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss improved from 0.34135 to 0.30544, saving model to best_m.h5\n",
      " - 4s - loss: 0.3672 - acc: 0.8350 - val_loss: 0.3054 - val_acc: 0.8479\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss improved from 0.30544 to 0.30537, saving model to best_m.h5\n",
      " - 4s - loss: 0.3696 - acc: 0.8283 - val_loss: 0.3054 - val_acc: 0.8579\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.3760 - acc: 0.8358 - val_loss: 0.8179 - val_acc: 0.6010\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.3593 - acc: 0.8392 - val_loss: 0.3829 - val_acc: 0.8180\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 3s - loss: 0.3593 - acc: 0.8414 - val_loss: 0.6005 - val_acc: 0.7357\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 3s - loss: 0.3728 - acc: 0.8316 - val_loss: 0.5077 - val_acc: 0.7506\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 3s - loss: 0.3354 - acc: 0.8475 - val_loss: 0.3700 - val_acc: 0.8329\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.3711 - acc: 0.8375 - val_loss: 0.4094 - val_acc: 0.7706\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.3774 - acc: 0.8214 - val_loss: 0.3872 - val_acc: 0.8005\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.3356 - acc: 0.8383 - val_loss: 0.3143 - val_acc: 0.8379\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.3692 - acc: 0.8339 - val_loss: 0.4417 - val_acc: 0.7656\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 3s - loss: 0.3858 - acc: 0.8242 - val_loss: 0.3142 - val_acc: 0.8554\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 3s - loss: 0.3225 - acc: 0.8591 - val_loss: 0.3374 - val_acc: 0.8404\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 3s - loss: 0.3457 - acc: 0.8358 - val_loss: 0.3623 - val_acc: 0.8130\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.3763 - acc: 0.8406 - val_loss: 0.3195 - val_acc: 0.8379\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss improved from 0.30537 to 0.30094, saving model to best_m.h5\n",
      " - 4s - loss: 0.3611 - acc: 0.8375 - val_loss: 0.3009 - val_acc: 0.8454\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.3206 - acc: 0.8550 - val_loss: 0.3032 - val_acc: 0.8504\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss improved from 0.30094 to 0.29992, saving model to best_m.h5\n",
      " - 4s - loss: 0.3533 - acc: 0.8450 - val_loss: 0.2999 - val_acc: 0.8603\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.3945 - acc: 0.8193 - val_loss: 0.3121 - val_acc: 0.8254\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.3463 - acc: 0.8458 - val_loss: 0.3187 - val_acc: 0.8354\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.3397 - acc: 0.8458 - val_loss: 0.5200 - val_acc: 0.7506\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.3270 - acc: 0.8597 - val_loss: 0.3223 - val_acc: 0.8404\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.3274 - acc: 0.8617 - val_loss: 0.4016 - val_acc: 0.8204\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.3230 - acc: 0.8566 - val_loss: 0.3766 - val_acc: 0.8204\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss improved from 0.29992 to 0.28178, saving model to best_m.h5\n",
      " - 4s - loss: 0.3342 - acc: 0.8658 - val_loss: 0.2818 - val_acc: 0.8454\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 5s - loss: 0.3475 - acc: 0.8439 - val_loss: 0.3285 - val_acc: 0.8429\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 5s - loss: 0.3373 - acc: 0.8558 - val_loss: 0.3509 - val_acc: 0.8404\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.3185 - acc: 0.8583 - val_loss: 0.3158 - val_acc: 0.8479\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.3587 - acc: 0.8431 - val_loss: 0.3573 - val_acc: 0.8204\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 3s - loss: 0.3427 - acc: 0.8481 - val_loss: 0.3531 - val_acc: 0.8155\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 3s - loss: 0.3478 - acc: 0.8416 - val_loss: 0.4539 - val_acc: 0.7830\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 3s - loss: 0.3512 - acc: 0.8522 - val_loss: 0.3010 - val_acc: 0.8579\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 3s - loss: 0.3195 - acc: 0.8500 - val_loss: 0.3022 - val_acc: 0.8354\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 3s - loss: 0.3323 - acc: 0.8520 - val_loss: 0.4200 - val_acc: 0.7980\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 3s - loss: 0.3240 - acc: 0.8516 - val_loss: 0.3185 - val_acc: 0.8379\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 3s - loss: 0.3212 - acc: 0.8625 - val_loss: 0.6536 - val_acc: 0.7032\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 3s - loss: 0.3298 - acc: 0.8531 - val_loss: 0.3220 - val_acc: 0.8379\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 3s - loss: 0.3284 - acc: 0.8458 - val_loss: 0.3005 - val_acc: 0.8579\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 3s - loss: 0.3087 - acc: 0.8600 - val_loss: 0.4211 - val_acc: 0.7880\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 3s - loss: 0.3280 - acc: 0.8589 - val_loss: 0.3613 - val_acc: 0.8304\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 3s - loss: 0.3237 - acc: 0.8533 - val_loss: 0.2821 - val_acc: 0.8603\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 3s - loss: 0.3155 - acc: 0.8616 - val_loss: 0.4357 - val_acc: 0.8030\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 4s - loss: 0.2875 - acc: 0.8808 - val_loss: 0.2944 - val_acc: 0.8554\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 3s - loss: 0.3002 - acc: 0.8654 - val_loss: 0.6458 - val_acc: 0.7282\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 3s - loss: 0.3132 - acc: 0.8714 - val_loss: 0.4733 - val_acc: 0.7830\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 3s - loss: 0.3060 - acc: 0.8681 - val_loss: 0.3101 - val_acc: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 3s - loss: 0.3064 - acc: 0.8614 - val_loss: 0.2841 - val_acc: 0.8803\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 4s - loss: 0.2880 - acc: 0.8739 - val_loss: 0.2832 - val_acc: 0.8628\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 3s - loss: 0.2876 - acc: 0.8739 - val_loss: 0.2860 - val_acc: 0.8579\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 4s - loss: 0.3008 - acc: 0.8670 - val_loss: 0.2849 - val_acc: 0.8603\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 4s - loss: 0.3137 - acc: 0.8691 - val_loss: 0.2905 - val_acc: 0.8529\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 3s - loss: 0.3022 - acc: 0.8598 - val_loss: 0.3083 - val_acc: 0.8479\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 3s - loss: 0.2944 - acc: 0.8689 - val_loss: 0.2869 - val_acc: 0.8529\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss improved from 0.28178 to 0.27729, saving model to best_m.h5\n",
      " - 4s - loss: 0.3021 - acc: 0.8706 - val_loss: 0.2773 - val_acc: 0.8529\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 3s - loss: 0.2926 - acc: 0.8633 - val_loss: 0.2889 - val_acc: 0.8479\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 4s - loss: 0.2874 - acc: 0.8683 - val_loss: 0.2781 - val_acc: 0.8504\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 4s - loss: 0.2875 - acc: 0.8731 - val_loss: 0.2893 - val_acc: 0.8429\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 5s - loss: 0.2769 - acc: 0.8775 - val_loss: 0.3203 - val_acc: 0.8504\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.2460 - acc: 0.8908 - val_loss: 0.2897 - val_acc: 0.8504\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 5s - loss: 0.2730 - acc: 0.8706 - val_loss: 0.3506 - val_acc: 0.8404\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 5s - loss: 0.2832 - acc: 0.8733 - val_loss: 0.3222 - val_acc: 0.8554\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 4s - loss: 0.2689 - acc: 0.8750 - val_loss: 0.2889 - val_acc: 0.8429\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 3s - loss: 0.2860 - acc: 0.8764 - val_loss: 0.2776 - val_acc: 0.8479\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 3s - loss: 0.2662 - acc: 0.8850 - val_loss: 0.2824 - val_acc: 0.8554\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 4s - loss: 0.2763 - acc: 0.8748 - val_loss: 0.2808 - val_acc: 0.8404\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.2805 - acc: 0.8700 - val_loss: 0.2919 - val_acc: 0.8479\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 4s - loss: 0.2954 - acc: 0.8689 - val_loss: 0.2804 - val_acc: 0.8504\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 4s - loss: 0.2727 - acc: 0.8716 - val_loss: 0.2832 - val_acc: 0.8554\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 4s - loss: 0.2837 - acc: 0.8767 - val_loss: 0.2809 - val_acc: 0.8628\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 3s - loss: 0.3065 - acc: 0.8737 - val_loss: 0.2960 - val_acc: 0.8653\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 4s - loss: 0.2836 - acc: 0.8792 - val_loss: 0.2833 - val_acc: 0.8579\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 4s - loss: 0.2405 - acc: 0.9008 - val_loss: 0.3042 - val_acc: 0.8479\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 5s - loss: 0.2681 - acc: 0.8825 - val_loss: 0.2920 - val_acc: 0.8554\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 4s - loss: 0.2737 - acc: 0.8858 - val_loss: 0.2817 - val_acc: 0.8504\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 3s - loss: 0.2537 - acc: 0.8931 - val_loss: 0.3157 - val_acc: 0.8603\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 3s - loss: 0.2723 - acc: 0.8875 - val_loss: 0.2834 - val_acc: 0.8753\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 3s - loss: 0.3029 - acc: 0.8737 - val_loss: 0.2882 - val_acc: 0.8753\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 3s - loss: 0.2745 - acc: 0.8783 - val_loss: 0.3006 - val_acc: 0.8529\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss improved from 0.27729 to 0.27504, saving model to best_m.h5\n",
      " - 3s - loss: 0.2458 - acc: 0.8914 - val_loss: 0.2750 - val_acc: 0.8703\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 4s - loss: 0.2798 - acc: 0.8783 - val_loss: 0.2828 - val_acc: 0.8579\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 3s - loss: 0.3015 - acc: 0.8664 - val_loss: 0.2848 - val_acc: 0.8653\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 4s - loss: 0.2373 - acc: 0.9058 - val_loss: 0.2967 - val_acc: 0.8653\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 3s - loss: 0.2700 - acc: 0.8889 - val_loss: 0.3347 - val_acc: 0.8454\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 3s - loss: 0.2582 - acc: 0.8841 - val_loss: 0.3153 - val_acc: 0.8579\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 3s - loss: 0.2725 - acc: 0.8775 - val_loss: 0.2963 - val_acc: 0.8703\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 3s - loss: 0.2608 - acc: 0.8833 - val_loss: 0.3199 - val_acc: 0.8603\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 3s - loss: 0.2566 - acc: 0.8879 - val_loss: 0.3547 - val_acc: 0.8504\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.2765 - acc: 0.8816 - val_loss: 0.2997 - val_acc: 0.8678\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 3s - loss: 0.2578 - acc: 0.8950 - val_loss: 0.2876 - val_acc: 0.8878\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 3s - loss: 0.2868 - acc: 0.8689 - val_loss: 0.2889 - val_acc: 0.8529\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 4s - loss: 0.2646 - acc: 0.8992 - val_loss: 0.2833 - val_acc: 0.8728\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 4s - loss: 0.2570 - acc: 0.8883 - val_loss: 0.2977 - val_acc: 0.8579\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.2466 - acc: 0.8939 - val_loss: 0.2879 - val_acc: 0.8828\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 4s - loss: 0.2589 - acc: 0.8908 - val_loss: 0.2839 - val_acc: 0.8628\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 4s - loss: 0.2528 - acc: 0.8917 - val_loss: 0.2995 - val_acc: 0.8603\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.68580, saving model to best_m.h5\n",
      " - 9s - loss: 0.6899 - acc: 0.6028 - val_loss: 0.6858 - val_acc: 0.5611\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss improved from 0.68580 to 0.66261, saving model to best_m.h5\n",
      " - 3s - loss: 0.6005 - acc: 0.6820 - val_loss: 0.6626 - val_acc: 0.5586\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 3s - loss: 0.5390 - acc: 0.7253 - val_loss: 0.6910 - val_acc: 0.5611\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 3s - loss: 0.5095 - acc: 0.7447 - val_loss: 0.8484 - val_acc: 0.5611\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 3s - loss: 0.5028 - acc: 0.7550 - val_loss: 0.6697 - val_acc: 0.5786\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss improved from 0.66261 to 0.50768, saving model to best_m.h5\n",
      " - 3s - loss: 0.4786 - acc: 0.7670 - val_loss: 0.5077 - val_acc: 0.7232\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 3s - loss: 0.5017 - acc: 0.7584 - val_loss: 0.8174 - val_acc: 0.6010\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 3s - loss: 0.4787 - acc: 0.7666 - val_loss: 0.5905 - val_acc: 0.6808\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss improved from 0.50768 to 0.36812, saving model to best_m.h5\n",
      " - 3s - loss: 0.4343 - acc: 0.7891 - val_loss: 0.3681 - val_acc: 0.8329\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 3s - loss: 0.4553 - acc: 0.7908 - val_loss: 0.4610 - val_acc: 0.7581\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 3s - loss: 0.4212 - acc: 0.8045 - val_loss: 1.0813 - val_acc: 0.6060\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.36812 to 0.34564, saving model to best_m.h5\n",
      " - 3s - loss: 0.4700 - acc: 0.7720 - val_loss: 0.3456 - val_acc: 0.8279\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 3s - loss: 0.4341 - acc: 0.7972 - val_loss: 0.3712 - val_acc: 0.8454\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 3s - loss: 0.4390 - acc: 0.7931 - val_loss: 0.4688 - val_acc: 0.8130\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 3s - loss: 0.4236 - acc: 0.7997 - val_loss: 0.4036 - val_acc: 0.8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/120\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 3s - loss: 0.4054 - acc: 0.8025 - val_loss: 0.7218 - val_acc: 0.6683\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 3s - loss: 0.4196 - acc: 0.8033 - val_loss: 0.4186 - val_acc: 0.7930\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 0.3790 - acc: 0.8108 - val_loss: 1.1936 - val_acc: 0.5835\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss improved from 0.34564 to 0.33031, saving model to best_m.h5\n",
      " - 3s - loss: 0.4373 - acc: 0.7884 - val_loss: 0.3303 - val_acc: 0.8304\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 3s - loss: 0.4354 - acc: 0.7808 - val_loss: 1.0436 - val_acc: 0.6010\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 3s - loss: 0.3958 - acc: 0.8253 - val_loss: 0.4341 - val_acc: 0.7805\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 3s - loss: 0.3715 - acc: 0.8100 - val_loss: 0.3457 - val_acc: 0.8329\n",
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 3s - loss: 0.3855 - acc: 0.8207 - val_loss: 0.9536 - val_acc: 0.6434\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 3s - loss: 0.3953 - acc: 0.8197 - val_loss: 0.3582 - val_acc: 0.8229\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss improved from 0.33031 to 0.32273, saving model to best_m.h5\n",
      " - 3s - loss: 0.3840 - acc: 0.8192 - val_loss: 0.3227 - val_acc: 0.8628\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 3s - loss: 0.3740 - acc: 0.8176 - val_loss: 0.3402 - val_acc: 0.8254\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 3s - loss: 0.3898 - acc: 0.8178 - val_loss: 0.4405 - val_acc: 0.7805\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 3s - loss: 0.3671 - acc: 0.8175 - val_loss: 0.4955 - val_acc: 0.8130\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 3s - loss: 0.3717 - acc: 0.8172 - val_loss: 1.3770 - val_acc: 0.5362\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 3s - loss: 0.3522 - acc: 0.8316 - val_loss: 0.3777 - val_acc: 0.8504\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 3s - loss: 0.3629 - acc: 0.8242 - val_loss: 0.3907 - val_acc: 0.8055\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss improved from 0.32273 to 0.29201, saving model to best_m.h5\n",
      " - 3s - loss: 0.3430 - acc: 0.8458 - val_loss: 0.2920 - val_acc: 0.8903\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 3s - loss: 0.3601 - acc: 0.8291 - val_loss: 0.3463 - val_acc: 0.8404\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 3s - loss: 0.3410 - acc: 0.8375 - val_loss: 0.5369 - val_acc: 0.7905\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 3s - loss: 0.3241 - acc: 0.8508 - val_loss: 0.3088 - val_acc: 0.8828\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 3s - loss: 0.3276 - acc: 0.8458 - val_loss: 0.3129 - val_acc: 0.8379\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 3s - loss: 0.3603 - acc: 0.8322 - val_loss: 0.3034 - val_acc: 0.8678\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 3s - loss: 0.3480 - acc: 0.8258 - val_loss: 0.3850 - val_acc: 0.8130\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss improved from 0.29201 to 0.28655, saving model to best_m.h5\n",
      " - 3s - loss: 0.3470 - acc: 0.8417 - val_loss: 0.2865 - val_acc: 0.8828\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 3s - loss: 0.3363 - acc: 0.8497 - val_loss: 0.3301 - val_acc: 0.8454\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 3s - loss: 0.3438 - acc: 0.8287 - val_loss: 0.4775 - val_acc: 0.7731\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss improved from 0.28655 to 0.28056, saving model to best_m.h5\n",
      " - 3s - loss: 0.3145 - acc: 0.8475 - val_loss: 0.2806 - val_acc: 0.8853\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 3s - loss: 0.3383 - acc: 0.8447 - val_loss: 0.9478 - val_acc: 0.6608\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 3s - loss: 0.3151 - acc: 0.8539 - val_loss: 0.2964 - val_acc: 0.8653\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 3s - loss: 0.3340 - acc: 0.8514 - val_loss: 0.7070 - val_acc: 0.7182\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 3s - loss: 0.3541 - acc: 0.8197 - val_loss: 0.4473 - val_acc: 0.7382\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss improved from 0.28056 to 0.27373, saving model to best_m.h5\n",
      " - 4s - loss: 0.3130 - acc: 0.8683 - val_loss: 0.2737 - val_acc: 0.8828\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.3515 - acc: 0.8422 - val_loss: 0.4301 - val_acc: 0.7955\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 3s - loss: 0.3488 - acc: 0.8309 - val_loss: 0.3443 - val_acc: 0.8429\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 3s - loss: 0.3268 - acc: 0.8383 - val_loss: 0.3819 - val_acc: 0.8479\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.3260 - acc: 0.8522 - val_loss: 0.3036 - val_acc: 0.8579\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.3046 - acc: 0.8481 - val_loss: 0.6291 - val_acc: 0.7930\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 3s - loss: 0.3337 - acc: 0.8581 - val_loss: 0.2782 - val_acc: 0.8903\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.3043 - acc: 0.8623 - val_loss: 0.4333 - val_acc: 0.7905\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.3179 - acc: 0.8506 - val_loss: 0.3343 - val_acc: 0.8429\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 3s - loss: 0.3012 - acc: 0.8598 - val_loss: 0.6432 - val_acc: 0.6958\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 3s - loss: 0.3247 - acc: 0.8447 - val_loss: 0.3299 - val_acc: 0.8404\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 4s - loss: 0.3254 - acc: 0.8645 - val_loss: 0.3551 - val_acc: 0.8603\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.27373 to 0.26196, saving model to best_m.h5\n",
      " - 5s - loss: 0.3110 - acc: 0.8631 - val_loss: 0.2620 - val_acc: 0.8878\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.3002 - acc: 0.8666 - val_loss: 0.3309 - val_acc: 0.8429\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 3s - loss: 0.3397 - acc: 0.8389 - val_loss: 0.3350 - val_acc: 0.8653\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 3s - loss: 0.3129 - acc: 0.8583 - val_loss: 0.4236 - val_acc: 0.7955\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 3s - loss: 0.3076 - acc: 0.8625 - val_loss: 0.5087 - val_acc: 0.8279\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 3s - loss: 0.3088 - acc: 0.8616 - val_loss: 0.2886 - val_acc: 0.8703\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 3s - loss: 0.3102 - acc: 0.8773 - val_loss: 0.5953 - val_acc: 0.7756\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 3s - loss: 0.2938 - acc: 0.8708 - val_loss: 0.4105 - val_acc: 0.8080\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 3s - loss: 0.3238 - acc: 0.8481 - val_loss: 0.5422 - val_acc: 0.7656\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 3s - loss: 0.2991 - acc: 0.8589 - val_loss: 0.3334 - val_acc: 0.8304\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 3s - loss: 0.2885 - acc: 0.8741 - val_loss: 2.6088 - val_acc: 0.5287\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 3s - loss: 0.3070 - acc: 0.8708 - val_loss: 0.3135 - val_acc: 0.8479\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss improved from 0.26196 to 0.25638, saving model to best_m.h5\n",
      " - 4s - loss: 0.3072 - acc: 0.8566 - val_loss: 0.2564 - val_acc: 0.8778\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss improved from 0.25638 to 0.25309, saving model to best_m.h5\n",
      " - 3s - loss: 0.3010 - acc: 0.8747 - val_loss: 0.2531 - val_acc: 0.8878\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 3s - loss: 0.2845 - acc: 0.8742 - val_loss: 0.2545 - val_acc: 0.8953\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss improved from 0.25309 to 0.23700, saving model to best_m.h5\n",
      " - 3s - loss: 0.2660 - acc: 0.8856 - val_loss: 0.2370 - val_acc: 0.8928\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 3s - loss: 0.2777 - acc: 0.8798 - val_loss: 0.2772 - val_acc: 0.8753\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 3s - loss: 0.2695 - acc: 0.8841 - val_loss: 0.2586 - val_acc: 0.8853\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 3s - loss: 0.2908 - acc: 0.8639 - val_loss: 0.2486 - val_acc: 0.8878\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 3s - loss: 0.2780 - acc: 0.8731 - val_loss: 0.2427 - val_acc: 0.9002\n",
      "Epoch 79/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079: val_loss did not improve\n",
      " - 3s - loss: 0.2961 - acc: 0.8700 - val_loss: 0.2429 - val_acc: 0.9027\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 4s - loss: 0.2621 - acc: 0.8900 - val_loss: 0.2476 - val_acc: 0.8903\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 4s - loss: 0.2586 - acc: 0.8817 - val_loss: 0.2543 - val_acc: 0.8728\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 4s - loss: 0.2535 - acc: 0.8866 - val_loss: 0.2458 - val_acc: 0.8853\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 4s - loss: 0.2358 - acc: 0.8983 - val_loss: 0.2687 - val_acc: 0.8853\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 3s - loss: 0.2614 - acc: 0.8825 - val_loss: 0.2751 - val_acc: 0.8803\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 4s - loss: 0.2512 - acc: 0.8850 - val_loss: 0.2528 - val_acc: 0.8878\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 4s - loss: 0.3049 - acc: 0.8595 - val_loss: 0.2529 - val_acc: 0.8928\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 4s - loss: 0.2547 - acc: 0.8917 - val_loss: 0.2417 - val_acc: 0.8853\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss improved from 0.23700 to 0.23574, saving model to best_m.h5\n",
      " - 3s - loss: 0.2983 - acc: 0.8681 - val_loss: 0.2357 - val_acc: 0.8878\n",
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 3s - loss: 0.2655 - acc: 0.8766 - val_loss: 0.2417 - val_acc: 0.9002\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss improved from 0.23574 to 0.23251, saving model to best_m.h5\n",
      " - 4s - loss: 0.2683 - acc: 0.8770 - val_loss: 0.2325 - val_acc: 0.9002\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.2584 - acc: 0.8850 - val_loss: 0.2495 - val_acc: 0.8928\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 3s - loss: 0.2708 - acc: 0.8900 - val_loss: 0.2913 - val_acc: 0.8678\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 3s - loss: 0.2451 - acc: 0.9008 - val_loss: 0.2589 - val_acc: 0.8928\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 3s - loss: 0.2645 - acc: 0.8748 - val_loss: 0.2642 - val_acc: 0.8953\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 3s - loss: 0.2385 - acc: 0.8967 - val_loss: 0.2365 - val_acc: 0.8978\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 3s - loss: 0.2660 - acc: 0.8623 - val_loss: 0.2850 - val_acc: 0.8753\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 3s - loss: 0.2654 - acc: 0.8906 - val_loss: 0.2400 - val_acc: 0.8928\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 3s - loss: 0.2485 - acc: 0.8892 - val_loss: 0.2401 - val_acc: 0.9027\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 3s - loss: 0.2458 - acc: 0.9033 - val_loss: 0.2334 - val_acc: 0.9002\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 3s - loss: 0.2734 - acc: 0.8831 - val_loss: 0.2407 - val_acc: 0.8928\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 3s - loss: 0.2725 - acc: 0.8754 - val_loss: 0.2506 - val_acc: 0.8928\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 3s - loss: 0.2761 - acc: 0.8887 - val_loss: 0.2493 - val_acc: 0.8828\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 4s - loss: 0.2404 - acc: 0.8939 - val_loss: 0.2457 - val_acc: 0.8828\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 3s - loss: 0.2664 - acc: 0.8750 - val_loss: 0.2549 - val_acc: 0.8778\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 3s - loss: 0.2573 - acc: 0.8923 - val_loss: 0.2351 - val_acc: 0.9027\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 3s - loss: 0.2574 - acc: 0.8845 - val_loss: 0.2514 - val_acc: 0.8878\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 3s - loss: 0.2656 - acc: 0.8808 - val_loss: 0.2447 - val_acc: 0.8953\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 3s - loss: 0.2496 - acc: 0.8900 - val_loss: 0.2493 - val_acc: 0.8853\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 3s - loss: 0.2636 - acc: 0.8695 - val_loss: 0.2585 - val_acc: 0.8803\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 3s - loss: 0.2505 - acc: 0.8825 - val_loss: 0.2452 - val_acc: 0.8853\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 3s - loss: 0.2713 - acc: 0.8697 - val_loss: 0.2661 - val_acc: 0.8878\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 3s - loss: 0.2685 - acc: 0.8850 - val_loss: 0.2544 - val_acc: 0.8903\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.2431 - acc: 0.8878 - val_loss: 0.2723 - val_acc: 0.8703\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 3s - loss: 0.2367 - acc: 0.8992 - val_loss: 0.2432 - val_acc: 0.8903\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 4s - loss: 0.2315 - acc: 0.8973 - val_loss: 0.2680 - val_acc: 0.8753\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 4s - loss: 0.2523 - acc: 0.8906 - val_loss: 0.2554 - val_acc: 0.8778\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 3s - loss: 0.2533 - acc: 0.8845 - val_loss: 0.2607 - val_acc: 0.8828\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.2589 - acc: 0.8831 - val_loss: 0.2556 - val_acc: 0.8803\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 3s - loss: 0.2496 - acc: 0.8900 - val_loss: 0.2751 - val_acc: 0.8603\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 3s - loss: 0.2607 - acc: 0.8825 - val_loss: 0.2524 - val_acc: 0.8878\n",
      "============================\n",
      "Epoch 1/120\n",
      "Epoch 00001: val_loss improved from inf to 0.72358, saving model to best_m.h5\n",
      " - 10s - loss: 0.6921 - acc: 0.6216 - val_loss: 0.7236 - val_acc: 0.4938\n",
      "Epoch 2/120\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 3s - loss: 0.5939 - acc: 0.6881 - val_loss: 0.7534 - val_acc: 0.5062\n",
      "Epoch 3/120\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 3s - loss: 0.5378 - acc: 0.7291 - val_loss: 0.8089 - val_acc: 0.5062\n",
      "Epoch 4/120\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 3s - loss: 0.5473 - acc: 0.7106 - val_loss: 1.6614 - val_acc: 0.5062\n",
      "Epoch 5/120\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 3s - loss: 0.5317 - acc: 0.7197 - val_loss: 1.7010 - val_acc: 0.5062\n",
      "Epoch 6/120\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 3s - loss: 0.4824 - acc: 0.7625 - val_loss: 1.0523 - val_acc: 0.6060\n",
      "Epoch 7/120\n",
      "Epoch 00007: val_loss improved from 0.72358 to 0.66937, saving model to best_m.h5\n",
      " - 4s - loss: 0.4492 - acc: 0.7908 - val_loss: 0.6694 - val_acc: 0.6708\n",
      "Epoch 8/120\n",
      "Epoch 00008: val_loss improved from 0.66937 to 0.44842, saving model to best_m.h5\n",
      " - 4s - loss: 0.4667 - acc: 0.7858 - val_loss: 0.4484 - val_acc: 0.7556\n",
      "Epoch 9/120\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 3s - loss: 0.4698 - acc: 0.7764 - val_loss: 0.7126 - val_acc: 0.6434\n",
      "Epoch 10/120\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 3s - loss: 0.4610 - acc: 0.7787 - val_loss: 0.5051 - val_acc: 0.7955\n",
      "Epoch 11/120\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 3s - loss: 0.4350 - acc: 0.7958 - val_loss: 0.9278 - val_acc: 0.5387\n",
      "Epoch 12/120\n",
      "Epoch 00012: val_loss improved from 0.44842 to 0.44416, saving model to best_m.h5\n",
      " - 4s - loss: 0.4397 - acc: 0.7991 - val_loss: 0.4442 - val_acc: 0.7631\n",
      "Epoch 13/120\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.4246 - acc: 0.7900 - val_loss: 0.5203 - val_acc: 0.7905\n",
      "Epoch 14/120\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.4081 - acc: 0.8058 - val_loss: 1.2580 - val_acc: 0.5287\n",
      "Epoch 15/120\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 3s - loss: 0.4242 - acc: 0.8022 - val_loss: 1.4672 - val_acc: 0.5187\n",
      "Epoch 16/120\n",
      "Epoch 00016: val_loss improved from 0.44416 to 0.42056, saving model to best_m.h5\n",
      " - 4s - loss: 0.4103 - acc: 0.8089 - val_loss: 0.4206 - val_acc: 0.7830\n",
      "Epoch 17/120\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.4267 - acc: 0.7778 - val_loss: 1.1265 - val_acc: 0.5761\n",
      "Epoch 18/120\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 0.3924 - acc: 0.8150 - val_loss: 0.4535 - val_acc: 0.7980\n",
      "Epoch 19/120\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 3s - loss: 0.3993 - acc: 0.8050 - val_loss: 1.1160 - val_acc: 0.5586\n",
      "Epoch 20/120\n",
      "Epoch 00020: val_loss improved from 0.42056 to 0.35052, saving model to best_m.h5\n",
      " - 4s - loss: 0.4166 - acc: 0.8108 - val_loss: 0.3505 - val_acc: 0.8603\n",
      "Epoch 21/120\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.3627 - acc: 0.8375 - val_loss: 0.4422 - val_acc: 0.7880\n",
      "Epoch 22/120\n",
      "Epoch 00022: val_loss improved from 0.35052 to 0.34245, saving model to best_m.h5\n",
      " - 5s - loss: 0.3565 - acc: 0.8347 - val_loss: 0.3424 - val_acc: 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/120\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3420 - acc: 0.8492 - val_loss: 0.4571 - val_acc: 0.8005\n",
      "Epoch 24/120\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 5s - loss: 0.3913 - acc: 0.8137 - val_loss: 0.4287 - val_acc: 0.8005\n",
      "Epoch 25/120\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3596 - acc: 0.8358 - val_loss: 0.5613 - val_acc: 0.7207\n",
      "Epoch 26/120\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 5s - loss: 0.3214 - acc: 0.8525 - val_loss: 0.3459 - val_acc: 0.8404\n",
      "Epoch 27/120\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 3s - loss: 0.3674 - acc: 0.8281 - val_loss: 0.5123 - val_acc: 0.7980\n",
      "Epoch 28/120\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 3s - loss: 0.3507 - acc: 0.8383 - val_loss: 0.4433 - val_acc: 0.7880\n",
      "Epoch 29/120\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 3s - loss: 0.3459 - acc: 0.8308 - val_loss: 0.3839 - val_acc: 0.8005\n",
      "Epoch 30/120\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 3s - loss: 0.3367 - acc: 0.8350 - val_loss: 0.4390 - val_acc: 0.8180\n",
      "Epoch 31/120\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.3483 - acc: 0.8372 - val_loss: 0.3758 - val_acc: 0.7980\n",
      "Epoch 32/120\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 3s - loss: 0.3460 - acc: 0.8325 - val_loss: 0.3631 - val_acc: 0.8429\n",
      "Epoch 33/120\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.3602 - acc: 0.8345 - val_loss: 0.5787 - val_acc: 0.6858\n",
      "Epoch 34/120\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.3642 - acc: 0.8491 - val_loss: 0.5208 - val_acc: 0.7531\n",
      "Epoch 35/120\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.3309 - acc: 0.8425 - val_loss: 0.3723 - val_acc: 0.8229\n",
      "Epoch 36/120\n",
      "Epoch 00036: val_loss improved from 0.34245 to 0.33731, saving model to best_m.h5\n",
      " - 4s - loss: 0.3638 - acc: 0.8268 - val_loss: 0.3373 - val_acc: 0.8379\n",
      "Epoch 37/120\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.3467 - acc: 0.8292 - val_loss: 0.3715 - val_acc: 0.8379\n",
      "Epoch 38/120\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.3520 - acc: 0.8397 - val_loss: 0.3440 - val_acc: 0.8479\n",
      "Epoch 39/120\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 3s - loss: 0.3296 - acc: 0.8572 - val_loss: 0.3646 - val_acc: 0.8204\n",
      "Epoch 40/120\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.3096 - acc: 0.8581 - val_loss: 0.4198 - val_acc: 0.8254\n",
      "Epoch 41/120\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.3334 - acc: 0.8458 - val_loss: 0.3438 - val_acc: 0.8529\n",
      "Epoch 42/120\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 3s - loss: 0.3092 - acc: 0.8572 - val_loss: 0.3725 - val_acc: 0.8454\n",
      "Epoch 43/120\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 3s - loss: 0.3592 - acc: 0.8312 - val_loss: 0.5295 - val_acc: 0.7781\n",
      "Epoch 44/120\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.3154 - acc: 0.8650 - val_loss: 0.3706 - val_acc: 0.8479\n",
      "Epoch 45/120\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.3529 - acc: 0.8417 - val_loss: 0.4459 - val_acc: 0.8130\n",
      "Epoch 46/120\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 3s - loss: 0.2923 - acc: 0.8756 - val_loss: 0.3542 - val_acc: 0.8479\n",
      "Epoch 47/120\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 3s - loss: 0.3038 - acc: 0.8700 - val_loss: 0.3818 - val_acc: 0.8379\n",
      "Epoch 48/120\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.3247 - acc: 0.8442 - val_loss: 0.7625 - val_acc: 0.7157\n",
      "Epoch 49/120\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.3244 - acc: 0.8541 - val_loss: 0.3818 - val_acc: 0.8155\n",
      "Epoch 50/120\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 3s - loss: 0.3413 - acc: 0.8483 - val_loss: 0.4900 - val_acc: 0.7631\n",
      "Epoch 51/120\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.3229 - acc: 0.8714 - val_loss: 0.5459 - val_acc: 0.7880\n",
      "Epoch 52/120\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.3376 - acc: 0.8387 - val_loss: 0.3783 - val_acc: 0.8204\n",
      "Epoch 53/120\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 3s - loss: 0.3171 - acc: 0.8547 - val_loss: 0.6066 - val_acc: 0.7706\n",
      "Epoch 54/120\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 3s - loss: 0.3111 - acc: 0.8675 - val_loss: 0.7682 - val_acc: 0.6858\n",
      "Epoch 55/120\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 3s - loss: 0.3230 - acc: 0.8564 - val_loss: 0.7645 - val_acc: 0.7107\n",
      "Epoch 56/120\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 3s - loss: 0.3271 - acc: 0.8483 - val_loss: 0.3581 - val_acc: 0.8304\n",
      "Epoch 57/120\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 3s - loss: 0.2885 - acc: 0.8709 - val_loss: 0.3698 - val_acc: 0.8354\n",
      "Epoch 58/120\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 3s - loss: 0.3058 - acc: 0.8608 - val_loss: 0.3893 - val_acc: 0.8354\n",
      "Epoch 59/120\n",
      "Epoch 00059: val_loss improved from 0.33731 to 0.31171, saving model to best_m.h5\n",
      " - 3s - loss: 0.3205 - acc: 0.8447 - val_loss: 0.3117 - val_acc: 0.8628\n",
      "Epoch 60/120\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.3404 - acc: 0.8484 - val_loss: 0.4467 - val_acc: 0.8180\n",
      "Epoch 61/120\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 3s - loss: 0.3396 - acc: 0.8458 - val_loss: 0.3881 - val_acc: 0.8130\n",
      "Epoch 62/120\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.3063 - acc: 0.8445 - val_loss: 0.4258 - val_acc: 0.8254\n",
      "Epoch 63/120\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 3s - loss: 0.2904 - acc: 0.8708 - val_loss: 0.3503 - val_acc: 0.8603\n",
      "Epoch 64/120\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 4s - loss: 0.2950 - acc: 0.8714 - val_loss: 0.5953 - val_acc: 0.7556\n",
      "Epoch 65/120\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 4s - loss: 0.2945 - acc: 0.8797 - val_loss: 0.4952 - val_acc: 0.8105\n",
      "Epoch 66/120\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 3s - loss: 0.2779 - acc: 0.8742 - val_loss: 0.3588 - val_acc: 0.8454\n",
      "Epoch 67/120\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 4s - loss: 0.2938 - acc: 0.8641 - val_loss: 0.8127 - val_acc: 0.7132\n",
      "Epoch 68/120\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 3s - loss: 0.2995 - acc: 0.8675 - val_loss: 0.3721 - val_acc: 0.8204\n",
      "Epoch 69/120\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 4s - loss: 0.2889 - acc: 0.8800 - val_loss: 0.4352 - val_acc: 0.8279\n",
      "Epoch 70/120\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 4s - loss: 0.2974 - acc: 0.8629 - val_loss: 0.3479 - val_acc: 0.8504\n",
      "Epoch 71/120\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 3s - loss: 0.2667 - acc: 0.8733 - val_loss: 0.3462 - val_acc: 0.8304\n",
      "Epoch 72/120\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 3s - loss: 0.2769 - acc: 0.8633 - val_loss: 0.3427 - val_acc: 0.8404\n",
      "Epoch 73/120\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 4s - loss: 0.2607 - acc: 0.8756 - val_loss: 0.3472 - val_acc: 0.8454\n",
      "Epoch 74/120\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 4s - loss: 0.2632 - acc: 0.8858 - val_loss: 0.3645 - val_acc: 0.8479\n",
      "Epoch 75/120\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 3s - loss: 0.2755 - acc: 0.8681 - val_loss: 0.4032 - val_acc: 0.8254\n",
      "Epoch 76/120\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 4s - loss: 0.2438 - acc: 0.8867 - val_loss: 0.3801 - val_acc: 0.8404\n",
      "Epoch 77/120\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 4s - loss: 0.2536 - acc: 0.8775 - val_loss: 0.3618 - val_acc: 0.8429\n",
      "Epoch 78/120\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 4s - loss: 0.2779 - acc: 0.8789 - val_loss: 0.3640 - val_acc: 0.8479\n",
      "Epoch 79/120\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 4s - loss: 0.2636 - acc: 0.8687 - val_loss: 0.4140 - val_acc: 0.8429\n",
      "Epoch 80/120\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 4s - loss: 0.2375 - acc: 0.8967 - val_loss: 0.3671 - val_acc: 0.8554\n",
      "Epoch 81/120\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 4s - loss: 0.2615 - acc: 0.8808 - val_loss: 0.3624 - val_acc: 0.8529\n",
      "Epoch 82/120\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 3s - loss: 0.2530 - acc: 0.8825 - val_loss: 0.3642 - val_acc: 0.8229\n",
      "Epoch 83/120\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 4s - loss: 0.2569 - acc: 0.8856 - val_loss: 0.3742 - val_acc: 0.8354\n",
      "Epoch 84/120\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 4s - loss: 0.2689 - acc: 0.8664 - val_loss: 0.3698 - val_acc: 0.8354\n",
      "Epoch 85/120\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 3s - loss: 0.2498 - acc: 0.8925 - val_loss: 0.3655 - val_acc: 0.8529\n",
      "Epoch 86/120\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 4s - loss: 0.2540 - acc: 0.8817 - val_loss: 0.3693 - val_acc: 0.8404\n",
      "Epoch 87/120\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 4s - loss: 0.2508 - acc: 0.8837 - val_loss: 0.3759 - val_acc: 0.8628\n",
      "Epoch 88/120\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 3s - loss: 0.2595 - acc: 0.8856 - val_loss: 0.3734 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/120\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 3s - loss: 0.2709 - acc: 0.8833 - val_loss: 0.3657 - val_acc: 0.8429\n",
      "Epoch 90/120\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 4s - loss: 0.2309 - acc: 0.8981 - val_loss: 0.3619 - val_acc: 0.8603\n",
      "Epoch 91/120\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 3s - loss: 0.2381 - acc: 0.8992 - val_loss: 0.3748 - val_acc: 0.8304\n",
      "Epoch 92/120\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 3s - loss: 0.2700 - acc: 0.8750 - val_loss: 0.3620 - val_acc: 0.8529\n",
      "Epoch 93/120\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 4s - loss: 0.2653 - acc: 0.8831 - val_loss: 0.3621 - val_acc: 0.8529\n",
      "Epoch 94/120\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 4s - loss: 0.2332 - acc: 0.8889 - val_loss: 0.3557 - val_acc: 0.8504\n",
      "Epoch 95/120\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 4s - loss: 0.2408 - acc: 0.8958 - val_loss: 0.4032 - val_acc: 0.8329\n",
      "Epoch 96/120\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 4s - loss: 0.2638 - acc: 0.8825 - val_loss: 0.3677 - val_acc: 0.8504\n",
      "Epoch 97/120\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 4s - loss: 0.2307 - acc: 0.8933 - val_loss: 0.3919 - val_acc: 0.8379\n",
      "Epoch 98/120\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 4s - loss: 0.2377 - acc: 0.8908 - val_loss: 0.3721 - val_acc: 0.8479\n",
      "Epoch 99/120\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 3s - loss: 0.2536 - acc: 0.8881 - val_loss: 0.3734 - val_acc: 0.8703\n",
      "Epoch 100/120\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 4s - loss: 0.2461 - acc: 0.8942 - val_loss: 0.3893 - val_acc: 0.8479\n",
      "Epoch 101/120\n",
      "Epoch 00101: val_loss did not improve\n",
      " - 4s - loss: 0.2623 - acc: 0.8841 - val_loss: 0.3695 - val_acc: 0.8628\n",
      "Epoch 102/120\n",
      "Epoch 00102: val_loss did not improve\n",
      " - 3s - loss: 0.2598 - acc: 0.8776 - val_loss: 0.3746 - val_acc: 0.8529\n",
      "Epoch 103/120\n",
      "Epoch 00103: val_loss did not improve\n",
      " - 3s - loss: 0.2421 - acc: 0.8917 - val_loss: 0.3882 - val_acc: 0.8504\n",
      "Epoch 104/120\n",
      "Epoch 00104: val_loss did not improve\n",
      " - 3s - loss: 0.2428 - acc: 0.8875 - val_loss: 0.3714 - val_acc: 0.8479\n",
      "Epoch 105/120\n",
      "Epoch 00105: val_loss did not improve\n",
      " - 3s - loss: 0.2571 - acc: 0.8833 - val_loss: 0.3763 - val_acc: 0.8603\n",
      "Epoch 106/120\n",
      "Epoch 00106: val_loss did not improve\n",
      " - 3s - loss: 0.1885 - acc: 0.9208 - val_loss: 0.4035 - val_acc: 0.8504\n",
      "Epoch 107/120\n",
      "Epoch 00107: val_loss did not improve\n",
      " - 3s - loss: 0.2578 - acc: 0.8837 - val_loss: 0.3862 - val_acc: 0.8329\n",
      "Epoch 108/120\n",
      "Epoch 00108: val_loss did not improve\n",
      " - 3s - loss: 0.2534 - acc: 0.8841 - val_loss: 0.3837 - val_acc: 0.8454\n",
      "Epoch 109/120\n",
      "Epoch 00109: val_loss did not improve\n",
      " - 4s - loss: 0.2441 - acc: 0.8925 - val_loss: 0.3777 - val_acc: 0.8579\n",
      "Epoch 110/120\n",
      "Epoch 00110: val_loss did not improve\n",
      " - 3s - loss: 0.2758 - acc: 0.8795 - val_loss: 0.3741 - val_acc: 0.8454\n",
      "Epoch 111/120\n",
      "Epoch 00111: val_loss did not improve\n",
      " - 3s - loss: 0.2385 - acc: 0.8800 - val_loss: 0.3664 - val_acc: 0.8479\n",
      "Epoch 112/120\n",
      "Epoch 00112: val_loss did not improve\n",
      " - 4s - loss: 0.2409 - acc: 0.8958 - val_loss: 0.3763 - val_acc: 0.8504\n",
      "Epoch 113/120\n",
      "Epoch 00113: val_loss did not improve\n",
      " - 3s - loss: 0.2721 - acc: 0.8800 - val_loss: 0.3519 - val_acc: 0.8579\n",
      "Epoch 114/120\n",
      "Epoch 00114: val_loss did not improve\n",
      " - 4s - loss: 0.2327 - acc: 0.9025 - val_loss: 0.3830 - val_acc: 0.8554\n",
      "Epoch 115/120\n",
      "Epoch 00115: val_loss did not improve\n",
      " - 3s - loss: 0.2432 - acc: 0.8964 - val_loss: 0.3961 - val_acc: 0.8554\n",
      "Epoch 116/120\n",
      "Epoch 00116: val_loss did not improve\n",
      " - 4s - loss: 0.2651 - acc: 0.8870 - val_loss: 0.3810 - val_acc: 0.8653\n",
      "Epoch 117/120\n",
      "Epoch 00117: val_loss did not improve\n",
      " - 4s - loss: 0.2186 - acc: 0.9042 - val_loss: 0.3899 - val_acc: 0.8554\n",
      "Epoch 118/120\n",
      "Epoch 00118: val_loss did not improve\n",
      " - 3s - loss: 0.2648 - acc: 0.8823 - val_loss: 0.3761 - val_acc: 0.8554\n",
      "Epoch 119/120\n",
      "Epoch 00119: val_loss did not improve\n",
      " - 3s - loss: 0.2397 - acc: 0.8964 - val_loss: 0.3787 - val_acc: 0.8329\n",
      "Epoch 120/120\n",
      "Epoch 00120: val_loss did not improve\n",
      " - 4s - loss: 0.1985 - acc: 0.9217 - val_loss: 0.4055 - val_acc: 0.8529\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=120, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265676284575\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.149564\n",
      "1  4023181e    0.352891\n",
      "2  b20200e4    0.134070\n",
      "3  e7f018bb    0.981369\n",
      "4  4371c8c3    0.471172\n"
     ]
    }
   ],
   "source": [
    "with open('../features/cnn_5_aug_skimage_preprocess_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "# 2364\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_5_aug_skimage_preprocess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        img = np.dstack((band_1, band_2, band_3))\n",
    "        images.append(std_img(img))\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "    ConvBlock(model, 1, 32)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 4x4x128\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.58653, saving model to best_m.h5\n",
      " - 3s - loss: 0.6744 - acc: 0.7275 - val_loss: 0.5865 - val_acc: 0.6534\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.58653 to 0.47592, saving model to best_m.h5\n",
      " - 2s - loss: 0.5395 - acc: 0.7583 - val_loss: 0.4759 - val_acc: 0.7805\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.4337 - acc: 0.7950 - val_loss: 0.5093 - val_acc: 0.8055\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.3969 - acc: 0.8231 - val_loss: 0.5487 - val_acc: 0.7681\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.3227 - acc: 0.8516 - val_loss: 0.5301 - val_acc: 0.8229\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.3312 - acc: 0.8616 - val_loss: 1.7482 - val_acc: 0.5586\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.47592 to 0.26377, saving model to best_m.h5\n",
      " - 2s - loss: 0.3667 - acc: 0.8481 - val_loss: 0.2638 - val_acc: 0.8703\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.3301 - acc: 0.8575 - val_loss: 0.3051 - val_acc: 0.8653\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3578 - acc: 0.8581 - val_loss: 0.3832 - val_acc: 0.8828\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3214 - acc: 0.8658 - val_loss: 0.3880 - val_acc: 0.8155\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.26377 to 0.23786, saving model to best_m.h5\n",
      " - 2s - loss: 0.3096 - acc: 0.8575 - val_loss: 0.2379 - val_acc: 0.8903\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.2780 - acc: 0.8808 - val_loss: 0.2675 - val_acc: 0.8803\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss improved from 0.23786 to 0.21717, saving model to best_m.h5\n",
      " - 2s - loss: 0.3060 - acc: 0.8791 - val_loss: 0.2172 - val_acc: 0.9152\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.2753 - acc: 0.8808 - val_loss: 0.2271 - val_acc: 0.9177\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.3182 - acc: 0.8683 - val_loss: 0.4477 - val_acc: 0.8130\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.21717 to 0.20840, saving model to best_m.h5\n",
      " - 2s - loss: 0.2598 - acc: 0.8841 - val_loss: 0.2084 - val_acc: 0.9027\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.2760 - acc: 0.8858 - val_loss: 0.2106 - val_acc: 0.9052\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2523 - acc: 0.8887 - val_loss: 0.2207 - val_acc: 0.9102\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.20840 to 0.19586, saving model to best_m.h5\n",
      " - 2s - loss: 0.2294 - acc: 0.9108 - val_loss: 0.1959 - val_acc: 0.9277\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2622 - acc: 0.8841 - val_loss: 0.2520 - val_acc: 0.8778\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.2025 - acc: 0.9183 - val_loss: 0.2299 - val_acc: 0.8903\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2484 - acc: 0.8933 - val_loss: 0.3654 - val_acc: 0.8379\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.2049 - acc: 0.9175 - val_loss: 0.2259 - val_acc: 0.9002\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2205 - acc: 0.9033 - val_loss: 0.2076 - val_acc: 0.9127\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2363 - acc: 0.8942 - val_loss: 0.4562 - val_acc: 0.8080\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss improved from 0.19586 to 0.19424, saving model to best_m.h5\n",
      " - 2s - loss: 0.2374 - acc: 0.9000 - val_loss: 0.1942 - val_acc: 0.9252\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2404 - acc: 0.8958 - val_loss: 0.3575 - val_acc: 0.8404\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2267 - acc: 0.9083 - val_loss: 0.2567 - val_acc: 0.8828\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2576 - acc: 0.8908 - val_loss: 0.1980 - val_acc: 0.9227\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss improved from 0.19424 to 0.17951, saving model to best_m.h5\n",
      " - 2s - loss: 0.2072 - acc: 0.9097 - val_loss: 0.1795 - val_acc: 0.9277\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2112 - acc: 0.9200 - val_loss: 0.1970 - val_acc: 0.9202\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.1956 - acc: 0.9273 - val_loss: 0.1815 - val_acc: 0.9277\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2038 - acc: 0.9222 - val_loss: 0.2060 - val_acc: 0.9127\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2193 - acc: 0.9087 - val_loss: 0.2077 - val_acc: 0.9102\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.1913 - acc: 0.9217 - val_loss: 0.1879 - val_acc: 0.9177\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.1894 - acc: 0.9250 - val_loss: 0.1870 - val_acc: 0.9277\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.1912 - acc: 0.9173 - val_loss: 0.1951 - val_acc: 0.9077\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss improved from 0.17951 to 0.17915, saving model to best_m.h5\n",
      " - 2s - loss: 0.1962 - acc: 0.9195 - val_loss: 0.1791 - val_acc: 0.9327\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.1791 - acc: 0.9314 - val_loss: 0.2005 - val_acc: 0.8953\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss improved from 0.17915 to 0.17564, saving model to best_m.h5\n",
      " - 2s - loss: 0.1884 - acc: 0.9233 - val_loss: 0.1756 - val_acc: 0.9352\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.1688 - acc: 0.9300 - val_loss: 0.1949 - val_acc: 0.9127\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.1731 - acc: 0.9300 - val_loss: 0.1778 - val_acc: 0.9277\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss improved from 0.17564 to 0.17155, saving model to best_m.h5\n",
      " - 2s - loss: 0.1609 - acc: 0.9325 - val_loss: 0.1715 - val_acc: 0.9277\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.1620 - acc: 0.9358 - val_loss: 0.1861 - val_acc: 0.9252\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.1801 - acc: 0.9275 - val_loss: 0.1957 - val_acc: 0.9202\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.1626 - acc: 0.9308 - val_loss: 0.1735 - val_acc: 0.9401\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.1815 - acc: 0.9256 - val_loss: 0.1756 - val_acc: 0.9202\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.1642 - acc: 0.9375 - val_loss: 0.1814 - val_acc: 0.9302\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.1628 - acc: 0.9317 - val_loss: 0.1758 - val_acc: 0.9177\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.1722 - acc: 0.9317 - val_loss: 0.1720 - val_acc: 0.9352\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.1629 - acc: 0.9375 - val_loss: 0.1740 - val_acc: 0.9327\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss improved from 0.17155 to 0.17028, saving model to best_m.h5\n",
      " - 2s - loss: 0.1436 - acc: 0.9417 - val_loss: 0.1703 - val_acc: 0.9352\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.1975 - acc: 0.9323 - val_loss: 0.1821 - val_acc: 0.9302\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.1969 - acc: 0.9204 - val_loss: 0.1841 - val_acc: 0.9277\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.17028 to 0.16954, saving model to best_m.h5\n",
      " - 2s - loss: 0.1425 - acc: 0.9442 - val_loss: 0.1695 - val_acc: 0.9302\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.1481 - acc: 0.9425 - val_loss: 0.1971 - val_acc: 0.9227\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.1499 - acc: 0.9433 - val_loss: 0.1811 - val_acc: 0.9227\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.1623 - acc: 0.9333 - val_loss: 0.1715 - val_acc: 0.9302\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.1593 - acc: 0.9408 - val_loss: 0.1710 - val_acc: 0.9302\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.1689 - acc: 0.9383 - val_loss: 0.1751 - val_acc: 0.9252\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.1570 - acc: 0.9389 - val_loss: 0.1856 - val_acc: 0.9227\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.1525 - acc: 0.9408 - val_loss: 0.1742 - val_acc: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.1447 - acc: 0.9383 - val_loss: 0.1754 - val_acc: 0.9277\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.1578 - acc: 0.9375 - val_loss: 0.1756 - val_acc: 0.9277\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.1373 - acc: 0.9475 - val_loss: 0.1737 - val_acc: 0.9202\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.1459 - acc: 0.9458 - val_loss: 0.1773 - val_acc: 0.9302\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.1578 - acc: 0.9417 - val_loss: 0.1743 - val_acc: 0.9252\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.1733 - acc: 0.9248 - val_loss: 0.1867 - val_acc: 0.9152\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.1301 - acc: 0.9425 - val_loss: 0.1805 - val_acc: 0.9277\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.1486 - acc: 0.9406 - val_loss: 0.1760 - val_acc: 0.9127\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.1594 - acc: 0.9392 - val_loss: 0.1839 - val_acc: 0.9252\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.1557 - acc: 0.9398 - val_loss: 0.2105 - val_acc: 0.9202\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.1505 - acc: 0.9475 - val_loss: 0.1856 - val_acc: 0.9227\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.1643 - acc: 0.9333 - val_loss: 0.1905 - val_acc: 0.9202\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1696 - acc: 0.9283 - val_loss: 0.1890 - val_acc: 0.9202\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.71020, saving model to best_m.h5\n",
      " - 3s - loss: 0.6220 - acc: 0.7333 - val_loss: 0.7102 - val_acc: 0.5387\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.71020 to 0.51556, saving model to best_m.h5\n",
      " - 2s - loss: 0.4743 - acc: 0.8008 - val_loss: 0.5156 - val_acc: 0.7132\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.51556 to 0.46433, saving model to best_m.h5\n",
      " - 2s - loss: 0.3940 - acc: 0.8208 - val_loss: 0.4643 - val_acc: 0.7855\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.46433 to 0.44483, saving model to best_m.h5\n",
      " - 2s - loss: 0.3743 - acc: 0.8506 - val_loss: 0.4448 - val_acc: 0.8130\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.3754 - acc: 0.8372 - val_loss: 0.5909 - val_acc: 0.7631\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.3128 - acc: 0.8639 - val_loss: 0.6133 - val_acc: 0.7805\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.44483 to 0.30566, saving model to best_m.h5\n",
      " - 2s - loss: 0.2952 - acc: 0.8766 - val_loss: 0.3057 - val_acc: 0.8753\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.3331 - acc: 0.8606 - val_loss: 0.6814 - val_acc: 0.7905\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3126 - acc: 0.8662 - val_loss: 0.3488 - val_acc: 0.8479\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3078 - acc: 0.8639 - val_loss: 0.4592 - val_acc: 0.8055\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.30566 to 0.28529, saving model to best_m.h5\n",
      " - 2s - loss: 0.3246 - acc: 0.8683 - val_loss: 0.2853 - val_acc: 0.8803\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3210 - acc: 0.8667 - val_loss: 0.7749 - val_acc: 0.7581\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.2958 - acc: 0.8845 - val_loss: 0.3099 - val_acc: 0.8778\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.2260 - acc: 0.8948 - val_loss: 0.3052 - val_acc: 0.8753\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2938 - acc: 0.8767 - val_loss: 0.2954 - val_acc: 0.8628\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.28529 to 0.24638, saving model to best_m.h5\n",
      " - 2s - loss: 0.2198 - acc: 0.8933 - val_loss: 0.2464 - val_acc: 0.8978\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.2314 - acc: 0.9008 - val_loss: 0.3517 - val_acc: 0.8554\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 3s - loss: 0.2294 - acc: 0.9106 - val_loss: 0.2529 - val_acc: 0.8903\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 3s - loss: 0.2309 - acc: 0.8983 - val_loss: 0.3916 - val_acc: 0.8529\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2493 - acc: 0.9023 - val_loss: 0.2909 - val_acc: 0.8778\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss improved from 0.24638 to 0.23455, saving model to best_m.h5\n",
      " - 2s - loss: 0.2190 - acc: 0.9108 - val_loss: 0.2345 - val_acc: 0.9077\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2288 - acc: 0.9050 - val_loss: 0.2936 - val_acc: 0.8778\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 3s - loss: 0.1944 - acc: 0.9175 - val_loss: 0.2911 - val_acc: 0.8953\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 3s - loss: 0.2045 - acc: 0.9142 - val_loss: 0.2439 - val_acc: 0.9077\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss improved from 0.23455 to 0.22878, saving model to best_m.h5\n",
      " - 2s - loss: 0.2275 - acc: 0.9100 - val_loss: 0.2288 - val_acc: 0.9202\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2139 - acc: 0.9092 - val_loss: 0.4055 - val_acc: 0.8504\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2325 - acc: 0.9058 - val_loss: 0.2675 - val_acc: 0.8903\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2112 - acc: 0.9106 - val_loss: 0.3783 - val_acc: 0.8254\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss improved from 0.22878 to 0.22462, saving model to best_m.h5\n",
      " - 2s - loss: 0.1972 - acc: 0.9075 - val_loss: 0.2246 - val_acc: 0.9127\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2038 - acc: 0.9125 - val_loss: 0.2407 - val_acc: 0.8978\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2230 - acc: 0.9079 - val_loss: 0.2356 - val_acc: 0.9002\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss improved from 0.22462 to 0.21951, saving model to best_m.h5\n",
      " - 2s - loss: 0.1790 - acc: 0.9258 - val_loss: 0.2195 - val_acc: 0.9077\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.1826 - acc: 0.9222 - val_loss: 0.2321 - val_acc: 0.9027\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.1772 - acc: 0.9367 - val_loss: 0.2400 - val_acc: 0.9002\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.1652 - acc: 0.9283 - val_loss: 0.2353 - val_acc: 0.9052\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.1471 - acc: 0.9417 - val_loss: 0.2448 - val_acc: 0.9127\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.1840 - acc: 0.9267 - val_loss: 0.2319 - val_acc: 0.9002\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 3s - loss: 0.1791 - acc: 0.9266 - val_loss: 0.2363 - val_acc: 0.9102\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.1914 - acc: 0.9292 - val_loss: 0.2439 - val_acc: 0.9027\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.1754 - acc: 0.9333 - val_loss: 0.2550 - val_acc: 0.8928\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.1496 - acc: 0.9292 - val_loss: 0.2270 - val_acc: 0.9077\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.1642 - acc: 0.9342 - val_loss: 0.2337 - val_acc: 0.9077\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss improved from 0.21951 to 0.21947, saving model to best_m.h5\n",
      " - 2s - loss: 0.1648 - acc: 0.9281 - val_loss: 0.2195 - val_acc: 0.9102\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.1580 - acc: 0.9392 - val_loss: 0.2462 - val_acc: 0.9052\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.1518 - acc: 0.9392 - val_loss: 0.2295 - val_acc: 0.9127\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.1722 - acc: 0.9320 - val_loss: 0.2514 - val_acc: 0.9077\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.1584 - acc: 0.9342 - val_loss: 0.2479 - val_acc: 0.9127\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.1583 - acc: 0.9375 - val_loss: 0.2333 - val_acc: 0.9052\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 3s - loss: 0.1763 - acc: 0.9289 - val_loss: 0.2260 - val_acc: 0.9077\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.1672 - acc: 0.9373 - val_loss: 0.2272 - val_acc: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.1500 - acc: 0.9433 - val_loss: 0.2434 - val_acc: 0.9102\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 3s - loss: 0.1736 - acc: 0.9264 - val_loss: 0.2391 - val_acc: 0.9052\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.1263 - acc: 0.9517 - val_loss: 0.2258 - val_acc: 0.9152\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 4s - loss: 0.1651 - acc: 0.9275 - val_loss: 0.2325 - val_acc: 0.9102\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.1686 - acc: 0.9383 - val_loss: 0.2323 - val_acc: 0.9127\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.1668 - acc: 0.9333 - val_loss: 0.2239 - val_acc: 0.8978\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 5s - loss: 0.1471 - acc: 0.9458 - val_loss: 0.2674 - val_acc: 0.9027\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 4s - loss: 0.1492 - acc: 0.9367 - val_loss: 0.2255 - val_acc: 0.9002\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 4s - loss: 0.1608 - acc: 0.9354 - val_loss: 0.2316 - val_acc: 0.9102\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.1479 - acc: 0.9400 - val_loss: 0.2234 - val_acc: 0.9127\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 4s - loss: 0.1496 - acc: 0.9375 - val_loss: 0.2586 - val_acc: 0.9027\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.1415 - acc: 0.9442 - val_loss: 0.2314 - val_acc: 0.9027\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 5s - loss: 0.1307 - acc: 0.9500 - val_loss: 0.2327 - val_acc: 0.9102\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.47620, saving model to best_m.h5\n",
      " - 3s - loss: 0.6099 - acc: 0.7412 - val_loss: 0.4762 - val_acc: 0.7731\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.4264 - acc: 0.8083 - val_loss: 0.4951 - val_acc: 0.7556\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.47620 to 0.37915, saving model to best_m.h5\n",
      " - 2s - loss: 0.4352 - acc: 0.8014 - val_loss: 0.3791 - val_acc: 0.8329\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.37915 to 0.34172, saving model to best_m.h5\n",
      " - 3s - loss: 0.3974 - acc: 0.8247 - val_loss: 0.3417 - val_acc: 0.8479\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 3s - loss: 0.3747 - acc: 0.8297 - val_loss: 0.3769 - val_acc: 0.8379\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.34172 to 0.32333, saving model to best_m.h5\n",
      " - 2s - loss: 0.3459 - acc: 0.8489 - val_loss: 0.3233 - val_acc: 0.8404\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.3644 - acc: 0.8389 - val_loss: 0.4229 - val_acc: 0.8155\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.32333 to 0.29723, saving model to best_m.h5\n",
      " - 2s - loss: 0.3439 - acc: 0.8412 - val_loss: 0.2972 - val_acc: 0.8653\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 3s - loss: 0.3329 - acc: 0.8675 - val_loss: 0.9147 - val_acc: 0.7431\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 3s - loss: 0.3489 - acc: 0.8623 - val_loss: 0.4005 - val_acc: 0.8354\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.29723 to 0.27084, saving model to best_m.h5\n",
      " - 2s - loss: 0.2879 - acc: 0.8650 - val_loss: 0.2708 - val_acc: 0.8828\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3092 - acc: 0.8681 - val_loss: 0.2776 - val_acc: 0.8853\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.2870 - acc: 0.8783 - val_loss: 0.3091 - val_acc: 0.8628\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.27084 to 0.24257, saving model to best_m.h5\n",
      " - 3s - loss: 0.2567 - acc: 0.8900 - val_loss: 0.2426 - val_acc: 0.8878\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 3s - loss: 0.3507 - acc: 0.8603 - val_loss: 0.3709 - val_acc: 0.8404\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.2635 - acc: 0.8841 - val_loss: 0.2978 - val_acc: 0.8828\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.24257 to 0.22012, saving model to best_m.h5\n",
      " - 2s - loss: 0.2211 - acc: 0.9033 - val_loss: 0.2201 - val_acc: 0.9002\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2677 - acc: 0.8833 - val_loss: 0.3944 - val_acc: 0.8429\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2376 - acc: 0.9000 - val_loss: 0.2542 - val_acc: 0.8753\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2370 - acc: 0.9042 - val_loss: 0.3478 - val_acc: 0.8479\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.2188 - acc: 0.9042 - val_loss: 0.2556 - val_acc: 0.9002\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2090 - acc: 0.9125 - val_loss: 0.2473 - val_acc: 0.8853\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.2382 - acc: 0.8914 - val_loss: 0.2405 - val_acc: 0.8953\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 3s - loss: 0.2514 - acc: 0.8989 - val_loss: 0.2959 - val_acc: 0.8653\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2211 - acc: 0.9064 - val_loss: 0.3000 - val_acc: 0.8928\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2169 - acc: 0.9108 - val_loss: 0.3005 - val_acc: 0.8828\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2672 - acc: 0.8950 - val_loss: 0.4441 - val_acc: 0.8105\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 3s - loss: 0.2463 - acc: 0.8966 - val_loss: 0.2264 - val_acc: 0.8978\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 3s - loss: 0.2248 - acc: 0.9039 - val_loss: 0.2681 - val_acc: 0.8878\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2030 - acc: 0.9123 - val_loss: 0.2228 - val_acc: 0.9002\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.22012 to 0.19049, saving model to best_m.h5\n",
      " - 2s - loss: 0.1848 - acc: 0.9223 - val_loss: 0.1905 - val_acc: 0.9127\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2114 - acc: 0.9154 - val_loss: 0.2068 - val_acc: 0.9027\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2013 - acc: 0.9175 - val_loss: 0.2013 - val_acc: 0.9277\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.19049 to 0.18426, saving model to best_m.h5\n",
      " - 2s - loss: 0.2049 - acc: 0.9156 - val_loss: 0.1843 - val_acc: 0.9202\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.1915 - acc: 0.9217 - val_loss: 0.1863 - val_acc: 0.9127\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.1644 - acc: 0.9375 - val_loss: 0.2100 - val_acc: 0.8978\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.1684 - acc: 0.9308 - val_loss: 0.1891 - val_acc: 0.9202\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2091 - acc: 0.9137 - val_loss: 0.2097 - val_acc: 0.9002\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2017 - acc: 0.9231 - val_loss: 0.2104 - val_acc: 0.9202\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.1861 - acc: 0.9275 - val_loss: 0.1972 - val_acc: 0.9077\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.1951 - acc: 0.9233 - val_loss: 0.1940 - val_acc: 0.9302\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.1783 - acc: 0.9300 - val_loss: 0.1958 - val_acc: 0.9202\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.1723 - acc: 0.9342 - val_loss: 0.1923 - val_acc: 0.9177\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.1769 - acc: 0.9266 - val_loss: 0.2018 - val_acc: 0.9102\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2122 - acc: 0.9158 - val_loss: 0.2029 - val_acc: 0.9052\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1585 - acc: 0.9383 - val_loss: 0.2012 - val_acc: 0.8978\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 3s - loss: 0.1724 - acc: 0.9333 - val_loss: 0.1979 - val_acc: 0.8978\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.1710 - acc: 0.9264 - val_loss: 0.1999 - val_acc: 0.9152\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.1872 - acc: 0.9225 - val_loss: 0.1912 - val_acc: 0.9252\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.1681 - acc: 0.9308 - val_loss: 0.1978 - val_acc: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.1827 - acc: 0.9250 - val_loss: 0.1917 - val_acc: 0.9252\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.1598 - acc: 0.9400 - val_loss: 0.1984 - val_acc: 0.9052\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.1627 - acc: 0.9375 - val_loss: 0.1975 - val_acc: 0.8978\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.1619 - acc: 0.9350 - val_loss: 0.1848 - val_acc: 0.9227\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70980, saving model to best_m.h5\n",
      " - 3s - loss: 0.6475 - acc: 0.7208 - val_loss: 0.7098 - val_acc: 0.5711\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.70980 to 0.45213, saving model to best_m.h5\n",
      " - 2s - loss: 0.4515 - acc: 0.7900 - val_loss: 0.4521 - val_acc: 0.7681\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.4530 - acc: 0.8045 - val_loss: 0.5093 - val_acc: 0.7830\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.45213 to 0.36671, saving model to best_m.h5\n",
      " - 2s - loss: 0.3955 - acc: 0.8289 - val_loss: 0.3667 - val_acc: 0.8304\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.3173 - acc: 0.8608 - val_loss: 0.6069 - val_acc: 0.7955\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.36671 to 0.33677, saving model to best_m.h5\n",
      " - 2s - loss: 0.3772 - acc: 0.8372 - val_loss: 0.3368 - val_acc: 0.8429\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.3106 - acc: 0.8495 - val_loss: 0.5534 - val_acc: 0.7681\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.3006 - acc: 0.8683 - val_loss: 0.3445 - val_acc: 0.8429\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.33677 to 0.29961, saving model to best_m.h5\n",
      " - 2s - loss: 0.3355 - acc: 0.8572 - val_loss: 0.2996 - val_acc: 0.8703\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.2783 - acc: 0.8775 - val_loss: 0.3545 - val_acc: 0.8628\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.2770 - acc: 0.8731 - val_loss: 0.4178 - val_acc: 0.8304\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.2646 - acc: 0.8923 - val_loss: 0.4796 - val_acc: 0.8130\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.2881 - acc: 0.8783 - val_loss: 0.3911 - val_acc: 0.8329\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.2446 - acc: 0.8789 - val_loss: 0.3140 - val_acc: 0.8728\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2489 - acc: 0.8883 - val_loss: 0.3528 - val_acc: 0.8554\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.2303 - acc: 0.9017 - val_loss: 0.3142 - val_acc: 0.8678\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.2194 - acc: 0.9050 - val_loss: 0.3268 - val_acc: 0.8803\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2195 - acc: 0.9075 - val_loss: 0.3379 - val_acc: 0.8554\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.1947 - acc: 0.9167 - val_loss: 0.3646 - val_acc: 0.8354\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2389 - acc: 0.9033 - val_loss: 0.4220 - val_acc: 0.8329\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 3s - loss: 0.2279 - acc: 0.9006 - val_loss: 0.3287 - val_acc: 0.8603\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.1941 - acc: 0.9175 - val_loss: 0.3262 - val_acc: 0.8703\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.1996 - acc: 0.9081 - val_loss: 0.3173 - val_acc: 0.8803\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2020 - acc: 0.9108 - val_loss: 0.3477 - val_acc: 0.8753\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.1682 - acc: 0.9283 - val_loss: 0.3289 - val_acc: 0.8803\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 3s - loss: 0.2111 - acc: 0.9014 - val_loss: 0.3050 - val_acc: 0.8753\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss improved from 0.29961 to 0.29115, saving model to best_m.h5\n",
      " - 2s - loss: 0.1958 - acc: 0.9150 - val_loss: 0.2911 - val_acc: 0.8753\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2375 - acc: 0.9029 - val_loss: 0.3102 - val_acc: 0.8753\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.1958 - acc: 0.9239 - val_loss: 0.3514 - val_acc: 0.8504\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss improved from 0.29115 to 0.28485, saving model to best_m.h5\n",
      " - 2s - loss: 0.1725 - acc: 0.9258 - val_loss: 0.2848 - val_acc: 0.8853\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.28485 to 0.28372, saving model to best_m.h5\n",
      " - 2s - loss: 0.1915 - acc: 0.9217 - val_loss: 0.2837 - val_acc: 0.8853\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.1391 - acc: 0.9517 - val_loss: 0.2845 - val_acc: 0.8853\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.1621 - acc: 0.9292 - val_loss: 0.2858 - val_acc: 0.8853\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.1647 - acc: 0.9304 - val_loss: 0.2946 - val_acc: 0.8903\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.1473 - acc: 0.9375 - val_loss: 0.2916 - val_acc: 0.8903\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.1504 - acc: 0.9383 - val_loss: 0.2893 - val_acc: 0.8878\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.1421 - acc: 0.9492 - val_loss: 0.2865 - val_acc: 0.8853\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.1410 - acc: 0.9492 - val_loss: 0.2977 - val_acc: 0.8878\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.1661 - acc: 0.9325 - val_loss: 0.2931 - val_acc: 0.8778\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.1388 - acc: 0.9442 - val_loss: 0.2922 - val_acc: 0.8853\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.1244 - acc: 0.9500 - val_loss: 0.2894 - val_acc: 0.8878\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.1522 - acc: 0.9358 - val_loss: 0.2898 - val_acc: 0.8828\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.1375 - acc: 0.9458 - val_loss: 0.2910 - val_acc: 0.8828\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.1479 - acc: 0.9456 - val_loss: 0.2989 - val_acc: 0.8853\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.1409 - acc: 0.9383 - val_loss: 0.2932 - val_acc: 0.8803\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.1414 - acc: 0.9417 - val_loss: 0.2913 - val_acc: 0.8903\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.1410 - acc: 0.9458 - val_loss: 0.2987 - val_acc: 0.8853\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.1276 - acc: 0.9467 - val_loss: 0.3014 - val_acc: 0.8853\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.1539 - acc: 0.9314 - val_loss: 0.2996 - val_acc: 0.8928\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.1491 - acc: 0.9333 - val_loss: 0.2983 - val_acc: 0.8853\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.1334 - acc: 0.9408 - val_loss: 0.2995 - val_acc: 0.8853\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.001\n",
    "    elif epoch < 30:\n",
    "        return 0.0005\n",
    "    elif epoch < 45:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00005\n",
    "\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214248338003\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.004302\n",
      "1  4023181e    0.991425\n",
      "2  b20200e4    0.255892\n",
      "3  e7f018bb    0.997949\n",
      "4  4371c8c3    0.436680\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_4_aug1_feat_add_early.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_4_aug1_sub_add_early.csv', index=False)\n",
    "# aug_1 0.216\n",
    "# this one, small range and earlystop 0.214"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

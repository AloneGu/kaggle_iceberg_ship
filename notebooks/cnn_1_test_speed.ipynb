{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_aut(Xtr,ytr):\n",
    "    # aug on train\n",
    "    data_cnt = len(ytr)\n",
    "    print(data_cnt)\n",
    "    aug_X = []\n",
    "    aug_y = []\n",
    "\n",
    "    for i in range(data_cnt):\n",
    "        img = Xtr[i]\n",
    "        tmp_y = ytr[i]\n",
    "\n",
    "        # org img\n",
    "        aug_X.append(img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        # flip\n",
    "        tmp_img = np.fliplr(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        tmp_img = np.flipud(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        tmp_img = np.rot90(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "    return np.array(aug_X),np.array(aug_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same',input_shape=(75,75,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(16, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.6608 - acc: 0.6095 - val_loss: 0.6278 - val_acc: 0.6608\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62783, saving model to best_m.h5\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.5590 - acc: 0.7126 - val_loss: 0.5431 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62783 to 0.54309, saving model to best_m.h5\n",
      "Epoch 3/3\n",
      " - 3s - loss: 0.4904 - acc: 0.7589 - val_loss: 0.4749 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54309 to 0.47485, saving model to best_m.h5\n",
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/3\n",
      " - 3s - loss: 0.6727 - acc: 0.5856 - val_loss: 0.5940 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59396, saving model to best_m.h5\n",
      "Epoch 2/3\n",
      " - 3s - loss: 0.5989 - acc: 0.6706 - val_loss: 0.5529 - val_acc: 0.7581\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59396 to 0.55291, saving model to best_m.h5\n",
      "Epoch 3/3\n",
      " - 3s - loss: 0.5523 - acc: 0.7057 - val_loss: 0.4836 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55291 to 0.48359, saving model to best_m.h5\n",
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/3\n",
      " - 4s - loss: 0.6700 - acc: 0.5983 - val_loss: 0.6248 - val_acc: 0.6633\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62481, saving model to best_m.h5\n",
      "Epoch 2/3\n",
      " - 3s - loss: 0.5833 - acc: 0.6845 - val_loss: 0.6119 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62481 to 0.61193, saving model to best_m.h5\n",
      "Epoch 3/3\n",
      " - 3s - loss: 0.5662 - acc: 0.6966 - val_loss: 0.5611 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61193 to 0.56107, saving model to best_m.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        curr_x,curr_y = rot_aut(curr_x,curr_y)\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        model.fit(curr_x,curr_y,\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  batch_size=64, epochs=3, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk]\n",
    "                 )\n",
    "        model = load_model(model_p)\n",
    "        \n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4,rnd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

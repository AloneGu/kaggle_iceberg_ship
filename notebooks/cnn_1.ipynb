{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rot_aut(Xtr,ytr):\n",
    "    # aug on train\n",
    "    data_cnt = len(ytr)\n",
    "    print(data_cnt)\n",
    "    aug_X = []\n",
    "    aug_y = []\n",
    "\n",
    "    for i in range(data_cnt):\n",
    "        img = Xtr[i]\n",
    "        tmp_y = ytr[i]\n",
    "\n",
    "        # org img\n",
    "        aug_X.append(img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        # flip\n",
    "        tmp_img = np.fliplr(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        tmp_img = np.flipud(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "\n",
    "        tmp_img = np.rot90(img)\n",
    "        aug_X.append(tmp_img)\n",
    "        aug_y.append(tmp_y)\n",
    "    return np.array(aug_X),np.array(aug_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same',input_shape=(75,75,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(16, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_loss improved from inf to 0.60579, saving model to best_m.h5\n",
      " - 5s - loss: 0.6512 - acc: 0.6286 - val_loss: 0.6058 - val_acc: 0.6459\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_loss improved from 0.60579 to 0.59071, saving model to best_m.h5\n",
      " - 4s - loss: 0.5600 - acc: 0.7190 - val_loss: 0.5907 - val_acc: 0.6608\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_loss improved from 0.59071 to 0.50069, saving model to best_m.h5\n",
      " - 4s - loss: 0.5299 - acc: 0.7271 - val_loss: 0.5007 - val_acc: 0.7357\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_loss improved from 0.50069 to 0.41185, saving model to best_m.h5\n",
      " - 4s - loss: 0.4474 - acc: 0.7812 - val_loss: 0.4119 - val_acc: 0.7905\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_loss improved from 0.41185 to 0.38154, saving model to best_m.h5\n",
      " - 4s - loss: 0.3986 - acc: 0.8015 - val_loss: 0.3815 - val_acc: 0.8429\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_loss improved from 0.38154 to 0.34553, saving model to best_m.h5\n",
      " - 4s - loss: 0.3659 - acc: 0.8261 - val_loss: 0.3455 - val_acc: 0.8329\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3472 - acc: 0.8337 - val_loss: 0.3795 - val_acc: 0.8204\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_loss improved from 0.34553 to 0.33714, saving model to best_m.h5\n",
      " - 4s - loss: 0.3245 - acc: 0.8504 - val_loss: 0.3371 - val_acc: 0.8155\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_loss improved from 0.33714 to 0.32464, saving model to best_m.h5\n",
      " - 4s - loss: 0.3156 - acc: 0.8560 - val_loss: 0.3246 - val_acc: 0.8603\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_loss improved from 0.32464 to 0.31698, saving model to best_m.h5\n",
      " - 4s - loss: 0.3253 - acc: 0.8514 - val_loss: 0.3170 - val_acc: 0.8728\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.2994 - acc: 0.8601 - val_loss: 0.3444 - val_acc: 0.8554\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_loss improved from 0.31698 to 0.31658, saving model to best_m.h5\n",
      " - 4s - loss: 0.2958 - acc: 0.8651 - val_loss: 0.3166 - val_acc: 0.8529\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.2703 - acc: 0.8770 - val_loss: 0.3639 - val_acc: 0.8404\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_loss improved from 0.31658 to 0.31184, saving model to best_m.h5\n",
      " - 4s - loss: 0.2725 - acc: 0.8788 - val_loss: 0.3118 - val_acc: 0.8554\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_loss improved from 0.31184 to 0.30674, saving model to best_m.h5\n",
      " - 4s - loss: 0.2595 - acc: 0.8797 - val_loss: 0.3067 - val_acc: 0.8653\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2554 - acc: 0.8832 - val_loss: 0.3116 - val_acc: 0.8703\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2506 - acc: 0.8855 - val_loss: 0.3442 - val_acc: 0.8579\n",
      "Epoch 18/30\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2520 - acc: 0.8838 - val_loss: 0.3150 - val_acc: 0.8579\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2374 - acc: 0.8948 - val_loss: 0.3241 - val_acc: 0.8628\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2196 - acc: 0.9065 - val_loss: 0.3338 - val_acc: 0.8579\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2063 - acc: 0.9106 - val_loss: 0.3189 - val_acc: 0.8603\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2193 - acc: 0.9048 - val_loss: 0.3458 - val_acc: 0.8753\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.1918 - acc: 0.9160 - val_loss: 0.3683 - val_acc: 0.8554\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.1917 - acc: 0.9181 - val_loss: 0.3529 - val_acc: 0.8603\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.1776 - acc: 0.9217 - val_loss: 0.3282 - val_acc: 0.8653\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.1755 - acc: 0.9300 - val_loss: 0.3340 - val_acc: 0.8628\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.1682 - acc: 0.9277 - val_loss: 0.3772 - val_acc: 0.8579\n",
      "Epoch 28/30\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.1581 - acc: 0.9320 - val_loss: 0.3589 - val_acc: 0.8728\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.1585 - acc: 0.9370 - val_loss: 0.4384 - val_acc: 0.8504\n",
      "Epoch 30/30\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.1650 - acc: 0.9312 - val_loss: 0.3772 - val_acc: 0.8653\n",
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_loss improved from inf to 0.62832, saving model to best_m.h5\n",
      " - 4s - loss: 0.6718 - acc: 0.5879 - val_loss: 0.6283 - val_acc: 0.7257\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_loss improved from 0.62832 to 0.55325, saving model to best_m.h5\n",
      " - 4s - loss: 0.5987 - acc: 0.6656 - val_loss: 0.5533 - val_acc: 0.7307\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_loss improved from 0.55325 to 0.46048, saving model to best_m.h5\n",
      " - 4s - loss: 0.5481 - acc: 0.7020 - val_loss: 0.4605 - val_acc: 0.7756\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_loss improved from 0.46048 to 0.37618, saving model to best_m.h5\n",
      " - 4s - loss: 0.4589 - acc: 0.7760 - val_loss: 0.3762 - val_acc: 0.8379\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_loss improved from 0.37618 to 0.33790, saving model to best_m.h5\n",
      " - 4s - loss: 0.4111 - acc: 0.8015 - val_loss: 0.3379 - val_acc: 0.8529\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3956 - acc: 0.8047 - val_loss: 0.3770 - val_acc: 0.8404\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_loss improved from 0.33790 to 0.30894, saving model to best_m.h5\n",
      " - 4s - loss: 0.3695 - acc: 0.8298 - val_loss: 0.3089 - val_acc: 0.8678\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3393 - acc: 0.8414 - val_loss: 0.3314 - val_acc: 0.8554\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_loss improved from 0.30894 to 0.30438, saving model to best_m.h5\n",
      " - 4s - loss: 0.3314 - acc: 0.8435 - val_loss: 0.3044 - val_acc: 0.8653\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_loss improved from 0.30438 to 0.28167, saving model to best_m.h5\n",
      " - 4s - loss: 0.3284 - acc: 0.8431 - val_loss: 0.2817 - val_acc: 0.8878\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3142 - acc: 0.8549 - val_loss: 0.3020 - val_acc: 0.8778\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_loss improved from 0.28167 to 0.27359, saving model to best_m.h5\n",
      " - 4s - loss: 0.2946 - acc: 0.8626 - val_loss: 0.2736 - val_acc: 0.8928\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.2969 - acc: 0.8620 - val_loss: 0.3195 - val_acc: 0.8678\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.2903 - acc: 0.8672 - val_loss: 0.2984 - val_acc: 0.8778\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.2743 - acc: 0.8707 - val_loss: 0.2750 - val_acc: 0.8828\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_loss improved from 0.27359 to 0.27279, saving model to best_m.h5\n",
      " - 4s - loss: 0.2699 - acc: 0.8780 - val_loss: 0.2728 - val_acc: 0.8628\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2661 - acc: 0.8788 - val_loss: 0.2908 - val_acc: 0.8828\n",
      "Epoch 18/30\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2578 - acc: 0.8849 - val_loss: 0.2746 - val_acc: 0.8903\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2557 - acc: 0.8805 - val_loss: 0.2735 - val_acc: 0.8878\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2391 - acc: 0.8899 - val_loss: 0.3190 - val_acc: 0.8678\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_loss improved from 0.27279 to 0.26788, saving model to best_m.h5\n",
      " - 4s - loss: 0.2394 - acc: 0.8872 - val_loss: 0.2679 - val_acc: 0.8778\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2315 - acc: 0.8986 - val_loss: 0.3092 - val_acc: 0.8579\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2119 - acc: 0.9034 - val_loss: 0.2954 - val_acc: 0.8803\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2226 - acc: 0.8946 - val_loss: 0.2774 - val_acc: 0.8853\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2032 - acc: 0.9102 - val_loss: 0.3305 - val_acc: 0.8803\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.1986 - acc: 0.9138 - val_loss: 0.3104 - val_acc: 0.8928\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2040 - acc: 0.9088 - val_loss: 0.2782 - val_acc: 0.8953\n",
      "Epoch 28/30\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.1811 - acc: 0.9208 - val_loss: 0.2830 - val_acc: 0.8828\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.1788 - acc: 0.9258 - val_loss: 0.2949 - val_acc: 0.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.1679 - acc: 0.9291 - val_loss: 0.2982 - val_acc: 0.8778\n",
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_loss improved from inf to 0.65402, saving model to best_m.h5\n",
      " - 4s - loss: 0.6769 - acc: 0.5875 - val_loss: 0.6540 - val_acc: 0.6633\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_loss improved from 0.65402 to 0.58081, saving model to best_m.h5\n",
      " - 4s - loss: 0.5887 - acc: 0.6833 - val_loss: 0.5808 - val_acc: 0.6783\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_loss improved from 0.58081 to 0.54441, saving model to best_m.h5\n",
      " - 4s - loss: 0.5562 - acc: 0.7026 - val_loss: 0.5444 - val_acc: 0.6933\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_loss improved from 0.54441 to 0.51716, saving model to best_m.h5\n",
      " - 4s - loss: 0.5084 - acc: 0.7286 - val_loss: 0.5172 - val_acc: 0.7182\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_loss improved from 0.51716 to 0.43185, saving model to best_m.h5\n",
      " - 4s - loss: 0.4603 - acc: 0.7587 - val_loss: 0.4318 - val_acc: 0.7556\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_loss improved from 0.43185 to 0.41177, saving model to best_m.h5\n",
      " - 4s - loss: 0.4219 - acc: 0.7916 - val_loss: 0.4118 - val_acc: 0.7731\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_loss improved from 0.41177 to 0.41162, saving model to best_m.h5\n",
      " - 4s - loss: 0.3868 - acc: 0.8115 - val_loss: 0.4116 - val_acc: 0.7581\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_loss improved from 0.41162 to 0.37839, saving model to best_m.h5\n",
      " - 4s - loss: 0.3688 - acc: 0.8300 - val_loss: 0.3784 - val_acc: 0.8030\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_loss improved from 0.37839 to 0.34525, saving model to best_m.h5\n",
      " - 4s - loss: 0.3398 - acc: 0.8419 - val_loss: 0.3453 - val_acc: 0.8579\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_loss improved from 0.34525 to 0.33406, saving model to best_m.h5\n",
      " - 4s - loss: 0.3215 - acc: 0.8452 - val_loss: 0.3341 - val_acc: 0.8653\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3092 - acc: 0.8522 - val_loss: 0.3623 - val_acc: 0.8055\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.2911 - acc: 0.8685 - val_loss: 0.3559 - val_acc: 0.8155\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.2959 - acc: 0.8682 - val_loss: 0.3490 - val_acc: 0.8479\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_loss improved from 0.33406 to 0.31671, saving model to best_m.h5\n",
      " - 4s - loss: 0.2659 - acc: 0.8795 - val_loss: 0.3167 - val_acc: 0.8603\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.2658 - acc: 0.8788 - val_loss: 0.3233 - val_acc: 0.8554\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2538 - acc: 0.8880 - val_loss: 0.3229 - val_acc: 0.8653\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2582 - acc: 0.8865 - val_loss: 0.3538 - val_acc: 0.8728\n",
      "Epoch 18/30\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2364 - acc: 0.8897 - val_loss: 0.3199 - val_acc: 0.8728\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2389 - acc: 0.8886 - val_loss: 0.3257 - val_acc: 0.8579\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2336 - acc: 0.8942 - val_loss: 0.3467 - val_acc: 0.8703\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2087 - acc: 0.9086 - val_loss: 0.3588 - val_acc: 0.8703\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2037 - acc: 0.9067 - val_loss: 0.3257 - val_acc: 0.8628\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.1994 - acc: 0.9148 - val_loss: 0.3277 - val_acc: 0.8628\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2159 - acc: 0.9069 - val_loss: 0.3310 - val_acc: 0.8653\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.1962 - acc: 0.9152 - val_loss: 0.3270 - val_acc: 0.8678\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.1876 - acc: 0.9181 - val_loss: 0.3331 - val_acc: 0.8728\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.1717 - acc: 0.9271 - val_loss: 0.3318 - val_acc: 0.8753\n",
      "Epoch 28/30\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.1645 - acc: 0.9289 - val_loss: 0.3468 - val_acc: 0.8778\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.1604 - acc: 0.9318 - val_loss: 0.3866 - val_acc: 0.8603\n",
      "Epoch 30/30\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.1513 - acc: 0.9379 - val_loss: 0.3669 - val_acc: 0.8653\n",
      "1203\n",
      "Train on 4812 samples, validate on 401 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_loss improved from inf to 0.59697, saving model to best_m.h5\n",
      " - 4s - loss: 0.6621 - acc: 0.6133 - val_loss: 0.5970 - val_acc: 0.6858\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_loss improved from 0.59697 to 0.56010, saving model to best_m.h5\n",
      " - 4s - loss: 0.5832 - acc: 0.6843 - val_loss: 0.5601 - val_acc: 0.7307\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_loss improved from 0.56010 to 0.49023, saving model to best_m.h5\n",
      " - 4s - loss: 0.5313 - acc: 0.7190 - val_loss: 0.4902 - val_acc: 0.7681\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 4s - loss: 0.4666 - acc: 0.7602 - val_loss: 0.5412 - val_acc: 0.7007\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_loss improved from 0.49023 to 0.46805, saving model to best_m.h5\n",
      " - 4s - loss: 0.4415 - acc: 0.7801 - val_loss: 0.4681 - val_acc: 0.7830\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_loss improved from 0.46805 to 0.40710, saving model to best_m.h5\n",
      " - 4s - loss: 0.4062 - acc: 0.8030 - val_loss: 0.4071 - val_acc: 0.8279\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_loss improved from 0.40710 to 0.37849, saving model to best_m.h5\n",
      " - 4s - loss: 0.3832 - acc: 0.8225 - val_loss: 0.3785 - val_acc: 0.8579\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_loss improved from 0.37849 to 0.35853, saving model to best_m.h5\n",
      " - 4s - loss: 0.3544 - acc: 0.8294 - val_loss: 0.3585 - val_acc: 0.8603\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3560 - acc: 0.8356 - val_loss: 0.3591 - val_acc: 0.8454\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_loss improved from 0.35853 to 0.34583, saving model to best_m.h5\n",
      " - 4s - loss: 0.3258 - acc: 0.8514 - val_loss: 0.3458 - val_acc: 0.8529\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_loss improved from 0.34583 to 0.31853, saving model to best_m.h5\n",
      " - 4s - loss: 0.3109 - acc: 0.8585 - val_loss: 0.3185 - val_acc: 0.8653\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.2985 - acc: 0.8585 - val_loss: 0.3370 - val_acc: 0.8504\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_loss improved from 0.31853 to 0.31201, saving model to best_m.h5\n",
      " - 4s - loss: 0.2920 - acc: 0.8649 - val_loss: 0.3120 - val_acc: 0.8628\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_loss improved from 0.31201 to 0.30342, saving model to best_m.h5\n",
      " - 4s - loss: 0.2727 - acc: 0.8776 - val_loss: 0.3034 - val_acc: 0.8579\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_loss improved from 0.30342 to 0.28597, saving model to best_m.h5\n",
      " - 4s - loss: 0.2697 - acc: 0.8734 - val_loss: 0.2860 - val_acc: 0.8903\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2740 - acc: 0.8766 - val_loss: 0.2892 - val_acc: 0.8603\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2549 - acc: 0.8780 - val_loss: 0.3898 - val_acc: 0.8354\n",
      "Epoch 18/30\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2486 - acc: 0.8880 - val_loss: 0.3178 - val_acc: 0.8678\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_loss improved from 0.28597 to 0.27813, saving model to best_m.h5\n",
      " - 4s - loss: 0.2454 - acc: 0.8924 - val_loss: 0.2781 - val_acc: 0.8778\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2274 - acc: 0.8988 - val_loss: 0.2818 - val_acc: 0.8678\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2289 - acc: 0.8955 - val_loss: 0.3466 - val_acc: 0.8404\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2315 - acc: 0.8961 - val_loss: 0.2930 - val_acc: 0.8603\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_loss improved from 0.27813 to 0.26482, saving model to best_m.h5\n",
      " - 4s - loss: 0.2246 - acc: 0.8982 - val_loss: 0.2648 - val_acc: 0.8753\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2169 - acc: 0.9042 - val_loss: 0.2726 - val_acc: 0.8803\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.1926 - acc: 0.9167 - val_loss: 0.3413 - val_acc: 0.8628\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2064 - acc: 0.9048 - val_loss: 0.2758 - val_acc: 0.8728\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.1847 - acc: 0.9165 - val_loss: 0.2767 - val_acc: 0.8653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "Epoch 00028: val_loss improved from 0.26482 to 0.24809, saving model to best_m.h5\n",
      " - 4s - loss: 0.1841 - acc: 0.9221 - val_loss: 0.2481 - val_acc: 0.8828\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.1834 - acc: 0.9194 - val_loss: 0.2540 - val_acc: 0.8878\n",
      "Epoch 30/30\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.1673 - acc: 0.9298 - val_loss: 0.2695 - val_acc: 0.8828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        curr_x,curr_y = rot_aut(curr_x,curr_y)\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        model.fit(curr_x,curr_y,\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  batch_size=64, epochs=30, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk]\n",
    "                 )\n",
    "        model = load_model(model_p)\n",
    "        \n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4,rnd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.284853572701\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.414002\n",
      "1  4023181e    0.593756\n",
      "2  b20200e4    0.199288\n",
      "3  e7f018bb    0.985243\n",
      "4  4371c8c3    0.602222\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_1_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_1_sub.csv', index=False)\n",
    "# batch 64 0.274\n",
    "# batch 16 0.268\n",
    "\n",
    "# check     xgb\n",
    "# fold 4 , pre 1519\n",
    "# fold3 16 batch, 1531   0.296\n",
    "# fold3 64 batch, 1529 , 0.284\n",
    "# fold4 64 batch, 1549 , 0.261\n",
    "# fold4 16 batch, 1551 , 0.276\n",
    "# fold3 32 batch, 1547 , 0.267\n",
    "# fold4 64 batch, 1537 , 0.284,   rnd=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

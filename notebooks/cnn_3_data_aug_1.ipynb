{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        img = np.dstack((band_1, band_2, band_3))\n",
    "        images.append(std_img(img))\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model=Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70321, saving model to best_m.h5\n",
      " - 3s - loss: 0.6820 - acc: 0.5536 - val_loss: 0.7032 - val_acc: 0.4913\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.70321 to 0.43996, saving model to best_m.h5\n",
      " - 2s - loss: 0.6015 - acc: 0.6474 - val_loss: 0.4400 - val_acc: 0.8155\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.43996 to 0.42348, saving model to best_m.h5\n",
      " - 2s - loss: 0.5070 - acc: 0.7491 - val_loss: 0.4235 - val_acc: 0.8254\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.42348 to 0.37630, saving model to best_m.h5\n",
      " - 2s - loss: 0.4860 - acc: 0.7572 - val_loss: 0.3763 - val_acc: 0.8454\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.37630 to 0.32262, saving model to best_m.h5\n",
      " - 2s - loss: 0.5057 - acc: 0.7641 - val_loss: 0.3226 - val_acc: 0.8579\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4354 - acc: 0.8025 - val_loss: 0.3524 - val_acc: 0.8579\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4805 - acc: 0.7658 - val_loss: 0.3456 - val_acc: 0.8678\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.4202 - acc: 0.8142 - val_loss: 0.3423 - val_acc: 0.8379\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.4098 - acc: 0.8039 - val_loss: 0.3495 - val_acc: 0.8628\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3839 - acc: 0.8283 - val_loss: 0.3381 - val_acc: 0.8603\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.32262 to 0.23600, saving model to best_m.h5\n",
      " - 2s - loss: 0.3474 - acc: 0.8367 - val_loss: 0.2360 - val_acc: 0.8953\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3314 - acc: 0.8608 - val_loss: 0.2693 - val_acc: 0.8728\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.3735 - acc: 0.8372 - val_loss: 0.2685 - val_acc: 0.8728\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.23600 to 0.21219, saving model to best_m.h5\n",
      " - 2s - loss: 0.3338 - acc: 0.8406 - val_loss: 0.2122 - val_acc: 0.9077\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.3137 - acc: 0.8531 - val_loss: 0.2207 - val_acc: 0.9052\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.21219 to 0.20654, saving model to best_m.h5\n",
      " - 2s - loss: 0.3169 - acc: 0.8575 - val_loss: 0.2065 - val_acc: 0.9052\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.3246 - acc: 0.8589 - val_loss: 0.2356 - val_acc: 0.9002\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.3458 - acc: 0.8450 - val_loss: 0.2290 - val_acc: 0.9027\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2876 - acc: 0.8808 - val_loss: 0.2268 - val_acc: 0.8928\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3375 - acc: 0.8550 - val_loss: 0.2154 - val_acc: 0.9077\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.3057 - acc: 0.8617 - val_loss: 0.2367 - val_acc: 0.8953\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.3329 - acc: 0.8453 - val_loss: 0.2144 - val_acc: 0.9077\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.3238 - acc: 0.8608 - val_loss: 0.2422 - val_acc: 0.9127\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.3172 - acc: 0.8666 - val_loss: 0.2422 - val_acc: 0.9027\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2778 - acc: 0.8733 - val_loss: 0.2207 - val_acc: 0.9052\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss improved from 0.20654 to 0.20332, saving model to best_m.h5\n",
      " - 2s - loss: 0.2867 - acc: 0.8725 - val_loss: 0.2033 - val_acc: 0.9152\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2962 - acc: 0.8725 - val_loss: 0.2076 - val_acc: 0.9152\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.3227 - acc: 0.8673 - val_loss: 0.2469 - val_acc: 0.9077\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2990 - acc: 0.8667 - val_loss: 0.2210 - val_acc: 0.9052\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2800 - acc: 0.8858 - val_loss: 0.2184 - val_acc: 0.9127\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.20332 to 0.19318, saving model to best_m.h5\n",
      " - 2s - loss: 0.2772 - acc: 0.8767 - val_loss: 0.1932 - val_acc: 0.9302\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss improved from 0.19318 to 0.19226, saving model to best_m.h5\n",
      " - 2s - loss: 0.2669 - acc: 0.8800 - val_loss: 0.1923 - val_acc: 0.9302\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.3048 - acc: 0.8776 - val_loss: 0.2030 - val_acc: 0.9302\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.19226 to 0.19092, saving model to best_m.h5\n",
      " - 2s - loss: 0.2468 - acc: 0.8958 - val_loss: 0.1909 - val_acc: 0.9302\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2493 - acc: 0.8981 - val_loss: 0.1926 - val_acc: 0.9202\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2614 - acc: 0.8808 - val_loss: 0.1998 - val_acc: 0.9202\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss improved from 0.19092 to 0.18898, saving model to best_m.h5\n",
      " - 2s - loss: 0.2535 - acc: 0.8914 - val_loss: 0.1890 - val_acc: 0.9327\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss improved from 0.18898 to 0.18829, saving model to best_m.h5\n",
      " - 2s - loss: 0.2385 - acc: 0.8941 - val_loss: 0.1883 - val_acc: 0.9277\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss improved from 0.18829 to 0.18644, saving model to best_m.h5\n",
      " - 2s - loss: 0.2549 - acc: 0.8933 - val_loss: 0.1864 - val_acc: 0.9352\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2476 - acc: 0.8883 - val_loss: 0.1893 - val_acc: 0.9377\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss improved from 0.18644 to 0.18325, saving model to best_m.h5\n",
      " - 2s - loss: 0.2582 - acc: 0.8791 - val_loss: 0.1832 - val_acc: 0.9252\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss improved from 0.18325 to 0.18234, saving model to best_m.h5\n",
      " - 2s - loss: 0.2539 - acc: 0.8816 - val_loss: 0.1823 - val_acc: 0.9302\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2420 - acc: 0.8850 - val_loss: 0.1876 - val_acc: 0.9202\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2212 - acc: 0.9041 - val_loss: 0.1927 - val_acc: 0.9152\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2666 - acc: 0.8925 - val_loss: 0.1975 - val_acc: 0.9227\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2474 - acc: 0.8975 - val_loss: 0.1977 - val_acc: 0.9177\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2592 - acc: 0.8908 - val_loss: 0.1971 - val_acc: 0.9352\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2390 - acc: 0.8923 - val_loss: 0.1977 - val_acc: 0.9227\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2617 - acc: 0.8766 - val_loss: 0.1906 - val_acc: 0.9277\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2479 - acc: 0.8908 - val_loss: 0.1957 - val_acc: 0.9277\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2621 - acc: 0.8892 - val_loss: 0.1947 - val_acc: 0.9202\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2734 - acc: 0.8804 - val_loss: 0.1846 - val_acc: 0.9327\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2511 - acc: 0.9006 - val_loss: 0.1934 - val_acc: 0.9277\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2579 - acc: 0.8964 - val_loss: 0.1981 - val_acc: 0.9202\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.18234 to 0.18098, saving model to best_m.h5\n",
      " - 2s - loss: 0.2332 - acc: 0.8933 - val_loss: 0.1810 - val_acc: 0.9302\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2520 - acc: 0.8875 - val_loss: 0.1906 - val_acc: 0.9202\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.2363 - acc: 0.8950 - val_loss: 0.2023 - val_acc: 0.9302\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2349 - acc: 0.8900 - val_loss: 0.1836 - val_acc: 0.9252\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2280 - acc: 0.9025 - val_loss: 0.1869 - val_acc: 0.9327\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2465 - acc: 0.8858 - val_loss: 0.1866 - val_acc: 0.9352\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2327 - acc: 0.8925 - val_loss: 0.2007 - val_acc: 0.9177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2633 - acc: 0.8914 - val_loss: 0.1922 - val_acc: 0.9352\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.2384 - acc: 0.9033 - val_loss: 0.1972 - val_acc: 0.9152\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2590 - acc: 0.8942 - val_loss: 0.1958 - val_acc: 0.9227\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.2473 - acc: 0.8964 - val_loss: 0.1859 - val_acc: 0.9202\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.2313 - acc: 0.8906 - val_loss: 0.1844 - val_acc: 0.9177\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2505 - acc: 0.8914 - val_loss: 0.1868 - val_acc: 0.9177\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.2544 - acc: 0.8873 - val_loss: 0.1931 - val_acc: 0.9177\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2369 - acc: 0.8983 - val_loss: 0.1869 - val_acc: 0.9252\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss improved from 0.18098 to 0.18063, saving model to best_m.h5\n",
      " - 2s - loss: 0.2301 - acc: 0.9000 - val_loss: 0.1806 - val_acc: 0.9252\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss improved from 0.18063 to 0.17786, saving model to best_m.h5\n",
      " - 2s - loss: 0.2356 - acc: 0.9106 - val_loss: 0.1779 - val_acc: 0.9277\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.2361 - acc: 0.8981 - val_loss: 0.1878 - val_acc: 0.9227\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.2277 - acc: 0.9000 - val_loss: 0.1799 - val_acc: 0.9302\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.2376 - acc: 0.9025 - val_loss: 0.1820 - val_acc: 0.9277\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss improved from 0.17786 to 0.17597, saving model to best_m.h5\n",
      " - 2s - loss: 0.2333 - acc: 0.8983 - val_loss: 0.1760 - val_acc: 0.9252\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.2283 - acc: 0.9014 - val_loss: 0.1919 - val_acc: 0.9177\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss improved from 0.17597 to 0.17017, saving model to best_m.h5\n",
      " - 2s - loss: 0.2117 - acc: 0.9158 - val_loss: 0.1702 - val_acc: 0.9302\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.2167 - acc: 0.9092 - val_loss: 0.1755 - val_acc: 0.9302\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.2282 - acc: 0.8975 - val_loss: 0.1895 - val_acc: 0.9152\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.2331 - acc: 0.9000 - val_loss: 0.1897 - val_acc: 0.9302\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.2402 - acc: 0.8992 - val_loss: 0.1866 - val_acc: 0.9277\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.2530 - acc: 0.8975 - val_loss: 0.1803 - val_acc: 0.9327\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.2400 - acc: 0.9033 - val_loss: 0.1899 - val_acc: 0.9227\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.2403 - acc: 0.8917 - val_loss: 0.1785 - val_acc: 0.9426\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.2394 - acc: 0.9000 - val_loss: 0.1855 - val_acc: 0.9277\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.2029 - acc: 0.9150 - val_loss: 0.1719 - val_acc: 0.9302\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.2536 - acc: 0.8889 - val_loss: 0.1871 - val_acc: 0.9252\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.1983 - acc: 0.9150 - val_loss: 0.1759 - val_acc: 0.9277\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.2492 - acc: 0.8950 - val_loss: 0.1832 - val_acc: 0.9227\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.2115 - acc: 0.9158 - val_loss: 0.1893 - val_acc: 0.9152\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.2547 - acc: 0.8964 - val_loss: 0.1793 - val_acc: 0.9327\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.2489 - acc: 0.8917 - val_loss: 0.1782 - val_acc: 0.9352\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.2297 - acc: 0.9039 - val_loss: 0.2007 - val_acc: 0.9077\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.2239 - acc: 0.9042 - val_loss: 0.1806 - val_acc: 0.9252\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.2223 - acc: 0.9067 - val_loss: 0.1952 - val_acc: 0.9177\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.2115 - acc: 0.9106 - val_loss: 0.1750 - val_acc: 0.9302\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.2358 - acc: 0.9033 - val_loss: 0.1822 - val_acc: 0.9277\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.2249 - acc: 0.9025 - val_loss: 0.1868 - val_acc: 0.9202\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.2203 - acc: 0.9092 - val_loss: 0.1831 - val_acc: 0.9227\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.2234 - acc: 0.9058 - val_loss: 0.1956 - val_acc: 0.9177\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.61631, saving model to best_m.h5\n",
      " - 2s - loss: 0.6971 - acc: 0.5328 - val_loss: 0.6163 - val_acc: 0.6534\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.61631 to 0.50352, saving model to best_m.h5\n",
      " - 2s - loss: 0.6086 - acc: 0.6472 - val_loss: 0.5035 - val_acc: 0.7307\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.50352 to 0.47267, saving model to best_m.h5\n",
      " - 2s - loss: 0.5040 - acc: 0.7672 - val_loss: 0.4727 - val_acc: 0.7656\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.47267 to 0.45628, saving model to best_m.h5\n",
      " - 2s - loss: 0.4555 - acc: 0.7958 - val_loss: 0.4563 - val_acc: 0.7805\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.45628 to 0.41293, saving model to best_m.h5\n",
      " - 2s - loss: 0.4316 - acc: 0.8028 - val_loss: 0.4129 - val_acc: 0.8155\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.41293 to 0.38959, saving model to best_m.h5\n",
      " - 2s - loss: 0.4321 - acc: 0.8022 - val_loss: 0.3896 - val_acc: 0.8055\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4483 - acc: 0.7883 - val_loss: 0.4201 - val_acc: 0.8005\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.38959 to 0.32892, saving model to best_m.h5\n",
      " - 2s - loss: 0.3640 - acc: 0.8375 - val_loss: 0.3289 - val_acc: 0.8329\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3703 - acc: 0.8450 - val_loss: 0.4091 - val_acc: 0.7905\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.32892 to 0.30762, saving model to best_m.h5\n",
      " - 2s - loss: 0.3416 - acc: 0.8466 - val_loss: 0.3076 - val_acc: 0.8404\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.3032 - acc: 0.8575 - val_loss: 0.3087 - val_acc: 0.8678\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3241 - acc: 0.8616 - val_loss: 0.3198 - val_acc: 0.8678\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss improved from 0.30762 to 0.29874, saving model to best_m.h5\n",
      " - 2s - loss: 0.2851 - acc: 0.8725 - val_loss: 0.2987 - val_acc: 0.8803\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.29874 to 0.29209, saving model to best_m.h5\n",
      " - 2s - loss: 0.2838 - acc: 0.8783 - val_loss: 0.2921 - val_acc: 0.8678\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2993 - acc: 0.8716 - val_loss: 0.3025 - val_acc: 0.8628\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.2950 - acc: 0.8681 - val_loss: 0.3778 - val_acc: 0.8304\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.29209 to 0.28188, saving model to best_m.h5\n",
      " - 2s - loss: 0.3018 - acc: 0.8733 - val_loss: 0.2819 - val_acc: 0.8903\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.28188 to 0.27972, saving model to best_m.h5\n",
      " - 2s - loss: 0.3073 - acc: 0.8750 - val_loss: 0.2797 - val_acc: 0.8878\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2876 - acc: 0.8733 - val_loss: 0.2815 - val_acc: 0.8753\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss improved from 0.27972 to 0.27375, saving model to best_m.h5\n",
      " - 2s - loss: 0.3061 - acc: 0.8698 - val_loss: 0.2737 - val_acc: 0.8728\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.3029 - acc: 0.8598 - val_loss: 0.2982 - val_acc: 0.8728\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2791 - acc: 0.8917 - val_loss: 0.2815 - val_acc: 0.8803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "Epoch 00023: val_loss improved from 0.27375 to 0.27151, saving model to best_m.h5\n",
      " - 2s - loss: 0.2706 - acc: 0.8766 - val_loss: 0.2715 - val_acc: 0.8678\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss improved from 0.27151 to 0.26454, saving model to best_m.h5\n",
      " - 2s - loss: 0.2894 - acc: 0.8908 - val_loss: 0.2645 - val_acc: 0.8828\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.3064 - acc: 0.8758 - val_loss: 0.2851 - val_acc: 0.8579\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2659 - acc: 0.8756 - val_loss: 0.2810 - val_acc: 0.8803\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss improved from 0.26454 to 0.25927, saving model to best_m.h5\n",
      " - 2s - loss: 0.2705 - acc: 0.8900 - val_loss: 0.2593 - val_acc: 0.8828\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2857 - acc: 0.8792 - val_loss: 0.2607 - val_acc: 0.8703\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2439 - acc: 0.8925 - val_loss: 0.2716 - val_acc: 0.8878\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2667 - acc: 0.8842 - val_loss: 0.2629 - val_acc: 0.8878\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.25927 to 0.25091, saving model to best_m.h5\n",
      " - 2s - loss: 0.2487 - acc: 0.8983 - val_loss: 0.2509 - val_acc: 0.8878\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2361 - acc: 0.9033 - val_loss: 0.2610 - val_acc: 0.8753\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2679 - acc: 0.8845 - val_loss: 0.2540 - val_acc: 0.8878\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2359 - acc: 0.9083 - val_loss: 0.2575 - val_acc: 0.8828\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss improved from 0.25091 to 0.24979, saving model to best_m.h5\n",
      " - 2s - loss: 0.2305 - acc: 0.9033 - val_loss: 0.2498 - val_acc: 0.8903\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2465 - acc: 0.8942 - val_loss: 0.2541 - val_acc: 0.8878\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss improved from 0.24979 to 0.24896, saving model to best_m.h5\n",
      " - 2s - loss: 0.2479 - acc: 0.8837 - val_loss: 0.2490 - val_acc: 0.8903\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2292 - acc: 0.8975 - val_loss: 0.2513 - val_acc: 0.8878\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2490 - acc: 0.8958 - val_loss: 0.2538 - val_acc: 0.8828\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2188 - acc: 0.9025 - val_loss: 0.2593 - val_acc: 0.8778\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss improved from 0.24896 to 0.24432, saving model to best_m.h5\n",
      " - 2s - loss: 0.2301 - acc: 0.8950 - val_loss: 0.2443 - val_acc: 0.8978\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2398 - acc: 0.8942 - val_loss: 0.2578 - val_acc: 0.8778\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2455 - acc: 0.9025 - val_loss: 0.2472 - val_acc: 0.8903\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss improved from 0.24432 to 0.24389, saving model to best_m.h5\n",
      " - 2s - loss: 0.2256 - acc: 0.8983 - val_loss: 0.2439 - val_acc: 0.8878\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss improved from 0.24389 to 0.24380, saving model to best_m.h5\n",
      " - 2s - loss: 0.2576 - acc: 0.8883 - val_loss: 0.2438 - val_acc: 0.8928\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2410 - acc: 0.8953 - val_loss: 0.2520 - val_acc: 0.8953\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2242 - acc: 0.9042 - val_loss: 0.2474 - val_acc: 0.8878\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2216 - acc: 0.9056 - val_loss: 0.2542 - val_acc: 0.8778\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2461 - acc: 0.8898 - val_loss: 0.2527 - val_acc: 0.8878\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2363 - acc: 0.9075 - val_loss: 0.2474 - val_acc: 0.8978\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2316 - acc: 0.9050 - val_loss: 0.2487 - val_acc: 0.8928\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2130 - acc: 0.9133 - val_loss: 0.2545 - val_acc: 0.8903\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2429 - acc: 0.8942 - val_loss: 0.2444 - val_acc: 0.8903\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2487 - acc: 0.8967 - val_loss: 0.2655 - val_acc: 0.8828\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.2392 - acc: 0.9031 - val_loss: 0.2517 - val_acc: 0.8903\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2175 - acc: 0.9033 - val_loss: 0.2470 - val_acc: 0.8928\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.1910 - acc: 0.9225 - val_loss: 0.2527 - val_acc: 0.8903\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2238 - acc: 0.9075 - val_loss: 0.2457 - val_acc: 0.8978\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss improved from 0.24380 to 0.23799, saving model to best_m.h5\n",
      " - 2s - loss: 0.2152 - acc: 0.9050 - val_loss: 0.2380 - val_acc: 0.8978\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2290 - acc: 0.9073 - val_loss: 0.2514 - val_acc: 0.8878\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2410 - acc: 0.9058 - val_loss: 0.2442 - val_acc: 0.8953\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2126 - acc: 0.9131 - val_loss: 0.2455 - val_acc: 0.8903\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.2232 - acc: 0.9108 - val_loss: 0.2408 - val_acc: 0.9002\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2166 - acc: 0.9050 - val_loss: 0.2597 - val_acc: 0.8803\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.2384 - acc: 0.9064 - val_loss: 0.2559 - val_acc: 0.8853\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.2248 - acc: 0.8989 - val_loss: 0.2462 - val_acc: 0.9027\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2350 - acc: 0.9008 - val_loss: 0.2449 - val_acc: 0.9002\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss improved from 0.23799 to 0.23656, saving model to best_m.h5\n",
      " - 2s - loss: 0.2065 - acc: 0.9183 - val_loss: 0.2366 - val_acc: 0.9002\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2332 - acc: 0.9039 - val_loss: 0.2378 - val_acc: 0.8953\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2370 - acc: 0.9058 - val_loss: 0.2416 - val_acc: 0.8953\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.2332 - acc: 0.8964 - val_loss: 0.2412 - val_acc: 0.8928\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.2215 - acc: 0.9083 - val_loss: 0.2686 - val_acc: 0.8628\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.2170 - acc: 0.9017 - val_loss: 0.2484 - val_acc: 0.8853\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.2335 - acc: 0.9025 - val_loss: 0.2408 - val_acc: 0.8878\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.2067 - acc: 0.9133 - val_loss: 0.2406 - val_acc: 0.8903\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss improved from 0.23656 to 0.23557, saving model to best_m.h5\n",
      " - 2s - loss: 0.2280 - acc: 0.8973 - val_loss: 0.2356 - val_acc: 0.8978\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.2066 - acc: 0.9117 - val_loss: 0.2387 - val_acc: 0.8928\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.2243 - acc: 0.8917 - val_loss: 0.2395 - val_acc: 0.8978\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.2036 - acc: 0.9192 - val_loss: 0.2454 - val_acc: 0.8928\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.2164 - acc: 0.9067 - val_loss: 0.2386 - val_acc: 0.8903\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.2300 - acc: 0.9058 - val_loss: 0.2475 - val_acc: 0.8978\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.2107 - acc: 0.9150 - val_loss: 0.2415 - val_acc: 0.8928\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.2192 - acc: 0.9142 - val_loss: 0.2392 - val_acc: 0.8978\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.2038 - acc: 0.9167 - val_loss: 0.2467 - val_acc: 0.8878\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss improved from 0.23557 to 0.23342, saving model to best_m.h5\n",
      " - 2s - loss: 0.2335 - acc: 0.9033 - val_loss: 0.2334 - val_acc: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1968 - acc: 0.9058 - val_loss: 0.2419 - val_acc: 0.8853\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.1980 - acc: 0.9067 - val_loss: 0.2764 - val_acc: 0.8628\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.2153 - acc: 0.9008 - val_loss: 0.2474 - val_acc: 0.8928\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.2223 - acc: 0.9058 - val_loss: 0.2362 - val_acc: 0.9002\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.2170 - acc: 0.9125 - val_loss: 0.2341 - val_acc: 0.8928\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.2121 - acc: 0.9108 - val_loss: 0.2369 - val_acc: 0.8953\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss improved from 0.23342 to 0.23240, saving model to best_m.h5\n",
      " - 2s - loss: 0.2155 - acc: 0.9042 - val_loss: 0.2324 - val_acc: 0.8953\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.2203 - acc: 0.9033 - val_loss: 0.2357 - val_acc: 0.8903\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss improved from 0.23240 to 0.23024, saving model to best_m.h5\n",
      " - 2s - loss: 0.2117 - acc: 0.9091 - val_loss: 0.2302 - val_acc: 0.9052\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.2208 - acc: 0.9042 - val_loss: 0.2383 - val_acc: 0.8953\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.2027 - acc: 0.9183 - val_loss: 0.2464 - val_acc: 0.9077\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.2254 - acc: 0.9004 - val_loss: 0.2535 - val_acc: 0.8778\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss improved from 0.23024 to 0.22803, saving model to best_m.h5\n",
      " - 2s - loss: 0.2102 - acc: 0.9050 - val_loss: 0.2280 - val_acc: 0.8903\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.2039 - acc: 0.9117 - val_loss: 0.2340 - val_acc: 0.8878\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.2099 - acc: 0.9125 - val_loss: 0.2296 - val_acc: 0.9102\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.60665, saving model to best_m.h5\n",
      " - 2s - loss: 0.6944 - acc: 0.5586 - val_loss: 0.6067 - val_acc: 0.6459\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.60665 to 0.54113, saving model to best_m.h5\n",
      " - 2s - loss: 0.6416 - acc: 0.6053 - val_loss: 0.5411 - val_acc: 0.7007\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.54113 to 0.45574, saving model to best_m.h5\n",
      " - 2s - loss: 0.5673 - acc: 0.6920 - val_loss: 0.4557 - val_acc: 0.7905\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.45574 to 0.40341, saving model to best_m.h5\n",
      " - 2s - loss: 0.4902 - acc: 0.7558 - val_loss: 0.4034 - val_acc: 0.8304\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.40341 to 0.36995, saving model to best_m.h5\n",
      " - 2s - loss: 0.4381 - acc: 0.7791 - val_loss: 0.3699 - val_acc: 0.8105\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4588 - acc: 0.7908 - val_loss: 0.4389 - val_acc: 0.7980\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4228 - acc: 0.8039 - val_loss: 0.3858 - val_acc: 0.8379\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.36995 to 0.34969, saving model to best_m.h5\n",
      " - 2s - loss: 0.3979 - acc: 0.8083 - val_loss: 0.3497 - val_acc: 0.8429\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.34969 to 0.31024, saving model to best_m.h5\n",
      " - 2s - loss: 0.3753 - acc: 0.8258 - val_loss: 0.3102 - val_acc: 0.8678\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.31024 to 0.29539, saving model to best_m.h5\n",
      " - 2s - loss: 0.3593 - acc: 0.8383 - val_loss: 0.2954 - val_acc: 0.8628\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.29539 to 0.26413, saving model to best_m.h5\n",
      " - 2s - loss: 0.3476 - acc: 0.8391 - val_loss: 0.2641 - val_acc: 0.8803\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3212 - acc: 0.8550 - val_loss: 0.3138 - val_acc: 0.8504\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.3353 - acc: 0.8450 - val_loss: 0.2678 - val_acc: 0.8928\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.3091 - acc: 0.8633 - val_loss: 0.3449 - val_acc: 0.8404\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2964 - acc: 0.8616 - val_loss: 0.3471 - val_acc: 0.8454\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.3386 - acc: 0.8450 - val_loss: 0.2835 - val_acc: 0.8628\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.3162 - acc: 0.8583 - val_loss: 0.2816 - val_acc: 0.8703\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.26413 to 0.25230, saving model to best_m.h5\n",
      " - 2s - loss: 0.3179 - acc: 0.8617 - val_loss: 0.2523 - val_acc: 0.8803\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2791 - acc: 0.8758 - val_loss: 0.2539 - val_acc: 0.8953\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3390 - acc: 0.8539 - val_loss: 0.3002 - val_acc: 0.8803\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.3184 - acc: 0.8558 - val_loss: 0.2557 - val_acc: 0.9052\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2671 - acc: 0.8766 - val_loss: 0.2600 - val_acc: 0.8878\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.3077 - acc: 0.8587 - val_loss: 0.2732 - val_acc: 0.9127\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss improved from 0.25230 to 0.24896, saving model to best_m.h5\n",
      " - 2s - loss: 0.3095 - acc: 0.8558 - val_loss: 0.2490 - val_acc: 0.9052\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss improved from 0.24896 to 0.24154, saving model to best_m.h5\n",
      " - 2s - loss: 0.2698 - acc: 0.8833 - val_loss: 0.2415 - val_acc: 0.9052\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2745 - acc: 0.8850 - val_loss: 0.2711 - val_acc: 0.8953\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.3240 - acc: 0.8558 - val_loss: 0.2692 - val_acc: 0.8878\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2947 - acc: 0.8593 - val_loss: 0.2995 - val_acc: 0.8753\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.3106 - acc: 0.8525 - val_loss: 0.2534 - val_acc: 0.9102\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2697 - acc: 0.8825 - val_loss: 0.2604 - val_acc: 0.8903\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.24154 to 0.23594, saving model to best_m.h5\n",
      " - 2s - loss: 0.2572 - acc: 0.8858 - val_loss: 0.2359 - val_acc: 0.8978\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss improved from 0.23594 to 0.23592, saving model to best_m.h5\n",
      " - 2s - loss: 0.2655 - acc: 0.8883 - val_loss: 0.2359 - val_acc: 0.8953\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss improved from 0.23592 to 0.22267, saving model to best_m.h5\n",
      " - 2s - loss: 0.2658 - acc: 0.8853 - val_loss: 0.2227 - val_acc: 0.9027\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2823 - acc: 0.8748 - val_loss: 0.2424 - val_acc: 0.8953\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2633 - acc: 0.8831 - val_loss: 0.2306 - val_acc: 0.9027\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss improved from 0.22267 to 0.21964, saving model to best_m.h5\n",
      " - 2s - loss: 0.2513 - acc: 0.8875 - val_loss: 0.2196 - val_acc: 0.9052\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2499 - acc: 0.8939 - val_loss: 0.2231 - val_acc: 0.9052\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2331 - acc: 0.9025 - val_loss: 0.2251 - val_acc: 0.8953\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2494 - acc: 0.8933 - val_loss: 0.2292 - val_acc: 0.8978\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss improved from 0.21964 to 0.21827, saving model to best_m.h5\n",
      " - 2s - loss: 0.2492 - acc: 0.8983 - val_loss: 0.2183 - val_acc: 0.9052\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2552 - acc: 0.8950 - val_loss: 0.2302 - val_acc: 0.8978\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2393 - acc: 0.8950 - val_loss: 0.2325 - val_acc: 0.8928\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2263 - acc: 0.9023 - val_loss: 0.2227 - val_acc: 0.8978\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2457 - acc: 0.8900 - val_loss: 0.2266 - val_acc: 0.8928\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2346 - acc: 0.8958 - val_loss: 0.2209 - val_acc: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2517 - acc: 0.8958 - val_loss: 0.2193 - val_acc: 0.9052\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.21827 to 0.21626, saving model to best_m.h5\n",
      " - 2s - loss: 0.2258 - acc: 0.9042 - val_loss: 0.2163 - val_acc: 0.9077\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2696 - acc: 0.8933 - val_loss: 0.2330 - val_acc: 0.8978\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2523 - acc: 0.8883 - val_loss: 0.2286 - val_acc: 0.8978\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2571 - acc: 0.8914 - val_loss: 0.2480 - val_acc: 0.8953\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2525 - acc: 0.8939 - val_loss: 0.2334 - val_acc: 0.8953\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2328 - acc: 0.8998 - val_loss: 0.2196 - val_acc: 0.9002\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2539 - acc: 0.8883 - val_loss: 0.2233 - val_acc: 0.9052\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 2s - loss: 0.2273 - acc: 0.8992 - val_loss: 0.2327 - val_acc: 0.8953\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 2s - loss: 0.2315 - acc: 0.9006 - val_loss: 0.2234 - val_acc: 0.8953\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2286 - acc: 0.8925 - val_loss: 0.2381 - val_acc: 0.8928\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.2377 - acc: 0.8897 - val_loss: 0.2365 - val_acc: 0.8928\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2559 - acc: 0.8875 - val_loss: 0.2321 - val_acc: 0.8978\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2402 - acc: 0.8950 - val_loss: 0.2324 - val_acc: 0.8978\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 2s - loss: 0.2333 - acc: 0.8975 - val_loss: 0.2200 - val_acc: 0.9102\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2486 - acc: 0.8950 - val_loss: 0.2239 - val_acc: 0.9027\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2362 - acc: 0.8958 - val_loss: 0.2349 - val_acc: 0.8928\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss improved from 0.21626 to 0.21444, saving model to best_m.h5\n",
      " - 2s - loss: 0.2159 - acc: 0.9092 - val_loss: 0.2144 - val_acc: 0.9027\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 2s - loss: 0.2498 - acc: 0.8839 - val_loss: 0.2151 - val_acc: 0.9102\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.2209 - acc: 0.9025 - val_loss: 0.2313 - val_acc: 0.8953\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 2s - loss: 0.2547 - acc: 0.8923 - val_loss: 0.2296 - val_acc: 0.8978\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2259 - acc: 0.9025 - val_loss: 0.2296 - val_acc: 0.9027\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.2331 - acc: 0.9006 - val_loss: 0.2396 - val_acc: 0.8953\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2544 - acc: 0.8942 - val_loss: 0.2300 - val_acc: 0.8978\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2435 - acc: 0.9000 - val_loss: 0.2442 - val_acc: 0.8978\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.2324 - acc: 0.8931 - val_loss: 0.2379 - val_acc: 0.9027\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.2248 - acc: 0.9014 - val_loss: 0.2174 - val_acc: 0.9077\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.2363 - acc: 0.9008 - val_loss: 0.2271 - val_acc: 0.9002\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.2377 - acc: 0.8942 - val_loss: 0.2290 - val_acc: 0.9002\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.2508 - acc: 0.8942 - val_loss: 0.2347 - val_acc: 0.9027\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.2285 - acc: 0.9033 - val_loss: 0.2295 - val_acc: 0.9002\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.2317 - acc: 0.8906 - val_loss: 0.2183 - val_acc: 0.9077\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.2346 - acc: 0.8950 - val_loss: 0.2284 - val_acc: 0.8978\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.2433 - acc: 0.8939 - val_loss: 0.2295 - val_acc: 0.9127\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.2337 - acc: 0.8973 - val_loss: 0.2186 - val_acc: 0.9127\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.2270 - acc: 0.9092 - val_loss: 0.2510 - val_acc: 0.8778\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.2539 - acc: 0.8908 - val_loss: 0.2616 - val_acc: 0.8753\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.2379 - acc: 0.9033 - val_loss: 0.2309 - val_acc: 0.9002\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.2452 - acc: 0.9017 - val_loss: 0.2227 - val_acc: 0.9127\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.2383 - acc: 0.8950 - val_loss: 0.2263 - val_acc: 0.9027\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.2278 - acc: 0.9092 - val_loss: 0.2243 - val_acc: 0.9027\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.2311 - acc: 0.9042 - val_loss: 0.2192 - val_acc: 0.9027\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss improved from 0.21444 to 0.20969, saving model to best_m.h5\n",
      " - 2s - loss: 0.2295 - acc: 0.8939 - val_loss: 0.2097 - val_acc: 0.9102\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.2221 - acc: 0.9050 - val_loss: 0.2338 - val_acc: 0.9027\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.2280 - acc: 0.9033 - val_loss: 0.2287 - val_acc: 0.9077\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.2370 - acc: 0.8989 - val_loss: 0.2148 - val_acc: 0.9152\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.2301 - acc: 0.9075 - val_loss: 0.2267 - val_acc: 0.8978\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.2343 - acc: 0.9000 - val_loss: 0.2194 - val_acc: 0.9127\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.2390 - acc: 0.8967 - val_loss: 0.2371 - val_acc: 0.9027\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.2308 - acc: 0.8928 - val_loss: 0.2183 - val_acc: 0.8978\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.2335 - acc: 0.8958 - val_loss: 0.2142 - val_acc: 0.8978\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.2243 - acc: 0.8925 - val_loss: 0.2375 - val_acc: 0.8978\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.2368 - acc: 0.8898 - val_loss: 0.2303 - val_acc: 0.8928\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.2192 - acc: 0.9078 - val_loss: 0.2302 - val_acc: 0.9077\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.2283 - acc: 0.9000 - val_loss: 0.2342 - val_acc: 0.9077\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.66891, saving model to best_m.h5\n",
      " - 2s - loss: 0.7122 - acc: 0.5139 - val_loss: 0.6689 - val_acc: 0.5636\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.66891 to 0.60228, saving model to best_m.h5\n",
      " - 2s - loss: 0.6477 - acc: 0.5933 - val_loss: 0.6023 - val_acc: 0.5312\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.60228 to 0.48040, saving model to best_m.h5\n",
      " - 2s - loss: 0.5668 - acc: 0.6747 - val_loss: 0.4804 - val_acc: 0.7880\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.48040 to 0.42399, saving model to best_m.h5\n",
      " - 2s - loss: 0.4884 - acc: 0.7716 - val_loss: 0.4240 - val_acc: 0.8130\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.42399 to 0.39706, saving model to best_m.h5\n",
      " - 2s - loss: 0.4867 - acc: 0.7716 - val_loss: 0.3971 - val_acc: 0.8105\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4491 - acc: 0.7775 - val_loss: 0.4951 - val_acc: 0.7357\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 2s - loss: 0.4195 - acc: 0.8047 - val_loss: 0.4596 - val_acc: 0.7581\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.39706 to 0.34305, saving model to best_m.h5\n",
      " - 2s - loss: 0.3582 - acc: 0.8281 - val_loss: 0.3431 - val_acc: 0.8628\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3857 - acc: 0.8233 - val_loss: 0.4170 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.34305 to 0.33122, saving model to best_m.h5\n",
      " - 2s - loss: 0.3472 - acc: 0.8275 - val_loss: 0.3312 - val_acc: 0.8429\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.33122 to 0.32128, saving model to best_m.h5\n",
      " - 2s - loss: 0.3202 - acc: 0.8516 - val_loss: 0.3213 - val_acc: 0.8753\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 2s - loss: 0.3020 - acc: 0.8650 - val_loss: 0.3393 - val_acc: 0.8828\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.2962 - acc: 0.8716 - val_loss: 0.3477 - val_acc: 0.8828\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.32128 to 0.31907, saving model to best_m.h5\n",
      " - 2s - loss: 0.3125 - acc: 0.8462 - val_loss: 0.3191 - val_acc: 0.8703\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss improved from 0.31907 to 0.31004, saving model to best_m.h5\n",
      " - 2s - loss: 0.2824 - acc: 0.8750 - val_loss: 0.3100 - val_acc: 0.8703\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.2907 - acc: 0.8791 - val_loss: 0.3411 - val_acc: 0.8978\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.31004 to 0.30196, saving model to best_m.h5\n",
      " - 2s - loss: 0.2942 - acc: 0.8716 - val_loss: 0.3020 - val_acc: 0.8579\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2673 - acc: 0.8817 - val_loss: 0.3120 - val_acc: 0.8529\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2820 - acc: 0.8689 - val_loss: 0.3055 - val_acc: 0.8953\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2959 - acc: 0.8772 - val_loss: 0.3245 - val_acc: 0.8728\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.2726 - acc: 0.8873 - val_loss: 0.3067 - val_acc: 0.8978\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2569 - acc: 0.8892 - val_loss: 0.3080 - val_acc: 0.8703\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss improved from 0.30196 to 0.26872, saving model to best_m.h5\n",
      " - 2s - loss: 0.2779 - acc: 0.8842 - val_loss: 0.2687 - val_acc: 0.9027\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2680 - acc: 0.8764 - val_loss: 0.3755 - val_acc: 0.8479\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2832 - acc: 0.8741 - val_loss: 0.3094 - val_acc: 0.8828\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2751 - acc: 0.8770 - val_loss: 0.3115 - val_acc: 0.8778\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2354 - acc: 0.8958 - val_loss: 0.3050 - val_acc: 0.8803\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss improved from 0.26872 to 0.26780, saving model to best_m.h5\n",
      " - 2s - loss: 0.2549 - acc: 0.8881 - val_loss: 0.2678 - val_acc: 0.9102\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss improved from 0.26780 to 0.26702, saving model to best_m.h5\n",
      " - 2s - loss: 0.2801 - acc: 0.8850 - val_loss: 0.2670 - val_acc: 0.9027\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2308 - acc: 0.9058 - val_loss: 0.2709 - val_acc: 0.9027\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.26702 to 0.25787, saving model to best_m.h5\n",
      " - 2s - loss: 0.2364 - acc: 0.9048 - val_loss: 0.2579 - val_acc: 0.9177\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2372 - acc: 0.8948 - val_loss: 0.2822 - val_acc: 0.8928\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2350 - acc: 0.8914 - val_loss: 0.2599 - val_acc: 0.9152\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.25787 to 0.25561, saving model to best_m.h5\n",
      " - 2s - loss: 0.2200 - acc: 0.9117 - val_loss: 0.2556 - val_acc: 0.9202\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2484 - acc: 0.8903 - val_loss: 0.2587 - val_acc: 0.9127\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2376 - acc: 0.8931 - val_loss: 0.2715 - val_acc: 0.9052\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2242 - acc: 0.9031 - val_loss: 0.2568 - val_acc: 0.9177\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2381 - acc: 0.9042 - val_loss: 0.2566 - val_acc: 0.9177\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2370 - acc: 0.9000 - val_loss: 0.2716 - val_acc: 0.9127\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2149 - acc: 0.9125 - val_loss: 0.2579 - val_acc: 0.9127\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2168 - acc: 0.9092 - val_loss: 0.2724 - val_acc: 0.9077\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2278 - acc: 0.9025 - val_loss: 0.2577 - val_acc: 0.9177\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2130 - acc: 0.9125 - val_loss: 0.2584 - val_acc: 0.9152\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2105 - acc: 0.9095 - val_loss: 0.2605 - val_acc: 0.9127\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2155 - acc: 0.9106 - val_loss: 0.2605 - val_acc: 0.9077\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2182 - acc: 0.9075 - val_loss: 0.2618 - val_acc: 0.9202\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2256 - acc: 0.9131 - val_loss: 0.2669 - val_acc: 0.9177\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2248 - acc: 0.9023 - val_loss: 0.2618 - val_acc: 0.9127\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2112 - acc: 0.9158 - val_loss: 0.2613 - val_acc: 0.9127\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss improved from 0.25561 to 0.25324, saving model to best_m.h5\n",
      " - 2s - loss: 0.2123 - acc: 0.9117 - val_loss: 0.2532 - val_acc: 0.9152\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 2s - loss: 0.2064 - acc: 0.9125 - val_loss: 0.2552 - val_acc: 0.9202\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 2s - loss: 0.2262 - acc: 0.9017 - val_loss: 0.2678 - val_acc: 0.9127\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 2s - loss: 0.2272 - acc: 0.8972 - val_loss: 0.2681 - val_acc: 0.9077\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss improved from 0.25324 to 0.24979, saving model to best_m.h5\n",
      " - 2s - loss: 0.2184 - acc: 0.9100 - val_loss: 0.2498 - val_acc: 0.9277\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.24979 to 0.24968, saving model to best_m.h5\n",
      " - 2s - loss: 0.2225 - acc: 0.9106 - val_loss: 0.2497 - val_acc: 0.9227\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 2s - loss: 0.2141 - acc: 0.9017 - val_loss: 0.2498 - val_acc: 0.9202\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 2s - loss: 0.1911 - acc: 0.9142 - val_loss: 0.2564 - val_acc: 0.9127\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 2s - loss: 0.2147 - acc: 0.9100 - val_loss: 0.2668 - val_acc: 0.9102\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 2s - loss: 0.2034 - acc: 0.9125 - val_loss: 0.2530 - val_acc: 0.9127\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss improved from 0.24968 to 0.24628, saving model to best_m.h5\n",
      " - 2s - loss: 0.2184 - acc: 0.9033 - val_loss: 0.2463 - val_acc: 0.9202\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 2s - loss: 0.2273 - acc: 0.9083 - val_loss: 0.2478 - val_acc: 0.9227\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 2s - loss: 0.2061 - acc: 0.9200 - val_loss: 0.2527 - val_acc: 0.9202\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 2s - loss: 0.2223 - acc: 0.9100 - val_loss: 0.2559 - val_acc: 0.9252\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss improved from 0.24628 to 0.24374, saving model to best_m.h5\n",
      " - 2s - loss: 0.2052 - acc: 0.9183 - val_loss: 0.2437 - val_acc: 0.9252\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 2s - loss: 0.2007 - acc: 0.9117 - val_loss: 0.2514 - val_acc: 0.9177\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss improved from 0.24374 to 0.23905, saving model to best_m.h5\n",
      " - 2s - loss: 0.2207 - acc: 0.9050 - val_loss: 0.2390 - val_acc: 0.9227\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 2s - loss: 0.2077 - acc: 0.9181 - val_loss: 0.2655 - val_acc: 0.9052\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 2s - loss: 0.1996 - acc: 0.9158 - val_loss: 0.2427 - val_acc: 0.9252\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 2s - loss: 0.2180 - acc: 0.9108 - val_loss: 0.2611 - val_acc: 0.9127\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 2s - loss: 0.2037 - acc: 0.9092 - val_loss: 0.2480 - val_acc: 0.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 2s - loss: 0.2170 - acc: 0.9075 - val_loss: 0.2477 - val_acc: 0.9227\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 2s - loss: 0.2223 - acc: 0.9008 - val_loss: 0.2429 - val_acc: 0.9177\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 2s - loss: 0.1954 - acc: 0.9100 - val_loss: 0.2470 - val_acc: 0.9152\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 2s - loss: 0.2009 - acc: 0.9050 - val_loss: 0.2451 - val_acc: 0.9252\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 2s - loss: 0.1888 - acc: 0.9158 - val_loss: 0.2726 - val_acc: 0.9002\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 2s - loss: 0.2091 - acc: 0.9067 - val_loss: 0.2481 - val_acc: 0.9227\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 2s - loss: 0.2036 - acc: 0.9108 - val_loss: 0.2454 - val_acc: 0.9302\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 2s - loss: 0.1848 - acc: 0.9283 - val_loss: 0.2498 - val_acc: 0.9202\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 2s - loss: 0.2112 - acc: 0.9200 - val_loss: 0.2403 - val_acc: 0.9202\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 2s - loss: 0.2370 - acc: 0.9014 - val_loss: 0.2951 - val_acc: 0.8778\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 2s - loss: 0.2196 - acc: 0.9133 - val_loss: 0.2501 - val_acc: 0.9127\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 2s - loss: 0.1823 - acc: 0.9208 - val_loss: 0.2503 - val_acc: 0.9177\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 2s - loss: 0.1962 - acc: 0.9142 - val_loss: 0.2783 - val_acc: 0.8978\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 2s - loss: 0.1859 - acc: 0.9175 - val_loss: 0.2523 - val_acc: 0.9227\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 2s - loss: 0.1911 - acc: 0.9158 - val_loss: 0.2518 - val_acc: 0.9202\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 2s - loss: 0.1994 - acc: 0.9131 - val_loss: 0.2572 - val_acc: 0.9152\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 2s - loss: 0.1847 - acc: 0.9175 - val_loss: 0.2486 - val_acc: 0.9252\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 2s - loss: 0.2181 - acc: 0.9139 - val_loss: 0.2669 - val_acc: 0.9102\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 2s - loss: 0.2080 - acc: 0.9070 - val_loss: 0.2492 - val_acc: 0.9127\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 2s - loss: 0.2047 - acc: 0.9158 - val_loss: 0.2445 - val_acc: 0.9252\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 2s - loss: 0.1829 - acc: 0.9200 - val_loss: 0.2565 - val_acc: 0.9202\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 2s - loss: 0.1925 - acc: 0.9183 - val_loss: 0.2658 - val_acc: 0.9127\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 2s - loss: 0.2187 - acc: 0.9048 - val_loss: 0.2454 - val_acc: 0.9202\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 2s - loss: 0.2012 - acc: 0.9233 - val_loss: 0.2454 - val_acc: 0.9252\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 2s - loss: 0.1950 - acc: 0.9100 - val_loss: 0.2488 - val_acc: 0.9227\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 2s - loss: 0.1915 - acc: 0.9117 - val_loss: 0.2770 - val_acc: 0.9027\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 2s - loss: 0.2173 - acc: 0.8975 - val_loss: 0.2489 - val_acc: 0.9252\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 2s - loss: 0.1880 - acc: 0.9250 - val_loss: 0.2458 - val_acc: 0.9227\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 2s - loss: 0.1806 - acc: 0.9167 - val_loss: 0.2756 - val_acc: 0.9077\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 2s - loss: 0.1861 - acc: 0.9300 - val_loss: 0.2584 - val_acc: 0.9177\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch<10:\n",
    "        return 0.001\n",
    "    elif epoch<30:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211734517896\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.121678\n",
      "1  4023181e    0.582949\n",
      "2  b20200e4    0.083990\n",
      "3  e7f018bb    0.997006\n",
      "4  4371c8c3    0.059046\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_3_aug1_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_3_aug1_sub.csv', index=False)\n",
    "# pre 228\n",
    "# new 2117"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

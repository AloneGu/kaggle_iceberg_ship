{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('new_preprocess_x_y.pkl','rb') as fin:\n",
    "    train_x,y,test_x = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),input_shape=(75, 75, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.64032, saving model to best_m.h5\n",
      " - 2s - loss: 0.6674 - acc: 0.5841 - val_loss: 0.6403 - val_acc: 0.6160\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.64032 to 0.58922, saving model to best_m.h5\n",
      " - 1s - loss: 0.6311 - acc: 0.6038 - val_loss: 0.5892 - val_acc: 0.6234\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.58922 to 0.54435, saving model to best_m.h5\n",
      " - 1s - loss: 0.5606 - acc: 0.6868 - val_loss: 0.5443 - val_acc: 0.7207\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.54435 to 0.52949, saving model to best_m.h5\n",
      " - 1s - loss: 0.5319 - acc: 0.7299 - val_loss: 0.5295 - val_acc: 0.7132\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.52949 to 0.40854, saving model to best_m.h5\n",
      " - 1s - loss: 0.4552 - acc: 0.7874 - val_loss: 0.4085 - val_acc: 0.7980\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss improved from 0.40854 to 0.39018, saving model to best_m.h5\n",
      " - 1s - loss: 0.3891 - acc: 0.8336 - val_loss: 0.3902 - val_acc: 0.8354\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.4372 - acc: 0.8142 - val_loss: 0.3965 - val_acc: 0.8304\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.3983 - acc: 0.8215 - val_loss: 0.4013 - val_acc: 0.8304\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.3601 - acc: 0.8445 - val_loss: 0.4199 - val_acc: 0.7731\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.4185 - acc: 0.8085 - val_loss: 0.4690 - val_acc: 0.7930\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.39018 to 0.35827, saving model to best_m.h5\n",
      " - 1s - loss: 0.3640 - acc: 0.8369 - val_loss: 0.3583 - val_acc: 0.8404\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.35827 to 0.32490, saving model to best_m.h5\n",
      " - 1s - loss: 0.3366 - acc: 0.8648 - val_loss: 0.3249 - val_acc: 0.8579\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss improved from 0.32490 to 0.32309, saving model to best_m.h5\n",
      " - 1s - loss: 0.3284 - acc: 0.8480 - val_loss: 0.3231 - val_acc: 0.8429\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.3244 - acc: 0.8608 - val_loss: 0.3830 - val_acc: 0.8454\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.3273 - acc: 0.8384 - val_loss: 0.3443 - val_acc: 0.8404\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss improved from 0.32309 to 0.31612, saving model to best_m.h5\n",
      " - 1s - loss: 0.3225 - acc: 0.8530 - val_loss: 0.3161 - val_acc: 0.8529\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.2923 - acc: 0.8609 - val_loss: 0.3475 - val_acc: 0.8429\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.2943 - acc: 0.8550 - val_loss: 0.4133 - val_acc: 0.8254\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss improved from 0.31612 to 0.30429, saving model to best_m.h5\n",
      " - 1s - loss: 0.2989 - acc: 0.8595 - val_loss: 0.3043 - val_acc: 0.8579\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss improved from 0.30429 to 0.28735, saving model to best_m.h5\n",
      " - 1s - loss: 0.2978 - acc: 0.8569 - val_loss: 0.2873 - val_acc: 0.8454\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.2888 - acc: 0.8634 - val_loss: 0.5271 - val_acc: 0.8005\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss improved from 0.28735 to 0.27780, saving model to best_m.h5\n",
      " - 1s - loss: 0.2955 - acc: 0.8666 - val_loss: 0.2778 - val_acc: 0.8753\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.2538 - acc: 0.8896 - val_loss: 0.3108 - val_acc: 0.8628\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.2596 - acc: 0.8792 - val_loss: 0.3243 - val_acc: 0.8653\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss improved from 0.27780 to 0.26554, saving model to best_m.h5\n",
      " - 1s - loss: 0.2651 - acc: 0.8910 - val_loss: 0.2655 - val_acc: 0.8878\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.2603 - acc: 0.8989 - val_loss: 0.4493 - val_acc: 0.8379\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.2206 - acc: 0.8989 - val_loss: 0.2660 - val_acc: 0.8778\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.2587 - acc: 0.8952 - val_loss: 0.2959 - val_acc: 0.8878\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.2735 - acc: 0.8882 - val_loss: 0.3459 - val_acc: 0.8479\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.2602 - acc: 0.8933 - val_loss: 0.3054 - val_acc: 0.8678\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss improved from 0.26554 to 0.24552, saving model to best_m.h5\n",
      " - 1s - loss: 0.2351 - acc: 0.9102 - val_loss: 0.2455 - val_acc: 0.8903\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.2377 - acc: 0.9003 - val_loss: 0.2677 - val_acc: 0.8878\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.2269 - acc: 0.9113 - val_loss: 0.2704 - val_acc: 0.8778\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.2132 - acc: 0.9211 - val_loss: 0.2527 - val_acc: 0.8878\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.2084 - acc: 0.9045 - val_loss: 0.2456 - val_acc: 0.8928\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.2181 - acc: 0.9164 - val_loss: 0.2634 - val_acc: 0.8878\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.2082 - acc: 0.9130 - val_loss: 0.2627 - val_acc: 0.8878\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 0.2042 - acc: 0.9138 - val_loss: 0.2535 - val_acc: 0.8978\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss improved from 0.24552 to 0.24470, saving model to best_m.h5\n",
      " - 1s - loss: 0.2263 - acc: 0.8972 - val_loss: 0.2447 - val_acc: 0.8978\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.1871 - acc: 0.9203 - val_loss: 0.2707 - val_acc: 0.8828\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.2004 - acc: 0.9223 - val_loss: 0.2540 - val_acc: 0.8828\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.2223 - acc: 0.9104 - val_loss: 0.2550 - val_acc: 0.8878\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss improved from 0.24470 to 0.23951, saving model to best_m.h5\n",
      " - 1s - loss: 0.2036 - acc: 0.9200 - val_loss: 0.2395 - val_acc: 0.9052\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.1990 - acc: 0.9211 - val_loss: 0.2539 - val_acc: 0.8978\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.2098 - acc: 0.9223 - val_loss: 0.2573 - val_acc: 0.8853\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.2047 - acc: 0.9228 - val_loss: 0.2491 - val_acc: 0.8903\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.1928 - acc: 0.9203 - val_loss: 0.2514 - val_acc: 0.8903\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.1986 - acc: 0.9181 - val_loss: 0.2511 - val_acc: 0.8903\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.1955 - acc: 0.9214 - val_loss: 0.2515 - val_acc: 0.8928\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.2120 - acc: 0.9189 - val_loss: 0.2469 - val_acc: 0.8953\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.62925, saving model to best_m.h5\n",
      " - 2s - loss: 0.6683 - acc: 0.5660 - val_loss: 0.6292 - val_acc: 0.6135\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.62925 to 0.53672, saving model to best_m.h5\n",
      " - 1s - loss: 0.6168 - acc: 0.6376 - val_loss: 0.5367 - val_acc: 0.6908\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.53672 to 0.40164, saving model to best_m.h5\n",
      " - 1s - loss: 0.5158 - acc: 0.7246 - val_loss: 0.4016 - val_acc: 0.8329\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.40164 to 0.38991, saving model to best_m.h5\n",
      " - 1s - loss: 0.4514 - acc: 0.7756 - val_loss: 0.3899 - val_acc: 0.8479\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.4422 - acc: 0.7970 - val_loss: 0.4437 - val_acc: 0.8105\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss improved from 0.38991 to 0.33176, saving model to best_m.h5\n",
      " - 1s - loss: 0.4108 - acc: 0.8071 - val_loss: 0.3318 - val_acc: 0.8603\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.33176 to 0.29485, saving model to best_m.h5\n",
      " - 1s - loss: 0.3936 - acc: 0.8105 - val_loss: 0.2948 - val_acc: 0.8678\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.3492 - acc: 0.8476 - val_loss: 0.3840 - val_acc: 0.8279\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.3681 - acc: 0.8189 - val_loss: 0.3236 - val_acc: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.3966 - acc: 0.8133 - val_loss: 0.3198 - val_acc: 0.8529\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.29485 to 0.28277, saving model to best_m.h5\n",
      " - 1s - loss: 0.3161 - acc: 0.8527 - val_loss: 0.2828 - val_acc: 0.8903\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.28277 to 0.27351, saving model to best_m.h5\n",
      " - 1s - loss: 0.3277 - acc: 0.8448 - val_loss: 0.2735 - val_acc: 0.8878\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.2857 - acc: 0.8708 - val_loss: 0.3071 - val_acc: 0.8878\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.3141 - acc: 0.8597 - val_loss: 0.2772 - val_acc: 0.8554\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss improved from 0.27351 to 0.25352, saving model to best_m.h5\n",
      " - 1s - loss: 0.2818 - acc: 0.8831 - val_loss: 0.2535 - val_acc: 0.8903\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.2893 - acc: 0.8682 - val_loss: 0.3507 - val_acc: 0.8753\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.2551 - acc: 0.8865 - val_loss: 0.3168 - val_acc: 0.8928\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.2858 - acc: 0.8786 - val_loss: 0.2646 - val_acc: 0.8903\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.2778 - acc: 0.8803 - val_loss: 0.2563 - val_acc: 0.8828\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.2621 - acc: 0.8828 - val_loss: 0.2598 - val_acc: 0.8878\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.2931 - acc: 0.8693 - val_loss: 0.2541 - val_acc: 0.8953\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.2662 - acc: 0.8851 - val_loss: 0.3137 - val_acc: 0.8653\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.2801 - acc: 0.8761 - val_loss: 0.2674 - val_acc: 0.8978\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.2259 - acc: 0.9057 - val_loss: 0.2549 - val_acc: 0.8978\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.2435 - acc: 0.8876 - val_loss: 0.3094 - val_acc: 0.8878\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.2637 - acc: 0.8896 - val_loss: 0.2540 - val_acc: 0.9077\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.2497 - acc: 0.9006 - val_loss: 0.2894 - val_acc: 0.8703\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.2627 - acc: 0.8876 - val_loss: 0.3017 - val_acc: 0.8603\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.2265 - acc: 0.9029 - val_loss: 0.2541 - val_acc: 0.9102\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.2425 - acc: 0.8972 - val_loss: 0.2993 - val_acc: 0.8803\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.1971 - acc: 0.9144 - val_loss: 0.2594 - val_acc: 0.8928\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.2144 - acc: 0.9079 - val_loss: 0.2573 - val_acc: 0.8953\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.2287 - acc: 0.9028 - val_loss: 0.2618 - val_acc: 0.8903\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 0.1950 - acc: 0.9133 - val_loss: 0.2658 - val_acc: 0.8953\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.1938 - acc: 0.9175 - val_loss: 0.2581 - val_acc: 0.8928\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.2089 - acc: 0.9071 - val_loss: 0.2631 - val_acc: 0.8953\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.2165 - acc: 0.9048 - val_loss: 0.2560 - val_acc: 0.8953\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 0.2103 - acc: 0.9133 - val_loss: 0.2588 - val_acc: 0.8928\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.1973 - acc: 0.9076 - val_loss: 0.2577 - val_acc: 0.9002\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.2086 - acc: 0.9158 - val_loss: 0.2610 - val_acc: 0.8953\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.1811 - acc: 0.9195 - val_loss: 0.2616 - val_acc: 0.8903\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.1967 - acc: 0.9203 - val_loss: 0.2758 - val_acc: 0.8953\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.1902 - acc: 0.9279 - val_loss: 0.2726 - val_acc: 0.8953\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.2088 - acc: 0.9096 - val_loss: 0.2563 - val_acc: 0.8953\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.2069 - acc: 0.9099 - val_loss: 0.2597 - val_acc: 0.8928\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.2148 - acc: 0.9088 - val_loss: 0.2607 - val_acc: 0.8953\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.1884 - acc: 0.9231 - val_loss: 0.2690 - val_acc: 0.8903\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.2052 - acc: 0.9101 - val_loss: 0.2578 - val_acc: 0.9002\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.2025 - acc: 0.9130 - val_loss: 0.2666 - val_acc: 0.8953\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.1818 - acc: 0.9301 - val_loss: 0.2616 - val_acc: 0.8903\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.60646, saving model to best_m.h5\n",
      " - 2s - loss: 0.6664 - acc: 0.5542 - val_loss: 0.6065 - val_acc: 0.5985\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.60646 to 0.60154, saving model to best_m.h5\n",
      " - 1s - loss: 0.6015 - acc: 0.6343 - val_loss: 0.6015 - val_acc: 0.6534\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.60154 to 0.45502, saving model to best_m.h5\n",
      " - 1s - loss: 0.5352 - acc: 0.7149 - val_loss: 0.4550 - val_acc: 0.8603\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.45502 to 0.44847, saving model to best_m.h5\n",
      " - 1s - loss: 0.5101 - acc: 0.7513 - val_loss: 0.4485 - val_acc: 0.8479\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.3978 - acc: 0.8353 - val_loss: 0.4677 - val_acc: 0.8229\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss improved from 0.44847 to 0.35497, saving model to best_m.h5\n",
      " - 1s - loss: 0.4339 - acc: 0.7958 - val_loss: 0.3550 - val_acc: 0.8753\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.35497 to 0.35178, saving model to best_m.h5\n",
      " - 1s - loss: 0.3900 - acc: 0.8271 - val_loss: 0.3518 - val_acc: 0.8778\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss improved from 0.35178 to 0.33393, saving model to best_m.h5\n",
      " - 1s - loss: 0.3993 - acc: 0.8293 - val_loss: 0.3339 - val_acc: 0.8653\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.4323 - acc: 0.8110 - val_loss: 0.3921 - val_acc: 0.8479\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.3869 - acc: 0.8361 - val_loss: 0.3583 - val_acc: 0.8479\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.33393 to 0.31099, saving model to best_m.h5\n",
      " - 1s - loss: 0.3829 - acc: 0.8311 - val_loss: 0.3110 - val_acc: 0.8828\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.31099 to 0.29988, saving model to best_m.h5\n",
      " - 1s - loss: 0.3462 - acc: 0.8558 - val_loss: 0.2999 - val_acc: 0.8853\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss improved from 0.29988 to 0.28001, saving model to best_m.h5\n",
      " - 1s - loss: 0.3425 - acc: 0.8426 - val_loss: 0.2800 - val_acc: 0.8828\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.3545 - acc: 0.8378 - val_loss: 0.3071 - val_acc: 0.8678\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.3678 - acc: 0.8398 - val_loss: 0.3120 - val_acc: 0.8828\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss improved from 0.28001 to 0.27569, saving model to best_m.h5\n",
      " - 1s - loss: 0.3241 - acc: 0.8623 - val_loss: 0.2757 - val_acc: 0.8828\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.3512 - acc: 0.8471 - val_loss: 0.2894 - val_acc: 0.8753\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.2985 - acc: 0.8727 - val_loss: 0.2865 - val_acc: 0.8554\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss improved from 0.27569 to 0.24822, saving model to best_m.h5\n",
      " - 1s - loss: 0.2733 - acc: 0.8843 - val_loss: 0.2482 - val_acc: 0.9027\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.2956 - acc: 0.8648 - val_loss: 0.2708 - val_acc: 0.8853\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.2818 - acc: 0.8795 - val_loss: 0.3179 - val_acc: 0.8703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.2661 - acc: 0.8860 - val_loss: 0.2778 - val_acc: 0.8653\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 0.2715 - acc: 0.8736 - val_loss: 0.2668 - val_acc: 0.8778\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 1s - loss: 0.3051 - acc: 0.8767 - val_loss: 0.2622 - val_acc: 0.8828\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss improved from 0.24822 to 0.24296, saving model to best_m.h5\n",
      " - 1s - loss: 0.2786 - acc: 0.8758 - val_loss: 0.2430 - val_acc: 0.8903\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.2452 - acc: 0.8859 - val_loss: 0.2452 - val_acc: 0.8928\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.2308 - acc: 0.9006 - val_loss: 0.2825 - val_acc: 0.8803\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.2438 - acc: 0.8921 - val_loss: 0.2513 - val_acc: 0.8828\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.2658 - acc: 0.8947 - val_loss: 0.3743 - val_acc: 0.8379\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.2884 - acc: 0.8727 - val_loss: 0.2448 - val_acc: 0.9077\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.2154 - acc: 0.9150 - val_loss: 0.2468 - val_acc: 0.9052\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss improved from 0.24296 to 0.23906, saving model to best_m.h5\n",
      " - 1s - loss: 0.2502 - acc: 0.8927 - val_loss: 0.2391 - val_acc: 0.8903\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.2121 - acc: 0.9070 - val_loss: 0.2400 - val_acc: 0.9027\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss improved from 0.23906 to 0.23157, saving model to best_m.h5\n",
      " - 1s - loss: 0.2081 - acc: 0.9122 - val_loss: 0.2316 - val_acc: 0.8978\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss improved from 0.23157 to 0.23000, saving model to best_m.h5\n",
      " - 1s - loss: 0.2069 - acc: 0.9074 - val_loss: 0.2300 - val_acc: 0.9102\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.2129 - acc: 0.9096 - val_loss: 0.2301 - val_acc: 0.9052\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.2264 - acc: 0.9003 - val_loss: 0.2337 - val_acc: 0.9052\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss improved from 0.23000 to 0.22846, saving model to best_m.h5\n",
      " - 1s - loss: 0.2244 - acc: 0.9040 - val_loss: 0.2285 - val_acc: 0.9052\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.2211 - acc: 0.9017 - val_loss: 0.2296 - val_acc: 0.9102\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.2153 - acc: 0.9082 - val_loss: 0.2290 - val_acc: 0.9152\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.2212 - acc: 0.9054 - val_loss: 0.2300 - val_acc: 0.9077\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.2135 - acc: 0.9133 - val_loss: 0.2287 - val_acc: 0.9002\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.2080 - acc: 0.9138 - val_loss: 0.2359 - val_acc: 0.9077\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.2142 - acc: 0.9090 - val_loss: 0.2335 - val_acc: 0.9127\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.1895 - acc: 0.9203 - val_loss: 0.2346 - val_acc: 0.9077\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.2040 - acc: 0.9093 - val_loss: 0.2375 - val_acc: 0.9077\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.2194 - acc: 0.9071 - val_loss: 0.2307 - val_acc: 0.9027\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.2182 - acc: 0.9062 - val_loss: 0.2290 - val_acc: 0.9077\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.2019 - acc: 0.9051 - val_loss: 0.2348 - val_acc: 0.8978\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.1867 - acc: 0.9189 - val_loss: 0.2306 - val_acc: 0.9102\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.62188, saving model to best_m.h5\n",
      " - 2s - loss: 0.6685 - acc: 0.5615 - val_loss: 0.6219 - val_acc: 0.6135\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.62188 to 0.56733, saving model to best_m.h5\n",
      " - 1s - loss: 0.6022 - acc: 0.6317 - val_loss: 0.5673 - val_acc: 0.6758\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.56733 to 0.50655, saving model to best_m.h5\n",
      " - 1s - loss: 0.5571 - acc: 0.6950 - val_loss: 0.5066 - val_acc: 0.7257\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.50655 to 0.44678, saving model to best_m.h5\n",
      " - 1s - loss: 0.5185 - acc: 0.7601 - val_loss: 0.4468 - val_acc: 0.8030\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.44678 to 0.44516, saving model to best_m.h5\n",
      " - 1s - loss: 0.4465 - acc: 0.7930 - val_loss: 0.4452 - val_acc: 0.7855\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss improved from 0.44516 to 0.42929, saving model to best_m.h5\n",
      " - 1s - loss: 0.4581 - acc: 0.7992 - val_loss: 0.4293 - val_acc: 0.7955\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.3892 - acc: 0.8293 - val_loss: 0.5079 - val_acc: 0.7631\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.3871 - acc: 0.8387 - val_loss: 0.4733 - val_acc: 0.7930\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.4093 - acc: 0.8245 - val_loss: 0.4754 - val_acc: 0.7805\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.3533 - acc: 0.8539 - val_loss: 0.4437 - val_acc: 0.8155\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.3358 - acc: 0.8617 - val_loss: 0.4406 - val_acc: 0.8229\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.42929 to 0.42085, saving model to best_m.h5\n",
      " - 1s - loss: 0.3409 - acc: 0.8629 - val_loss: 0.4208 - val_acc: 0.8080\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.3213 - acc: 0.8631 - val_loss: 0.4343 - val_acc: 0.8130\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.3481 - acc: 0.8598 - val_loss: 0.4376 - val_acc: 0.7955\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss improved from 0.42085 to 0.40201, saving model to best_m.h5\n",
      " - 1s - loss: 0.3106 - acc: 0.8657 - val_loss: 0.4020 - val_acc: 0.8155\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss improved from 0.40201 to 0.39719, saving model to best_m.h5\n",
      " - 1s - loss: 0.2998 - acc: 0.8809 - val_loss: 0.3972 - val_acc: 0.8180\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss improved from 0.39719 to 0.37900, saving model to best_m.h5\n",
      " - 1s - loss: 0.3000 - acc: 0.8741 - val_loss: 0.3790 - val_acc: 0.8229\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss improved from 0.37900 to 0.34690, saving model to best_m.h5\n",
      " - 1s - loss: 0.2909 - acc: 0.8843 - val_loss: 0.3469 - val_acc: 0.8379\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.2717 - acc: 0.8952 - val_loss: 0.3916 - val_acc: 0.8155\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.2913 - acc: 0.8792 - val_loss: 0.4389 - val_acc: 0.8080\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 1s - loss: 0.3163 - acc: 0.8637 - val_loss: 0.3637 - val_acc: 0.8279\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 0.2944 - acc: 0.8795 - val_loss: 0.3797 - val_acc: 0.8204\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss improved from 0.34690 to 0.31106, saving model to best_m.h5\n",
      " - 1s - loss: 0.2841 - acc: 0.8767 - val_loss: 0.3111 - val_acc: 0.8603\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss improved from 0.31106 to 0.30895, saving model to best_m.h5\n",
      " - 1s - loss: 0.2583 - acc: 0.8888 - val_loss: 0.3090 - val_acc: 0.8603\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 0.2474 - acc: 0.8983 - val_loss: 0.3259 - val_acc: 0.8504\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 1s - loss: 0.2543 - acc: 0.8924 - val_loss: 0.3119 - val_acc: 0.8603\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 0.2558 - acc: 0.8910 - val_loss: 0.3254 - val_acc: 0.8579\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 0.2535 - acc: 0.8983 - val_loss: 0.3244 - val_acc: 0.8628\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 1s - loss: 0.2392 - acc: 0.8983 - val_loss: 0.3180 - val_acc: 0.8653\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 0.2339 - acc: 0.9046 - val_loss: 0.3252 - val_acc: 0.8479\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 0.2369 - acc: 0.8997 - val_loss: 0.3255 - val_acc: 0.8828\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 0.2031 - acc: 0.9135 - val_loss: 0.3167 - val_acc: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 0.2421 - acc: 0.9006 - val_loss: 0.3178 - val_acc: 0.8778\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss improved from 0.30895 to 0.30555, saving model to best_m.h5\n",
      " - 1s - loss: 0.1870 - acc: 0.9211 - val_loss: 0.3056 - val_acc: 0.8803\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 1s - loss: 0.2225 - acc: 0.9090 - val_loss: 0.3179 - val_acc: 0.8803\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 0.1997 - acc: 0.9217 - val_loss: 0.3445 - val_acc: 0.8753\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 1s - loss: 0.2089 - acc: 0.9093 - val_loss: 0.3112 - val_acc: 0.8803\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 0.1918 - acc: 0.9186 - val_loss: 0.3208 - val_acc: 0.8853\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 1s - loss: 0.2067 - acc: 0.9150 - val_loss: 0.3272 - val_acc: 0.8853\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 0.1971 - acc: 0.9214 - val_loss: 0.3197 - val_acc: 0.8853\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 1s - loss: 0.2079 - acc: 0.9169 - val_loss: 0.3182 - val_acc: 0.8753\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 1s - loss: 0.2121 - acc: 0.9164 - val_loss: 0.3360 - val_acc: 0.8828\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 1s - loss: 0.1979 - acc: 0.9130 - val_loss: 0.3373 - val_acc: 0.8828\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 1s - loss: 0.1985 - acc: 0.9178 - val_loss: 0.3330 - val_acc: 0.8803\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 1s - loss: 0.2052 - acc: 0.9088 - val_loss: 0.3191 - val_acc: 0.8853\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 1s - loss: 0.1747 - acc: 0.9262 - val_loss: 0.3203 - val_acc: 0.8853\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 1s - loss: 0.1985 - acc: 0.9200 - val_loss: 0.3343 - val_acc: 0.8828\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 1s - loss: 0.2008 - acc: 0.9172 - val_loss: 0.3176 - val_acc: 0.8853\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 1s - loss: 0.2038 - acc: 0.9138 - val_loss: 0.3281 - val_acc: 0.8903\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 1s - loss: 0.1959 - acc: 0.9181 - val_loss: 0.3304 - val_acc: 0.8878\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch<10:\n",
    "        return 0.001\n",
    "    elif epoch<30:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.00005\n",
    "\n",
    "def kfold_train(fold_cnt=3,rnd=233):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 32\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=50, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.256762398449\n",
      "         id    is_iceberg\n",
      "0  5941774d  1.517783e-02\n",
      "1  4023181e  3.707070e-01\n",
      "2  b20200e4  2.806452e-08\n",
      "3  e7f018bb  9.553727e-01\n",
      "4  4371c8c3  3.394186e-02\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_2_aug1_feat_new_preprocess.pkl','wb') as fout: # no help\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_2_aug1_sub_new_preprocess.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

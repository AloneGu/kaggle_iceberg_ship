{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        img = np.dstack((band_1, band_2, band_3))\n",
    "        images.append(std_img(img))\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model=Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.69641, saving model to best_m.h5\n",
      " - 3s - loss: 0.6990 - acc: 0.5203 - val_loss: 0.6964 - val_acc: 0.5387\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6462 - acc: 0.5908 - val_loss: 0.7002 - val_acc: 0.4938\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.69641 to 0.53120, saving model to best_m.h5\n",
      " - 2s - loss: 0.6189 - acc: 0.6234 - val_loss: 0.5312 - val_acc: 0.7756\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.53120 to 0.41428, saving model to best_m.h5\n",
      " - 2s - loss: 0.5485 - acc: 0.7253 - val_loss: 0.4143 - val_acc: 0.8130\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.41428 to 0.35424, saving model to best_m.h5\n",
      " - 2s - loss: 0.5071 - acc: 0.7512 - val_loss: 0.3542 - val_acc: 0.8603\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss improved from 0.35424 to 0.30210, saving model to best_m.h5\n",
      " - 2s - loss: 0.4348 - acc: 0.7933 - val_loss: 0.3021 - val_acc: 0.8429\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.30210 to 0.26651, saving model to best_m.h5\n",
      " - 2s - loss: 0.4228 - acc: 0.8108 - val_loss: 0.2665 - val_acc: 0.8753\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss improved from 0.26651 to 0.25123, saving model to best_m.h5\n",
      " - 2s - loss: 0.4358 - acc: 0.8058 - val_loss: 0.2512 - val_acc: 0.9002\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3940 - acc: 0.8216 - val_loss: 0.2530 - val_acc: 0.8828\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3522 - acc: 0.8358 - val_loss: 0.2769 - val_acc: 0.8404\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 2s - loss: 0.3345 - acc: 0.8623 - val_loss: 0.2627 - val_acc: 0.8678\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.25123 to 0.24003, saving model to best_m.h5\n",
      " - 3s - loss: 0.3289 - acc: 0.8583 - val_loss: 0.2400 - val_acc: 0.8903\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss improved from 0.24003 to 0.23568, saving model to best_m.h5\n",
      " - 2s - loss: 0.3002 - acc: 0.8606 - val_loss: 0.2357 - val_acc: 0.8778\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss improved from 0.23568 to 0.23460, saving model to best_m.h5\n",
      " - 2s - loss: 0.3080 - acc: 0.8608 - val_loss: 0.2346 - val_acc: 0.9002\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.3219 - acc: 0.8700 - val_loss: 0.3243 - val_acc: 0.8479\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.2869 - acc: 0.8783 - val_loss: 0.2481 - val_acc: 0.8853\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 2s - loss: 0.3157 - acc: 0.8568 - val_loss: 0.2375 - val_acc: 0.8953\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2841 - acc: 0.8816 - val_loss: 0.2873 - val_acc: 0.8803\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2927 - acc: 0.8858 - val_loss: 0.2440 - val_acc: 0.8978\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss improved from 0.23460 to 0.20259, saving model to best_m.h5\n",
      " - 2s - loss: 0.2902 - acc: 0.8775 - val_loss: 0.2026 - val_acc: 0.9102\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss improved from 0.20259 to 0.20185, saving model to best_m.h5\n",
      " - 2s - loss: 0.2905 - acc: 0.8698 - val_loss: 0.2019 - val_acc: 0.9177\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2939 - acc: 0.8816 - val_loss: 0.2220 - val_acc: 0.9177\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.2691 - acc: 0.8875 - val_loss: 0.3202 - val_acc: 0.8479\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2933 - acc: 0.8825 - val_loss: 0.2107 - val_acc: 0.9102\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2835 - acc: 0.8850 - val_loss: 0.2414 - val_acc: 0.8778\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.3118 - acc: 0.8600 - val_loss: 0.2640 - val_acc: 0.8803\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2683 - acc: 0.8841 - val_loss: 0.2116 - val_acc: 0.9002\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2640 - acc: 0.8925 - val_loss: 0.2594 - val_acc: 0.8953\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.3097 - acc: 0.8529 - val_loss: 0.2485 - val_acc: 0.8953\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2745 - acc: 0.8881 - val_loss: 0.2075 - val_acc: 0.9177\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2406 - acc: 0.9017 - val_loss: 0.2112 - val_acc: 0.9027\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss improved from 0.20185 to 0.20021, saving model to best_m.h5\n",
      " - 2s - loss: 0.2399 - acc: 0.8983 - val_loss: 0.2002 - val_acc: 0.9077\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss improved from 0.20021 to 0.19244, saving model to best_m.h5\n",
      " - 2s - loss: 0.2437 - acc: 0.8942 - val_loss: 0.1924 - val_acc: 0.9227\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 2s - loss: 0.2551 - acc: 0.8917 - val_loss: 0.2098 - val_acc: 0.9052\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2106 - acc: 0.9058 - val_loss: 0.1968 - val_acc: 0.9177\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2508 - acc: 0.8900 - val_loss: 0.2089 - val_acc: 0.8978\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2239 - acc: 0.9067 - val_loss: 0.1935 - val_acc: 0.9177\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2493 - acc: 0.8881 - val_loss: 0.1998 - val_acc: 0.9102\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2282 - acc: 0.9117 - val_loss: 0.1981 - val_acc: 0.9227\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2471 - acc: 0.8958 - val_loss: 0.2039 - val_acc: 0.9127\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2454 - acc: 0.8931 - val_loss: 0.2078 - val_acc: 0.9102\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2280 - acc: 0.9050 - val_loss: 0.2009 - val_acc: 0.9152\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2267 - acc: 0.9092 - val_loss: 0.1937 - val_acc: 0.9227\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2380 - acc: 0.9092 - val_loss: 0.1970 - val_acc: 0.9102\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2322 - acc: 0.9075 - val_loss: 0.2108 - val_acc: 0.9127\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss improved from 0.19244 to 0.18427, saving model to best_m.h5\n",
      " - 2s - loss: 0.2144 - acc: 0.9183 - val_loss: 0.1843 - val_acc: 0.9252\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2452 - acc: 0.8892 - val_loss: 0.1879 - val_acc: 0.9252\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2284 - acc: 0.9025 - val_loss: 0.1848 - val_acc: 0.9277\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2318 - acc: 0.9067 - val_loss: 0.1860 - val_acc: 0.9302\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2479 - acc: 0.8942 - val_loss: 0.1900 - val_acc: 0.9227\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.69533, saving model to best_m.h5\n",
      " - 2s - loss: 0.6899 - acc: 0.5272 - val_loss: 0.6953 - val_acc: 0.4938\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.69533 to 0.52200, saving model to best_m.h5\n",
      " - 2s - loss: 0.6167 - acc: 0.6364 - val_loss: 0.5220 - val_acc: 0.7282\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.52200 to 0.47688, saving model to best_m.h5\n",
      " - 2s - loss: 0.5701 - acc: 0.7147 - val_loss: 0.4769 - val_acc: 0.7905\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.4643 - acc: 0.7872 - val_loss: 0.5057 - val_acc: 0.7606\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.47688 to 0.46587, saving model to best_m.h5\n",
      " - 2s - loss: 0.4519 - acc: 0.7878 - val_loss: 0.4659 - val_acc: 0.7681\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4142 - acc: 0.8081 - val_loss: 0.5251 - val_acc: 0.7581\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.46587 to 0.35441, saving model to best_m.h5\n",
      " - 2s - loss: 0.4270 - acc: 0.8012 - val_loss: 0.3544 - val_acc: 0.8404\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.3861 - acc: 0.8316 - val_loss: 0.4210 - val_acc: 0.8379\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss improved from 0.35441 to 0.34746, saving model to best_m.h5\n",
      " - 2s - loss: 0.3538 - acc: 0.8475 - val_loss: 0.3475 - val_acc: 0.8628\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3791 - acc: 0.8270 - val_loss: 0.3833 - val_acc: 0.8180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.34746 to 0.33769, saving model to best_m.h5\n",
      " - 2s - loss: 0.3381 - acc: 0.8623 - val_loss: 0.3377 - val_acc: 0.8479\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.33769 to 0.29435, saving model to best_m.h5\n",
      " - 2s - loss: 0.2900 - acc: 0.8750 - val_loss: 0.2943 - val_acc: 0.8703\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.2818 - acc: 0.8875 - val_loss: 0.3178 - val_acc: 0.8579\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.3173 - acc: 0.8589 - val_loss: 0.3294 - val_acc: 0.8728\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2792 - acc: 0.8841 - val_loss: 0.3151 - val_acc: 0.8803\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss improved from 0.29435 to 0.29397, saving model to best_m.h5\n",
      " - 2s - loss: 0.2672 - acc: 0.8817 - val_loss: 0.2940 - val_acc: 0.8703\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss improved from 0.29397 to 0.27477, saving model to best_m.h5\n",
      " - 2s - loss: 0.2589 - acc: 0.8900 - val_loss: 0.2748 - val_acc: 0.8853\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss improved from 0.27477 to 0.26413, saving model to best_m.h5\n",
      " - 2s - loss: 0.2866 - acc: 0.8766 - val_loss: 0.2641 - val_acc: 0.8878\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2578 - acc: 0.8892 - val_loss: 0.2741 - val_acc: 0.8703\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2748 - acc: 0.8733 - val_loss: 0.3067 - val_acc: 0.8728\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss improved from 0.26413 to 0.25860, saving model to best_m.h5\n",
      " - 2s - loss: 0.2846 - acc: 0.8841 - val_loss: 0.2586 - val_acc: 0.8953\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2429 - acc: 0.9008 - val_loss: 0.3613 - val_acc: 0.8529\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.2983 - acc: 0.8856 - val_loss: 0.2724 - val_acc: 0.8703\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2965 - acc: 0.8791 - val_loss: 0.2770 - val_acc: 0.8878\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2622 - acc: 0.8892 - val_loss: 0.2795 - val_acc: 0.8579\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2589 - acc: 0.8975 - val_loss: 0.2647 - val_acc: 0.8878\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2698 - acc: 0.8875 - val_loss: 0.2682 - val_acc: 0.8728\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2665 - acc: 0.8914 - val_loss: 0.2599 - val_acc: 0.8728\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2712 - acc: 0.8823 - val_loss: 0.2765 - val_acc: 0.8928\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2681 - acc: 0.8867 - val_loss: 0.3220 - val_acc: 0.8429\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2643 - acc: 0.8989 - val_loss: 0.2643 - val_acc: 0.8778\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss improved from 0.25860 to 0.25172, saving model to best_m.h5\n",
      " - 2s - loss: 0.2484 - acc: 0.8883 - val_loss: 0.2517 - val_acc: 0.8978\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2343 - acc: 0.9016 - val_loss: 0.2565 - val_acc: 0.8828\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss improved from 0.25172 to 0.24764, saving model to best_m.h5\n",
      " - 2s - loss: 0.2265 - acc: 0.9133 - val_loss: 0.2476 - val_acc: 0.8928\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2083 - acc: 0.9075 - val_loss: 0.2885 - val_acc: 0.8753\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2280 - acc: 0.9006 - val_loss: 0.2565 - val_acc: 0.8928\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2306 - acc: 0.9017 - val_loss: 0.2555 - val_acc: 0.8903\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss improved from 0.24764 to 0.24233, saving model to best_m.h5\n",
      " - 2s - loss: 0.2308 - acc: 0.9117 - val_loss: 0.2423 - val_acc: 0.8978\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2254 - acc: 0.9025 - val_loss: 0.2617 - val_acc: 0.8828\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2422 - acc: 0.9075 - val_loss: 0.2440 - val_acc: 0.8978\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss improved from 0.24233 to 0.24227, saving model to best_m.h5\n",
      " - 2s - loss: 0.2181 - acc: 0.9000 - val_loss: 0.2423 - val_acc: 0.8903\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2395 - acc: 0.8939 - val_loss: 0.2606 - val_acc: 0.8803\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2255 - acc: 0.9031 - val_loss: 0.2455 - val_acc: 0.8853\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2283 - acc: 0.9041 - val_loss: 0.2439 - val_acc: 0.8928\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2285 - acc: 0.9050 - val_loss: 0.2472 - val_acc: 0.8928\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss improved from 0.24227 to 0.24015, saving model to best_m.h5\n",
      " - 2s - loss: 0.2251 - acc: 0.9117 - val_loss: 0.2402 - val_acc: 0.8953\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2065 - acc: 0.9142 - val_loss: 0.2601 - val_acc: 0.8828\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2141 - acc: 0.9125 - val_loss: 0.2420 - val_acc: 0.8978\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2134 - acc: 0.9150 - val_loss: 0.2665 - val_acc: 0.8678\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2411 - acc: 0.8975 - val_loss: 0.2439 - val_acc: 0.8978\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.61296, saving model to best_m.h5\n",
      " - 2s - loss: 0.6919 - acc: 0.5339 - val_loss: 0.6130 - val_acc: 0.6658\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 2s - loss: 0.6809 - acc: 0.5386 - val_loss: 0.6678 - val_acc: 0.6185\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss improved from 0.61296 to 0.53395, saving model to best_m.h5\n",
      " - 2s - loss: 0.6473 - acc: 0.6030 - val_loss: 0.5339 - val_acc: 0.7207\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.53395 to 0.50336, saving model to best_m.h5\n",
      " - 2s - loss: 0.5664 - acc: 0.6825 - val_loss: 0.5034 - val_acc: 0.7431\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.50336 to 0.40657, saving model to best_m.h5\n",
      " - 2s - loss: 0.5067 - acc: 0.7481 - val_loss: 0.4066 - val_acc: 0.8204\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4859 - acc: 0.7678 - val_loss: 0.5230 - val_acc: 0.7307\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.40657 to 0.39374, saving model to best_m.h5\n",
      " - 2s - loss: 0.4850 - acc: 0.7864 - val_loss: 0.3937 - val_acc: 0.8329\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.4909 - acc: 0.7722 - val_loss: 0.4955 - val_acc: 0.7556\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.4656 - acc: 0.7916 - val_loss: 0.4242 - val_acc: 0.8155\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss improved from 0.39374 to 0.38443, saving model to best_m.h5\n",
      " - 2s - loss: 0.4805 - acc: 0.7858 - val_loss: 0.3844 - val_acc: 0.8504\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.38443 to 0.35273, saving model to best_m.h5\n",
      " - 2s - loss: 0.4019 - acc: 0.8216 - val_loss: 0.3527 - val_acc: 0.8479\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.35273 to 0.33960, saving model to best_m.h5\n",
      " - 2s - loss: 0.3956 - acc: 0.8289 - val_loss: 0.3396 - val_acc: 0.8554\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.3782 - acc: 0.8475 - val_loss: 0.3514 - val_acc: 0.8529\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss improved from 0.33960 to 0.32502, saving model to best_m.h5\n",
      " - 2s - loss: 0.4197 - acc: 0.8189 - val_loss: 0.3250 - val_acc: 0.8579\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss improved from 0.32502 to 0.32342, saving model to best_m.h5\n",
      " - 2s - loss: 0.3690 - acc: 0.8404 - val_loss: 0.3234 - val_acc: 0.8454\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.3963 - acc: 0.8133 - val_loss: 0.3357 - val_acc: 0.8504\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss improved from 0.32342 to 0.28535, saving model to best_m.h5\n",
      " - 2s - loss: 0.3472 - acc: 0.8375 - val_loss: 0.2854 - val_acc: 0.8678\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss improved from 0.28535 to 0.26768, saving model to best_m.h5\n",
      " - 2s - loss: 0.3439 - acc: 0.8458 - val_loss: 0.2677 - val_acc: 0.8903\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.3394 - acc: 0.8664 - val_loss: 0.2859 - val_acc: 0.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.3570 - acc: 0.8442 - val_loss: 0.3027 - val_acc: 0.8653\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.3489 - acc: 0.8591 - val_loss: 0.3179 - val_acc: 0.8803\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.3447 - acc: 0.8481 - val_loss: 0.3180 - val_acc: 0.8703\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss improved from 0.26768 to 0.26655, saving model to best_m.h5\n",
      " - 2s - loss: 0.3462 - acc: 0.8483 - val_loss: 0.2665 - val_acc: 0.8903\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss improved from 0.26655 to 0.25946, saving model to best_m.h5\n",
      " - 2s - loss: 0.3345 - acc: 0.8533 - val_loss: 0.2595 - val_acc: 0.8853\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss improved from 0.25946 to 0.25662, saving model to best_m.h5\n",
      " - 2s - loss: 0.3276 - acc: 0.8450 - val_loss: 0.2566 - val_acc: 0.8953\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2785 - acc: 0.8808 - val_loss: 0.2877 - val_acc: 0.8828\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.3345 - acc: 0.8575 - val_loss: 0.2579 - val_acc: 0.9002\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss improved from 0.25662 to 0.23898, saving model to best_m.h5\n",
      " - 2s - loss: 0.3317 - acc: 0.8641 - val_loss: 0.2390 - val_acc: 0.9002\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss improved from 0.23898 to 0.23327, saving model to best_m.h5\n",
      " - 2s - loss: 0.2931 - acc: 0.8892 - val_loss: 0.2333 - val_acc: 0.8928\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss improved from 0.23327 to 0.23213, saving model to best_m.h5\n",
      " - 2s - loss: 0.2927 - acc: 0.8664 - val_loss: 0.2321 - val_acc: 0.9002\n",
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.3161 - acc: 0.8639 - val_loss: 0.2424 - val_acc: 0.8978\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2914 - acc: 0.8708 - val_loss: 0.2338 - val_acc: 0.8928\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss improved from 0.23213 to 0.23158, saving model to best_m.h5\n",
      " - 2s - loss: 0.2710 - acc: 0.8806 - val_loss: 0.2316 - val_acc: 0.9002\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss improved from 0.23158 to 0.21714, saving model to best_m.h5\n",
      " - 2s - loss: 0.2761 - acc: 0.8800 - val_loss: 0.2171 - val_acc: 0.8953\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2631 - acc: 0.8875 - val_loss: 0.2261 - val_acc: 0.8978\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2599 - acc: 0.8808 - val_loss: 0.2214 - val_acc: 0.9077\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2821 - acc: 0.8808 - val_loss: 0.2223 - val_acc: 0.9002\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.2928 - acc: 0.8629 - val_loss: 0.2447 - val_acc: 0.8978\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2938 - acc: 0.8816 - val_loss: 0.2330 - val_acc: 0.8978\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2835 - acc: 0.8667 - val_loss: 0.2335 - val_acc: 0.8928\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2763 - acc: 0.8800 - val_loss: 0.2385 - val_acc: 0.8953\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 2s - loss: 0.2684 - acc: 0.8831 - val_loss: 0.2251 - val_acc: 0.9152\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.2861 - acc: 0.8731 - val_loss: 0.2276 - val_acc: 0.9027\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.2598 - acc: 0.8791 - val_loss: 0.2178 - val_acc: 0.8978\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 2s - loss: 0.2756 - acc: 0.8850 - val_loss: 0.2227 - val_acc: 0.9027\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.2560 - acc: 0.8814 - val_loss: 0.2710 - val_acc: 0.8903\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.2602 - acc: 0.8933 - val_loss: 0.2531 - val_acc: 0.8978\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 2s - loss: 0.2595 - acc: 0.8856 - val_loss: 0.2363 - val_acc: 0.9002\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.2585 - acc: 0.8917 - val_loss: 0.2421 - val_acc: 0.9027\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2678 - acc: 0.8848 - val_loss: 0.2435 - val_acc: 0.9002\n",
      "============================\n",
      "Epoch 1/50\n",
      "Epoch 00001: val_loss improved from inf to 0.64513, saving model to best_m.h5\n",
      " - 2s - loss: 0.6896 - acc: 0.5522 - val_loss: 0.6451 - val_acc: 0.5287\n",
      "Epoch 2/50\n",
      "Epoch 00002: val_loss improved from 0.64513 to 0.55582, saving model to best_m.h5\n",
      " - 2s - loss: 0.6128 - acc: 0.6522 - val_loss: 0.5558 - val_acc: 0.7132\n",
      "Epoch 3/50\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 2s - loss: 0.5521 - acc: 0.7112 - val_loss: 0.6097 - val_acc: 0.6708\n",
      "Epoch 4/50\n",
      "Epoch 00004: val_loss improved from 0.55582 to 0.44771, saving model to best_m.h5\n",
      " - 2s - loss: 0.5010 - acc: 0.7575 - val_loss: 0.4477 - val_acc: 0.8130\n",
      "Epoch 5/50\n",
      "Epoch 00005: val_loss improved from 0.44771 to 0.37850, saving model to best_m.h5\n",
      " - 2s - loss: 0.4391 - acc: 0.8005 - val_loss: 0.3785 - val_acc: 0.8304\n",
      "Epoch 6/50\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.4282 - acc: 0.7958 - val_loss: 0.3995 - val_acc: 0.8379\n",
      "Epoch 7/50\n",
      "Epoch 00007: val_loss improved from 0.37850 to 0.34358, saving model to best_m.h5\n",
      " - 2s - loss: 0.4241 - acc: 0.8133 - val_loss: 0.3436 - val_acc: 0.8653\n",
      "Epoch 8/50\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 2s - loss: 0.3910 - acc: 0.8250 - val_loss: 0.3513 - val_acc: 0.8778\n",
      "Epoch 9/50\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.3567 - acc: 0.8491 - val_loss: 0.3964 - val_acc: 0.8429\n",
      "Epoch 10/50\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.3404 - acc: 0.8575 - val_loss: 0.3616 - val_acc: 0.8703\n",
      "Epoch 11/50\n",
      "Epoch 00011: val_loss improved from 0.34358 to 0.31276, saving model to best_m.h5\n",
      " - 2s - loss: 0.2985 - acc: 0.8658 - val_loss: 0.3128 - val_acc: 0.8479\n",
      "Epoch 12/50\n",
      "Epoch 00012: val_loss improved from 0.31276 to 0.30343, saving model to best_m.h5\n",
      " - 2s - loss: 0.2872 - acc: 0.8816 - val_loss: 0.3034 - val_acc: 0.8828\n",
      "Epoch 13/50\n",
      "Epoch 00013: val_loss improved from 0.30343 to 0.30322, saving model to best_m.h5\n",
      " - 2s - loss: 0.2775 - acc: 0.8858 - val_loss: 0.3032 - val_acc: 0.8878\n",
      "Epoch 14/50\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 2s - loss: 0.2608 - acc: 0.8823 - val_loss: 0.4279 - val_acc: 0.8753\n",
      "Epoch 15/50\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 2s - loss: 0.2784 - acc: 0.8714 - val_loss: 0.3115 - val_acc: 0.8828\n",
      "Epoch 16/50\n",
      "Epoch 00016: val_loss improved from 0.30322 to 0.29977, saving model to best_m.h5\n",
      " - 2s - loss: 0.2394 - acc: 0.9067 - val_loss: 0.2998 - val_acc: 0.8903\n",
      "Epoch 17/50\n",
      "Epoch 00017: val_loss improved from 0.29977 to 0.29217, saving model to best_m.h5\n",
      " - 2s - loss: 0.2843 - acc: 0.8783 - val_loss: 0.2922 - val_acc: 0.8753\n",
      "Epoch 18/50\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 2s - loss: 0.2905 - acc: 0.8741 - val_loss: 0.3031 - val_acc: 0.8828\n",
      "Epoch 19/50\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2656 - acc: 0.8856 - val_loss: 0.3171 - val_acc: 0.8554\n",
      "Epoch 20/50\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2471 - acc: 0.9050 - val_loss: 0.2989 - val_acc: 0.8828\n",
      "Epoch 21/50\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 2s - loss: 0.2564 - acc: 0.8917 - val_loss: 0.2986 - val_acc: 0.8928\n",
      "Epoch 22/50\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 2s - loss: 0.2308 - acc: 0.8897 - val_loss: 0.2964 - val_acc: 0.8828\n",
      "Epoch 23/50\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 2s - loss: 0.2547 - acc: 0.9008 - val_loss: 0.3039 - val_acc: 0.8728\n",
      "Epoch 24/50\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 2s - loss: 0.2636 - acc: 0.8875 - val_loss: 0.3117 - val_acc: 0.8953\n",
      "Epoch 25/50\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 2s - loss: 0.2611 - acc: 0.8939 - val_loss: 0.3301 - val_acc: 0.8828\n",
      "Epoch 26/50\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 2s - loss: 0.2645 - acc: 0.8967 - val_loss: 0.2989 - val_acc: 0.8953\n",
      "Epoch 27/50\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 2s - loss: 0.2189 - acc: 0.9100 - val_loss: 0.3293 - val_acc: 0.8853\n",
      "Epoch 28/50\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 2s - loss: 0.2730 - acc: 0.8808 - val_loss: 0.3733 - val_acc: 0.8778\n",
      "Epoch 29/50\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 2s - loss: 0.2377 - acc: 0.9122 - val_loss: 0.2994 - val_acc: 0.8853\n",
      "Epoch 30/50\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 2s - loss: 0.2265 - acc: 0.9083 - val_loss: 0.3443 - val_acc: 0.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 2s - loss: 0.2066 - acc: 0.9181 - val_loss: 0.3138 - val_acc: 0.8903\n",
      "Epoch 32/50\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 2s - loss: 0.2180 - acc: 0.9083 - val_loss: 0.2983 - val_acc: 0.8903\n",
      "Epoch 33/50\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 2s - loss: 0.2206 - acc: 0.9092 - val_loss: 0.3073 - val_acc: 0.8953\n",
      "Epoch 34/50\n",
      "Epoch 00034: val_loss improved from 0.29217 to 0.29014, saving model to best_m.h5\n",
      " - 2s - loss: 0.2079 - acc: 0.9175 - val_loss: 0.2901 - val_acc: 0.8878\n",
      "Epoch 35/50\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 2s - loss: 0.2048 - acc: 0.9122 - val_loss: 0.3042 - val_acc: 0.8953\n",
      "Epoch 36/50\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 2s - loss: 0.2250 - acc: 0.9081 - val_loss: 0.3107 - val_acc: 0.8753\n",
      "Epoch 37/50\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 2s - loss: 0.2269 - acc: 0.9073 - val_loss: 0.2950 - val_acc: 0.9027\n",
      "Epoch 38/50\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 2s - loss: 0.1870 - acc: 0.9167 - val_loss: 0.3003 - val_acc: 0.8978\n",
      "Epoch 39/50\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 2s - loss: 0.2080 - acc: 0.9167 - val_loss: 0.2975 - val_acc: 0.8953\n",
      "Epoch 40/50\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 2s - loss: 0.2067 - acc: 0.9173 - val_loss: 0.3057 - val_acc: 0.8978\n",
      "Epoch 41/50\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 2s - loss: 0.2042 - acc: 0.9175 - val_loss: 0.2918 - val_acc: 0.8953\n",
      "Epoch 42/50\n",
      "Epoch 00042: val_loss improved from 0.29014 to 0.28536, saving model to best_m.h5\n",
      " - 2s - loss: 0.2213 - acc: 0.9108 - val_loss: 0.2854 - val_acc: 0.8953\n",
      "Epoch 43/50\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 2s - loss: 0.1936 - acc: 0.9158 - val_loss: 0.2959 - val_acc: 0.8978\n",
      "Epoch 44/50\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 2s - loss: 0.1965 - acc: 0.9116 - val_loss: 0.2929 - val_acc: 0.8978\n",
      "Epoch 45/50\n",
      "Epoch 00045: val_loss improved from 0.28536 to 0.28321, saving model to best_m.h5\n",
      " - 2s - loss: 0.2172 - acc: 0.9133 - val_loss: 0.2832 - val_acc: 0.8903\n",
      "Epoch 46/50\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 2s - loss: 0.1940 - acc: 0.9150 - val_loss: 0.2910 - val_acc: 0.8978\n",
      "Epoch 47/50\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 2s - loss: 0.1962 - acc: 0.9200 - val_loss: 0.2862 - val_acc: 0.8978\n",
      "Epoch 48/50\n",
      "Epoch 00048: val_loss improved from 0.28321 to 0.27385, saving model to best_m.h5\n",
      " - 2s - loss: 0.2123 - acc: 0.9070 - val_loss: 0.2739 - val_acc: 0.9002\n",
      "Epoch 49/50\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 2s - loss: 0.1860 - acc: 0.9233 - val_loss: 0.2918 - val_acc: 0.8978\n",
      "Epoch 50/50\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 2s - loss: 0.2078 - acc: 0.9150 - val_loss: 0.2757 - val_acc: 0.8953\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch<10:\n",
    "        return 0.001\n",
    "    elif epoch<30:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "def kfold_train(fold_cnt=3,rnd=42):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            #zoom_range=0.05,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=50, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.228852774132\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.047126\n",
      "1  4023181e    0.476509\n",
      "2  b20200e4    0.038597\n",
      "3  e7f018bb    0.994452\n",
      "4  4371c8c3    0.022245\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/cnn_3_aug2_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/cnn_3_aug2_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

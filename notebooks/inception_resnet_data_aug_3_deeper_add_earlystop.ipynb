{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        img = np.dstack([band_1,band_2,band_3])\n",
    "        img = std_img(img)\n",
    "\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.0005\n",
    "    elif epoch < 30:\n",
    "        return 0.0001\n",
    "    elif epoch < 45:\n",
    "        return 0.00005\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def create_incept_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    \n",
    "    # bn\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 64, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "     # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "    \n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    x = Conv2D(96, 3, strides=2, padding='same',activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.75366, saving model to best_m.h5\n",
      " - 8s - loss: 0.5844 - acc: 0.7241 - val_loss: 0.7537 - val_acc: 0.4663\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.75366 to 0.68708, saving model to best_m.h5\n",
      " - 4s - loss: 0.3887 - acc: 0.8225 - val_loss: 0.6871 - val_acc: 0.6733\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 4s - loss: 0.3783 - acc: 0.8195 - val_loss: 1.7931 - val_acc: 0.5960\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 4s - loss: 0.3427 - acc: 0.8258 - val_loss: 1.5125 - val_acc: 0.6359\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.68708 to 0.52680, saving model to best_m.h5\n",
      " - 4s - loss: 0.4256 - acc: 0.8322 - val_loss: 0.5268 - val_acc: 0.8030\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.52680 to 0.51448, saving model to best_m.h5\n",
      " - 4s - loss: 0.3210 - acc: 0.8566 - val_loss: 0.5145 - val_acc: 0.7656\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3236 - acc: 0.8466 - val_loss: 1.0855 - val_acc: 0.5636\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3205 - acc: 0.8729 - val_loss: 0.7428 - val_acc: 0.7182\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.2993 - acc: 0.8758 - val_loss: 0.5247 - val_acc: 0.7581\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.51448 to 0.41875, saving model to best_m.h5\n",
      " - 4s - loss: 0.2935 - acc: 0.8758 - val_loss: 0.4187 - val_acc: 0.8304\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3030 - acc: 0.8808 - val_loss: 0.4685 - val_acc: 0.8180\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss improved from 0.41875 to 0.38775, saving model to best_m.h5\n",
      " - 4s - loss: 0.2454 - acc: 0.8892 - val_loss: 0.3877 - val_acc: 0.8529\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss improved from 0.38775 to 0.34571, saving model to best_m.h5\n",
      " - 5s - loss: 0.2802 - acc: 0.8925 - val_loss: 0.3457 - val_acc: 0.8454\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.2995 - acc: 0.8733 - val_loss: 0.5037 - val_acc: 0.8254\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.2761 - acc: 0.8792 - val_loss: 0.9482 - val_acc: 0.7032\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2436 - acc: 0.8992 - val_loss: 0.3509 - val_acc: 0.8429\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.34571 to 0.28501, saving model to best_m.h5\n",
      " - 5s - loss: 0.2038 - acc: 0.9125 - val_loss: 0.2850 - val_acc: 0.8903\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 5s - loss: 0.2178 - acc: 0.9067 - val_loss: 0.2886 - val_acc: 0.8803\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.28501 to 0.27133, saving model to best_m.h5\n",
      " - 5s - loss: 0.2536 - acc: 0.9039 - val_loss: 0.2713 - val_acc: 0.8978\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 5s - loss: 0.2314 - acc: 0.9039 - val_loss: 0.3095 - val_acc: 0.8853\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2262 - acc: 0.9025 - val_loss: 0.2898 - val_acc: 0.8778\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2011 - acc: 0.9175 - val_loss: 0.2944 - val_acc: 0.8903\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2400 - acc: 0.8912 - val_loss: 0.3318 - val_acc: 0.8703\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2137 - acc: 0.9192 - val_loss: 0.2978 - val_acc: 0.8803\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2077 - acc: 0.9108 - val_loss: 0.3094 - val_acc: 0.8753\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2182 - acc: 0.9028 - val_loss: 0.2906 - val_acc: 0.8828\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2238 - acc: 0.9083 - val_loss: 0.2863 - val_acc: 0.8828\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2475 - acc: 0.8959 - val_loss: 0.2763 - val_acc: 0.8878\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2271 - acc: 0.8998 - val_loss: 0.3032 - val_acc: 0.8728\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.1904 - acc: 0.9233 - val_loss: 0.3220 - val_acc: 0.8728\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2615 - acc: 0.9060 - val_loss: 0.3033 - val_acc: 0.8778\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.2142 - acc: 0.9095 - val_loss: 0.2796 - val_acc: 0.8803\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.1848 - acc: 0.9208 - val_loss: 0.2872 - val_acc: 0.8828\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.1994 - acc: 0.9167 - val_loss: 0.2877 - val_acc: 0.8903\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.1872 - acc: 0.9250 - val_loss: 0.2954 - val_acc: 0.8878\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 5s - loss: 0.1923 - acc: 0.9298 - val_loss: 0.2952 - val_acc: 0.8853\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.1896 - acc: 0.9292 - val_loss: 0.2871 - val_acc: 0.8753\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.1645 - acc: 0.9308 - val_loss: 0.2924 - val_acc: 0.8828\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.1902 - acc: 0.9192 - val_loss: 0.2933 - val_acc: 0.8803\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.83673, saving model to best_m.h5\n",
      " - 12s - loss: 0.6131 - acc: 0.7128 - val_loss: 0.8367 - val_acc: 0.4589\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.83673 to 0.72987, saving model to best_m.h5\n",
      " - 4s - loss: 0.4619 - acc: 0.7870 - val_loss: 0.7299 - val_acc: 0.6559\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.72987 to 0.41488, saving model to best_m.h5\n",
      " - 4s - loss: 0.3999 - acc: 0.8158 - val_loss: 0.4149 - val_acc: 0.7781\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.41488 to 0.33017, saving model to best_m.h5\n",
      " - 4s - loss: 0.3902 - acc: 0.8172 - val_loss: 0.3302 - val_acc: 0.8304\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 4s - loss: 0.4334 - acc: 0.8160 - val_loss: 0.4079 - val_acc: 0.7905\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3908 - acc: 0.8391 - val_loss: 0.3706 - val_acc: 0.8180\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3501 - acc: 0.8483 - val_loss: 0.3344 - val_acc: 0.8404\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3553 - acc: 0.8281 - val_loss: 0.4782 - val_acc: 0.8105\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.33017 to 0.26074, saving model to best_m.h5\n",
      " - 4s - loss: 0.3329 - acc: 0.8587 - val_loss: 0.2607 - val_acc: 0.8728\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.26074 to 0.21716, saving model to best_m.h5\n",
      " - 4s - loss: 0.3247 - acc: 0.8600 - val_loss: 0.2172 - val_acc: 0.9127\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3603 - acc: 0.8487 - val_loss: 0.2800 - val_acc: 0.8678\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.3419 - acc: 0.8578 - val_loss: 0.3601 - val_acc: 0.8005\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.3242 - acc: 0.8633 - val_loss: 0.3188 - val_acc: 0.8678\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.3175 - acc: 0.8678 - val_loss: 0.2639 - val_acc: 0.8853\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.3079 - acc: 0.8798 - val_loss: 0.3706 - val_acc: 0.8229\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.3158 - acc: 0.8639 - val_loss: 0.2504 - val_acc: 0.8778\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.21716 to 0.20800, saving model to best_m.h5\n",
      " - 4s - loss: 0.2673 - acc: 0.8975 - val_loss: 0.2080 - val_acc: 0.9052\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2497 - acc: 0.8889 - val_loss: 0.2147 - val_acc: 0.8953\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2519 - acc: 0.8908 - val_loss: 0.2120 - val_acc: 0.9052\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2666 - acc: 0.8923 - val_loss: 0.2778 - val_acc: 0.8853\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss improved from 0.20800 to 0.20201, saving model to best_m.h5\n",
      " - 4s - loss: 0.2786 - acc: 0.8792 - val_loss: 0.2020 - val_acc: 0.9152\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2878 - acc: 0.8806 - val_loss: 0.2056 - val_acc: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2656 - acc: 0.8895 - val_loss: 0.2161 - val_acc: 0.9052\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2194 - acc: 0.9133 - val_loss: 0.2210 - val_acc: 0.9177\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss improved from 0.20201 to 0.19894, saving model to best_m.h5\n",
      " - 4s - loss: 0.2483 - acc: 0.8983 - val_loss: 0.1989 - val_acc: 0.9227\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2444 - acc: 0.8931 - val_loss: 0.2067 - val_acc: 0.9102\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2480 - acc: 0.8917 - val_loss: 0.1991 - val_acc: 0.9177\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2544 - acc: 0.8995 - val_loss: 0.2065 - val_acc: 0.9002\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2176 - acc: 0.9117 - val_loss: 0.2117 - val_acc: 0.9177\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2325 - acc: 0.9031 - val_loss: 0.2169 - val_acc: 0.9002\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.19894 to 0.19407, saving model to best_m.h5\n",
      " - 4s - loss: 0.2360 - acc: 0.9000 - val_loss: 0.1941 - val_acc: 0.9152\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss improved from 0.19407 to 0.19003, saving model to best_m.h5\n",
      " - 5s - loss: 0.2245 - acc: 0.9075 - val_loss: 0.1900 - val_acc: 0.9152\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.2258 - acc: 0.9075 - val_loss: 0.1941 - val_acc: 0.9052\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.19003 to 0.18694, saving model to best_m.h5\n",
      " - 4s - loss: 0.2262 - acc: 0.9075 - val_loss: 0.1869 - val_acc: 0.9227\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.1917 - acc: 0.9192 - val_loss: 0.1933 - val_acc: 0.9302\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2076 - acc: 0.9125 - val_loss: 0.1886 - val_acc: 0.9227\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.2499 - acc: 0.9014 - val_loss: 0.1997 - val_acc: 0.9127\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.2156 - acc: 0.9189 - val_loss: 0.1919 - val_acc: 0.9177\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.2219 - acc: 0.9058 - val_loss: 0.2029 - val_acc: 0.9102\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.2050 - acc: 0.9208 - val_loss: 0.1888 - val_acc: 0.9202\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.1939 - acc: 0.9247 - val_loss: 0.2025 - val_acc: 0.9077\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss improved from 0.18694 to 0.18631, saving model to best_m.h5\n",
      " - 4s - loss: 0.2074 - acc: 0.9150 - val_loss: 0.1863 - val_acc: 0.9227\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.2423 - acc: 0.9128 - val_loss: 0.2024 - val_acc: 0.9127\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.1832 - acc: 0.9292 - val_loss: 0.1929 - val_acc: 0.9227\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.2061 - acc: 0.9175 - val_loss: 0.1959 - val_acc: 0.9227\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1901 - acc: 0.9258 - val_loss: 0.1876 - val_acc: 0.9227\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.18631 to 0.18498, saving model to best_m.h5\n",
      " - 5s - loss: 0.2049 - acc: 0.9200 - val_loss: 0.1850 - val_acc: 0.9227\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 5s - loss: 0.2109 - acc: 0.9031 - val_loss: 0.1908 - val_acc: 0.9052\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 5s - loss: 0.2020 - acc: 0.9147 - val_loss: 0.1916 - val_acc: 0.9152\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.1901 - acc: 0.9206 - val_loss: 0.1895 - val_acc: 0.9202\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.1768 - acc: 0.9258 - val_loss: 0.1907 - val_acc: 0.9177\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.1996 - acc: 0.9192 - val_loss: 0.1876 - val_acc: 0.9152\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss improved from 0.18498 to 0.18196, saving model to best_m.h5\n",
      " - 4s - loss: 0.1885 - acc: 0.9225 - val_loss: 0.1820 - val_acc: 0.9302\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 4s - loss: 0.1774 - acc: 0.9283 - val_loss: 0.1823 - val_acc: 0.9277\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.1913 - acc: 0.9208 - val_loss: 0.1900 - val_acc: 0.9202\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.1969 - acc: 0.9150 - val_loss: 0.1876 - val_acc: 0.9277\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 4s - loss: 0.1806 - acc: 0.9292 - val_loss: 0.1908 - val_acc: 0.9277\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 4s - loss: 0.1924 - acc: 0.9133 - val_loss: 0.1842 - val_acc: 0.9352\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 5s - loss: 0.1645 - acc: 0.9350 - val_loss: 0.1901 - val_acc: 0.9252\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.1827 - acc: 0.9225 - val_loss: 0.1846 - val_acc: 0.9277\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss improved from 0.18196 to 0.18145, saving model to best_m.h5\n",
      " - 4s - loss: 0.1610 - acc: 0.9300 - val_loss: 0.1814 - val_acc: 0.9302\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.2210 - acc: 0.9145 - val_loss: 0.1982 - val_acc: 0.9102\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss improved from 0.18145 to 0.18008, saving model to best_m.h5\n",
      " - 4s - loss: 0.1669 - acc: 0.9292 - val_loss: 0.1801 - val_acc: 0.9302\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 4s - loss: 0.1874 - acc: 0.9200 - val_loss: 0.1899 - val_acc: 0.9102\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 4s - loss: 0.1679 - acc: 0.9267 - val_loss: 0.1860 - val_acc: 0.9302\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 4s - loss: 0.1983 - acc: 0.9114 - val_loss: 0.1802 - val_acc: 0.9352\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 4s - loss: 0.1962 - acc: 0.9158 - val_loss: 0.1822 - val_acc: 0.9252\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 4s - loss: 0.1862 - acc: 0.9267 - val_loss: 0.1860 - val_acc: 0.9202\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 4s - loss: 0.1882 - acc: 0.9192 - val_loss: 0.1861 - val_acc: 0.9202\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 4s - loss: 0.1850 - acc: 0.9233 - val_loss: 0.1810 - val_acc: 0.9227\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 4s - loss: 0.1687 - acc: 0.9267 - val_loss: 0.1874 - val_acc: 0.9227\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 4s - loss: 0.1790 - acc: 0.9275 - val_loss: 0.1826 - val_acc: 0.9277\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 4s - loss: 0.1872 - acc: 0.9250 - val_loss: 0.1807 - val_acc: 0.9252\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss improved from 0.18008 to 0.17934, saving model to best_m.h5\n",
      " - 4s - loss: 0.1922 - acc: 0.9289 - val_loss: 0.1793 - val_acc: 0.9252\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 4s - loss: 0.1849 - acc: 0.9231 - val_loss: 0.1833 - val_acc: 0.9277\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 4s - loss: 0.1738 - acc: 0.9267 - val_loss: 0.1815 - val_acc: 0.9202\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 4s - loss: 0.1894 - acc: 0.9206 - val_loss: 0.1876 - val_acc: 0.9202\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 5s - loss: 0.1888 - acc: 0.9256 - val_loss: 0.1829 - val_acc: 0.9202\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 4s - loss: 0.1739 - acc: 0.9317 - val_loss: 0.1817 - val_acc: 0.9277\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss improved from 0.17934 to 0.17798, saving model to best_m.h5\n",
      " - 4s - loss: 0.1952 - acc: 0.9125 - val_loss: 0.1780 - val_acc: 0.9327\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 4s - loss: 0.1757 - acc: 0.9342 - val_loss: 0.1857 - val_acc: 0.9252\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss improved from 0.17798 to 0.17576, saving model to best_m.h5\n",
      " - 4s - loss: 0.1877 - acc: 0.9250 - val_loss: 0.1758 - val_acc: 0.9302\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 4s - loss: 0.1637 - acc: 0.9317 - val_loss: 0.1773 - val_acc: 0.9202\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 4s - loss: 0.1990 - acc: 0.9183 - val_loss: 0.1761 - val_acc: 0.9202\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 4s - loss: 0.1771 - acc: 0.9275 - val_loss: 0.1801 - val_acc: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 4s - loss: 0.2115 - acc: 0.9176 - val_loss: 0.1817 - val_acc: 0.9127\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 4s - loss: 0.1572 - acc: 0.9292 - val_loss: 0.1800 - val_acc: 0.9202\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 4s - loss: 0.1747 - acc: 0.9275 - val_loss: 0.1769 - val_acc: 0.9152\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 4s - loss: 0.1677 - acc: 0.9292 - val_loss: 0.1784 - val_acc: 0.9252\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 4s - loss: 0.1840 - acc: 0.9141 - val_loss: 0.1777 - val_acc: 0.9177\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 4s - loss: 0.1766 - acc: 0.9308 - val_loss: 0.1782 - val_acc: 0.9252\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 4s - loss: 0.1828 - acc: 0.9181 - val_loss: 0.1829 - val_acc: 0.9252\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss improved from 0.17576 to 0.17562, saving model to best_m.h5\n",
      " - 4s - loss: 0.1560 - acc: 0.9367 - val_loss: 0.1756 - val_acc: 0.9227\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 4s - loss: 0.1824 - acc: 0.9206 - val_loss: 0.1779 - val_acc: 0.9202\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 4s - loss: 0.1614 - acc: 0.9333 - val_loss: 0.1895 - val_acc: 0.9227\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 4s - loss: 0.1947 - acc: 0.9167 - val_loss: 0.1906 - val_acc: 0.9227\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 4s - loss: 0.1531 - acc: 0.9266 - val_loss: 0.1810 - val_acc: 0.9152\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 4s - loss: 0.1803 - acc: 0.9292 - val_loss: 0.1798 - val_acc: 0.9177\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 4s - loss: 0.1958 - acc: 0.9237 - val_loss: 0.1964 - val_acc: 0.9227\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 5s - loss: 0.1756 - acc: 0.9231 - val_loss: 0.1886 - val_acc: 0.9127\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.71137, saving model to best_m.h5\n",
      " - 17s - loss: 0.5866 - acc: 0.7191 - val_loss: 0.7114 - val_acc: 0.4888\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.71137 to 0.67032, saving model to best_m.h5\n",
      " - 4s - loss: 0.4556 - acc: 0.7916 - val_loss: 0.6703 - val_acc: 0.6334\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.67032 to 0.58518, saving model to best_m.h5\n",
      " - 4s - loss: 0.3556 - acc: 0.8239 - val_loss: 0.5852 - val_acc: 0.7257\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 4s - loss: 0.3801 - acc: 0.8408 - val_loss: 1.4511 - val_acc: 0.5761\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 4s - loss: 0.3733 - acc: 0.8489 - val_loss: 1.0634 - val_acc: 0.5711\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.58518 to 0.31225, saving model to best_m.h5\n",
      " - 4s - loss: 0.3350 - acc: 0.8475 - val_loss: 0.3122 - val_acc: 0.8703\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3130 - acc: 0.8675 - val_loss: 0.3641 - val_acc: 0.8404\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3598 - acc: 0.8508 - val_loss: 0.5599 - val_acc: 0.7431\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3097 - acc: 0.8516 - val_loss: 0.3280 - val_acc: 0.8429\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.31225 to 0.25993, saving model to best_m.h5\n",
      " - 4s - loss: 0.3249 - acc: 0.8725 - val_loss: 0.2599 - val_acc: 0.8778\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3601 - acc: 0.8522 - val_loss: 0.3070 - val_acc: 0.8778\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss improved from 0.25993 to 0.25003, saving model to best_m.h5\n",
      " - 4s - loss: 0.2601 - acc: 0.8883 - val_loss: 0.2500 - val_acc: 0.8878\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.2968 - acc: 0.8841 - val_loss: 0.7896 - val_acc: 0.7332\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.25003 to 0.24166, saving model to best_m.h5\n",
      " - 5s - loss: 0.3426 - acc: 0.8604 - val_loss: 0.2417 - val_acc: 0.8903\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.2770 - acc: 0.8883 - val_loss: 0.2820 - val_acc: 0.8628\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2737 - acc: 0.8725 - val_loss: 0.2675 - val_acc: 0.8853\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.24166 to 0.20299, saving model to best_m.h5\n",
      " - 4s - loss: 0.2415 - acc: 0.9025 - val_loss: 0.2030 - val_acc: 0.9327\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 4s - loss: 0.2249 - acc: 0.9058 - val_loss: 0.2045 - val_acc: 0.9227\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2472 - acc: 0.8962 - val_loss: 0.2213 - val_acc: 0.9152\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2582 - acc: 0.9056 - val_loss: 0.2155 - val_acc: 0.9152\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss improved from 0.20299 to 0.19722, saving model to best_m.h5\n",
      " - 4s - loss: 0.2275 - acc: 0.9017 - val_loss: 0.1972 - val_acc: 0.9202\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2299 - acc: 0.9067 - val_loss: 0.2654 - val_acc: 0.8753\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2564 - acc: 0.8931 - val_loss: 0.2135 - val_acc: 0.9177\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2244 - acc: 0.9037 - val_loss: 0.2135 - val_acc: 0.9202\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2238 - acc: 0.9100 - val_loss: 0.2104 - val_acc: 0.9127\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.1984 - acc: 0.9200 - val_loss: 0.2024 - val_acc: 0.9252\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2158 - acc: 0.9083 - val_loss: 0.2079 - val_acc: 0.9202\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2069 - acc: 0.9167 - val_loss: 0.2155 - val_acc: 0.9177\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2014 - acc: 0.9183 - val_loss: 0.2180 - val_acc: 0.9102\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2265 - acc: 0.9100 - val_loss: 0.2167 - val_acc: 0.9202\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2018 - acc: 0.9192 - val_loss: 0.2109 - val_acc: 0.9227\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.1922 - acc: 0.9208 - val_loss: 0.2015 - val_acc: 0.9177\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss improved from 0.19722 to 0.19530, saving model to best_m.h5\n",
      " - 4s - loss: 0.1970 - acc: 0.9250 - val_loss: 0.1953 - val_acc: 0.9252\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.1972 - acc: 0.9217 - val_loss: 0.2023 - val_acc: 0.9202\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.2374 - acc: 0.9020 - val_loss: 0.2021 - val_acc: 0.9327\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.1993 - acc: 0.9100 - val_loss: 0.2225 - val_acc: 0.9127\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.1972 - acc: 0.9167 - val_loss: 0.2217 - val_acc: 0.9102\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.1831 - acc: 0.9225 - val_loss: 0.2240 - val_acc: 0.9077\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.2169 - acc: 0.9079 - val_loss: 0.1966 - val_acc: 0.9227\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.1901 - acc: 0.9225 - val_loss: 0.1981 - val_acc: 0.9227\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss improved from 0.19530 to 0.19210, saving model to best_m.h5\n",
      " - 4s - loss: 0.2006 - acc: 0.9089 - val_loss: 0.1921 - val_acc: 0.9252\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.1766 - acc: 0.9217 - val_loss: 0.1995 - val_acc: 0.9177\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.1831 - acc: 0.9217 - val_loss: 0.1924 - val_acc: 0.9377\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss improved from 0.19210 to 0.19149, saving model to best_m.h5\n",
      " - 4s - loss: 0.2136 - acc: 0.9123 - val_loss: 0.1915 - val_acc: 0.9277\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.2157 - acc: 0.9148 - val_loss: 0.2028 - val_acc: 0.9227\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1974 - acc: 0.9181 - val_loss: 0.1970 - val_acc: 0.9252\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.1864 - acc: 0.9175 - val_loss: 0.1981 - val_acc: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.1981 - acc: 0.9281 - val_loss: 0.1940 - val_acc: 0.9252\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.2036 - acc: 0.9073 - val_loss: 0.1947 - val_acc: 0.9252\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.1684 - acc: 0.9267 - val_loss: 0.1916 - val_acc: 0.9277\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.1855 - acc: 0.9214 - val_loss: 0.1925 - val_acc: 0.9277\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss improved from 0.19149 to 0.19091, saving model to best_m.h5\n",
      " - 4s - loss: 0.1924 - acc: 0.9150 - val_loss: 0.1909 - val_acc: 0.9277\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.1735 - acc: 0.9333 - val_loss: 0.1931 - val_acc: 0.9277\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 4s - loss: 0.1692 - acc: 0.9267 - val_loss: 0.1932 - val_acc: 0.9277\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.1854 - acc: 0.9217 - val_loss: 0.1950 - val_acc: 0.9202\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.2018 - acc: 0.9183 - val_loss: 0.1934 - val_acc: 0.9277\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 4s - loss: 0.2014 - acc: 0.9142 - val_loss: 0.1952 - val_acc: 0.9277\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 4s - loss: 0.1628 - acc: 0.9325 - val_loss: 0.1959 - val_acc: 0.9252\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 4s - loss: 0.1924 - acc: 0.9108 - val_loss: 0.1986 - val_acc: 0.9227\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.1685 - acc: 0.9175 - val_loss: 0.1984 - val_acc: 0.9177\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 4s - loss: 0.1729 - acc: 0.9367 - val_loss: 0.1955 - val_acc: 0.9277\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.1734 - acc: 0.9342 - val_loss: 0.1968 - val_acc: 0.9277\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 4s - loss: 0.1790 - acc: 0.9217 - val_loss: 0.1979 - val_acc: 0.9227\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 4s - loss: 0.1826 - acc: 0.9275 - val_loss: 0.1989 - val_acc: 0.9252\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 4s - loss: 0.1831 - acc: 0.9275 - val_loss: 0.2062 - val_acc: 0.9227\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 4s - loss: 0.1665 - acc: 0.9366 - val_loss: 0.2034 - val_acc: 0.9202\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 4s - loss: 0.1867 - acc: 0.9208 - val_loss: 0.1991 - val_acc: 0.9202\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 4s - loss: 0.1944 - acc: 0.9145 - val_loss: 0.2055 - val_acc: 0.9177\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 4s - loss: 0.2183 - acc: 0.9004 - val_loss: 0.1964 - val_acc: 0.9277\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 4s - loss: 0.1838 - acc: 0.9175 - val_loss: 0.1931 - val_acc: 0.9277\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 4s - loss: 0.1735 - acc: 0.9317 - val_loss: 0.1948 - val_acc: 0.9277\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 4s - loss: 0.1898 - acc: 0.9223 - val_loss: 0.2063 - val_acc: 0.9152\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.78724, saving model to best_m.h5\n",
      " - 23s - loss: 0.5650 - acc: 0.7183 - val_loss: 0.7872 - val_acc: 0.4613\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.78724 to 0.63142, saving model to best_m.h5\n",
      " - 4s - loss: 0.4199 - acc: 0.8158 - val_loss: 0.6314 - val_acc: 0.5786\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.63142 to 0.39081, saving model to best_m.h5\n",
      " - 4s - loss: 0.4179 - acc: 0.8295 - val_loss: 0.3908 - val_acc: 0.7855\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 4s - loss: 0.3771 - acc: 0.8266 - val_loss: 0.4161 - val_acc: 0.8155\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.39081 to 0.34651, saving model to best_m.h5\n",
      " - 4s - loss: 0.3586 - acc: 0.8391 - val_loss: 0.3465 - val_acc: 0.8329\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3447 - acc: 0.8466 - val_loss: 0.5167 - val_acc: 0.8229\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.34651 to 0.26097, saving model to best_m.h5\n",
      " - 4s - loss: 0.3783 - acc: 0.8335 - val_loss: 0.2610 - val_acc: 0.8753\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3580 - acc: 0.8376 - val_loss: 0.2767 - val_acc: 0.8778\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3418 - acc: 0.8522 - val_loss: 0.6865 - val_acc: 0.6209\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 4s - loss: 0.3078 - acc: 0.8700 - val_loss: 0.3209 - val_acc: 0.8229\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3353 - acc: 0.8501 - val_loss: 0.4005 - val_acc: 0.7855\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.2893 - acc: 0.8733 - val_loss: 0.8450 - val_acc: 0.6160\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss improved from 0.26097 to 0.22792, saving model to best_m.h5\n",
      " - 4s - loss: 0.3040 - acc: 0.8716 - val_loss: 0.2279 - val_acc: 0.9202\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.3229 - acc: 0.8608 - val_loss: 1.5199 - val_acc: 0.7007\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.2706 - acc: 0.8883 - val_loss: 0.2655 - val_acc: 0.8678\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.3090 - acc: 0.8812 - val_loss: 0.2554 - val_acc: 0.8678\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.22792 to 0.20684, saving model to best_m.h5\n",
      " - 4s - loss: 0.2766 - acc: 0.8900 - val_loss: 0.2068 - val_acc: 0.9102\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.20684 to 0.19190, saving model to best_m.h5\n",
      " - 4s - loss: 0.2708 - acc: 0.8920 - val_loss: 0.1919 - val_acc: 0.9327\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.19190 to 0.18845, saving model to best_m.h5\n",
      " - 4s - loss: 0.2352 - acc: 0.9050 - val_loss: 0.1884 - val_acc: 0.9252\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2534 - acc: 0.9067 - val_loss: 0.2081 - val_acc: 0.9052\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2482 - acc: 0.9000 - val_loss: 0.1930 - val_acc: 0.9252\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2504 - acc: 0.8933 - val_loss: 0.2125 - val_acc: 0.9077\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2341 - acc: 0.9058 - val_loss: 0.2033 - val_acc: 0.9127\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss improved from 0.18845 to 0.17076, saving model to best_m.h5\n",
      " - 4s - loss: 0.2232 - acc: 0.9150 - val_loss: 0.1708 - val_acc: 0.9227\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2318 - acc: 0.9039 - val_loss: 0.2046 - val_acc: 0.9127\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.3024 - acc: 0.8731 - val_loss: 0.1951 - val_acc: 0.9327\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2143 - acc: 0.9089 - val_loss: 0.1883 - val_acc: 0.9152\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2440 - acc: 0.9017 - val_loss: 0.1742 - val_acc: 0.9327\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2141 - acc: 0.9242 - val_loss: 0.1978 - val_acc: 0.9277\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2229 - acc: 0.9108 - val_loss: 0.1719 - val_acc: 0.9401\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2292 - acc: 0.9075 - val_loss: 0.1742 - val_acc: 0.9227\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.2018 - acc: 0.9250 - val_loss: 0.1814 - val_acc: 0.9277\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.2347 - acc: 0.9106 - val_loss: 0.1831 - val_acc: 0.9252\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.2037 - acc: 0.9258 - val_loss: 0.1722 - val_acc: 0.9252\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss improved from 0.17076 to 0.16694, saving model to best_m.h5\n",
      " - 4s - loss: 0.1799 - acc: 0.9217 - val_loss: 0.1669 - val_acc: 0.9377\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2483 - acc: 0.9008 - val_loss: 0.1895 - val_acc: 0.9252\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.2042 - acc: 0.9183 - val_loss: 0.1875 - val_acc: 0.9177\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.2234 - acc: 0.9067 - val_loss: 0.1841 - val_acc: 0.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.2190 - acc: 0.9070 - val_loss: 0.1718 - val_acc: 0.9252\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.1994 - acc: 0.9233 - val_loss: 0.1698 - val_acc: 0.9352\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.1935 - acc: 0.9208 - val_loss: 0.1938 - val_acc: 0.9152\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.2098 - acc: 0.9189 - val_loss: 0.1719 - val_acc: 0.9352\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.2184 - acc: 0.9075 - val_loss: 0.1861 - val_acc: 0.9352\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.2180 - acc: 0.9043 - val_loss: 0.1778 - val_acc: 0.9377\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.2153 - acc: 0.9125 - val_loss: 0.1830 - val_acc: 0.9277\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1981 - acc: 0.9150 - val_loss: 0.1702 - val_acc: 0.9302\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.2193 - acc: 0.9008 - val_loss: 0.1701 - val_acc: 0.9352\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.1918 - acc: 0.9166 - val_loss: 0.1717 - val_acc: 0.9277\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.1797 - acc: 0.9267 - val_loss: 0.1697 - val_acc: 0.9352\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.1810 - acc: 0.9350 - val_loss: 0.1682 - val_acc: 0.9327\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.2078 - acc: 0.9029 - val_loss: 0.1754 - val_acc: 0.9277\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.2043 - acc: 0.9137 - val_loss: 0.1691 - val_acc: 0.9352\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.2157 - acc: 0.9189 - val_loss: 0.1722 - val_acc: 0.9277\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 4s - loss: 0.2077 - acc: 0.9100 - val_loss: 0.1704 - val_acc: 0.9352\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.1753 - acc: 0.9333 - val_loss: 0.1695 - val_acc: 0.9352\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=9):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_incept_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201199186747\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.075037\n",
      "1  4023181e    0.875867\n",
      "2  b20200e4    0.056142\n",
      "3  e7f018bb    0.998137\n",
      "4  4371c8c3    0.311983\n"
     ]
    }
   ],
   "source": [
    "with open('../features/incept_aug3_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/incept_aug3_sub.csv', index=False)\n",
    "# deep2 0.2110\n",
    "# deep3 0.2119\n",
    "\n",
    "# deep3 new 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    \n",
    "    x = Conv2D(128, 3, strides=2, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70379, saving model to best_m.h5\n",
      " - 26s - loss: 1.2550 - acc: 0.5603 - val_loss: 0.7038 - val_acc: 0.4663\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5912 - acc: 0.6662 - val_loss: 0.7226 - val_acc: 0.4663\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.70379 to 0.66071, saving model to best_m.h5\n",
      " - 6s - loss: 0.5339 - acc: 0.7733 - val_loss: 0.6607 - val_acc: 0.5786\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4741 - acc: 0.8183 - val_loss: 0.6636 - val_acc: 0.5985\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.66071 to 0.49273, saving model to best_m.h5\n",
      " - 6s - loss: 0.4396 - acc: 0.8116 - val_loss: 0.4927 - val_acc: 0.7855\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.4372 - acc: 0.8125 - val_loss: 0.5870 - val_acc: 0.7756\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.49273 to 0.46280, saving model to best_m.h5\n",
      " - 6s - loss: 0.4488 - acc: 0.8164 - val_loss: 0.4628 - val_acc: 0.7830\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4820 - acc: 0.7889 - val_loss: 0.5768 - val_acc: 0.7456\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4960 - acc: 0.8045 - val_loss: 0.4812 - val_acc: 0.7955\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4762 - acc: 0.8056 - val_loss: 0.6063 - val_acc: 0.8204\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4734 - acc: 0.8006 - val_loss: 0.4907 - val_acc: 0.7706\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4763 - acc: 0.8072 - val_loss: 1.0092 - val_acc: 0.7456\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4210 - acc: 0.8264 - val_loss: 0.4874 - val_acc: 0.7706\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.46280 to 0.44947, saving model to best_m.h5\n",
      " - 6s - loss: 0.4591 - acc: 0.8258 - val_loss: 0.4495 - val_acc: 0.7930\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss improved from 0.44947 to 0.44703, saving model to best_m.h5\n",
      " - 6s - loss: 0.4289 - acc: 0.8131 - val_loss: 0.4470 - val_acc: 0.7880\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.44703 to 0.43174, saving model to best_m.h5\n",
      " - 6s - loss: 0.3838 - acc: 0.8362 - val_loss: 0.4317 - val_acc: 0.8005\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.43174 to 0.42272, saving model to best_m.h5\n",
      " - 6s - loss: 0.4011 - acc: 0.8370 - val_loss: 0.4227 - val_acc: 0.7980\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.3986 - acc: 0.8518 - val_loss: 0.5396 - val_acc: 0.7332\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3808 - acc: 0.8542 - val_loss: 0.4322 - val_acc: 0.8030\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss improved from 0.42272 to 0.41260, saving model to best_m.h5\n",
      " - 6s - loss: 0.3450 - acc: 0.8625 - val_loss: 0.4126 - val_acc: 0.8105\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss improved from 0.41260 to 0.40563, saving model to best_m.h5\n",
      " - 6s - loss: 0.3582 - acc: 0.8566 - val_loss: 0.4056 - val_acc: 0.8279\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.3561 - acc: 0.8600 - val_loss: 0.4078 - val_acc: 0.8155\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3253 - acc: 0.8716 - val_loss: 0.4064 - val_acc: 0.8155\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3502 - acc: 0.8725 - val_loss: 0.4697 - val_acc: 0.7756\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3343 - acc: 0.8700 - val_loss: 0.4182 - val_acc: 0.8130\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss improved from 0.40563 to 0.39173, saving model to best_m.h5\n",
      " - 6s - loss: 0.3252 - acc: 0.8700 - val_loss: 0.3917 - val_acc: 0.8304\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3348 - acc: 0.8589 - val_loss: 0.3948 - val_acc: 0.8254\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss improved from 0.39173 to 0.36832, saving model to best_m.h5\n",
      " - 6s - loss: 0.3429 - acc: 0.8692 - val_loss: 0.3683 - val_acc: 0.8454\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.4012 - acc: 0.8434 - val_loss: 0.4503 - val_acc: 0.7955\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.3299 - acc: 0.8675 - val_loss: 0.3740 - val_acc: 0.8329\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.3054 - acc: 0.8825 - val_loss: 0.3688 - val_acc: 0.8379\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.3097 - acc: 0.8858 - val_loss: 0.3689 - val_acc: 0.8429\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss improved from 0.36832 to 0.35401, saving model to best_m.h5\n",
      " - 6s - loss: 0.3089 - acc: 0.8833 - val_loss: 0.3540 - val_acc: 0.8504\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.35401 to 0.33915, saving model to best_m.h5\n",
      " - 6s - loss: 0.3502 - acc: 0.8487 - val_loss: 0.3392 - val_acc: 0.8529\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.3202 - acc: 0.8803 - val_loss: 0.3521 - val_acc: 0.8354\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2828 - acc: 0.8833 - val_loss: 0.3830 - val_acc: 0.8354\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2857 - acc: 0.8883 - val_loss: 0.3660 - val_acc: 0.8379\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2839 - acc: 0.8867 - val_loss: 0.3568 - val_acc: 0.8429\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2887 - acc: 0.8867 - val_loss: 0.3445 - val_acc: 0.8479\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2625 - acc: 0.8983 - val_loss: 0.3456 - val_acc: 0.8554\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.3161 - acc: 0.8764 - val_loss: 0.3589 - val_acc: 0.8429\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2885 - acc: 0.8929 - val_loss: 0.3481 - val_acc: 0.8479\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2852 - acc: 0.8864 - val_loss: 0.3456 - val_acc: 0.8479\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss improved from 0.33915 to 0.33392, saving model to best_m.h5\n",
      " - 6s - loss: 0.2756 - acc: 0.8908 - val_loss: 0.3339 - val_acc: 0.8554\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2875 - acc: 0.8789 - val_loss: 0.3418 - val_acc: 0.8379\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2559 - acc: 0.8975 - val_loss: 0.3348 - val_acc: 0.8554\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.33392 to 0.32662, saving model to best_m.h5\n",
      " - 6s - loss: 0.2641 - acc: 0.9122 - val_loss: 0.3266 - val_acc: 0.8504\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2491 - acc: 0.9033 - val_loss: 0.3316 - val_acc: 0.8554\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2601 - acc: 0.8983 - val_loss: 0.3434 - val_acc: 0.8579\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2825 - acc: 0.8981 - val_loss: 0.3368 - val_acc: 0.8454\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2769 - acc: 0.8950 - val_loss: 0.3449 - val_acc: 0.8454\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2812 - acc: 0.8831 - val_loss: 0.3323 - val_acc: 0.8579\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2561 - acc: 0.9133 - val_loss: 0.3456 - val_acc: 0.8479\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss improved from 0.32662 to 0.32285, saving model to best_m.h5\n",
      " - 6s - loss: 0.2745 - acc: 0.8850 - val_loss: 0.3228 - val_acc: 0.8603\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.32285 to 0.32076, saving model to best_m.h5\n",
      " - 6s - loss: 0.2488 - acc: 0.9108 - val_loss: 0.3208 - val_acc: 0.8678\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2784 - acc: 0.8973 - val_loss: 0.3244 - val_acc: 0.8678\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2427 - acc: 0.9075 - val_loss: 0.3213 - val_acc: 0.8603\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2647 - acc: 0.9000 - val_loss: 0.3303 - val_acc: 0.8603\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2602 - acc: 0.9008 - val_loss: 0.3253 - val_acc: 0.8628\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2610 - acc: 0.8964 - val_loss: 0.3230 - val_acc: 0.8579\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2608 - acc: 0.9025 - val_loss: 0.3336 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2626 - acc: 0.9148 - val_loss: 0.3339 - val_acc: 0.8529\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2416 - acc: 0.9106 - val_loss: 0.3304 - val_acc: 0.8579\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2279 - acc: 0.9192 - val_loss: 0.3359 - val_acc: 0.8529\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2665 - acc: 0.9058 - val_loss: 0.3328 - val_acc: 0.8529\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2531 - acc: 0.9008 - val_loss: 0.3236 - val_acc: 0.8703\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.2600 - acc: 0.8933 - val_loss: 0.3271 - val_acc: 0.8678\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2439 - acc: 0.9073 - val_loss: 0.3279 - val_acc: 0.8628\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2435 - acc: 0.9058 - val_loss: 0.3288 - val_acc: 0.8529\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.2493 - acc: 0.9067 - val_loss: 0.3443 - val_acc: 0.8504\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss improved from 0.32076 to 0.31944, saving model to best_m.h5\n",
      " - 6s - loss: 0.2617 - acc: 0.8973 - val_loss: 0.3194 - val_acc: 0.8653\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2459 - acc: 0.9070 - val_loss: 0.3305 - val_acc: 0.8504\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss improved from 0.31944 to 0.31207, saving model to best_m.h5\n",
      " - 6s - loss: 0.2371 - acc: 0.9039 - val_loss: 0.3121 - val_acc: 0.8603\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.2486 - acc: 0.9008 - val_loss: 0.3191 - val_acc: 0.8678\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2376 - acc: 0.9108 - val_loss: 0.3274 - val_acc: 0.8579\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2414 - acc: 0.9056 - val_loss: 0.3130 - val_acc: 0.8628\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss improved from 0.31207 to 0.31116, saving model to best_m.h5\n",
      " - 6s - loss: 0.2466 - acc: 0.8956 - val_loss: 0.3112 - val_acc: 0.8628\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2439 - acc: 0.9123 - val_loss: 0.3253 - val_acc: 0.8603\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss improved from 0.31116 to 0.30890, saving model to best_m.h5\n",
      " - 6s - loss: 0.2507 - acc: 0.9025 - val_loss: 0.3089 - val_acc: 0.8554\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.2321 - acc: 0.9150 - val_loss: 0.3203 - val_acc: 0.8728\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.2655 - acc: 0.8947 - val_loss: 0.3126 - val_acc: 0.8678\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.2442 - acc: 0.9056 - val_loss: 0.3326 - val_acc: 0.8554\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2515 - acc: 0.9073 - val_loss: 0.3136 - val_acc: 0.8678\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.2455 - acc: 0.9100 - val_loss: 0.3145 - val_acc: 0.8628\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.2344 - acc: 0.9092 - val_loss: 0.3136 - val_acc: 0.8678\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.2322 - acc: 0.9106 - val_loss: 0.3098 - val_acc: 0.8653\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 0.2333 - acc: 0.9079 - val_loss: 0.3261 - val_acc: 0.8579\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 6s - loss: 0.2418 - acc: 0.9042 - val_loss: 0.3216 - val_acc: 0.8603\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 6s - loss: 0.2656 - acc: 0.9060 - val_loss: 0.3249 - val_acc: 0.8579\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.2513 - acc: 0.9092 - val_loss: 0.3135 - val_acc: 0.8628\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss improved from 0.30890 to 0.30707, saving model to best_m.h5\n",
      " - 6s - loss: 0.2544 - acc: 0.9075 - val_loss: 0.3071 - val_acc: 0.8653\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.2421 - acc: 0.9017 - val_loss: 0.3270 - val_acc: 0.8454\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.2405 - acc: 0.9158 - val_loss: 0.3177 - val_acc: 0.8628\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 6s - loss: 0.2419 - acc: 0.9158 - val_loss: 0.3140 - val_acc: 0.8728\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 0.2168 - acc: 0.9217 - val_loss: 0.3117 - val_acc: 0.8703\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 6s - loss: 0.2421 - acc: 0.9125 - val_loss: 0.3260 - val_acc: 0.8628\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 6s - loss: 0.2494 - acc: 0.9056 - val_loss: 0.3228 - val_acc: 0.8603\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 6s - loss: 0.2431 - acc: 0.9050 - val_loss: 0.3115 - val_acc: 0.8678\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 6s - loss: 0.2245 - acc: 0.9175 - val_loss: 0.3200 - val_acc: 0.8603\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 6s - loss: 0.2391 - acc: 0.9042 - val_loss: 0.3127 - val_acc: 0.8653\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.71442, saving model to best_m.h5\n",
      " - 31s - loss: 1.3530 - acc: 0.5930 - val_loss: 0.7144 - val_acc: 0.4589\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5727 - acc: 0.6908 - val_loss: 0.7935 - val_acc: 0.4589\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4859 - acc: 0.7642 - val_loss: 1.0028 - val_acc: 0.5786\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.5187 - acc: 0.7874 - val_loss: 1.0956 - val_acc: 0.5486\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 6s - loss: 0.4662 - acc: 0.7958 - val_loss: 1.3535 - val_acc: 0.6010\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.71442 to 0.67702, saving model to best_m.h5\n",
      " - 6s - loss: 0.4169 - acc: 0.8008 - val_loss: 0.6770 - val_acc: 0.7731\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.4341 - acc: 0.8025 - val_loss: 0.6916 - val_acc: 0.5835\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4180 - acc: 0.7931 - val_loss: 0.7081 - val_acc: 0.7606\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.67702 to 0.38367, saving model to best_m.h5\n",
      " - 6s - loss: 0.4021 - acc: 0.8258 - val_loss: 0.3837 - val_acc: 0.8005\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.38367 to 0.30628, saving model to best_m.h5\n",
      " - 6s - loss: 0.3892 - acc: 0.8264 - val_loss: 0.3063 - val_acc: 0.8554\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4255 - acc: 0.7989 - val_loss: 0.3530 - val_acc: 0.8229\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.3986 - acc: 0.8216 - val_loss: 0.4905 - val_acc: 0.8030\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4255 - acc: 0.8297 - val_loss: 0.4294 - val_acc: 0.8479\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3994 - acc: 0.8264 - val_loss: 0.4522 - val_acc: 0.7805\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3965 - acc: 0.8239 - val_loss: 0.3294 - val_acc: 0.8803\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.30628 to 0.30308, saving model to best_m.h5\n",
      " - 6s - loss: 0.3619 - acc: 0.8306 - val_loss: 0.3031 - val_acc: 0.8529\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.30308 to 0.23831, saving model to best_m.h5\n",
      " - 6s - loss: 0.3296 - acc: 0.8516 - val_loss: 0.2383 - val_acc: 0.8828\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.3344 - acc: 0.8550 - val_loss: 0.2408 - val_acc: 0.8853\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3191 - acc: 0.8572 - val_loss: 0.2453 - val_acc: 0.8878\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss improved from 0.23831 to 0.22502, saving model to best_m.h5\n",
      " - 6s - loss: 0.3453 - acc: 0.8550 - val_loss: 0.2250 - val_acc: 0.8978\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 7s - loss: 0.3400 - acc: 0.8608 - val_loss: 0.2545 - val_acc: 0.8928\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss improved from 0.22502 to 0.21912, saving model to best_m.h5\n",
      " - 6s - loss: 0.2896 - acc: 0.8708 - val_loss: 0.2191 - val_acc: 0.9177\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3159 - acc: 0.8506 - val_loss: 0.2392 - val_acc: 0.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3094 - acc: 0.8673 - val_loss: 0.2697 - val_acc: 0.8903\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3216 - acc: 0.8554 - val_loss: 0.3294 - val_acc: 0.8653\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.3223 - acc: 0.8617 - val_loss: 0.2415 - val_acc: 0.8878\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3187 - acc: 0.8545 - val_loss: 0.2329 - val_acc: 0.9177\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss improved from 0.21912 to 0.21131, saving model to best_m.h5\n",
      " - 6s - loss: 0.3078 - acc: 0.8641 - val_loss: 0.2113 - val_acc: 0.9152\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2931 - acc: 0.8783 - val_loss: 0.2262 - val_acc: 0.8878\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss improved from 0.21131 to 0.20529, saving model to best_m.h5\n",
      " - 6s - loss: 0.2785 - acc: 0.8800 - val_loss: 0.2053 - val_acc: 0.9102\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2802 - acc: 0.8856 - val_loss: 0.2186 - val_acc: 0.9127\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2749 - acc: 0.8866 - val_loss: 0.2370 - val_acc: 0.8928\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2745 - acc: 0.8775 - val_loss: 0.2267 - val_acc: 0.9152\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.20529 to 0.19729, saving model to best_m.h5\n",
      " - 6s - loss: 0.2465 - acc: 0.9000 - val_loss: 0.1973 - val_acc: 0.9277\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.3085 - acc: 0.8704 - val_loss: 0.2273 - val_acc: 0.9177\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2816 - acc: 0.8858 - val_loss: 0.2094 - val_acc: 0.9127\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss improved from 0.19729 to 0.18691, saving model to best_m.h5\n",
      " - 6s - loss: 0.2616 - acc: 0.9000 - val_loss: 0.1869 - val_acc: 0.9152\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2817 - acc: 0.8848 - val_loss: 0.2051 - val_acc: 0.9302\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.3068 - acc: 0.8637 - val_loss: 0.2109 - val_acc: 0.9227\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2765 - acc: 0.8858 - val_loss: 0.2026 - val_acc: 0.9352\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2574 - acc: 0.8983 - val_loss: 0.2066 - val_acc: 0.9177\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.3025 - acc: 0.8701 - val_loss: 0.2413 - val_acc: 0.9177\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2742 - acc: 0.8800 - val_loss: 0.2100 - val_acc: 0.9177\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2754 - acc: 0.8848 - val_loss: 0.1962 - val_acc: 0.9202\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2932 - acc: 0.8825 - val_loss: 0.1950 - val_acc: 0.9401\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2426 - acc: 0.8967 - val_loss: 0.1914 - val_acc: 0.9377\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2569 - acc: 0.8904 - val_loss: 0.1895 - val_acc: 0.9302\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.3061 - acc: 0.8787 - val_loss: 0.1983 - val_acc: 0.9352\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2734 - acc: 0.8758 - val_loss: 0.1920 - val_acc: 0.9327\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2646 - acc: 0.8897 - val_loss: 0.1967 - val_acc: 0.9302\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2390 - acc: 0.9083 - val_loss: 0.1940 - val_acc: 0.9377\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2630 - acc: 0.8917 - val_loss: 0.1896 - val_acc: 0.9302\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2575 - acc: 0.8931 - val_loss: 0.2057 - val_acc: 0.9227\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.2400 - acc: 0.8950 - val_loss: 0.1995 - val_acc: 0.9302\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2653 - acc: 0.8992 - val_loss: 0.1904 - val_acc: 0.9327\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2581 - acc: 0.8925 - val_loss: 0.1916 - val_acc: 0.9401\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2577 - acc: 0.8973 - val_loss: 0.1897 - val_acc: 0.9377\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.69462, saving model to best_m.h5\n",
      " - 35s - loss: 1.3037 - acc: 0.5791 - val_loss: 0.6946 - val_acc: 0.4938\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5854 - acc: 0.7047 - val_loss: 0.8541 - val_acc: 0.4913\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4686 - acc: 0.7841 - val_loss: 1.0200 - val_acc: 0.5137\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4567 - acc: 0.7912 - val_loss: 1.2069 - val_acc: 0.6409\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.69462 to 0.50496, saving model to best_m.h5\n",
      " - 6s - loss: 0.4525 - acc: 0.7789 - val_loss: 0.5050 - val_acc: 0.7880\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.50496 to 0.34825, saving model to best_m.h5\n",
      " - 6s - loss: 0.4217 - acc: 0.8050 - val_loss: 0.3483 - val_acc: 0.8603\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.4479 - acc: 0.8058 - val_loss: 0.3733 - val_acc: 0.8429\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.34825 to 0.34290, saving model to best_m.h5\n",
      " - 6s - loss: 0.4544 - acc: 0.7664 - val_loss: 0.3429 - val_acc: 0.8479\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4803 - acc: 0.7595 - val_loss: 0.5868 - val_acc: 0.6908\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4666 - acc: 0.7625 - val_loss: 2.1543 - val_acc: 0.5761\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4528 - acc: 0.7758 - val_loss: 0.3667 - val_acc: 0.7706\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4482 - acc: 0.7847 - val_loss: 0.6977 - val_acc: 0.6584\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.3836 - acc: 0.8200 - val_loss: 0.3554 - val_acc: 0.8603\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.34290 to 0.34016, saving model to best_m.h5\n",
      " - 6s - loss: 0.4003 - acc: 0.8281 - val_loss: 0.3402 - val_acc: 0.8254\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss improved from 0.34016 to 0.29505, saving model to best_m.h5\n",
      " - 6s - loss: 0.3524 - acc: 0.8533 - val_loss: 0.2950 - val_acc: 0.8703\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.29505 to 0.28197, saving model to best_m.h5\n",
      " - 6s - loss: 0.3283 - acc: 0.8575 - val_loss: 0.2820 - val_acc: 0.8753\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.3249 - acc: 0.8481 - val_loss: 0.3349 - val_acc: 0.8304\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.3619 - acc: 0.8379 - val_loss: 0.3202 - val_acc: 0.8678\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.28197 to 0.26065, saving model to best_m.h5\n",
      " - 6s - loss: 0.2951 - acc: 0.8683 - val_loss: 0.2607 - val_acc: 0.8978\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.3302 - acc: 0.8614 - val_loss: 0.2825 - val_acc: 0.8728\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2924 - acc: 0.8725 - val_loss: 0.2673 - val_acc: 0.8953\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.3066 - acc: 0.8737 - val_loss: 0.2853 - val_acc: 0.8703\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3108 - acc: 0.8508 - val_loss: 0.3067 - val_acc: 0.8579\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3139 - acc: 0.8648 - val_loss: 0.2926 - val_acc: 0.8853\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss improved from 0.26065 to 0.25009, saving model to best_m.h5\n",
      " - 6s - loss: 0.3049 - acc: 0.8791 - val_loss: 0.2501 - val_acc: 0.8928\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.3090 - acc: 0.8603 - val_loss: 0.3490 - val_acc: 0.8554\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2784 - acc: 0.8867 - val_loss: 0.2754 - val_acc: 0.8928\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.3042 - acc: 0.8600 - val_loss: 0.2931 - val_acc: 0.8828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2567 - acc: 0.8931 - val_loss: 0.2556 - val_acc: 0.8928\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.3015 - acc: 0.8739 - val_loss: 0.2793 - val_acc: 0.8928\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2771 - acc: 0.8791 - val_loss: 0.2528 - val_acc: 0.9127\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2824 - acc: 0.8808 - val_loss: 0.2722 - val_acc: 0.8928\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.3028 - acc: 0.8700 - val_loss: 0.2652 - val_acc: 0.8828\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2502 - acc: 0.8950 - val_loss: 0.2684 - val_acc: 0.8828\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2781 - acc: 0.8733 - val_loss: 0.2612 - val_acc: 0.8878\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2537 - acc: 0.8942 - val_loss: 0.2578 - val_acc: 0.9052\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2638 - acc: 0.8808 - val_loss: 0.2636 - val_acc: 0.8878\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2736 - acc: 0.8920 - val_loss: 0.2870 - val_acc: 0.8728\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2740 - acc: 0.8742 - val_loss: 0.2690 - val_acc: 0.9002\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2709 - acc: 0.8867 - val_loss: 0.2604 - val_acc: 0.9127\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2626 - acc: 0.8791 - val_loss: 0.2663 - val_acc: 0.9077\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2560 - acc: 0.8906 - val_loss: 0.2546 - val_acc: 0.9052\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2877 - acc: 0.8800 - val_loss: 0.2734 - val_acc: 0.8953\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss improved from 0.25009 to 0.24591, saving model to best_m.h5\n",
      " - 6s - loss: 0.2440 - acc: 0.9017 - val_loss: 0.2459 - val_acc: 0.9027\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss improved from 0.24591 to 0.23740, saving model to best_m.h5\n",
      " - 6s - loss: 0.2557 - acc: 0.8917 - val_loss: 0.2374 - val_acc: 0.9102\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2640 - acc: 0.8978 - val_loss: 0.2466 - val_acc: 0.9177\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2339 - acc: 0.9092 - val_loss: 0.2456 - val_acc: 0.9202\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 7s - loss: 0.2923 - acc: 0.8997 - val_loss: 0.2501 - val_acc: 0.9152\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2736 - acc: 0.8756 - val_loss: 0.2633 - val_acc: 0.9127\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2505 - acc: 0.9000 - val_loss: 0.2457 - val_acc: 0.9127\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2395 - acc: 0.8933 - val_loss: 0.2433 - val_acc: 0.9127\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2475 - acc: 0.8898 - val_loss: 0.2505 - val_acc: 0.9102\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2867 - acc: 0.8945 - val_loss: 0.2626 - val_acc: 0.9127\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.2306 - acc: 0.8973 - val_loss: 0.2487 - val_acc: 0.9077\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2550 - acc: 0.8900 - val_loss: 0.2439 - val_acc: 0.9127\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2534 - acc: 0.8933 - val_loss: 0.2489 - val_acc: 0.9102\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2360 - acc: 0.8867 - val_loss: 0.2527 - val_acc: 0.9052\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2700 - acc: 0.8874 - val_loss: 0.2586 - val_acc: 0.8978\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2690 - acc: 0.8883 - val_loss: 0.2500 - val_acc: 0.9102\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2546 - acc: 0.8787 - val_loss: 0.2400 - val_acc: 0.9202\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2353 - acc: 0.9058 - val_loss: 0.2375 - val_acc: 0.9102\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2419 - acc: 0.9191 - val_loss: 0.2441 - val_acc: 0.9127\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2689 - acc: 0.8908 - val_loss: 0.2500 - val_acc: 0.9102\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2302 - acc: 0.9017 - val_loss: 0.2411 - val_acc: 0.9202\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2606 - acc: 0.8973 - val_loss: 0.2444 - val_acc: 0.9127\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70105, saving model to best_m.h5\n",
      " - 40s - loss: 1.2222 - acc: 0.5653 - val_loss: 0.7011 - val_acc: 0.4613\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.6289 - acc: 0.6205 - val_loss: 0.7157 - val_acc: 0.4613\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.5691 - acc: 0.6997 - val_loss: 1.0160 - val_acc: 0.4613\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.5052 - acc: 0.7353 - val_loss: 1.4348 - val_acc: 0.5761\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.70105 to 0.31151, saving model to best_m.h5\n",
      " - 6s - loss: 0.4682 - acc: 0.7797 - val_loss: 0.3115 - val_acc: 0.8529\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.31151 to 0.28248, saving model to best_m.h5\n",
      " - 6s - loss: 0.4590 - acc: 0.8066 - val_loss: 0.2825 - val_acc: 0.8853\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.4377 - acc: 0.8089 - val_loss: 0.3531 - val_acc: 0.8279\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4333 - acc: 0.7908 - val_loss: 0.4992 - val_acc: 0.7731\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4473 - acc: 0.7842 - val_loss: 0.3764 - val_acc: 0.8105\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4510 - acc: 0.7862 - val_loss: 0.3906 - val_acc: 0.8130\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4902 - acc: 0.7837 - val_loss: 0.3306 - val_acc: 0.8204\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4521 - acc: 0.7793 - val_loss: 0.4134 - val_acc: 0.8130\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4113 - acc: 0.7856 - val_loss: 0.3431 - val_acc: 0.8304\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.4097 - acc: 0.8131 - val_loss: 0.4864 - val_acc: 0.7406\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3730 - acc: 0.8041 - val_loss: 0.7546 - val_acc: 0.6833\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 6s - loss: 0.3881 - acc: 0.8158 - val_loss: 0.2830 - val_acc: 0.8454\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.28248 to 0.24118, saving model to best_m.h5\n",
      " - 6s - loss: 0.3454 - acc: 0.8325 - val_loss: 0.2412 - val_acc: 0.8978\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.24118 to 0.22857, saving model to best_m.h5\n",
      " - 6s - loss: 0.3358 - acc: 0.8447 - val_loss: 0.2286 - val_acc: 0.8978\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3262 - acc: 0.8508 - val_loss: 0.2456 - val_acc: 0.8978\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.3320 - acc: 0.8447 - val_loss: 0.2395 - val_acc: 0.8778\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.3247 - acc: 0.8558 - val_loss: 0.2292 - val_acc: 0.8953\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss improved from 0.22857 to 0.21479, saving model to best_m.h5\n",
      " - 6s - loss: 0.3093 - acc: 0.8531 - val_loss: 0.2148 - val_acc: 0.9052\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3020 - acc: 0.8479 - val_loss: 0.2389 - val_acc: 0.8803\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3529 - acc: 0.8460 - val_loss: 0.2335 - val_acc: 0.9052\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3536 - acc: 0.8529 - val_loss: 0.2892 - val_acc: 0.8603\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.3591 - acc: 0.8414 - val_loss: 0.2344 - val_acc: 0.9002\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3442 - acc: 0.8620 - val_loss: 0.2675 - val_acc: 0.8554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.3038 - acc: 0.8558 - val_loss: 0.2207 - val_acc: 0.9102\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.3035 - acc: 0.8533 - val_loss: 0.2395 - val_acc: 0.9077\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.3629 - acc: 0.8547 - val_loss: 0.2319 - val_acc: 0.9152\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.3023 - acc: 0.8591 - val_loss: 0.2194 - val_acc: 0.9177\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.3193 - acc: 0.8525 - val_loss: 0.2226 - val_acc: 0.9202\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.2838 - acc: 0.8758 - val_loss: 0.2163 - val_acc: 0.9152\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.3091 - acc: 0.8656 - val_loss: 0.2235 - val_acc: 0.9202\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss improved from 0.21479 to 0.21328, saving model to best_m.h5\n",
      " - 6s - loss: 0.2923 - acc: 0.8667 - val_loss: 0.2133 - val_acc: 0.9177\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss improved from 0.21328 to 0.20600, saving model to best_m.h5\n",
      " - 6s - loss: 0.2953 - acc: 0.8704 - val_loss: 0.2060 - val_acc: 0.9202\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2839 - acc: 0.8733 - val_loss: 0.2126 - val_acc: 0.9177\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2714 - acc: 0.8700 - val_loss: 0.2242 - val_acc: 0.9077\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.3316 - acc: 0.8714 - val_loss: 0.2150 - val_acc: 0.9227\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss improved from 0.20600 to 0.20323, saving model to best_m.h5\n",
      " - 6s - loss: 0.3032 - acc: 0.8742 - val_loss: 0.2032 - val_acc: 0.9302\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2575 - acc: 0.8841 - val_loss: 0.2077 - val_acc: 0.9202\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2784 - acc: 0.8670 - val_loss: 0.2245 - val_acc: 0.9002\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.3182 - acc: 0.8633 - val_loss: 0.2175 - val_acc: 0.9327\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2678 - acc: 0.8875 - val_loss: 0.2049 - val_acc: 0.9252\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2753 - acc: 0.8704 - val_loss: 0.2074 - val_acc: 0.9227\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.3073 - acc: 0.8609 - val_loss: 0.2127 - val_acc: 0.9152\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2754 - acc: 0.8808 - val_loss: 0.2097 - val_acc: 0.9277\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2639 - acc: 0.8697 - val_loss: 0.2064 - val_acc: 0.9252\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2655 - acc: 0.8725 - val_loss: 0.2063 - val_acc: 0.9227\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.3000 - acc: 0.8741 - val_loss: 0.2097 - val_acc: 0.9177\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2653 - acc: 0.8833 - val_loss: 0.2044 - val_acc: 0.9277\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2722 - acc: 0.8762 - val_loss: 0.2044 - val_acc: 0.9352\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss improved from 0.20323 to 0.20047, saving model to best_m.h5\n",
      " - 6s - loss: 0.2502 - acc: 0.8942 - val_loss: 0.2005 - val_acc: 0.9227\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss improved from 0.20047 to 0.19935, saving model to best_m.h5\n",
      " - 6s - loss: 0.2644 - acc: 0.8908 - val_loss: 0.1994 - val_acc: 0.9352\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.19935 to 0.19931, saving model to best_m.h5\n",
      " - 6s - loss: 0.2742 - acc: 0.8750 - val_loss: 0.1993 - val_acc: 0.9277\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2786 - acc: 0.8892 - val_loss: 0.2003 - val_acc: 0.9327\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2561 - acc: 0.8823 - val_loss: 0.1994 - val_acc: 0.9302\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.3037 - acc: 0.8729 - val_loss: 0.2070 - val_acc: 0.9352\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2835 - acc: 0.8728 - val_loss: 0.2039 - val_acc: 0.9352\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss improved from 0.19931 to 0.19533, saving model to best_m.h5\n",
      " - 6s - loss: 0.2539 - acc: 0.9017 - val_loss: 0.1953 - val_acc: 0.9252\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss improved from 0.19533 to 0.19014, saving model to best_m.h5\n",
      " - 6s - loss: 0.2259 - acc: 0.8998 - val_loss: 0.1901 - val_acc: 0.9227\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2596 - acc: 0.8900 - val_loss: 0.1951 - val_acc: 0.9227\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2547 - acc: 0.8883 - val_loss: 0.1918 - val_acc: 0.9352\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2879 - acc: 0.8864 - val_loss: 0.2034 - val_acc: 0.9252\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2563 - acc: 0.8850 - val_loss: 0.2012 - val_acc: 0.9277\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2590 - acc: 0.8875 - val_loss: 0.1974 - val_acc: 0.9277\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.2436 - acc: 0.8883 - val_loss: 0.1921 - val_acc: 0.9302\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.2599 - acc: 0.8875 - val_loss: 0.1994 - val_acc: 0.9202\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2683 - acc: 0.8820 - val_loss: 0.1983 - val_acc: 0.9277\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.3005 - acc: 0.8897 - val_loss: 0.2031 - val_acc: 0.9302\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.2922 - acc: 0.8683 - val_loss: 0.2079 - val_acc: 0.9252\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2435 - acc: 0.8873 - val_loss: 0.2021 - val_acc: 0.9302\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.2498 - acc: 0.8867 - val_loss: 0.1969 - val_acc: 0.9327\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 6s - loss: 0.2687 - acc: 0.8858 - val_loss: 0.1975 - val_acc: 0.9377\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2602 - acc: 0.8833 - val_loss: 0.1988 - val_acc: 0.9252\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2343 - acc: 0.8967 - val_loss: 0.1946 - val_acc: 0.9277\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.2726 - acc: 0.8789 - val_loss: 0.1959 - val_acc: 0.9401\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2661 - acc: 0.8914 - val_loss: 0.1987 - val_acc: 0.9252\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.2695 - acc: 0.8950 - val_loss: 0.1985 - val_acc: 0.9227\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.3021 - acc: 0.8629 - val_loss: 0.2083 - val_acc: 0.9352\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.2871 - acc: 0.8867 - val_loss: 0.2028 - val_acc: 0.9302\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=9):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_resnet_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.230381632957\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.212729\n",
      "1  4023181e    0.731043\n",
      "2  b20200e4    0.044830\n",
      "3  e7f018bb    0.958758\n",
      "4  4371c8c3    0.095437\n"
     ]
    }
   ],
   "source": [
    "with open('../features/resnet_aug3_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/resnet_aug3_sub.csv', index=False)\n",
    "# deep2 0.227\n",
    "# deep3 0.223\n",
    "# deep3 new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

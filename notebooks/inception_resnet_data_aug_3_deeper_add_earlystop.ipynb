{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_df = pd.read_json('../input/train.json')\n",
    "test_df = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "def std_img(x):\n",
    "    for i in range(3):\n",
    "        x[:, :, i] -= np.mean(x[:, :, i].flatten())\n",
    "        x[:, :, i] /= np.std(x[:, :, i].flatten()) + 1e-7\n",
    "    return x\n",
    "\n",
    "def get_image(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1 + band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        img = np.dstack([band_1,band_2,band_3])\n",
    "        img = std_img(img)\n",
    "\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "train_x = get_image(train_df)\n",
    "test_x = get_image(test_df)\n",
    "\n",
    "print(train_x.shape,test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_iceberg.values\n",
    "print(y[:5])\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def lr_f(epoch):\n",
    "    if epoch < 15:\n",
    "        return 0.0005\n",
    "    elif epoch < 30:\n",
    "        return 0.0001\n",
    "    elif epoch < 45:\n",
    "        return 0.00005\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def create_incept_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    \n",
    "    # bn\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 64, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "     # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "    \n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    x = Conv2D(96, 3, strides=2, padding='same',activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70156, saving model to best_m.h5\n",
      " - 8s - loss: 0.5379 - acc: 0.7425 - val_loss: 0.7016 - val_acc: 0.4239\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 4s - loss: 0.4653 - acc: 0.7847 - val_loss: 1.4719 - val_acc: 0.5337\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.70156 to 0.61749, saving model to best_m.h5\n",
      " - 5s - loss: 0.3719 - acc: 0.8153 - val_loss: 0.6175 - val_acc: 0.6808\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.61749 to 0.54278, saving model to best_m.h5\n",
      " - 4s - loss: 0.3692 - acc: 0.8216 - val_loss: 0.5428 - val_acc: 0.7855\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 4s - loss: 0.3865 - acc: 0.8425 - val_loss: 0.7010 - val_acc: 0.7606\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3381 - acc: 0.8450 - val_loss: 0.5498 - val_acc: 0.8155\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3631 - acc: 0.8416 - val_loss: 0.8030 - val_acc: 0.7282\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3034 - acc: 0.8533 - val_loss: 0.5686 - val_acc: 0.8180\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.54278 to 0.39358, saving model to best_m.h5\n",
      " - 5s - loss: 0.3629 - acc: 0.8270 - val_loss: 0.3936 - val_acc: 0.8379\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 5s - loss: 0.3039 - acc: 0.8741 - val_loss: 0.4257 - val_acc: 0.8429\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss improved from 0.39358 to 0.38886, saving model to best_m.h5\n",
      " - 5s - loss: 0.2869 - acc: 0.8608 - val_loss: 0.3889 - val_acc: 0.8254\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 5s - loss: 0.3191 - acc: 0.8623 - val_loss: 0.8999 - val_acc: 0.6783\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 5s - loss: 0.3264 - acc: 0.8639 - val_loss: 0.6403 - val_acc: 0.7631\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.38886 to 0.33061, saving model to best_m.h5\n",
      " - 5s - loss: 0.3093 - acc: 0.8700 - val_loss: 0.3306 - val_acc: 0.8579\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 5s - loss: 0.2905 - acc: 0.8733 - val_loss: 0.4703 - val_acc: 0.8055\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 5s - loss: 0.2545 - acc: 0.8992 - val_loss: 0.3359 - val_acc: 0.8529\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.33061 to 0.31892, saving model to best_m.h5\n",
      " - 5s - loss: 0.2802 - acc: 0.8992 - val_loss: 0.3189 - val_acc: 0.8653\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.31892 to 0.31128, saving model to best_m.h5\n",
      " - 5s - loss: 0.2319 - acc: 0.9075 - val_loss: 0.3113 - val_acc: 0.8554\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2436 - acc: 0.9066 - val_loss: 0.3284 - val_acc: 0.8653\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 5s - loss: 0.2399 - acc: 0.9050 - val_loss: 0.3235 - val_acc: 0.8653\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 5s - loss: 0.2289 - acc: 0.9000 - val_loss: 0.3389 - val_acc: 0.8529\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss improved from 0.31128 to 0.29955, saving model to best_m.h5\n",
      " - 4s - loss: 0.2246 - acc: 0.9067 - val_loss: 0.2995 - val_acc: 0.8878\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2075 - acc: 0.9083 - val_loss: 0.3865 - val_acc: 0.8529\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss improved from 0.29955 to 0.29796, saving model to best_m.h5\n",
      " - 4s - loss: 0.2654 - acc: 0.8973 - val_loss: 0.2980 - val_acc: 0.8803\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2094 - acc: 0.9200 - val_loss: 0.3323 - val_acc: 0.8653\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2274 - acc: 0.9083 - val_loss: 0.3287 - val_acc: 0.8479\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2117 - acc: 0.9150 - val_loss: 0.3152 - val_acc: 0.8828\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2312 - acc: 0.9142 - val_loss: 0.3424 - val_acc: 0.8753\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.1889 - acc: 0.9206 - val_loss: 0.3524 - val_acc: 0.8579\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2162 - acc: 0.8956 - val_loss: 0.3476 - val_acc: 0.8554\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2044 - acc: 0.9100 - val_loss: 0.3207 - val_acc: 0.8828\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.1936 - acc: 0.9192 - val_loss: 0.3091 - val_acc: 0.8878\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.2112 - acc: 0.9058 - val_loss: 0.3097 - val_acc: 0.8728\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.1923 - acc: 0.9175 - val_loss: 0.3160 - val_acc: 0.8778\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.1927 - acc: 0.9308 - val_loss: 0.3187 - val_acc: 0.8778\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2015 - acc: 0.9208 - val_loss: 0.3114 - val_acc: 0.8803\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.1888 - acc: 0.9208 - val_loss: 0.3234 - val_acc: 0.8853\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.1719 - acc: 0.9166 - val_loss: 0.3110 - val_acc: 0.8778\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.1564 - acc: 0.9375 - val_loss: 0.3479 - val_acc: 0.8728\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.1863 - acc: 0.9214 - val_loss: 0.3509 - val_acc: 0.8628\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.2208 - acc: 0.9189 - val_loss: 0.3224 - val_acc: 0.8728\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss improved from 0.29796 to 0.29376, saving model to best_m.h5\n",
      " - 5s - loss: 0.1999 - acc: 0.9092 - val_loss: 0.2938 - val_acc: 0.8853\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.1782 - acc: 0.9258 - val_loss: 0.3192 - val_acc: 0.8778\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.1934 - acc: 0.9150 - val_loss: 0.3241 - val_acc: 0.8628\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.1732 - acc: 0.9300 - val_loss: 0.3462 - val_acc: 0.8678\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1990 - acc: 0.9133 - val_loss: 0.3247 - val_acc: 0.8803\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 5s - loss: 0.1779 - acc: 0.9250 - val_loss: 0.3234 - val_acc: 0.8753\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 5s - loss: 0.1741 - acc: 0.9298 - val_loss: 0.3242 - val_acc: 0.8728\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 5s - loss: 0.1780 - acc: 0.9289 - val_loss: 0.3325 - val_acc: 0.8653\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.1667 - acc: 0.9258 - val_loss: 0.3249 - val_acc: 0.8703\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 5s - loss: 0.1846 - acc: 0.9239 - val_loss: 0.3220 - val_acc: 0.8678\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 5s - loss: 0.1798 - acc: 0.9250 - val_loss: 0.3203 - val_acc: 0.8653\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.1686 - acc: 0.9342 - val_loss: 0.3234 - val_acc: 0.8728\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 5s - loss: 0.1819 - acc: 0.9248 - val_loss: 0.3271 - val_acc: 0.8653\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 5s - loss: 0.1840 - acc: 0.9241 - val_loss: 0.3255 - val_acc: 0.8753\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.1821 - acc: 0.9250 - val_loss: 0.3210 - val_acc: 0.8878\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 5s - loss: 0.1549 - acc: 0.9367 - val_loss: 0.3293 - val_acc: 0.8803\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 5s - loss: 0.1723 - acc: 0.9317 - val_loss: 0.3282 - val_acc: 0.8853\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 5s - loss: 0.1790 - acc: 0.9208 - val_loss: 0.3309 - val_acc: 0.8703\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 5s - loss: 0.1800 - acc: 0.9381 - val_loss: 0.3226 - val_acc: 0.8728\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 4s - loss: 0.1786 - acc: 0.9250 - val_loss: 0.3220 - val_acc: 0.8828\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 4s - loss: 0.1659 - acc: 0.9358 - val_loss: 0.3292 - val_acc: 0.8678\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.83117, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.5622 - acc: 0.7208 - val_loss: 0.8312 - val_acc: 0.5411\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.83117 to 0.60048, saving model to best_m.h5\n",
      " - 4s - loss: 0.4831 - acc: 0.7653 - val_loss: 0.6005 - val_acc: 0.5636\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 4s - loss: 0.3964 - acc: 0.8178 - val_loss: 1.2601 - val_acc: 0.5761\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 4s - loss: 0.3812 - acc: 0.8122 - val_loss: 0.7853 - val_acc: 0.7007\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 4s - loss: 0.4308 - acc: 0.8145 - val_loss: 0.7166 - val_acc: 0.6384\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.60048 to 0.29856, saving model to best_m.h5\n",
      " - 4s - loss: 0.3875 - acc: 0.8191 - val_loss: 0.2986 - val_acc: 0.8703\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3523 - acc: 0.8392 - val_loss: 0.3896 - val_acc: 0.8603\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3909 - acc: 0.8353 - val_loss: 0.4454 - val_acc: 0.7980\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3660 - acc: 0.8416 - val_loss: 0.6602 - val_acc: 0.6983\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 4s - loss: 0.3544 - acc: 0.8441 - val_loss: 0.5380 - val_acc: 0.7581\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3232 - acc: 0.8725 - val_loss: 0.3147 - val_acc: 0.8429\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.3526 - acc: 0.8550 - val_loss: 0.9296 - val_acc: 0.6958\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss improved from 0.29856 to 0.28782, saving model to best_m.h5\n",
      " - 4s - loss: 0.3438 - acc: 0.8564 - val_loss: 0.2878 - val_acc: 0.8504\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss improved from 0.28782 to 0.25935, saving model to best_m.h5\n",
      " - 4s - loss: 0.3256 - acc: 0.8639 - val_loss: 0.2593 - val_acc: 0.9052\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss improved from 0.25935 to 0.23737, saving model to best_m.h5\n",
      " - 4s - loss: 0.3086 - acc: 0.8683 - val_loss: 0.2374 - val_acc: 0.9127\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.23737 to 0.20071, saving model to best_m.h5\n",
      " - 5s - loss: 0.2592 - acc: 0.8956 - val_loss: 0.2007 - val_acc: 0.9327\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2467 - acc: 0.9000 - val_loss: 0.2120 - val_acc: 0.9177\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.20071 to 0.19237, saving model to best_m.h5\n",
      " - 5s - loss: 0.2637 - acc: 0.8889 - val_loss: 0.1924 - val_acc: 0.9302\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.19237 to 0.18915, saving model to best_m.h5\n",
      " - 5s - loss: 0.2571 - acc: 0.8883 - val_loss: 0.1891 - val_acc: 0.9177\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2432 - acc: 0.8900 - val_loss: 0.1943 - val_acc: 0.9152\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2472 - acc: 0.9058 - val_loss: 0.2327 - val_acc: 0.9127\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2735 - acc: 0.8804 - val_loss: 0.2128 - val_acc: 0.9202\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2328 - acc: 0.9000 - val_loss: 0.2093 - val_acc: 0.9152\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2608 - acc: 0.8981 - val_loss: 0.2098 - val_acc: 0.9052\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2960 - acc: 0.8945 - val_loss: 0.3039 - val_acc: 0.8853\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2361 - acc: 0.9017 - val_loss: 0.2269 - val_acc: 0.9127\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2316 - acc: 0.9000 - val_loss: 0.2066 - val_acc: 0.9052\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2251 - acc: 0.9083 - val_loss: 0.2150 - val_acc: 0.9152\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2491 - acc: 0.8970 - val_loss: 0.2077 - val_acc: 0.9027\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2150 - acc: 0.9142 - val_loss: 0.3150 - val_acc: 0.8778\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2196 - acc: 0.9108 - val_loss: 0.2066 - val_acc: 0.9202\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss improved from 0.18915 to 0.18813, saving model to best_m.h5\n",
      " - 4s - loss: 0.2201 - acc: 0.9067 - val_loss: 0.1881 - val_acc: 0.9277\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.2494 - acc: 0.8968 - val_loss: 0.2354 - val_acc: 0.9102\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.2317 - acc: 0.8992 - val_loss: 0.1948 - val_acc: 0.9177\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.1900 - acc: 0.9275 - val_loss: 0.1950 - val_acc: 0.9177\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2064 - acc: 0.9164 - val_loss: 0.1971 - val_acc: 0.9277\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.2298 - acc: 0.8972 - val_loss: 0.2146 - val_acc: 0.9027\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.1926 - acc: 0.9258 - val_loss: 0.1950 - val_acc: 0.9177\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.2238 - acc: 0.9200 - val_loss: 0.2005 - val_acc: 0.9127\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.1784 - acc: 0.9239 - val_loss: 0.1992 - val_acc: 0.9227\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.1846 - acc: 0.9233 - val_loss: 0.2000 - val_acc: 0.9202\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.2292 - acc: 0.9133 - val_loss: 0.2030 - val_acc: 0.9202\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.1934 - acc: 0.9173 - val_loss: 0.2026 - val_acc: 0.9252\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.1848 - acc: 0.9233 - val_loss: 0.2040 - val_acc: 0.9252\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.2133 - acc: 0.9117 - val_loss: 0.2060 - val_acc: 0.9102\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.1739 - acc: 0.9250 - val_loss: 0.1897 - val_acc: 0.9227\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.1978 - acc: 0.9245 - val_loss: 0.1884 - val_acc: 0.9302\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.1854 - acc: 0.9298 - val_loss: 0.1890 - val_acc: 0.9277\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.1740 - acc: 0.9323 - val_loss: 0.1903 - val_acc: 0.9302\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.2124 - acc: 0.9133 - val_loss: 0.1887 - val_acc: 0.9401\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.2075 - acc: 0.9139 - val_loss: 0.1916 - val_acc: 0.9252\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.1498 - acc: 0.9433 - val_loss: 0.1903 - val_acc: 0.9277\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.69572, saving model to best_m.h5\n",
      " - 18s - loss: 0.5986 - acc: 0.7116 - val_loss: 0.6957 - val_acc: 0.5935\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.69572 to 0.67048, saving model to best_m.h5\n",
      " - 4s - loss: 0.4348 - acc: 0.8022 - val_loss: 0.6705 - val_acc: 0.6783\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.67048 to 0.62056, saving model to best_m.h5\n",
      " - 5s - loss: 0.4011 - acc: 0.8183 - val_loss: 0.6206 - val_acc: 0.7257\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.62056 to 0.48457, saving model to best_m.h5\n",
      " - 5s - loss: 0.3816 - acc: 0.8308 - val_loss: 0.4846 - val_acc: 0.7481\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.48457 to 0.35619, saving model to best_m.h5\n",
      " - 6s - loss: 0.3808 - acc: 0.8308 - val_loss: 0.3562 - val_acc: 0.8105\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3707 - acc: 0.8389 - val_loss: 0.4665 - val_acc: 0.8080\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 5s - loss: 0.3720 - acc: 0.8300 - val_loss: 0.4697 - val_acc: 0.7307\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3545 - acc: 0.8445 - val_loss: 0.5759 - val_acc: 0.7107\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3278 - acc: 0.8539 - val_loss: 0.5027 - val_acc: 0.8254\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss improved from 0.35619 to 0.26224, saving model to best_m.h5\n",
      " - 5s - loss: 0.3266 - acc: 0.8625 - val_loss: 0.2622 - val_acc: 0.8653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3745 - acc: 0.8570 - val_loss: 0.4756 - val_acc: 0.6783\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.3890 - acc: 0.8422 - val_loss: 0.3089 - val_acc: 0.8628\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.3737 - acc: 0.8270 - val_loss: 0.5717 - val_acc: 0.7257\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.2999 - acc: 0.8658 - val_loss: 0.4266 - val_acc: 0.7656\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.3247 - acc: 0.8600 - val_loss: 0.2931 - val_acc: 0.8703\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.26224 to 0.23186, saving model to best_m.h5\n",
      " - 4s - loss: 0.3024 - acc: 0.8801 - val_loss: 0.2319 - val_acc: 0.9077\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 4s - loss: 0.2827 - acc: 0.8831 - val_loss: 0.2919 - val_acc: 0.8454\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.23186 to 0.22389, saving model to best_m.h5\n",
      " - 4s - loss: 0.2738 - acc: 0.8814 - val_loss: 0.2239 - val_acc: 0.9077\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2573 - acc: 0.8775 - val_loss: 0.2592 - val_acc: 0.8853\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.2634 - acc: 0.8908 - val_loss: 0.2338 - val_acc: 0.9002\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2531 - acc: 0.8900 - val_loss: 0.2455 - val_acc: 0.8903\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2390 - acc: 0.9008 - val_loss: 0.2344 - val_acc: 0.8903\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2670 - acc: 0.8795 - val_loss: 0.2895 - val_acc: 0.8703\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2260 - acc: 0.9017 - val_loss: 0.2271 - val_acc: 0.9127\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2289 - acc: 0.9100 - val_loss: 0.2270 - val_acc: 0.9152\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2318 - acc: 0.8992 - val_loss: 0.2489 - val_acc: 0.8978\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss improved from 0.22389 to 0.21616, saving model to best_m.h5\n",
      " - 4s - loss: 0.2596 - acc: 0.9014 - val_loss: 0.2162 - val_acc: 0.9177\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2549 - acc: 0.8908 - val_loss: 0.2352 - val_acc: 0.9052\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 4s - loss: 0.2351 - acc: 0.9017 - val_loss: 0.2267 - val_acc: 0.9152\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2164 - acc: 0.9100 - val_loss: 0.2233 - val_acc: 0.8978\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2243 - acc: 0.9092 - val_loss: 0.2180 - val_acc: 0.9152\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.2121 - acc: 0.9117 - val_loss: 0.2184 - val_acc: 0.9127\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 4s - loss: 0.2119 - acc: 0.9064 - val_loss: 0.2249 - val_acc: 0.9077\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.2280 - acc: 0.9033 - val_loss: 0.2422 - val_acc: 0.9077\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 4s - loss: 0.2074 - acc: 0.9098 - val_loss: 0.2322 - val_acc: 0.9102\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2242 - acc: 0.9067 - val_loss: 0.2287 - val_acc: 0.9127\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.2319 - acc: 0.9103 - val_loss: 0.2259 - val_acc: 0.9127\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.1964 - acc: 0.9206 - val_loss: 0.2185 - val_acc: 0.9127\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 4s - loss: 0.2150 - acc: 0.9150 - val_loss: 0.2207 - val_acc: 0.9077\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.2088 - acc: 0.9089 - val_loss: 0.2589 - val_acc: 0.9052\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 4s - loss: 0.1810 - acc: 0.9175 - val_loss: 0.2190 - val_acc: 0.9077\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.2158 - acc: 0.9033 - val_loss: 0.2304 - val_acc: 0.9077\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.1996 - acc: 0.9258 - val_loss: 0.2507 - val_acc: 0.9002\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.2242 - acc: 0.9089 - val_loss: 0.2384 - val_acc: 0.9152\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 5s - loss: 0.1972 - acc: 0.9258 - val_loss: 0.2258 - val_acc: 0.9052\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.2178 - acc: 0.9167 - val_loss: 0.2258 - val_acc: 0.9002\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.2149 - acc: 0.9095 - val_loss: 0.2300 - val_acc: 0.8978\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.75585, saving model to best_m.h5\n",
      " - 23s - loss: 0.6116 - acc: 0.7331 - val_loss: 0.7558 - val_acc: 0.4613\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.75585 to 0.53117, saving model to best_m.h5\n",
      " - 4s - loss: 0.4252 - acc: 0.7956 - val_loss: 0.5312 - val_acc: 0.6833\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 0.53117 to 0.47067, saving model to best_m.h5\n",
      " - 4s - loss: 0.4520 - acc: 0.7847 - val_loss: 0.4707 - val_acc: 0.7282\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.47067 to 0.26947, saving model to best_m.h5\n",
      " - 4s - loss: 0.4000 - acc: 0.8122 - val_loss: 0.2695 - val_acc: 0.8828\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.26947 to 0.25724, saving model to best_m.h5\n",
      " - 4s - loss: 0.3519 - acc: 0.8364 - val_loss: 0.2572 - val_acc: 0.9002\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 4s - loss: 0.3865 - acc: 0.8225 - val_loss: 0.9057 - val_acc: 0.7032\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.3529 - acc: 0.8400 - val_loss: 0.6034 - val_acc: 0.7481\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 4s - loss: 0.3451 - acc: 0.8414 - val_loss: 0.3779 - val_acc: 0.8404\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.25724 to 0.22704, saving model to best_m.h5\n",
      " - 4s - loss: 0.3778 - acc: 0.8387 - val_loss: 0.2270 - val_acc: 0.9052\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 4s - loss: 0.3486 - acc: 0.8481 - val_loss: 0.3552 - val_acc: 0.8180\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 4s - loss: 0.3398 - acc: 0.8450 - val_loss: 0.3392 - val_acc: 0.8753\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 4s - loss: 0.3382 - acc: 0.8541 - val_loss: 0.2441 - val_acc: 0.8978\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 4s - loss: 0.3683 - acc: 0.8556 - val_loss: 0.3331 - val_acc: 0.8628\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 4s - loss: 0.3292 - acc: 0.8670 - val_loss: 0.5484 - val_acc: 0.8180\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 4s - loss: 0.3845 - acc: 0.8454 - val_loss: 0.4035 - val_acc: 0.8055\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.2794 - acc: 0.8841 - val_loss: 0.2503 - val_acc: 0.8803\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.22704 to 0.20630, saving model to best_m.h5\n",
      " - 4s - loss: 0.2968 - acc: 0.8825 - val_loss: 0.2063 - val_acc: 0.9152\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 5s - loss: 0.3207 - acc: 0.8681 - val_loss: 0.2089 - val_acc: 0.9102\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 4s - loss: 0.2717 - acc: 0.8900 - val_loss: 0.2173 - val_acc: 0.9052\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 4s - loss: 0.3118 - acc: 0.8665 - val_loss: 0.2235 - val_acc: 0.8903\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 4s - loss: 0.2909 - acc: 0.8766 - val_loss: 0.2116 - val_acc: 0.8953\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 4s - loss: 0.2420 - acc: 0.9075 - val_loss: 0.2405 - val_acc: 0.8978\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 4s - loss: 0.2865 - acc: 0.8756 - val_loss: 0.2164 - val_acc: 0.9052\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 4s - loss: 0.2773 - acc: 0.8845 - val_loss: 0.2261 - val_acc: 0.8978\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 4s - loss: 0.2442 - acc: 0.8989 - val_loss: 0.2389 - val_acc: 0.8928\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 4s - loss: 0.2675 - acc: 0.8787 - val_loss: 0.2293 - val_acc: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 4s - loss: 0.2561 - acc: 0.8883 - val_loss: 0.2094 - val_acc: 0.9052\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 4s - loss: 0.2491 - acc: 0.9023 - val_loss: 0.2220 - val_acc: 0.9027\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss improved from 0.20630 to 0.20386, saving model to best_m.h5\n",
      " - 4s - loss: 0.2518 - acc: 0.9006 - val_loss: 0.2039 - val_acc: 0.9077\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 4s - loss: 0.2600 - acc: 0.8892 - val_loss: 0.2252 - val_acc: 0.8903\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 4s - loss: 0.2278 - acc: 0.9075 - val_loss: 0.2054 - val_acc: 0.9127\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 4s - loss: 0.2296 - acc: 0.9042 - val_loss: 0.2134 - val_acc: 0.9077\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss improved from 0.20386 to 0.19859, saving model to best_m.h5\n",
      " - 4s - loss: 0.2316 - acc: 0.9058 - val_loss: 0.1986 - val_acc: 0.9077\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 4s - loss: 0.2361 - acc: 0.9083 - val_loss: 0.2026 - val_acc: 0.9077\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss improved from 0.19859 to 0.19642, saving model to best_m.h5\n",
      " - 4s - loss: 0.2200 - acc: 0.9058 - val_loss: 0.1964 - val_acc: 0.9102\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 4s - loss: 0.2440 - acc: 0.9000 - val_loss: 0.2059 - val_acc: 0.9127\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 4s - loss: 0.2373 - acc: 0.9122 - val_loss: 0.2277 - val_acc: 0.9052\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 4s - loss: 0.2333 - acc: 0.9067 - val_loss: 0.2115 - val_acc: 0.9152\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss improved from 0.19642 to 0.19550, saving model to best_m.h5\n",
      " - 4s - loss: 0.2044 - acc: 0.9175 - val_loss: 0.1955 - val_acc: 0.9202\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 4s - loss: 0.2309 - acc: 0.9041 - val_loss: 0.2324 - val_acc: 0.9027\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss improved from 0.19550 to 0.19358, saving model to best_m.h5\n",
      " - 4s - loss: 0.2239 - acc: 0.9092 - val_loss: 0.1936 - val_acc: 0.9127\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 4s - loss: 0.1987 - acc: 0.9208 - val_loss: 0.2067 - val_acc: 0.9052\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 4s - loss: 0.2199 - acc: 0.9150 - val_loss: 0.2049 - val_acc: 0.9077\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 4s - loss: 0.2591 - acc: 0.8937 - val_loss: 0.2049 - val_acc: 0.9027\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 4s - loss: 0.2081 - acc: 0.9192 - val_loss: 0.2174 - val_acc: 0.9077\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 4s - loss: 0.2101 - acc: 0.9131 - val_loss: 0.1974 - val_acc: 0.9127\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 4s - loss: 0.2080 - acc: 0.9264 - val_loss: 0.1991 - val_acc: 0.9127\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 4s - loss: 0.2129 - acc: 0.9158 - val_loss: 0.1972 - val_acc: 0.9177\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 4s - loss: 0.2209 - acc: 0.9131 - val_loss: 0.1997 - val_acc: 0.9127\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 4s - loss: 0.2132 - acc: 0.9183 - val_loss: 0.1946 - val_acc: 0.9127\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 4s - loss: 0.1924 - acc: 0.9156 - val_loss: 0.2041 - val_acc: 0.9127\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 4s - loss: 0.1864 - acc: 0.9250 - val_loss: 0.1994 - val_acc: 0.9127\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 4s - loss: 0.1893 - acc: 0.9292 - val_loss: 0.2053 - val_acc: 0.9127\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 4s - loss: 0.2013 - acc: 0.9150 - val_loss: 0.2003 - val_acc: 0.9127\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 4s - loss: 0.2108 - acc: 0.9198 - val_loss: 0.2007 - val_acc: 0.9127\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 4s - loss: 0.2005 - acc: 0.9142 - val_loss: 0.1987 - val_acc: 0.9152\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 4s - loss: 0.1756 - acc: 0.9316 - val_loss: 0.1972 - val_acc: 0.9177\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 4s - loss: 0.2019 - acc: 0.9250 - val_loss: 0.1962 - val_acc: 0.9177\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 4s - loss: 0.1852 - acc: 0.9200 - val_loss: 0.2004 - val_acc: 0.9127\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 4s - loss: 0.2066 - acc: 0.9175 - val_loss: 0.1976 - val_acc: 0.9177\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 4s - loss: 0.2159 - acc: 0.9117 - val_loss: 0.1952 - val_acc: 0.9202\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=9):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_incept_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222908367275\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.103524\n",
      "1  4023181e    0.736135\n",
      "2  b20200e4    0.012855\n",
      "3  e7f018bb    0.996237\n",
      "4  4371c8c3    0.072173\n"
     ]
    }
   ],
   "source": [
    "with open('../features/incept_aug3_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/incept_aug3_sub.csv', index=False)\n",
    "# deep2 0.2110\n",
    "# deep3 0.2119\n",
    "\n",
    "# deep3 new 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D,Flatten\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    bn_axis = 3\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model():\n",
    "    img_input = Input(shape=(75,75,3))\n",
    "    channel_axis = 3\n",
    "    bn_axis = 3\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    \n",
    "    x = Conv2D(128, 3, strides=2, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(img_input, x, name='inception_v3')\n",
    "print('model model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70762, saving model to best_m.h5\n",
      " - 26s - loss: 1.2818 - acc: 0.5914 - val_loss: 0.7076 - val_acc: 0.4663\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5367 - acc: 0.7322 - val_loss: 1.1087 - val_acc: 0.4663\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.4680 - acc: 0.7900 - val_loss: 1.1132 - val_acc: 0.4663\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.70762 to 0.64968, saving model to best_m.h5\n",
      " - 6s - loss: 0.4825 - acc: 0.7847 - val_loss: 0.6497 - val_acc: 0.6908\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.64968 to 0.40204, saving model to best_m.h5\n",
      " - 6s - loss: 0.4374 - acc: 0.8162 - val_loss: 0.4020 - val_acc: 0.8155\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.4257 - acc: 0.8181 - val_loss: 0.4354 - val_acc: 0.7930\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.4312 - acc: 0.7966 - val_loss: 0.6463 - val_acc: 0.7531\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4424 - acc: 0.7972 - val_loss: 0.4177 - val_acc: 0.8379\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4073 - acc: 0.8191 - val_loss: 1.3334 - val_acc: 0.6110\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4177 - acc: 0.8191 - val_loss: 0.4066 - val_acc: 0.8354\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.3918 - acc: 0.8225 - val_loss: 0.5558 - val_acc: 0.7531\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4136 - acc: 0.8247 - val_loss: 1.0096 - val_acc: 0.7506\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4561 - acc: 0.8114 - val_loss: 0.9465 - val_acc: 0.6983\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.3473 - acc: 0.8550 - val_loss: 0.4672 - val_acc: 0.7556\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3633 - acc: 0.8566 - val_loss: 0.4701 - val_acc: 0.7955\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.40204 to 0.34597, saving model to best_m.h5\n",
      " - 6s - loss: 0.3268 - acc: 0.8442 - val_loss: 0.3460 - val_acc: 0.8579\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 6s - loss: 0.2984 - acc: 0.8639 - val_loss: 0.3593 - val_acc: 0.8579\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 6s - loss: 0.3279 - acc: 0.8608 - val_loss: 0.3485 - val_acc: 0.8454\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3165 - acc: 0.8791 - val_loss: 0.3724 - val_acc: 0.8404\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss improved from 0.34597 to 0.31124, saving model to best_m.h5\n",
      " - 6s - loss: 0.2747 - acc: 0.8864 - val_loss: 0.3112 - val_acc: 0.8678\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.2967 - acc: 0.8825 - val_loss: 0.3215 - val_acc: 0.8579\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2674 - acc: 0.8966 - val_loss: 0.3306 - val_acc: 0.8529\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.2576 - acc: 0.8925 - val_loss: 0.3181 - val_acc: 0.8529\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.2570 - acc: 0.8883 - val_loss: 0.3215 - val_acc: 0.8603\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.2367 - acc: 0.8975 - val_loss: 0.3644 - val_acc: 0.8504\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2507 - acc: 0.8931 - val_loss: 0.3143 - val_acc: 0.8454\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.2777 - acc: 0.8948 - val_loss: 0.3564 - val_acc: 0.8429\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.3012 - acc: 0.8650 - val_loss: 0.3173 - val_acc: 0.8603\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2777 - acc: 0.8825 - val_loss: 0.3405 - val_acc: 0.8479\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.2991 - acc: 0.9079 - val_loss: 0.3219 - val_acc: 0.8579\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.31124 to 0.30073, saving model to best_m.h5\n",
      " - 6s - loss: 0.2705 - acc: 0.8858 - val_loss: 0.3007 - val_acc: 0.8703\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.2893 - acc: 0.8837 - val_loss: 0.3334 - val_acc: 0.8429\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss improved from 0.30073 to 0.29822, saving model to best_m.h5\n",
      " - 6s - loss: 0.2493 - acc: 0.8958 - val_loss: 0.2982 - val_acc: 0.8678\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 6s - loss: 0.2390 - acc: 0.9025 - val_loss: 0.3054 - val_acc: 0.8554\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2890 - acc: 0.8953 - val_loss: 0.3383 - val_acc: 0.8479\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.2656 - acc: 0.8837 - val_loss: 0.3053 - val_acc: 0.8703\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.2449 - acc: 0.8992 - val_loss: 0.3010 - val_acc: 0.8753\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2409 - acc: 0.8992 - val_loss: 0.3061 - val_acc: 0.8653\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2481 - acc: 0.8922 - val_loss: 0.3149 - val_acc: 0.8603\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2086 - acc: 0.9000 - val_loss: 0.3436 - val_acc: 0.8579\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2712 - acc: 0.8939 - val_loss: 0.3024 - val_acc: 0.8778\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2443 - acc: 0.9058 - val_loss: 0.3022 - val_acc: 0.8778\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2244 - acc: 0.9131 - val_loss: 0.3178 - val_acc: 0.8579\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2563 - acc: 0.8950 - val_loss: 0.3061 - val_acc: 0.8603\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss improved from 0.29822 to 0.29747, saving model to best_m.h5\n",
      " - 6s - loss: 0.2215 - acc: 0.9108 - val_loss: 0.2975 - val_acc: 0.8703\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss improved from 0.29747 to 0.29342, saving model to best_m.h5\n",
      " - 6s - loss: 0.2266 - acc: 0.9133 - val_loss: 0.2934 - val_acc: 0.8703\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.29342 to 0.29032, saving model to best_m.h5\n",
      " - 6s - loss: 0.2463 - acc: 0.8978 - val_loss: 0.2903 - val_acc: 0.8703\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2388 - acc: 0.8970 - val_loss: 0.2917 - val_acc: 0.8703\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2262 - acc: 0.9108 - val_loss: 0.2910 - val_acc: 0.8728\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2482 - acc: 0.8981 - val_loss: 0.2913 - val_acc: 0.8703\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2393 - acc: 0.9073 - val_loss: 0.2957 - val_acc: 0.8728\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2255 - acc: 0.9114 - val_loss: 0.2969 - val_acc: 0.8703\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2242 - acc: 0.8900 - val_loss: 0.2905 - val_acc: 0.8678\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss improved from 0.29032 to 0.28832, saving model to best_m.h5\n",
      " - 6s - loss: 0.2112 - acc: 0.9100 - val_loss: 0.2883 - val_acc: 0.8778\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2363 - acc: 0.9039 - val_loss: 0.2940 - val_acc: 0.8678\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2406 - acc: 0.8958 - val_loss: 0.2966 - val_acc: 0.8678\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2177 - acc: 0.9050 - val_loss: 0.2938 - val_acc: 0.8778\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 6s - loss: 0.2420 - acc: 0.8975 - val_loss: 0.2945 - val_acc: 0.8653\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2021 - acc: 0.9125 - val_loss: 0.2918 - val_acc: 0.8753\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2288 - acc: 0.9192 - val_loss: 0.2970 - val_acc: 0.8728\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2410 - acc: 0.8975 - val_loss: 0.2979 - val_acc: 0.8703\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2150 - acc: 0.9133 - val_loss: 0.2933 - val_acc: 0.8753\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2525 - acc: 0.8920 - val_loss: 0.2922 - val_acc: 0.8678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.2256 - acc: 0.9225 - val_loss: 0.2886 - val_acc: 0.8703\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss improved from 0.28832 to 0.28734, saving model to best_m.h5\n",
      " - 6s - loss: 0.1944 - acc: 0.9250 - val_loss: 0.2873 - val_acc: 0.8678\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.1936 - acc: 0.9133 - val_loss: 0.2886 - val_acc: 0.8678\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.2227 - acc: 0.9148 - val_loss: 0.2944 - val_acc: 0.8703\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss improved from 0.28734 to 0.28691, saving model to best_m.h5\n",
      " - 6s - loss: 0.2247 - acc: 0.9025 - val_loss: 0.2869 - val_acc: 0.8728\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2078 - acc: 0.9125 - val_loss: 0.2888 - val_acc: 0.8753\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.2161 - acc: 0.9125 - val_loss: 0.2890 - val_acc: 0.8803\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 6s - loss: 0.2095 - acc: 0.9117 - val_loss: 0.2890 - val_acc: 0.8753\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2529 - acc: 0.8985 - val_loss: 0.2933 - val_acc: 0.8703\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.2493 - acc: 0.9054 - val_loss: 0.2947 - val_acc: 0.8678\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss improved from 0.28691 to 0.28686, saving model to best_m.h5\n",
      " - 6s - loss: 0.2254 - acc: 0.9100 - val_loss: 0.2869 - val_acc: 0.8678\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss improved from 0.28686 to 0.28408, saving model to best_m.h5\n",
      " - 6s - loss: 0.2385 - acc: 0.8948 - val_loss: 0.2841 - val_acc: 0.8778\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2402 - acc: 0.8979 - val_loss: 0.2939 - val_acc: 0.8703\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.1959 - acc: 0.9117 - val_loss: 0.2895 - val_acc: 0.8653\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2022 - acc: 0.9242 - val_loss: 0.2893 - val_acc: 0.8653\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.2119 - acc: 0.9164 - val_loss: 0.2888 - val_acc: 0.8703\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.2002 - acc: 0.9192 - val_loss: 0.2881 - val_acc: 0.8703\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.2622 - acc: 0.8975 - val_loss: 0.2935 - val_acc: 0.8728\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.2153 - acc: 0.9092 - val_loss: 0.2916 - val_acc: 0.8728\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2093 - acc: 0.9179 - val_loss: 0.2903 - val_acc: 0.8579\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.2229 - acc: 0.9142 - val_loss: 0.2917 - val_acc: 0.8653\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.2121 - acc: 0.9125 - val_loss: 0.2971 - val_acc: 0.8678\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.2274 - acc: 0.9092 - val_loss: 0.2951 - val_acc: 0.8653\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 0.2079 - acc: 0.9133 - val_loss: 0.2937 - val_acc: 0.8603\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 6s - loss: 0.1818 - acc: 0.9258 - val_loss: 0.3037 - val_acc: 0.8579\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 6s - loss: 0.2083 - acc: 0.9167 - val_loss: 0.2930 - val_acc: 0.8653\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.2086 - acc: 0.9089 - val_loss: 0.2921 - val_acc: 0.8653\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.2119 - acc: 0.9164 - val_loss: 0.2936 - val_acc: 0.8728\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.1979 - acc: 0.9175 - val_loss: 0.2924 - val_acc: 0.8653\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.2197 - acc: 0.9158 - val_loss: 0.2936 - val_acc: 0.8728\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 6s - loss: 0.2200 - acc: 0.9145 - val_loss: 0.2904 - val_acc: 0.8678\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 0.2367 - acc: 0.9145 - val_loss: 0.2968 - val_acc: 0.8603\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.70982, saving model to best_m.h5\n",
      " - 31s - loss: 1.1635 - acc: 0.5786 - val_loss: 0.7098 - val_acc: 0.4589\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 6s - loss: 0.5902 - acc: 0.6614 - val_loss: 0.7868 - val_acc: 0.4589\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.5391 - acc: 0.7439 - val_loss: 0.8327 - val_acc: 0.4788\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.5008 - acc: 0.7606 - val_loss: 0.7470 - val_acc: 0.5985\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.70982 to 0.36360, saving model to best_m.h5\n",
      " - 6s - loss: 0.4321 - acc: 0.7900 - val_loss: 0.3636 - val_acc: 0.7980\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 0.36360 to 0.36237, saving model to best_m.h5\n",
      " - 6s - loss: 0.4882 - acc: 0.7837 - val_loss: 0.3624 - val_acc: 0.8229\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.36237 to 0.29472, saving model to best_m.h5\n",
      " - 6s - loss: 0.4935 - acc: 0.7489 - val_loss: 0.2947 - val_acc: 0.8404\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.4043 - acc: 0.8045 - val_loss: 0.3352 - val_acc: 0.8379\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4192 - acc: 0.8100 - val_loss: 2.2068 - val_acc: 0.5910\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.4194 - acc: 0.7981 - val_loss: 0.4781 - val_acc: 0.7855\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4328 - acc: 0.7881 - val_loss: 0.5957 - val_acc: 0.7581\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4235 - acc: 0.7906 - val_loss: 0.7910 - val_acc: 0.7057\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4076 - acc: 0.8066 - val_loss: 0.9589 - val_acc: 0.7257\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.4124 - acc: 0.7939 - val_loss: 0.6420 - val_acc: 0.7382\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3842 - acc: 0.8125 - val_loss: 0.3560 - val_acc: 0.8080\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.29472 to 0.26819, saving model to best_m.h5\n",
      " - 6s - loss: 0.3950 - acc: 0.8037 - val_loss: 0.2682 - val_acc: 0.8628\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.26819 to 0.26628, saving model to best_m.h5\n",
      " - 6s - loss: 0.3781 - acc: 0.8258 - val_loss: 0.2663 - val_acc: 0.8554\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.26628 to 0.25491, saving model to best_m.h5\n",
      " - 6s - loss: 0.3536 - acc: 0.8278 - val_loss: 0.2549 - val_acc: 0.8603\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.25491 to 0.23402, saving model to best_m.h5\n",
      " - 6s - loss: 0.3175 - acc: 0.8391 - val_loss: 0.2340 - val_acc: 0.8753\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.3155 - acc: 0.8497 - val_loss: 0.2744 - val_acc: 0.8504\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.3197 - acc: 0.8458 - val_loss: 0.3018 - val_acc: 0.8529\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.2936 - acc: 0.8750 - val_loss: 0.2345 - val_acc: 0.8828\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3268 - acc: 0.8550 - val_loss: 0.2472 - val_acc: 0.8953\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3028 - acc: 0.8733 - val_loss: 0.2524 - val_acc: 0.8853\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3203 - acc: 0.8633 - val_loss: 0.2964 - val_acc: 0.8653\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.2916 - acc: 0.8648 - val_loss: 0.2518 - val_acc: 0.8853\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3275 - acc: 0.8566 - val_loss: 0.2551 - val_acc: 0.8828\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.3202 - acc: 0.8556 - val_loss: 0.3015 - val_acc: 0.8703\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.2797 - acc: 0.8783 - val_loss: 0.2346 - val_acc: 0.9002\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.3042 - acc: 0.8531 - val_loss: 0.2471 - val_acc: 0.8903\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss improved from 0.23402 to 0.23040, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.2816 - acc: 0.8789 - val_loss: 0.2304 - val_acc: 0.8928\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.3186 - acc: 0.8576 - val_loss: 0.2951 - val_acc: 0.8828\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.3179 - acc: 0.8789 - val_loss: 0.2498 - val_acc: 0.8978\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.23040 to 0.23028, saving model to best_m.h5\n",
      " - 6s - loss: 0.2971 - acc: 0.8667 - val_loss: 0.2303 - val_acc: 0.9052\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.2806 - acc: 0.8850 - val_loss: 0.2376 - val_acc: 0.8953\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss improved from 0.23028 to 0.22254, saving model to best_m.h5\n",
      " - 6s - loss: 0.2864 - acc: 0.8850 - val_loss: 0.2225 - val_acc: 0.8903\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.3023 - acc: 0.8716 - val_loss: 0.2445 - val_acc: 0.8953\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.3045 - acc: 0.8775 - val_loss: 0.2298 - val_acc: 0.8978\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2872 - acc: 0.8750 - val_loss: 0.2564 - val_acc: 0.8828\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.2597 - acc: 0.8850 - val_loss: 0.2367 - val_acc: 0.8953\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 6s - loss: 0.2784 - acc: 0.8791 - val_loss: 0.2586 - val_acc: 0.8878\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 6s - loss: 0.2852 - acc: 0.8767 - val_loss: 0.2588 - val_acc: 0.8928\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.2614 - acc: 0.8850 - val_loss: 0.2298 - val_acc: 0.8903\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 6s - loss: 0.2823 - acc: 0.8741 - val_loss: 0.2320 - val_acc: 0.8953\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.2601 - acc: 0.8989 - val_loss: 0.2301 - val_acc: 0.8978\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 6s - loss: 0.2630 - acc: 0.8867 - val_loss: 0.2301 - val_acc: 0.8903\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 6s - loss: 0.2584 - acc: 0.8956 - val_loss: 0.2329 - val_acc: 0.8878\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.2850 - acc: 0.8822 - val_loss: 0.2428 - val_acc: 0.8928\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2573 - acc: 0.8883 - val_loss: 0.2303 - val_acc: 0.8903\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2782 - acc: 0.8728 - val_loss: 0.2332 - val_acc: 0.8928\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2592 - acc: 0.8825 - val_loss: 0.2299 - val_acc: 0.8928\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2582 - acc: 0.8892 - val_loss: 0.2291 - val_acc: 0.8903\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2474 - acc: 0.8992 - val_loss: 0.2239 - val_acc: 0.8953\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 7s - loss: 0.2801 - acc: 0.8797 - val_loss: 0.2271 - val_acc: 0.9002\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 7s - loss: 0.2767 - acc: 0.8798 - val_loss: 0.2258 - val_acc: 0.8978\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.2279 - acc: 0.8983 - val_loss: 0.2254 - val_acc: 0.9002\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.69371, saving model to best_m.h5\n",
      " - 36s - loss: 1.1587 - acc: 0.5597 - val_loss: 0.6937 - val_acc: 0.4913\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.69371 to 0.67320, saving model to best_m.h5\n",
      " - 6s - loss: 0.5877 - acc: 0.6806 - val_loss: 0.6732 - val_acc: 0.5860\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.5208 - acc: 0.7575 - val_loss: 0.8907 - val_acc: 0.5187\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 6s - loss: 0.4943 - acc: 0.7706 - val_loss: 1.0087 - val_acc: 0.5786\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.67320 to 0.42535, saving model to best_m.h5\n",
      " - 6s - loss: 0.4995 - acc: 0.7681 - val_loss: 0.4254 - val_acc: 0.7955\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.4396 - acc: 0.7995 - val_loss: 3.3001 - val_acc: 0.5511\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 6s - loss: 0.4355 - acc: 0.7797 - val_loss: 1.5872 - val_acc: 0.6259\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.42535 to 0.34302, saving model to best_m.h5\n",
      " - 6s - loss: 0.4855 - acc: 0.7747 - val_loss: 0.3430 - val_acc: 0.8603\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4674 - acc: 0.7558 - val_loss: 0.6404 - val_acc: 0.6958\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 6s - loss: 0.5301 - acc: 0.7336 - val_loss: 6.7474 - val_acc: 0.5087\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.4473 - acc: 0.8047 - val_loss: 3.7091 - val_acc: 0.5162\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4501 - acc: 0.7956 - val_loss: 0.8880 - val_acc: 0.6309\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 0.4178 - acc: 0.8012 - val_loss: 1.1298 - val_acc: 0.6334\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.4336 - acc: 0.7700 - val_loss: 0.4813 - val_acc: 0.7481\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.3986 - acc: 0.8058 - val_loss: 0.3540 - val_acc: 0.8803\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss improved from 0.34302 to 0.30805, saving model to best_m.h5\n",
      " - 6s - loss: 0.3810 - acc: 0.8281 - val_loss: 0.3080 - val_acc: 0.8603\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.30805 to 0.29192, saving model to best_m.h5\n",
      " - 6s - loss: 0.3225 - acc: 0.8250 - val_loss: 0.2919 - val_acc: 0.8678\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.29192 to 0.28244, saving model to best_m.h5\n",
      " - 6s - loss: 0.3247 - acc: 0.8378 - val_loss: 0.2824 - val_acc: 0.8903\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 6s - loss: 0.3500 - acc: 0.8381 - val_loss: 0.3084 - val_acc: 0.8678\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 6s - loss: 0.3502 - acc: 0.8425 - val_loss: 0.2931 - val_acc: 0.8928\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 6s - loss: 0.3108 - acc: 0.8550 - val_loss: 0.3005 - val_acc: 0.8554\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss improved from 0.28244 to 0.27157, saving model to best_m.h5\n",
      " - 6s - loss: 0.3240 - acc: 0.8595 - val_loss: 0.2716 - val_acc: 0.8753\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.3166 - acc: 0.8550 - val_loss: 0.3019 - val_acc: 0.8828\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.3090 - acc: 0.8758 - val_loss: 0.2839 - val_acc: 0.8728\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 6s - loss: 0.3425 - acc: 0.8531 - val_loss: 0.2905 - val_acc: 0.8778\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.3511 - acc: 0.8420 - val_loss: 0.3988 - val_acc: 0.7905\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 6s - loss: 0.3354 - acc: 0.8500 - val_loss: 0.2828 - val_acc: 0.8803\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 6s - loss: 0.3337 - acc: 0.8639 - val_loss: 0.3290 - val_acc: 0.8354\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.3159 - acc: 0.8516 - val_loss: 0.2831 - val_acc: 0.8778\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss improved from 0.27157 to 0.26358, saving model to best_m.h5\n",
      " - 6s - loss: 0.2886 - acc: 0.8806 - val_loss: 0.2636 - val_acc: 0.8778\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.2838 - acc: 0.8758 - val_loss: 0.2637 - val_acc: 0.8978\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.3096 - acc: 0.8537 - val_loss: 0.2747 - val_acc: 0.9027\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 0.2878 - acc: 0.8917 - val_loss: 0.2717 - val_acc: 0.8953\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 7s - loss: 0.2998 - acc: 0.8700 - val_loss: 0.2760 - val_acc: 0.8978\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss improved from 0.26358 to 0.26253, saving model to best_m.h5\n",
      " - 7s - loss: 0.2910 - acc: 0.8925 - val_loss: 0.2625 - val_acc: 0.9027\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 0.3001 - acc: 0.8864 - val_loss: 0.2681 - val_acc: 0.8928\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 7s - loss: 0.2694 - acc: 0.8766 - val_loss: 0.2637 - val_acc: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 6s - loss: 0.2834 - acc: 0.8783 - val_loss: 0.2717 - val_acc: 0.8878\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.2846 - acc: 0.8733 - val_loss: 0.3170 - val_acc: 0.8254\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss improved from 0.26253 to 0.26221, saving model to best_m.h5\n",
      " - 7s - loss: 0.2871 - acc: 0.8833 - val_loss: 0.2622 - val_acc: 0.8903\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 0.3134 - acc: 0.8739 - val_loss: 0.2703 - val_acc: 0.8853\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 7s - loss: 0.2810 - acc: 0.8716 - val_loss: 0.2746 - val_acc: 0.8953\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 0.2802 - acc: 0.8825 - val_loss: 0.2810 - val_acc: 0.8928\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 0.2562 - acc: 0.8892 - val_loss: 0.2811 - val_acc: 0.8853\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 7s - loss: 0.2871 - acc: 0.8712 - val_loss: 0.2951 - val_acc: 0.8728\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss improved from 0.26221 to 0.26180, saving model to best_m.h5\n",
      " - 7s - loss: 0.2633 - acc: 0.8901 - val_loss: 0.2618 - val_acc: 0.8903\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.26180 to 0.25448, saving model to best_m.h5\n",
      " - 7s - loss: 0.2537 - acc: 0.8925 - val_loss: 0.2545 - val_acc: 0.8903\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss improved from 0.25448 to 0.25387, saving model to best_m.h5\n",
      " - 7s - loss: 0.2566 - acc: 0.8841 - val_loss: 0.2539 - val_acc: 0.8928\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.2888 - acc: 0.8737 - val_loss: 0.2608 - val_acc: 0.8878\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.2532 - acc: 0.8875 - val_loss: 0.2605 - val_acc: 0.8903\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 6s - loss: 0.2451 - acc: 0.9083 - val_loss: 0.2695 - val_acc: 0.8953\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.2518 - acc: 0.8931 - val_loss: 0.2745 - val_acc: 0.8953\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 6s - loss: 0.2416 - acc: 0.8998 - val_loss: 0.2576 - val_acc: 0.8878\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 6s - loss: 0.2737 - acc: 0.8831 - val_loss: 0.2612 - val_acc: 0.8903\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 6s - loss: 0.2838 - acc: 0.8745 - val_loss: 0.2635 - val_acc: 0.8903\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 0.2539 - acc: 0.8950 - val_loss: 0.2584 - val_acc: 0.8928\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.2836 - acc: 0.8858 - val_loss: 0.2597 - val_acc: 0.8903\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 0.2650 - acc: 0.8814 - val_loss: 0.2669 - val_acc: 0.8928\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 6s - loss: 0.2526 - acc: 0.8939 - val_loss: 0.2616 - val_acc: 0.8928\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.2447 - acc: 0.8950 - val_loss: 0.2550 - val_acc: 0.8903\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 6s - loss: 0.2687 - acc: 0.8858 - val_loss: 0.2592 - val_acc: 0.8928\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 0.2604 - acc: 0.8791 - val_loss: 0.2582 - val_acc: 0.8928\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 6s - loss: 0.2547 - acc: 0.8950 - val_loss: 0.2548 - val_acc: 0.8953\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 7s - loss: 0.2862 - acc: 0.8748 - val_loss: 0.2595 - val_acc: 0.8928\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 6s - loss: 0.2697 - acc: 0.8870 - val_loss: 0.2577 - val_acc: 0.8928\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 6s - loss: 0.2816 - acc: 0.8933 - val_loss: 0.2639 - val_acc: 0.8978\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss improved from 0.25387 to 0.25277, saving model to best_m.h5\n",
      " - 7s - loss: 0.2583 - acc: 0.8900 - val_loss: 0.2528 - val_acc: 0.8953\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss improved from 0.25277 to 0.25267, saving model to best_m.h5\n",
      " - 7s - loss: 0.2265 - acc: 0.9000 - val_loss: 0.2527 - val_acc: 0.8953\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.2624 - acc: 0.8917 - val_loss: 0.2611 - val_acc: 0.8953\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss improved from 0.25267 to 0.25252, saving model to best_m.h5\n",
      " - 8s - loss: 0.2350 - acc: 0.8966 - val_loss: 0.2525 - val_acc: 0.8953\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 7s - loss: 0.2611 - acc: 0.8858 - val_loss: 0.2563 - val_acc: 0.8978\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 6s - loss: 0.2505 - acc: 0.8992 - val_loss: 0.2553 - val_acc: 0.8953\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.2688 - acc: 0.8758 - val_loss: 0.2570 - val_acc: 0.8953\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 7s - loss: 0.2981 - acc: 0.8924 - val_loss: 0.2544 - val_acc: 0.8953\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 6s - loss: 0.2432 - acc: 0.8967 - val_loss: 0.2600 - val_acc: 0.8953\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.2445 - acc: 0.9000 - val_loss: 0.2544 - val_acc: 0.8953\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.2518 - acc: 0.8889 - val_loss: 0.2614 - val_acc: 0.8978\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.2676 - acc: 0.8814 - val_loss: 0.2565 - val_acc: 0.8928\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 6s - loss: 0.2321 - acc: 0.8983 - val_loss: 0.2565 - val_acc: 0.8978\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.2432 - acc: 0.8973 - val_loss: 0.2560 - val_acc: 0.8978\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.2617 - acc: 0.8989 - val_loss: 0.2556 - val_acc: 0.9002\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.2604 - acc: 0.8829 - val_loss: 0.2592 - val_acc: 0.8928\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.2469 - acc: 0.9025 - val_loss: 0.2555 - val_acc: 0.8928\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss improved from 0.25252 to 0.24804, saving model to best_m.h5\n",
      " - 7s - loss: 0.2545 - acc: 0.8873 - val_loss: 0.2480 - val_acc: 0.9002\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 7s - loss: 0.2561 - acc: 0.9012 - val_loss: 0.2790 - val_acc: 0.8803\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.2720 - acc: 0.8814 - val_loss: 0.2546 - val_acc: 0.8928\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 0.2599 - acc: 0.8814 - val_loss: 0.2528 - val_acc: 0.8953\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 6s - loss: 0.2504 - acc: 0.8875 - val_loss: 0.2577 - val_acc: 0.8878\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 7s - loss: 0.2329 - acc: 0.9100 - val_loss: 0.2531 - val_acc: 0.8928\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 0.2430 - acc: 0.8992 - val_loss: 0.2576 - val_acc: 0.8878\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.2505 - acc: 0.9042 - val_loss: 0.2512 - val_acc: 0.8978\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 6s - loss: 0.2542 - acc: 0.8981 - val_loss: 0.2556 - val_acc: 0.9002\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.2409 - acc: 0.8950 - val_loss: 0.2606 - val_acc: 0.8878\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 6s - loss: 0.2759 - acc: 0.8850 - val_loss: 0.2592 - val_acc: 0.8978\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 0.2320 - acc: 0.9008 - val_loss: 0.2635 - val_acc: 0.8878\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 6s - loss: 0.2211 - acc: 0.9067 - val_loss: 0.2488 - val_acc: 0.8953\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 6s - loss: 0.2462 - acc: 0.9006 - val_loss: 0.2517 - val_acc: 0.8953\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 6s - loss: 0.2588 - acc: 0.8892 - val_loss: 0.2574 - val_acc: 0.8903\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 6s - loss: 0.2426 - acc: 0.8983 - val_loss: 0.2525 - val_acc: 0.8953\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 7s - loss: 0.2449 - acc: 0.8933 - val_loss: 0.2646 - val_acc: 0.8878\n",
      "============================\n",
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 0.71167, saving model to best_m.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 42s - loss: 1.2354 - acc: 0.5180 - val_loss: 0.7117 - val_acc: 0.4613\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 0.71167 to 0.69429, saving model to best_m.h5\n",
      " - 6s - loss: 0.6537 - acc: 0.5964 - val_loss: 0.6943 - val_acc: 0.4613\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 6s - loss: 0.6025 - acc: 0.6633 - val_loss: 0.6968 - val_acc: 0.4738\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 0.69429 to 0.66185, saving model to best_m.h5\n",
      " - 6s - loss: 0.5534 - acc: 0.7414 - val_loss: 0.6618 - val_acc: 0.6010\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 0.66185 to 0.46065, saving model to best_m.h5\n",
      " - 6s - loss: 0.5624 - acc: 0.7408 - val_loss: 0.4607 - val_acc: 0.8055\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 6s - loss: 0.5574 - acc: 0.7458 - val_loss: 0.5943 - val_acc: 0.7631\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss improved from 0.46065 to 0.38712, saving model to best_m.h5\n",
      " - 6s - loss: 0.4911 - acc: 0.7775 - val_loss: 0.3871 - val_acc: 0.8279\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 6s - loss: 0.5289 - acc: 0.7508 - val_loss: 0.4099 - val_acc: 0.8379\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 0.4903 - acc: 0.7781 - val_loss: 0.5532 - val_acc: 0.7980\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 7s - loss: 0.5527 - acc: 0.7325 - val_loss: 0.4106 - val_acc: 0.8529\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 6s - loss: 0.5624 - acc: 0.7273 - val_loss: 0.6396 - val_acc: 0.7905\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 6s - loss: 0.4809 - acc: 0.7941 - val_loss: 0.4349 - val_acc: 0.8329\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 6s - loss: 0.4682 - acc: 0.8058 - val_loss: 0.5024 - val_acc: 0.8229\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 6s - loss: 0.5775 - acc: 0.7322 - val_loss: 2.8626 - val_acc: 0.5436\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 0.5355 - acc: 0.7650 - val_loss: 0.5556 - val_acc: 0.8155\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 6s - loss: 0.4911 - acc: 0.7911 - val_loss: 0.4036 - val_acc: 0.8329\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss improved from 0.38712 to 0.35557, saving model to best_m.h5\n",
      " - 6s - loss: 0.5084 - acc: 0.7837 - val_loss: 0.3556 - val_acc: 0.8703\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss improved from 0.35557 to 0.34367, saving model to best_m.h5\n",
      " - 6s - loss: 0.4523 - acc: 0.8056 - val_loss: 0.3437 - val_acc: 0.8703\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss improved from 0.34367 to 0.33799, saving model to best_m.h5\n",
      " - 7s - loss: 0.4431 - acc: 0.8072 - val_loss: 0.3380 - val_acc: 0.8828\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss improved from 0.33799 to 0.33007, saving model to best_m.h5\n",
      " - 6s - loss: 0.4526 - acc: 0.8158 - val_loss: 0.3301 - val_acc: 0.8853\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss improved from 0.33007 to 0.32729, saving model to best_m.h5\n",
      " - 6s - loss: 0.4170 - acc: 0.8250 - val_loss: 0.3273 - val_acc: 0.8903\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 6s - loss: 0.4127 - acc: 0.8375 - val_loss: 0.3335 - val_acc: 0.8853\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 6s - loss: 0.4637 - acc: 0.8103 - val_loss: 0.3314 - val_acc: 0.8828\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 6s - loss: 0.4141 - acc: 0.8306 - val_loss: 0.3524 - val_acc: 0.8753\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 7s - loss: 0.4196 - acc: 0.8358 - val_loss: 0.3801 - val_acc: 0.8653\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 6s - loss: 0.4259 - acc: 0.8275 - val_loss: 0.3332 - val_acc: 0.8903\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss improved from 0.32729 to 0.32431, saving model to best_m.h5\n",
      " - 7s - loss: 0.4056 - acc: 0.8375 - val_loss: 0.3243 - val_acc: 0.8803\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss improved from 0.32431 to 0.32356, saving model to best_m.h5\n",
      " - 6s - loss: 0.3947 - acc: 0.8343 - val_loss: 0.3236 - val_acc: 0.8803\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 6s - loss: 0.4102 - acc: 0.8267 - val_loss: 0.3370 - val_acc: 0.8678\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 6s - loss: 0.3923 - acc: 0.8406 - val_loss: 0.3477 - val_acc: 0.8653\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 6s - loss: 0.4459 - acc: 0.8233 - val_loss: 0.3269 - val_acc: 0.8678\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 6s - loss: 0.3892 - acc: 0.8309 - val_loss: 0.3299 - val_acc: 0.8678\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 6s - loss: 0.4058 - acc: 0.8331 - val_loss: 0.3437 - val_acc: 0.8803\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss improved from 0.32356 to 0.31930, saving model to best_m.h5\n",
      " - 6s - loss: 0.3944 - acc: 0.8325 - val_loss: 0.3193 - val_acc: 0.8828\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 6s - loss: 0.3786 - acc: 0.8453 - val_loss: 0.3235 - val_acc: 0.8603\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 6s - loss: 0.4039 - acc: 0.8450 - val_loss: 0.3281 - val_acc: 0.8903\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 6s - loss: 0.3878 - acc: 0.8341 - val_loss: 0.3226 - val_acc: 0.8778\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss improved from 0.31930 to 0.31767, saving model to best_m.h5\n",
      " - 6s - loss: 0.3842 - acc: 0.8414 - val_loss: 0.3177 - val_acc: 0.8853\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 6s - loss: 0.3970 - acc: 0.8358 - val_loss: 0.3276 - val_acc: 0.8903\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 6s - loss: 0.3848 - acc: 0.8439 - val_loss: 0.3395 - val_acc: 0.8928\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss improved from 0.31767 to 0.30413, saving model to best_m.h5\n",
      " - 6s - loss: 0.3909 - acc: 0.8375 - val_loss: 0.3041 - val_acc: 0.8903\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss improved from 0.30413 to 0.29683, saving model to best_m.h5\n",
      " - 6s - loss: 0.3319 - acc: 0.8650 - val_loss: 0.2968 - val_acc: 0.8928\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 6s - loss: 0.3742 - acc: 0.8489 - val_loss: 0.3637 - val_acc: 0.8529\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss improved from 0.29683 to 0.29002, saving model to best_m.h5\n",
      " - 6s - loss: 0.3634 - acc: 0.8467 - val_loss: 0.2900 - val_acc: 0.8928\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 0.3666 - acc: 0.8618 - val_loss: 0.3612 - val_acc: 0.8603\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 7s - loss: 0.3753 - acc: 0.8433 - val_loss: 0.2962 - val_acc: 0.9002\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss improved from 0.29002 to 0.28553, saving model to best_m.h5\n",
      " - 6s - loss: 0.3432 - acc: 0.8633 - val_loss: 0.2855 - val_acc: 0.8978\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 0.3780 - acc: 0.8468 - val_loss: 0.2961 - val_acc: 0.9027\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 0.3383 - acc: 0.8650 - val_loss: 0.2875 - val_acc: 0.8978\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 6s - loss: 0.3736 - acc: 0.8509 - val_loss: 0.2899 - val_acc: 0.8878\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss improved from 0.28553 to 0.28166, saving model to best_m.h5\n",
      " - 6s - loss: 0.3280 - acc: 0.8683 - val_loss: 0.2817 - val_acc: 0.8953\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 6s - loss: 0.3355 - acc: 0.8706 - val_loss: 0.2841 - val_acc: 0.8878\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss improved from 0.28166 to 0.28047, saving model to best_m.h5\n",
      " - 6s - loss: 0.3474 - acc: 0.8658 - val_loss: 0.2805 - val_acc: 0.8978\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss improved from 0.28047 to 0.27743, saving model to best_m.h5\n",
      " - 6s - loss: 0.3007 - acc: 0.8766 - val_loss: 0.2774 - val_acc: 0.8953\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss improved from 0.27743 to 0.27362, saving model to best_m.h5\n",
      " - 7s - loss: 0.3381 - acc: 0.8625 - val_loss: 0.2736 - val_acc: 0.8953\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 6s - loss: 0.3211 - acc: 0.8741 - val_loss: 0.2737 - val_acc: 0.9052\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 6s - loss: 0.3429 - acc: 0.8622 - val_loss: 0.2744 - val_acc: 0.9052\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss improved from 0.27362 to 0.27038, saving model to best_m.h5\n",
      " - 7s - loss: 0.3301 - acc: 0.8650 - val_loss: 0.2704 - val_acc: 0.8978\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 7s - loss: 0.3416 - acc: 0.8717 - val_loss: 0.2732 - val_acc: 0.9077\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 0.3473 - acc: 0.8697 - val_loss: 0.2771 - val_acc: 0.9027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 0.3465 - acc: 0.8658 - val_loss: 0.2763 - val_acc: 0.9077\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 7s - loss: 0.3201 - acc: 0.8770 - val_loss: 0.2797 - val_acc: 0.9052\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 8s - loss: 0.3369 - acc: 0.8689 - val_loss: 0.2787 - val_acc: 0.9052\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 6s - loss: 0.3377 - acc: 0.8691 - val_loss: 0.2817 - val_acc: 0.9102\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 0.3540 - acc: 0.8641 - val_loss: 0.2754 - val_acc: 0.8903\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 0.3371 - acc: 0.8723 - val_loss: 0.2783 - val_acc: 0.9077\n",
      "Epoch 67/100\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 6s - loss: 0.3187 - acc: 0.8816 - val_loss: 0.2791 - val_acc: 0.9027\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 6s - loss: 0.3217 - acc: 0.8775 - val_loss: 0.2757 - val_acc: 0.8953\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 6s - loss: 0.3371 - acc: 0.8623 - val_loss: 0.2720 - val_acc: 0.9027\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 6s - loss: 0.3336 - acc: 0.8650 - val_loss: 0.2733 - val_acc: 0.9027\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss improved from 0.27038 to 0.26760, saving model to best_m.h5\n",
      " - 6s - loss: 0.3282 - acc: 0.8741 - val_loss: 0.2676 - val_acc: 0.9102\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss improved from 0.26760 to 0.26672, saving model to best_m.h5\n",
      " - 7s - loss: 0.3295 - acc: 0.8537 - val_loss: 0.2667 - val_acc: 0.9027\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 6s - loss: 0.3267 - acc: 0.8748 - val_loss: 0.2692 - val_acc: 0.9102\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss improved from 0.26672 to 0.26501, saving model to best_m.h5\n",
      " - 6s - loss: 0.3108 - acc: 0.8825 - val_loss: 0.2650 - val_acc: 0.9127\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss improved from 0.26501 to 0.26492, saving model to best_m.h5\n",
      " - 6s - loss: 0.3395 - acc: 0.8739 - val_loss: 0.2649 - val_acc: 0.9052\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 6s - loss: 0.3066 - acc: 0.8841 - val_loss: 0.2686 - val_acc: 0.9027\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 6s - loss: 0.3213 - acc: 0.8833 - val_loss: 0.2691 - val_acc: 0.9002\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 6s - loss: 0.3075 - acc: 0.8750 - val_loss: 0.2682 - val_acc: 0.9102\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss improved from 0.26492 to 0.26286, saving model to best_m.h5\n",
      " - 6s - loss: 0.3110 - acc: 0.8808 - val_loss: 0.2629 - val_acc: 0.9102\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 6s - loss: 0.3172 - acc: 0.8725 - val_loss: 0.2641 - val_acc: 0.9102\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 6s - loss: 0.3181 - acc: 0.8783 - val_loss: 0.2635 - val_acc: 0.9102\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 6s - loss: 0.3263 - acc: 0.8747 - val_loss: 0.2638 - val_acc: 0.9077\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 0.3178 - acc: 0.8789 - val_loss: 0.2648 - val_acc: 0.9077\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 6s - loss: 0.3220 - acc: 0.8723 - val_loss: 0.2687 - val_acc: 0.9052\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 6s - loss: 0.3429 - acc: 0.8606 - val_loss: 0.2736 - val_acc: 0.9152\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 6s - loss: 0.3284 - acc: 0.8635 - val_loss: 0.2671 - val_acc: 0.9027\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss improved from 0.26286 to 0.26139, saving model to best_m.h5\n",
      " - 7s - loss: 0.3178 - acc: 0.8798 - val_loss: 0.2614 - val_acc: 0.9027\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss improved from 0.26139 to 0.25856, saving model to best_m.h5\n",
      " - 6s - loss: 0.3204 - acc: 0.8691 - val_loss: 0.2586 - val_acc: 0.9077\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss improved from 0.25856 to 0.25681, saving model to best_m.h5\n",
      " - 6s - loss: 0.2984 - acc: 0.8741 - val_loss: 0.2568 - val_acc: 0.9127\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 6s - loss: 0.3031 - acc: 0.8883 - val_loss: 0.2603 - val_acc: 0.9027\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 6s - loss: 0.3046 - acc: 0.8808 - val_loss: 0.2584 - val_acc: 0.9052\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss improved from 0.25681 to 0.25607, saving model to best_m.h5\n",
      " - 6s - loss: 0.3102 - acc: 0.8867 - val_loss: 0.2561 - val_acc: 0.9127\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 6s - loss: 0.3078 - acc: 0.8731 - val_loss: 0.2610 - val_acc: 0.9152\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 6s - loss: 0.3099 - acc: 0.8808 - val_loss: 0.2613 - val_acc: 0.9127\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 0.3075 - acc: 0.8708 - val_loss: 0.2580 - val_acc: 0.9052\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss improved from 0.25607 to 0.25594, saving model to best_m.h5\n",
      " - 6s - loss: 0.2972 - acc: 0.8833 - val_loss: 0.2559 - val_acc: 0.9027\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 6s - loss: 0.3051 - acc: 0.8766 - val_loss: 0.2561 - val_acc: 0.9027\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss improved from 0.25594 to 0.25393, saving model to best_m.h5\n",
      " - 6s - loss: 0.3138 - acc: 0.8825 - val_loss: 0.2539 - val_acc: 0.9077\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss improved from 0.25393 to 0.25017, saving model to best_m.h5\n",
      " - 6s - loss: 0.3028 - acc: 0.8825 - val_loss: 0.2502 - val_acc: 0.9127\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 6s - loss: 0.3283 - acc: 0.8839 - val_loss: 0.2520 - val_acc: 0.9052\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def kfold_train(fold_cnt=3,rnd=9):\n",
    "    train_pred, test_pred = np.zeros((1604,1)),np.zeros((8424,1))\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=True, random_state=2*rnd)\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        curr_x,curr_y = train_x[train_index],y[train_index]\n",
    "        val_x,val_y = train_x[test_index],y[test_index]\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        bat_size = 16\n",
    "        steps_train = len(curr_y)//bat_size\n",
    "        \n",
    "        \n",
    "        model = create_resnet_model()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "        model_p = 'best_m.h5'\n",
    "        model_chk = ModelCheckpoint(filepath=model_p, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        lr_s = LearningRateScheduler(lr_f)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 0, mode= 'min')\n",
    "        model.fit_generator(datagen.flow(curr_x, curr_y, batch_size=bat_size),\n",
    "                  validation_data=(val_x,val_y),\n",
    "                  steps_per_epoch = steps_train,\n",
    "                  epochs=100, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk,lr_s,early_stopping]\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        model = load_model(model_p)\n",
    "        train_pred[test_index] = model.predict(val_x)\n",
    "        test_pred = test_pred + model.predict(test_x)/fold_cnt\n",
    "        print('============================')\n",
    "    return train_pred,test_pred\n",
    "\n",
    "train_pred,test_pred = kfold_train(fold_cnt=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.251204758324\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.277818\n",
      "1  4023181e    0.474198\n",
      "2  b20200e4    0.000770\n",
      "3  e7f018bb    0.936852\n",
      "4  4371c8c3    0.030654\n"
     ]
    }
   ],
   "source": [
    "with open('../features/resnet_aug3_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "\n",
    "# train feat loss\n",
    "print(log_loss(y,train_pred))\n",
    "    \n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_df['id']\n",
    "submission['is_iceberg']=test_pred\n",
    "print(submission.head())\n",
    "submission.to_csv('../results/resnet_aug3_sub.csv', index=False)\n",
    "# deep2 0.227\n",
    "# deep3 0.223\n",
    "# deep3 new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

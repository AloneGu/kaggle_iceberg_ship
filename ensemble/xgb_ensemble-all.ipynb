{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../features/cnn_1_aug1_feat.pkl',\n",
      "'../features/cnn_1_aug_1_fold8_feat.pkl',\n",
      "'../features/cnn_1_aug_rescale_preprocess_feat.pkl',\n",
      "'../features/cnn_1_aug_skimage_denoise_feat.pkl',\n",
      "'../features/cnn_1_aug_skimage_preprocess_feat.pkl',\n",
      "'../features/cnn_1_feat.pkl',\n",
      "'../features/cnn_2_aug1_feat.pkl',\n",
      "'../features/cnn_2_aug_1_fold8_feat.pkl',\n",
      "'../features/cnn_2_aug_denoise_preprocess_feat.pkl',\n",
      "'../features/cnn_2_aug_rescale_preprocess_feat.pkl',\n",
      "'../features/cnn_2_aug_skimage_preprocess_feat.pkl',\n",
      "'../features/cnn_2_feat.pkl',\n",
      "'../features/cnn_3_aug1_feat.pkl',\n",
      "'../features/cnn_3_aug_1_fold8_feat.pkl',\n",
      "'../features/cnn_3_aug_denoise_preprocess_feat.pkl',\n",
      "'../features/cnn_3_aug_rescale_preprocess_feat.pkl',\n",
      "'../features/cnn_3_aug_skimage_preprocess_feat.pkl',\n",
      "'../features/cnn_4_aug1_feat.pkl',\n",
      "'../features/cnn_4_aug1_feat_add_early.pkl',\n",
      "'../features/cnn_4_aug_1_fold8_feat.pkl',\n",
      "'../features/cnn_4_aug_denoise_preprocess_feat.pkl',\n",
      "'../features/cnn_4_aug_rescale_preprocess_feat.pkl',\n",
      "'../features/cnn_4_aug_skimage_preprocess_feat.pkl',\n",
      "'../features/cnn_5_aug1_feat.pkl',\n",
      "'../features/cnn_5_aug_1_fold8_feat.pkl',\n",
      "'../features/cnn_5_aug_denoise_preprocess_feat.pkl',\n",
      "'../features/cnn_5_aug_rescale_preprocess_feat.pkl',\n",
      "'../features/cnn_5_aug_skimage_preprocess_feat.pkl',\n",
      "'../features/incept_1_feat.pkl',\n",
      "'../features/incept_aug1_feat.pkl',\n",
      "'../features/incept_aug1_fold8_feat.pkl',\n",
      "'../features/incept_aug2_feat.pkl',\n",
      "'../features/incept_aug3_feat.pkl',\n",
      "'../features/incept_aug4_feat.pkl',\n",
      "'../features/other_feat.pkl',\n",
      "'../features/other_model_gbrt.pkl',\n",
      "'../features/other_model_gbrt2.pkl',\n",
      "'../features/other_model_gbrt4.pkl',\n",
      "'../features/other_model_gbrt5.pkl',\n",
      "'../features/other_model_gbrt6.pkl',\n",
      "'../features/other_model_gbrt8.pkl',\n",
      "'../features/other_model_lgb.pkl',\n",
      "'../features/other_model_lgb2.pkl',\n",
      "'../features/other_model_lgb4.pkl',\n",
      "'../features/other_model_lgb5.pkl',\n",
      "'../features/other_model_lgb6.pkl',\n",
      "'../features/other_model_lgb8.pkl',\n",
      "'../features/other_model_lr.pkl',\n",
      "'../features/other_model_lr2.pkl',\n",
      "'../features/other_model_lr4.pkl',\n",
      "'../features/other_model_lr5.pkl',\n",
      "'../features/other_model_lr6.pkl',\n",
      "'../features/other_model_lr8.pkl',\n",
      "'../features/other_model_rf.pkl',\n",
      "'../features/other_model_rf2.pkl',\n",
      "'../features/other_model_rf4.pkl',\n",
      "'../features/other_model_rf5.pkl',\n",
      "'../features/other_model_rf6.pkl',\n",
      "'../features/other_model_rf8.pkl',\n",
      "'../features/other_model_xgb.pkl',\n",
      "'../features/other_model_xgb2.pkl',\n",
      "'../features/other_model_xgb4.pkl',\n",
      "'../features/other_model_xgb5.pkl',\n",
      "'../features/other_model_xgb6.pkl',\n",
      "'../features/other_model_xgb8.pkl',\n",
      "'../features/resnet_1_feat.pkl',\n",
      "'../features/resnet_aug1_feat.pkl',\n",
      "'../features/resnet_aug1_fold8_feat.pkl',\n",
      "'../features/resnet_aug2_feat.pkl',\n",
      "'../features/resnet_aug3_feat.pkl',\n",
      "'../features/resnet_aug4_feat.pkl',\n",
      "'../features/vgg16_1_feat.pkl',\n",
      "'../features/vgg_aug1_feat.pkl',\n",
      "'../features/vgg_aug1_fold8_feat.pkl',\n",
      "'../features/vgg_aug1_new_feat.pkl',\n",
      "'../features/xception_aug1_feat.pkl',\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "fl = list(glob.glob('../features/*.pkl'))\n",
    "for l in sorted(fl):\n",
    "    print(\"'{}',\".format(l))\n",
    "    \n",
    "# no other feat7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 86) (8424, 86) (1604,)\n"
     ]
    }
   ],
   "source": [
    "def load_x_y():\n",
    "    train_x,test_x=[],[]\n",
    "    for f in fl:\n",
    "        with open(f,'rb') as fin:\n",
    "            a,b = pickle.load(fin)\n",
    "            train_x.append(a)\n",
    "            test_x.append(b)\n",
    "    train_x = np.hstack(train_x)\n",
    "    test_x = np.hstack(test_x)\n",
    "    train_df = pd.read_json('../input/train.json')\n",
    "    y = train_df.is_iceberg.values\n",
    "    return train_x,test_x,y\n",
    "\n",
    "train_x,test_x,train_y = load_x_y()\n",
    "print(train_x.shape,test_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "def cv_test(k_cnt=3,rnd=42,save_flag=False,verbose_cnt=False):\n",
    "    kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd*2)\n",
    "    w_test_pred = None\n",
    "    r_val_loss = 0\n",
    "    test_pred = None\n",
    "    val_loss = 0\n",
    "    val_loss_list = []\n",
    "    for train_index, test_index in kf.split(train_x,train_y):\n",
    "        X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "        y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "        params = {\n",
    "                'colsample_bytree': 0.75,\n",
    "                'colsample_bylevel':0.95,\n",
    "                'gamma':0.2,\n",
    "                'subsample': 0.9,\n",
    "                'eta': 0.07,\n",
    "                'max_depth': 3,\n",
    "                'eval_metric':'logloss',\n",
    "                'objective':'binary:logistic',\n",
    "                'scale_pos_weight': 0.85,\n",
    "                \n",
    "                }\n",
    "        \n",
    "        # def mat\n",
    "        d_train = xgb.DMatrix(X_train, y_train)\n",
    "        d_valid = xgb.DMatrix(X_test, y_test)\n",
    "        d_test = xgb.DMatrix(test_x)\n",
    "        \n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        # train model\n",
    "        m = xgb.train(params, d_train, 500, watchlist, \n",
    "                        early_stopping_rounds=20,\n",
    "                        verbose_eval=verbose_cnt\n",
    "                        )\n",
    "        \n",
    "        # cal val loss\n",
    "        curr_val_loss = log_loss(y_test,m.predict(d_valid))\n",
    "        val_loss += curr_val_loss/k_cnt\n",
    "        val_loss_list.append(curr_val_loss)\n",
    "        curr_r_val_loss = 1.0 / curr_val_loss\n",
    "        r_val_loss += curr_r_val_loss\n",
    "        \n",
    "        if test_pred is None:\n",
    "            test_pred = m.predict(d_test)\n",
    "            w_test_pred = m.predict(d_test)*curr_r_val_loss\n",
    "        else:\n",
    "            curr_pred = m.predict(d_test)\n",
    "            test_pred += curr_pred\n",
    "            w_test_pred = w_test_pred + curr_pred*curr_r_val_loss\n",
    "\n",
    "    # avg\n",
    "    test_pred = test_pred / k_cnt\n",
    "    w_test_pred = w_test_pred / r_val_loss\n",
    "    \n",
    "    # train log loss\n",
    "    print('local average valid loss',val_loss,'val loss std',np.std(val_loss_list))\n",
    "    if save_flag:\n",
    "        test_df=pd.read_json('../input/test.json')\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test_df['id']\n",
    "        submission['is_iceberg']=test_pred\n",
    "        print(submission.head())\n",
    "        submission.to_csv('../results/all_xgb_sub_fold_{}_rnd_{}.csv'.format(k_cnt,rnd), index=False)\n",
    "        \n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test_df['id']\n",
    "        submission['is_iceberg']=w_test_pred\n",
    "        print(submission.head())\n",
    "        submission.to_csv('../results/weighted_all_xgb_sub_fold_{}_rnd_{}.csv'.format(k_cnt,rnd), index=False)\n",
    "\n",
    "    \n",
    "print('def done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find new rnd seed\n",
    "# for i in range(50):\n",
    "#     rnd = i*6\n",
    "#     print(rnd)\n",
    "#     cv_test(3,rnd,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find new rnd seed\n",
    "# for i in range(50):\n",
    "#     rnd = i*6\n",
    "#     print(rnd)\n",
    "#     cv_test(5,rnd,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.637147\tvalid-logloss:0.63954\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[123]\ttrain-logloss:0.036986\tvalid-logloss:0.127287\n",
      "\n",
      "[0]\ttrain-logloss:0.635534\tvalid-logloss:0.639735\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-logloss:0.041284\tvalid-logloss:0.140757\n",
      "\n",
      "[0]\ttrain-logloss:0.636413\tvalid-logloss:0.639591\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-logloss:0.046686\tvalid-logloss:0.147803\n",
      "\n",
      "local average valid loss 0.14003944576 val loss std 0.00959489791972\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.021510\n",
      "1  4023181e    0.724113\n",
      "2  b20200e4    0.032388\n",
      "3  e7f018bb    0.998013\n",
      "4  4371c8c3    0.157347\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.021322\n",
      "1  4023181e    0.716055\n",
      "2  b20200e4    0.030673\n",
      "3  e7f018bb    0.998042\n",
      "4  4371c8c3    0.157059\n"
     ]
    }
   ],
   "source": [
    "cv_test(3,42,True,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.637027\tvalid-logloss:0.639504\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-logloss:0.040365\tvalid-logloss:0.126506\n",
      "\n",
      "[0]\ttrain-logloss:0.635987\tvalid-logloss:0.638127\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-logloss:0.065923\tvalid-logloss:0.141593\n",
      "\n",
      "[0]\ttrain-logloss:0.635454\tvalid-logloss:0.641236\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-logloss:0.046232\tvalid-logloss:0.143883\n",
      "\n",
      "local average valid loss 0.139547295911 val loss std 0.00780115677448\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.028872\n",
      "1  4023181e    0.572236\n",
      "2  b20200e4    0.021871\n",
      "3  e7f018bb    0.997321\n",
      "4  4371c8c3    0.279149\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.029119\n",
      "1  4023181e    0.575447\n",
      "2  b20200e4    0.021783\n",
      "3  e7f018bb    0.997356\n",
      "4  4371c8c3    0.282570\n"
     ]
    }
   ],
   "source": [
    "cv_test(3,252,True,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.636709\tvalid-logloss:0.639726\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[155]\ttrain-logloss:0.03104\tvalid-logloss:0.117334\n",
      "\n",
      "[0]\ttrain-logloss:0.635561\tvalid-logloss:0.640207\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[95]\ttrain-logloss:0.051572\tvalid-logloss:0.15276\n",
      "\n",
      "[0]\ttrain-logloss:0.636661\tvalid-logloss:0.637856\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-logloss:0.06601\tvalid-logloss:0.12872\n",
      "\n",
      "[0]\ttrain-logloss:0.636992\tvalid-logloss:0.64087\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-logloss:0.028613\tvalid-logloss:0.13391\n",
      "\n",
      "[0]\ttrain-logloss:0.637428\tvalid-logloss:0.638905\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-logloss:0.058229\tvalid-logloss:0.119033\n",
      "\n",
      "local average valid loss 0.131828416642 val loss std 0.0130252259898\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.031997\n",
      "1  4023181e    0.654893\n",
      "2  b20200e4    0.026820\n",
      "3  e7f018bb    0.997791\n",
      "4  4371c8c3    0.135929\n",
      "         id  is_iceberg\n",
      "0  5941774d    0.032569\n",
      "1  4023181e    0.648153\n",
      "2  b20200e4    0.027059\n",
      "3  e7f018bb    0.997815\n",
      "4  4371c8c3    0.138285\n"
     ]
    }
   ],
   "source": [
    "cv_test(5,66,True,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
